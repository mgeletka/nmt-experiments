2021-03-14 09:34:01 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_vaswani_wmt_en_de_big', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/czeng_bpe32000/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=True, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=10, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0009], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=3584, max_tokens_valid=3584, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints_czeng2_en_cs', save_interval=1, save_interval_updates=5000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir='tensorboard_czeng2', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[16], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid,valid1', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2021-03-14 09:34:01 | INFO | fairseq.tasks.translation | [en] dictionary: 32768 types
2021-03-14 09:34:01 | INFO | fairseq.tasks.translation | [cs] dictionary: 32768 types
2021-03-14 09:34:01 | INFO | fairseq.data.data_utils | loaded 2983 examples from: data-bin/czeng_bpe32000/valid.en-cs.en
2021-03-14 09:34:01 | INFO | fairseq.data.data_utils | loaded 2983 examples from: data-bin/czeng_bpe32000/valid.en-cs.cs
2021-03-14 09:34:01 | INFO | fairseq.tasks.translation | data-bin/czeng_bpe32000/ valid en-cs 2983 examples
2021-03-14 09:34:01 | INFO | fairseq.data.data_utils | loaded 10000 examples from: data-bin/czeng_bpe32000/valid1.en-cs.en
2021-03-14 09:34:01 | INFO | fairseq.data.data_utils | loaded 10000 examples from: data-bin/czeng_bpe32000/valid1.en-cs.cs
2021-03-14 09:34:01 | INFO | fairseq.tasks.translation | data-bin/czeng_bpe32000/ valid1 en-cs 10000 examples
2021-03-14 09:34:03 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32768, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32768, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=32768, bias=False)
  )
)
2021-03-14 09:34:03 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2021-03-14 09:34:03 | INFO | fairseq_cli.train | model: transformer_vaswani_wmt_en_de_big (TransformerModel)
2021-03-14 09:34:03 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2021-03-14 09:34:03 | INFO | fairseq_cli.train | num. model params: 209911808 (num. trained: 209911808)
2021-03-14 09:34:04 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-03-14 09:34:04 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-03-14 09:34:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-03-14 09:34:04 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = GeForce RTX 3090                        
2021-03-14 09:34:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-03-14 09:34:04 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-03-14 09:34:04 | INFO | fairseq_cli.train | max tokens per GPU = 3584 and max sentences per GPU = None
2021-03-14 09:34:04 | INFO | fairseq.trainer | no existing checkpoint found checkpoints_czeng2_en_cs/checkpoint_last.pt
2021-03-14 09:34:04 | INFO | fairseq.trainer | loading train data for epoch 1
2021-03-14 09:34:05 | INFO | fairseq.data.data_utils | loaded 60980645 examples from: data-bin/czeng_bpe32000/train.en-cs.en
2021-03-14 09:34:06 | INFO | fairseq.data.data_utils | loaded 60980645 examples from: data-bin/czeng_bpe32000/train.en-cs.cs
2021-03-14 09:34:06 | INFO | fairseq.tasks.translation | data-bin/czeng_bpe32000/ train en-cs 60980645 examples
2021-03-14 09:34:44 | INFO | fairseq.trainer | begin training epoch 1
2021-03-14 09:34:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2021-03-14 09:34:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2021-03-14 09:34:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2021-03-14 09:34:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-14 09:35:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-14 09:37:58 | INFO | train_inner | epoch 001:    105 / 20258 loss=13.575, nll_loss=13.32, ppl=10224.6, wps=27717.2, ups=0.54, wpb=51009.4, bsz=2927.1, num_updates=100, lr=2.25975e-05, gnorm=2.407, loss_scale=4, train_wall=181, wall=234
2021-03-14 09:41:01 | INFO | train_inner | epoch 001:    205 / 20258 loss=11.778, nll_loss=11.279, ppl=2484.49, wps=27776.8, ups=0.55, wpb=50887.2, bsz=3050.2, num_updates=200, lr=4.5095e-05, gnorm=1.723, loss_scale=4, train_wall=180, wall=417
2021-03-14 09:44:04 | INFO | train_inner | epoch 001:    305 / 20258 loss=11.207, nll_loss=10.59, ppl=1541.74, wps=27807.9, ups=0.55, wpb=50838.4, bsz=2957.7, num_updates=300, lr=6.75925e-05, gnorm=1.455, loss_scale=4, train_wall=180, wall=600
2021-03-14 09:47:07 | INFO | train_inner | epoch 001:    405 / 20258 loss=10.76, nll_loss=10.069, ppl=1073.89, wps=27662.9, ups=0.55, wpb=50643.1, bsz=3066.2, num_updates=400, lr=9.009e-05, gnorm=1.472, loss_scale=4, train_wall=180, wall=783
2021-03-14 09:50:11 | INFO | train_inner | epoch 001:    505 / 20258 loss=10.367, nll_loss=9.608, ppl=780.23, wps=27753.4, ups=0.54, wpb=50941.9, bsz=3054.6, num_updates=500, lr=0.000112588, gnorm=1.39, loss_scale=4, train_wall=180, wall=966
2021-03-14 09:53:15 | INFO | train_inner | epoch 001:    605 / 20258 loss=9.957, nll_loss=9.127, ppl=559.17, wps=27780.5, ups=0.54, wpb=51070.4, bsz=2943.4, num_updates=600, lr=0.000135085, gnorm=1.379, loss_scale=4, train_wall=180, wall=1150
2021-03-14 09:56:19 | INFO | train_inner | epoch 001:    705 / 20258 loss=9.51, nll_loss=8.606, ppl=389.68, wps=27695.6, ups=0.54, wpb=50960.9, bsz=3016.4, num_updates=700, lr=0.000157583, gnorm=1.322, loss_scale=4, train_wall=181, wall=1334
2021-03-14 09:59:22 | INFO | train_inner | epoch 001:    805 / 20258 loss=9.15, nll_loss=8.186, ppl=291.23, wps=27767.6, ups=0.55, wpb=50804.7, bsz=2965.1, num_updates=800, lr=0.00018008, gnorm=1.255, loss_scale=4, train_wall=180, wall=1517
2021-03-14 10:02:25 | INFO | train_inner | epoch 001:    905 / 20258 loss=8.756, nll_loss=7.729, ppl=212.19, wps=27710.7, ups=0.54, wpb=50942.2, bsz=3039.8, num_updates=900, lr=0.000202578, gnorm=1.189, loss_scale=4, train_wall=180, wall=1701
2021-03-14 10:05:29 | INFO | train_inner | epoch 001:   1005 / 20258 loss=8.364, nll_loss=7.276, ppl=154.95, wps=27821.7, ups=0.54, wpb=51133.2, bsz=3077.4, num_updates=1000, lr=0.000225075, gnorm=1.129, loss_scale=4, train_wall=180, wall=1885
2021-03-14 10:08:33 | INFO | train_inner | epoch 001:   1105 / 20258 loss=8.016, nll_loss=6.872, ppl=117.12, wps=27648.1, ups=0.54, wpb=50737.3, bsz=3036.6, num_updates=1100, lr=0.000247573, gnorm=1.117, loss_scale=8, train_wall=180, wall=2068
2021-03-14 10:11:36 | INFO | train_inner | epoch 001:   1205 / 20258 loss=7.693, nll_loss=6.496, ppl=90.27, wps=27783.5, ups=0.54, wpb=51032.2, bsz=3032.8, num_updates=1200, lr=0.00027007, gnorm=1.075, loss_scale=8, train_wall=180, wall=2252
2021-03-14 10:14:40 | INFO | train_inner | epoch 001:   1305 / 20258 loss=7.379, nll_loss=6.13, ppl=70.04, wps=27813.1, ups=0.55, wpb=50980.8, bsz=3003.4, num_updates=1300, lr=0.000292568, gnorm=1.059, loss_scale=8, train_wall=180, wall=2435
2021-03-14 10:17:43 | INFO | train_inner | epoch 001:   1405 / 20258 loss=7.026, nll_loss=5.72, ppl=52.72, wps=27769.9, ups=0.55, wpb=50883.7, bsz=2985.4, num_updates=1400, lr=0.000315065, gnorm=0.948, loss_scale=8, train_wall=180, wall=2618
2021-03-14 10:20:47 | INFO | train_inner | epoch 001:   1505 / 20258 loss=6.695, nll_loss=5.337, ppl=40.42, wps=27805.2, ups=0.54, wpb=51091.1, bsz=3092.6, num_updates=1500, lr=0.000337563, gnorm=0.905, loss_scale=8, train_wall=180, wall=2802
2021-03-14 10:23:49 | INFO | train_inner | epoch 001:   1605 / 20258 loss=6.455, nll_loss=5.059, ppl=33.35, wps=27783.2, ups=0.55, wpb=50734.6, bsz=3023.8, num_updates=1600, lr=0.00036006, gnorm=0.886, loss_scale=8, train_wall=179, wall=2985
2021-03-14 10:26:52 | INFO | train_inner | epoch 001:   1705 / 20258 loss=6.228, nll_loss=4.798, ppl=27.83, wps=27760.4, ups=0.55, wpb=50730.3, bsz=2965.1, num_updates=1700, lr=0.000382558, gnorm=0.833, loss_scale=8, train_wall=179, wall=3168
2021-03-14 10:29:54 | INFO | train_inner | epoch 001:   1805 / 20258 loss=6.001, nll_loss=4.54, ppl=23.26, wps=27896.1, ups=0.55, wpb=50850.8, bsz=2998.2, num_updates=1800, lr=0.000405055, gnorm=0.741, loss_scale=8, train_wall=179, wall=3350
2021-03-14 10:32:57 | INFO | train_inner | epoch 001:   1905 / 20258 loss=5.782, nll_loss=4.29, ppl=19.57, wps=27664.7, ups=0.55, wpb=50515.4, bsz=3005.6, num_updates=1900, lr=0.000427553, gnorm=0.711, loss_scale=8, train_wall=179, wall=3532
2021-03-14 10:35:59 | INFO | train_inner | epoch 001:   2005 / 20258 loss=5.664, nll_loss=4.157, ppl=17.83, wps=27893.2, ups=0.55, wpb=50930.1, bsz=2899.8, num_updates=2000, lr=0.00045005, gnorm=0.678, loss_scale=8, train_wall=180, wall=3715
2021-03-14 10:39:02 | INFO | train_inner | epoch 001:   2105 / 20258 loss=5.501, nll_loss=3.975, ppl=15.73, wps=27795, ups=0.55, wpb=50729.1, bsz=3200, num_updates=2100, lr=0.000472548, gnorm=0.662, loss_scale=16, train_wall=179, wall=3898
2021-03-14 10:42:05 | INFO | train_inner | epoch 001:   2205 / 20258 loss=5.406, nll_loss=3.869, ppl=14.61, wps=27742.1, ups=0.55, wpb=50885.4, bsz=2977.3, num_updates=2200, lr=0.000495045, gnorm=0.629, loss_scale=16, train_wall=180, wall=4081
2021-03-14 10:45:08 | INFO | train_inner | epoch 001:   2305 / 20258 loss=5.298, nll_loss=3.748, ppl=13.44, wps=27890.7, ups=0.55, wpb=51024.6, bsz=3019.7, num_updates=2300, lr=0.000517543, gnorm=0.612, loss_scale=16, train_wall=180, wall=4264
2021-03-14 10:48:11 | INFO | train_inner | epoch 001:   2405 / 20258 loss=5.217, nll_loss=3.658, ppl=12.63, wps=27847.1, ups=0.55, wpb=50935.3, bsz=2956.3, num_updates=2400, lr=0.00054004, gnorm=0.588, loss_scale=16, train_wall=180, wall=4447
2021-03-14 10:51:14 | INFO | train_inner | epoch 001:   2505 / 20258 loss=5.149, nll_loss=3.585, ppl=12, wps=27774.4, ups=0.55, wpb=50615.9, bsz=2994.6, num_updates=2500, lr=0.000562537, gnorm=0.588, loss_scale=16, train_wall=179, wall=4629
2021-03-14 10:54:17 | INFO | train_inner | epoch 001:   2605 / 20258 loss=5.073, nll_loss=3.5, ppl=11.31, wps=27783.4, ups=0.55, wpb=50932.9, bsz=2983.6, num_updates=2600, lr=0.000585035, gnorm=0.573, loss_scale=16, train_wall=180, wall=4812
2021-03-14 10:54:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-14 10:57:22 | INFO | train_inner | epoch 001:   2706 / 20258 loss=5.005, nll_loss=3.427, ppl=10.75, wps=27497.5, ups=0.54, wpb=50887.3, bsz=3125.4, num_updates=2700, lr=0.000607532, gnorm=0.576, loss_scale=8, train_wall=182, wall=4997
2021-03-14 11:00:24 | INFO | train_inner | epoch 001:   2806 / 20258 loss=5.012, nll_loss=3.435, ppl=10.82, wps=28004, ups=0.55, wpb=51078.2, bsz=2904.3, num_updates=2800, lr=0.00063003, gnorm=0.566, loss_scale=8, train_wall=179, wall=5180
2021-03-14 11:03:27 | INFO | train_inner | epoch 001:   2906 / 20258 loss=4.942, nll_loss=3.359, ppl=10.26, wps=27872.7, ups=0.55, wpb=51030.8, bsz=2925.5, num_updates=2900, lr=0.000652528, gnorm=0.575, loss_scale=8, train_wall=180, wall=5363
2021-03-14 11:06:31 | INFO | train_inner | epoch 001:   3006 / 20258 loss=4.878, nll_loss=3.288, ppl=9.77, wps=27952.2, ups=0.55, wpb=51186.9, bsz=3005.8, num_updates=3000, lr=0.000675025, gnorm=0.57, loss_scale=8, train_wall=180, wall=5546
2021-03-14 11:09:34 | INFO | train_inner | epoch 001:   3106 / 20258 loss=4.866, nll_loss=3.277, ppl=9.69, wps=27947.7, ups=0.55, wpb=51146.4, bsz=2959.8, num_updates=3100, lr=0.000697522, gnorm=0.558, loss_scale=8, train_wall=180, wall=5729
2021-03-14 11:12:36 | INFO | train_inner | epoch 001:   3206 / 20258 loss=4.836, nll_loss=3.245, ppl=9.48, wps=27930.8, ups=0.55, wpb=50993.1, bsz=2993.3, num_updates=3200, lr=0.00072002, gnorm=0.605, loss_scale=8, train_wall=180, wall=5912
2021-03-14 11:15:38 | INFO | train_inner | epoch 001:   3306 / 20258 loss=4.801, nll_loss=3.207, ppl=9.23, wps=27902.8, ups=0.55, wpb=50871.9, bsz=3060.7, num_updates=3300, lr=0.000742518, gnorm=0.584, loss_scale=8, train_wall=179, wall=6094
2021-03-14 11:18:41 | INFO | train_inner | epoch 001:   3406 / 20258 loss=4.793, nll_loss=3.2, ppl=9.19, wps=27908.2, ups=0.55, wpb=50987, bsz=2998.3, num_updates=3400, lr=0.000765015, gnorm=0.594, loss_scale=8, train_wall=179, wall=6277
2021-03-14 11:21:43 | INFO | train_inner | epoch 001:   3506 / 20258 loss=4.769, nll_loss=3.173, ppl=9.02, wps=27792, ups=0.55, wpb=50559.9, bsz=2991.1, num_updates=3500, lr=0.000787513, gnorm=0.613, loss_scale=8, train_wall=179, wall=6459
2021-03-14 11:24:46 | INFO | train_inner | epoch 001:   3606 / 20258 loss=4.747, nll_loss=3.15, ppl=8.87, wps=27886, ups=0.55, wpb=50956.5, bsz=3049.6, num_updates=3600, lr=0.00081001, gnorm=0.602, loss_scale=8, train_wall=180, wall=6641
2021-03-14 11:27:48 | INFO | train_inner | epoch 001:   3706 / 20258 loss=4.741, nll_loss=3.144, ppl=8.84, wps=27902.4, ups=0.55, wpb=50923.1, bsz=2956.5, num_updates=3700, lr=0.000832507, gnorm=0.632, loss_scale=16, train_wall=180, wall=6824
2021-03-14 11:27:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-14 11:30:53 | INFO | train_inner | epoch 001:   3807 / 20258 loss=4.697, nll_loss=3.096, ppl=8.55, wps=27499.2, ups=0.54, wpb=50667.7, bsz=3166.4, num_updates=3800, lr=0.000855005, gnorm=0.628, loss_scale=8, train_wall=181, wall=7008
2021-03-14 11:33:55 | INFO | train_inner | epoch 001:   3907 / 20258 loss=4.731, nll_loss=3.134, ppl=8.78, wps=27814.1, ups=0.55, wpb=50661.2, bsz=3010.5, num_updates=3900, lr=0.000877503, gnorm=0.66, loss_scale=8, train_wall=179, wall=7190
2021-03-14 11:36:57 | INFO | train_inner | epoch 001:   4007 / 20258 loss=4.702, nll_loss=3.103, ppl=8.59, wps=27842.6, ups=0.55, wpb=50718.3, bsz=3059.2, num_updates=4000, lr=0.0009, gnorm=0.666, loss_scale=8, train_wall=179, wall=7372
2021-03-14 11:39:59 | INFO | train_inner | epoch 001:   4107 / 20258 loss=4.663, nll_loss=3.06, ppl=8.34, wps=27970, ups=0.55, wpb=51044.5, bsz=3017.8, num_updates=4100, lr=0.000888957, gnorm=0.631, loss_scale=8, train_wall=180, wall=7555
2021-03-14 11:43:03 | INFO | train_inner | epoch 001:   4207 / 20258 loss=4.627, nll_loss=3.02, ppl=8.11, wps=27836.4, ups=0.54, wpb=51112.5, bsz=3045.3, num_updates=4200, lr=0.00087831, gnorm=0.639, loss_scale=8, train_wall=180, wall=7738
2021-03-14 11:46:05 | INFO | train_inner | epoch 001:   4307 / 20258 loss=4.628, nll_loss=3.022, ppl=8.12, wps=27816.6, ups=0.55, wpb=50767.4, bsz=3014.3, num_updates=4300, lr=0.000868037, gnorm=0.647, loss_scale=8, train_wall=179, wall=7921
2021-03-14 11:49:09 | INFO | train_inner | epoch 001:   4407 / 20258 loss=4.594, nll_loss=2.984, ppl=7.91, wps=27938.9, ups=0.55, wpb=51211.6, bsz=3139.1, num_updates=4400, lr=0.000858116, gnorm=0.625, loss_scale=8, train_wall=180, wall=8104
2021-03-14 11:52:12 | INFO | train_inner | epoch 001:   4507 / 20258 loss=4.577, nll_loss=2.966, ppl=7.81, wps=27842.1, ups=0.55, wpb=50877.7, bsz=2943.5, num_updates=4500, lr=0.000848528, gnorm=0.63, loss_scale=8, train_wall=179, wall=8287
2021-03-14 11:55:14 | INFO | train_inner | epoch 001:   4607 / 20258 loss=4.571, nll_loss=2.961, ppl=7.79, wps=27810.9, ups=0.55, wpb=50700.6, bsz=3000.4, num_updates=4600, lr=0.000839254, gnorm=0.625, loss_scale=8, train_wall=179, wall=8469
2021-03-14 11:58:17 | INFO | train_inner | epoch 001:   4707 / 20258 loss=4.53, nll_loss=2.915, ppl=7.54, wps=27770.3, ups=0.55, wpb=50789.7, bsz=2915.4, num_updates=4700, lr=0.000830278, gnorm=0.597, loss_scale=8, train_wall=180, wall=8652
2021-03-14 12:01:19 | INFO | train_inner | epoch 001:   4807 / 20258 loss=4.528, nll_loss=2.914, ppl=7.54, wps=27880.7, ups=0.55, wpb=50887.5, bsz=2985.5, num_updates=4800, lr=0.000821584, gnorm=0.601, loss_scale=16, train_wall=179, wall=8835
2021-03-14 12:04:22 | INFO | train_inner | epoch 001:   4907 / 20258 loss=4.481, nll_loss=2.862, ppl=7.27, wps=27919.1, ups=0.55, wpb=51074.6, bsz=3044.5, num_updates=4900, lr=0.000813157, gnorm=0.586, loss_scale=16, train_wall=180, wall=9018
2021-03-14 12:07:24 | INFO | train_inner | epoch 001:   5007 / 20258 loss=4.508, nll_loss=2.893, ppl=7.43, wps=27934.7, ups=0.55, wpb=50781.4, bsz=2794.4, num_updates=5000, lr=0.000804984, gnorm=0.598, loss_scale=16, train_wall=179, wall=9199
2021-03-14 12:07:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 12:07:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.95 | nll_loss 3.257 | ppl 9.56 | bleu 21.97 | wps 4355.9 | wpb 2432 | bsz 90.4 | num_updates 5000
2021-03-14 12:07:42 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-14 12:07:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:07:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:07:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:07:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 12:08:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 12:08:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 12:08:37 | INFO | valid1 | epoch 001 | valid on 'valid1' subset | loss 4.792 | nll_loss 3.11 | ppl 8.64 | bleu 21.36 | wps 4041 | wpb 2359.4 | bsz 106.4 | num_updates 5000
2021-03-14 12:08:37 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 12:08:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 4.95) (writing took 4.496459896909073 seconds)
2021-03-14 12:10:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-14 12:11:46 | INFO | train_inner | epoch 001:   5108 / 20258 loss=4.466, nll_loss=2.846, ppl=7.19, wps=19437.9, ups=0.38, wpb=51021.2, bsz=2907.4, num_updates=5100, lr=0.000797053, gnorm=0.581, loss_scale=8, train_wall=181, wall=9462
2021-03-14 12:14:49 | INFO | train_inner | epoch 001:   5208 / 20258 loss=4.431, nll_loss=2.808, ppl=7, wps=27726.6, ups=0.55, wpb=50730.8, bsz=3069.3, num_updates=5200, lr=0.000789352, gnorm=0.592, loss_scale=8, train_wall=180, wall=9645
2021-03-14 12:17:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-14 12:17:55 | INFO | train_inner | epoch 001:   5309 / 20258 loss=4.425, nll_loss=2.802, ppl=6.98, wps=27559.8, ups=0.54, wpb=51033.7, bsz=3111, num_updates=5300, lr=0.00078187, gnorm=0.57, loss_scale=4, train_wall=182, wall=9830
2021-03-14 12:19:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-14 12:20:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 12:21:01 | INFO | train_inner | epoch 001:   5411 / 20258 loss=4.409, nll_loss=2.784, ppl=6.89, wps=27268.5, ups=0.54, wpb=50782.5, bsz=2988.6, num_updates=5400, lr=0.000774597, gnorm=0.607, loss_scale=1, train_wall=183, wall=10016
2021-03-14 12:24:04 | INFO | train_inner | epoch 001:   5511 / 20258 loss=4.397, nll_loss=2.771, ppl=6.82, wps=27971, ups=0.55, wpb=51181.6, bsz=2921.6, num_updates=5500, lr=0.000767523, gnorm=0.627, loss_scale=1, train_wall=180, wall=10199
2021-03-14 12:27:06 | INFO | train_inner | epoch 001:   5611 / 20258 loss=4.41, nll_loss=2.787, ppl=6.9, wps=27894.9, ups=0.55, wpb=50908.8, bsz=2961, num_updates=5600, lr=0.000760639, gnorm=0.571, loss_scale=1, train_wall=179, wall=10382
2021-03-14 12:30:09 | INFO | train_inner | epoch 001:   5711 / 20258 loss=4.381, nll_loss=2.755, ppl=6.75, wps=27896.5, ups=0.55, wpb=50883.2, bsz=3006.1, num_updates=5700, lr=0.000753937, gnorm=0.546, loss_scale=1, train_wall=179, wall=10564
2021-03-14 12:33:11 | INFO | train_inner | epoch 001:   5811 / 20258 loss=4.389, nll_loss=2.764, ppl=6.79, wps=27869.3, ups=0.55, wpb=50675.2, bsz=2964.7, num_updates=5800, lr=0.000747409, gnorm=0.555, loss_scale=1, train_wall=179, wall=10746
2021-03-14 12:36:14 | INFO | train_inner | epoch 001:   5911 / 20258 loss=4.352, nll_loss=2.723, ppl=6.6, wps=27928, ups=0.55, wpb=51166.7, bsz=3019.4, num_updates=5900, lr=0.000741048, gnorm=0.601, loss_scale=1, train_wall=180, wall=10929
2021-03-14 12:39:16 | INFO | train_inner | epoch 001:   6011 / 20258 loss=4.358, nll_loss=2.73, ppl=6.64, wps=27927, ups=0.55, wpb=50829.5, bsz=2966.1, num_updates=6000, lr=0.000734847, gnorm=0.531, loss_scale=1, train_wall=179, wall=11111
2021-03-14 12:42:18 | INFO | train_inner | epoch 001:   6111 / 20258 loss=4.356, nll_loss=2.728, ppl=6.63, wps=27842.3, ups=0.55, wpb=50833.2, bsz=2909.2, num_updates=6100, lr=0.000728799, gnorm=0.567, loss_scale=1, train_wall=179, wall=11294
2021-03-14 12:45:21 | INFO | train_inner | epoch 001:   6211 / 20258 loss=4.32, nll_loss=2.689, ppl=6.45, wps=27802, ups=0.55, wpb=50871.8, bsz=3075.3, num_updates=6200, lr=0.000722897, gnorm=0.528, loss_scale=1, train_wall=179, wall=11477
2021-03-14 12:48:24 | INFO | train_inner | epoch 001:   6311 / 20258 loss=4.298, nll_loss=2.665, ppl=6.34, wps=27918.9, ups=0.55, wpb=51109.5, bsz=3021.1, num_updates=6300, lr=0.000717137, gnorm=0.507, loss_scale=1, train_wall=180, wall=11660
2021-03-14 12:51:27 | INFO | train_inner | epoch 001:   6411 / 20258 loss=4.327, nll_loss=2.698, ppl=6.49, wps=28086, ups=0.55, wpb=51232.6, bsz=2983.9, num_updates=6400, lr=0.000711512, gnorm=0.526, loss_scale=1, train_wall=179, wall=11842
2021-03-14 12:54:29 | INFO | train_inner | epoch 001:   6511 / 20258 loss=4.283, nll_loss=2.649, ppl=6.27, wps=27892.6, ups=0.55, wpb=50957.8, bsz=3065.5, num_updates=6500, lr=0.000706018, gnorm=0.513, loss_scale=2, train_wall=179, wall=12025
2021-03-14 12:57:32 | INFO | train_inner | epoch 001:   6611 / 20258 loss=4.293, nll_loss=2.66, ppl=6.32, wps=28022.2, ups=0.55, wpb=51234.2, bsz=2992.7, num_updates=6600, lr=0.000700649, gnorm=0.524, loss_scale=2, train_wall=180, wall=12208
2021-03-14 13:00:35 | INFO | train_inner | epoch 001:   6711 / 20258 loss=4.273, nll_loss=2.638, ppl=6.22, wps=27894.9, ups=0.55, wpb=51064.2, bsz=3028.4, num_updates=6700, lr=0.000695401, gnorm=0.517, loss_scale=2, train_wall=180, wall=12391
2021-03-14 13:03:39 | INFO | train_inner | epoch 001:   6811 / 20258 loss=4.258, nll_loss=2.621, ppl=6.15, wps=27873.8, ups=0.55, wpb=51117.6, bsz=3001.1, num_updates=6800, lr=0.000690268, gnorm=0.51, loss_scale=2, train_wall=180, wall=12574
2021-03-14 13:06:42 | INFO | train_inner | epoch 001:   6911 / 20258 loss=4.257, nll_loss=2.62, ppl=6.15, wps=27914.2, ups=0.55, wpb=51105.7, bsz=2982.2, num_updates=6900, lr=0.000685248, gnorm=0.488, loss_scale=2, train_wall=180, wall=12757
2021-03-14 13:07:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 13:09:46 | INFO | train_inner | epoch 001:   7012 / 20258 loss=4.25, nll_loss=2.614, ppl=6.12, wps=27553.8, ups=0.54, wpb=50835.5, bsz=3020.1, num_updates=7000, lr=0.000680336, gnorm=0.518, loss_scale=1, train_wall=181, wall=12942
2021-03-14 13:12:49 | INFO | train_inner | epoch 001:   7112 / 20258 loss=4.269, nll_loss=2.636, ppl=6.21, wps=27806.5, ups=0.55, wpb=50805.8, bsz=3038.6, num_updates=7100, lr=0.000675528, gnorm=0.524, loss_scale=1, train_wall=179, wall=13125
2021-03-14 13:15:51 | INFO | train_inner | epoch 001:   7212 / 20258 loss=4.235, nll_loss=2.597, ppl=6.05, wps=27855.8, ups=0.55, wpb=50775.5, bsz=2996.2, num_updates=7200, lr=0.00067082, gnorm=0.513, loss_scale=1, train_wall=179, wall=13307
2021-03-14 13:18:54 | INFO | train_inner | epoch 001:   7312 / 20258 loss=4.254, nll_loss=2.62, ppl=6.15, wps=28131.5, ups=0.55, wpb=51339.7, bsz=3002.1, num_updates=7300, lr=0.00066621, gnorm=0.49, loss_scale=1, train_wall=179, wall=13489
2021-03-14 13:21:56 | INFO | train_inner | epoch 001:   7412 / 20258 loss=4.22, nll_loss=2.581, ppl=5.98, wps=27751.4, ups=0.55, wpb=50519.9, bsz=2939.9, num_updates=7400, lr=0.000661693, gnorm=0.487, loss_scale=1, train_wall=179, wall=13671
2021-03-14 13:24:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2021-03-14 13:25:00 | INFO | train_inner | epoch 001:   7513 / 20258 loss=4.221, nll_loss=2.583, ppl=5.99, wps=27669.7, ups=0.54, wpb=50992.3, bsz=3055, num_updates=7500, lr=0.000657267, gnorm=0.494, loss_scale=0.5, train_wall=181, wall=13856
2021-03-14 13:28:03 | INFO | train_inner | epoch 001:   7613 / 20258 loss=4.21, nll_loss=2.57, ppl=5.94, wps=27866.6, ups=0.55, wpb=50821.6, bsz=2896.8, num_updates=7600, lr=0.000652929, gnorm=0.491, loss_scale=0.5, train_wall=179, wall=14038
2021-03-14 13:31:05 | INFO | train_inner | epoch 001:   7713 / 20258 loss=4.216, nll_loss=2.578, ppl=5.97, wps=27873.4, ups=0.55, wpb=50780.2, bsz=2999, num_updates=7700, lr=0.000648675, gnorm=0.48, loss_scale=0.5, train_wall=179, wall=14220
2021-03-14 13:34:07 | INFO | train_inner | epoch 001:   7813 / 20258 loss=4.181, nll_loss=2.539, ppl=5.81, wps=27907.3, ups=0.55, wpb=50931.5, bsz=3020.8, num_updates=7800, lr=0.000644503, gnorm=0.481, loss_scale=0.5, train_wall=179, wall=14403
2021-03-14 13:37:10 | INFO | train_inner | epoch 001:   7913 / 20258 loss=4.179, nll_loss=2.537, ppl=5.8, wps=27984.7, ups=0.55, wpb=51279.4, bsz=3045.2, num_updates=7900, lr=0.000640411, gnorm=0.557, loss_scale=0.5, train_wall=180, wall=14586
2021-03-14 13:40:13 | INFO | train_inner | epoch 001:   8013 / 20258 loss=4.201, nll_loss=2.563, ppl=5.91, wps=27853.2, ups=0.55, wpb=50816.4, bsz=3113, num_updates=8000, lr=0.000636396, gnorm=0.483, loss_scale=0.5, train_wall=179, wall=14768
2021-03-14 13:43:15 | INFO | train_inner | epoch 001:   8113 / 20258 loss=4.2, nll_loss=2.561, ppl=5.9, wps=27967.2, ups=0.55, wpb=51037.6, bsz=2919.5, num_updates=8100, lr=0.000632456, gnorm=0.528, loss_scale=0.5, train_wall=179, wall=14951
2021-03-14 13:46:17 | INFO | train_inner | epoch 001:   8213 / 20258 loss=4.18, nll_loss=2.54, ppl=5.82, wps=27927.8, ups=0.55, wpb=50832.5, bsz=2987.2, num_updates=8200, lr=0.000628587, gnorm=0.455, loss_scale=0.5, train_wall=179, wall=15133
2021-03-14 13:49:20 | INFO | train_inner | epoch 001:   8313 / 20258 loss=4.152, nll_loss=2.508, ppl=5.69, wps=27875.5, ups=0.55, wpb=50883.5, bsz=3070.7, num_updates=8300, lr=0.000624789, gnorm=0.464, loss_scale=0.5, train_wall=179, wall=15316
2021-03-14 13:52:23 | INFO | train_inner | epoch 001:   8413 / 20258 loss=4.15, nll_loss=2.506, ppl=5.68, wps=27935.4, ups=0.55, wpb=51069.2, bsz=3037.7, num_updates=8400, lr=0.000621059, gnorm=0.451, loss_scale=0.5, train_wall=180, wall=15498
2021-03-14 13:55:25 | INFO | train_inner | epoch 001:   8513 / 20258 loss=4.146, nll_loss=2.502, ppl=5.66, wps=27724.1, ups=0.55, wpb=50488.6, bsz=3040.5, num_updates=8500, lr=0.000617395, gnorm=0.479, loss_scale=0.5, train_wall=179, wall=15680
2021-03-14 13:58:27 | INFO | train_inner | epoch 001:   8613 / 20258 loss=4.146, nll_loss=2.502, ppl=5.67, wps=27922.3, ups=0.55, wpb=50826.9, bsz=2978.6, num_updates=8600, lr=0.000613795, gnorm=0.465, loss_scale=1, train_wall=179, wall=15862
2021-03-14 14:01:29 | INFO | train_inner | epoch 001:   8713 / 20258 loss=4.119, nll_loss=2.472, ppl=5.55, wps=27791.5, ups=0.55, wpb=50674.4, bsz=3012.2, num_updates=8700, lr=0.000610257, gnorm=0.446, loss_scale=1, train_wall=179, wall=16045
2021-03-14 14:04:31 | INFO | train_inner | epoch 001:   8813 / 20258 loss=4.133, nll_loss=2.488, ppl=5.61, wps=27847.7, ups=0.55, wpb=50733.8, bsz=2988.1, num_updates=8800, lr=0.00060678, gnorm=0.47, loss_scale=1, train_wall=179, wall=16227
2021-03-14 14:07:34 | INFO | train_inner | epoch 001:   8913 / 20258 loss=4.137, nll_loss=2.493, ppl=5.63, wps=27927.2, ups=0.55, wpb=51064.4, bsz=2986.8, num_updates=8900, lr=0.000603361, gnorm=0.446, loss_scale=1, train_wall=179, wall=16410
2021-03-14 14:10:37 | INFO | train_inner | epoch 001:   9013 / 20258 loss=4.122, nll_loss=2.477, ppl=5.57, wps=27936.9, ups=0.55, wpb=51071, bsz=3172.3, num_updates=9000, lr=0.0006, gnorm=0.44, loss_scale=1, train_wall=180, wall=16593
2021-03-14 14:13:40 | INFO | train_inner | epoch 001:   9113 / 20258 loss=4.124, nll_loss=2.479, ppl=5.58, wps=27954.4, ups=0.55, wpb=50988.8, bsz=3123, num_updates=9100, lr=0.000596694, gnorm=0.46, loss_scale=1, train_wall=179, wall=16775
2021-03-14 14:16:42 | INFO | train_inner | epoch 001:   9213 / 20258 loss=4.111, nll_loss=2.465, ppl=5.52, wps=27878.7, ups=0.55, wpb=50808.3, bsz=2992.4, num_updates=9200, lr=0.000593442, gnorm=0.518, loss_scale=1, train_wall=179, wall=16957
2021-03-14 14:19:44 | INFO | train_inner | epoch 001:   9313 / 20258 loss=4.106, nll_loss=2.458, ppl=5.5, wps=27885.4, ups=0.55, wpb=50887.1, bsz=2891, num_updates=9300, lr=0.000590243, gnorm=0.47, loss_scale=1, train_wall=179, wall=17140
2021-03-14 14:22:47 | INFO | train_inner | epoch 001:   9413 / 20258 loss=4.106, nll_loss=2.459, ppl=5.5, wps=27951.1, ups=0.55, wpb=50959.7, bsz=3056.2, num_updates=9400, lr=0.000587095, gnorm=0.441, loss_scale=1, train_wall=179, wall=17322
2021-03-14 14:25:49 | INFO | train_inner | epoch 001:   9513 / 20258 loss=4.106, nll_loss=2.459, ppl=5.5, wps=27916.2, ups=0.55, wpb=50829.9, bsz=3025.1, num_updates=9500, lr=0.000583997, gnorm=0.491, loss_scale=1, train_wall=179, wall=17504
2021-03-14 14:28:51 | INFO | train_inner | epoch 001:   9613 / 20258 loss=4.126, nll_loss=2.483, ppl=5.59, wps=28070.8, ups=0.55, wpb=51140.6, bsz=2975.5, num_updates=9600, lr=0.000580948, gnorm=0.463, loss_scale=2, train_wall=179, wall=17686
2021-03-14 14:31:54 | INFO | train_inner | epoch 001:   9713 / 20258 loss=4.086, nll_loss=2.438, ppl=5.42, wps=27890.7, ups=0.55, wpb=50994.1, bsz=3099, num_updates=9700, lr=0.000577945, gnorm=0.443, loss_scale=2, train_wall=179, wall=17869
2021-03-14 14:34:56 | INFO | train_inner | epoch 001:   9813 / 20258 loss=4.095, nll_loss=2.449, ppl=5.46, wps=27825.9, ups=0.55, wpb=50792.7, bsz=3104.3, num_updates=9800, lr=0.000574989, gnorm=0.441, loss_scale=2, train_wall=179, wall=18052
2021-03-14 14:37:58 | INFO | train_inner | epoch 001:   9913 / 20258 loss=4.103, nll_loss=2.456, ppl=5.49, wps=27816.5, ups=0.55, wpb=50591.2, bsz=2863.4, num_updates=9900, lr=0.000572078, gnorm=0.429, loss_scale=2, train_wall=179, wall=18234
2021-03-14 14:41:00 | INFO | train_inner | epoch 001:  10013 / 20258 loss=4.084, nll_loss=2.436, ppl=5.41, wps=27871.9, ups=0.55, wpb=50686.3, bsz=2934.2, num_updates=10000, lr=0.00056921, gnorm=0.441, loss_scale=2, train_wall=179, wall=18415
2021-03-14 14:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 14:41:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.509 | nll_loss 2.797 | ppl 6.95 | bleu 25.13 | wps 4369.4 | wpb 2432 | bsz 90.4 | num_updates 10000 | best_loss 4.509
2021-03-14 14:41:18 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-14 14:41:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:41:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 14:41:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 14:41:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 14:42:11 | INFO | valid1 | epoch 001 | valid on 'valid1' subset | loss 4.422 | nll_loss 2.731 | ppl 6.64 | bleu 23.57 | wps 4254.3 | wpb 2359.4 | bsz 106.4 | num_updates 10000 | best_loss 4.422
2021-03-14 14:42:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 14:42:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 4.509) (writing took 6.182349223876372 seconds)
2021-03-14 14:45:20 | INFO | train_inner | epoch 001:  10113 / 20258 loss=4.062, nll_loss=2.411, ppl=5.32, wps=19651.2, ups=0.38, wpb=51081, bsz=3054.2, num_updates=10100, lr=0.000566385, gnorm=0.411, loss_scale=2, train_wall=180, wall=18675
2021-03-14 14:48:23 | INFO | train_inner | epoch 001:  10213 / 20258 loss=4.066, nll_loss=2.416, ppl=5.34, wps=27926.5, ups=0.55, wpb=51161, bsz=3029.2, num_updates=10200, lr=0.000563602, gnorm=0.439, loss_scale=2, train_wall=180, wall=18859
2021-03-14 14:51:27 | INFO | train_inner | epoch 001:  10313 / 20258 loss=4.057, nll_loss=2.406, ppl=5.3, wps=27886.4, ups=0.54, wpb=51207.4, bsz=3061.5, num_updates=10300, lr=0.000560859, gnorm=0.404, loss_scale=2, train_wall=180, wall=19042
2021-03-14 14:54:28 | INFO | train_inner | epoch 001:  10413 / 20258 loss=4.086, nll_loss=2.44, ppl=5.43, wps=28030.7, ups=0.55, wpb=50913.8, bsz=2980, num_updates=10400, lr=0.000558156, gnorm=0.434, loss_scale=2, train_wall=179, wall=19224
2021-03-14 14:57:31 | INFO | train_inner | epoch 001:  10513 / 20258 loss=4.054, nll_loss=2.402, ppl=5.29, wps=27831, ups=0.55, wpb=50769, bsz=2956.1, num_updates=10500, lr=0.000555492, gnorm=0.423, loss_scale=2, train_wall=179, wall=19406
2021-03-14 15:00:33 | INFO | train_inner | epoch 001:  10613 / 20258 loss=4.052, nll_loss=2.402, ppl=5.28, wps=28000.6, ups=0.55, wpb=51151.2, bsz=3074.7, num_updates=10600, lr=0.000552866, gnorm=0.44, loss_scale=4, train_wall=180, wall=19589
2021-03-14 15:03:36 | INFO | train_inner | epoch 001:  10713 / 20258 loss=4.074, nll_loss=2.426, ppl=5.37, wps=27823.8, ups=0.55, wpb=50701.3, bsz=2878.3, num_updates=10700, lr=0.000550276, gnorm=0.454, loss_scale=4, train_wall=179, wall=19771
2021-03-14 15:04:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-14 15:06:40 | INFO | train_inner | epoch 001:  10814 / 20258 loss=4.048, nll_loss=2.397, ppl=5.27, wps=27694.3, ups=0.54, wpb=51140, bsz=2941.2, num_updates=10800, lr=0.000547723, gnorm=0.417, loss_scale=2, train_wall=181, wall=19956
2021-03-14 15:09:43 | INFO | train_inner | epoch 001:  10914 / 20258 loss=4.017, nll_loss=2.363, ppl=5.14, wps=27814.9, ups=0.55, wpb=50773.7, bsz=3042.8, num_updates=10900, lr=0.000545204, gnorm=0.407, loss_scale=2, train_wall=179, wall=20138
2021-03-14 15:12:45 | INFO | train_inner | epoch 001:  11014 / 20258 loss=4.051, nll_loss=2.401, ppl=5.28, wps=27899.1, ups=0.55, wpb=50707.9, bsz=3043.4, num_updates=11000, lr=0.00054272, gnorm=0.427, loss_scale=2, train_wall=179, wall=20320
2021-03-14 15:15:47 | INFO | train_inner | epoch 001:  11114 / 20258 loss=4.042, nll_loss=2.391, ppl=5.25, wps=27979.8, ups=0.55, wpb=50924.9, bsz=2938.1, num_updates=11100, lr=0.00054027, gnorm=0.405, loss_scale=2, train_wall=179, wall=20502
2021-03-14 15:18:49 | INFO | train_inner | epoch 001:  11214 / 20258 loss=4.021, nll_loss=2.368, ppl=5.16, wps=27974.7, ups=0.55, wpb=51139.1, bsz=3046.3, num_updates=11200, lr=0.000537853, gnorm=0.401, loss_scale=2, train_wall=179, wall=20685
2021-03-14 15:21:51 | INFO | train_inner | epoch 001:  11314 / 20258 loss=4.04, nll_loss=2.389, ppl=5.24, wps=27985, ups=0.55, wpb=50849.3, bsz=2977.3, num_updates=11300, lr=0.000535468, gnorm=0.407, loss_scale=2, train_wall=179, wall=20867
2021-03-14 15:24:54 | INFO | train_inner | epoch 001:  11414 / 20258 loss=4.035, nll_loss=2.384, ppl=5.22, wps=27895.7, ups=0.55, wpb=50901.9, bsz=2976.7, num_updates=11400, lr=0.000533114, gnorm=0.521, loss_scale=2, train_wall=179, wall=21049
2021-03-14 15:27:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 15:27:58 | INFO | train_inner | epoch 001:  11515 / 20258 loss=4.021, nll_loss=2.368, ppl=5.16, wps=27582.5, ups=0.54, wpb=50811.4, bsz=3106.2, num_updates=11500, lr=0.000530791, gnorm=0.435, loss_scale=1, train_wall=181, wall=21233
2021-03-14 15:31:01 | INFO | train_inner | epoch 001:  11615 / 20258 loss=4.032, nll_loss=2.381, ppl=5.21, wps=28073.2, ups=0.55, wpb=51310.2, bsz=3022.1, num_updates=11600, lr=0.000528498, gnorm=0.387, loss_scale=1, train_wall=180, wall=21416
2021-03-14 15:34:03 | INFO | train_inner | epoch 001:  11715 / 20258 loss=4.031, nll_loss=2.379, ppl=5.2, wps=27944.7, ups=0.55, wpb=50852.6, bsz=2818.8, num_updates=11700, lr=0.000526235, gnorm=0.464, loss_scale=1, train_wall=179, wall=21598
2021-03-14 15:37:05 | INFO | train_inner | epoch 001:  11815 / 20258 loss=4.018, nll_loss=2.365, ppl=5.15, wps=27859.2, ups=0.55, wpb=50823.4, bsz=2969, num_updates=11800, lr=0.000524, gnorm=0.399, loss_scale=1, train_wall=179, wall=21781
2021-03-14 15:40:08 | INFO | train_inner | epoch 001:  11915 / 20258 loss=4.015, nll_loss=2.363, ppl=5.14, wps=27816.9, ups=0.55, wpb=50970.3, bsz=3097.7, num_updates=11900, lr=0.000521794, gnorm=0.404, loss_scale=1, train_wall=180, wall=21964
2021-03-14 15:43:11 | INFO | train_inner | epoch 001:  12015 / 20258 loss=3.995, nll_loss=2.34, ppl=5.06, wps=27792.3, ups=0.55, wpb=50813.2, bsz=2948.2, num_updates=12000, lr=0.000519615, gnorm=0.437, loss_scale=1, train_wall=179, wall=22147
2021-03-14 15:46:13 | INFO | train_inner | epoch 001:  12115 / 20258 loss=4.002, nll_loss=2.348, ppl=5.09, wps=27915.9, ups=0.55, wpb=50731.6, bsz=2955.8, num_updates=12100, lr=0.000517464, gnorm=0.416, loss_scale=1, train_wall=179, wall=22328
2021-03-14 15:49:16 | INFO | train_inner | epoch 001:  12215 / 20258 loss=3.982, nll_loss=2.326, ppl=5.01, wps=27962.6, ups=0.55, wpb=51146.7, bsz=3061.9, num_updates=12200, lr=0.000515339, gnorm=0.424, loss_scale=1, train_wall=180, wall=22511
2021-03-14 15:52:18 | INFO | train_inner | epoch 001:  12315 / 20258 loss=3.996, nll_loss=2.341, ppl=5.07, wps=27967.5, ups=0.55, wpb=50965.5, bsz=2960.4, num_updates=12300, lr=0.000513239, gnorm=0.393, loss_scale=1, train_wall=179, wall=22694
2021-03-14 15:55:20 | INFO | train_inner | epoch 001:  12415 / 20258 loss=3.98, nll_loss=2.324, ppl=5.01, wps=27734.2, ups=0.55, wpb=50540, bsz=3112.7, num_updates=12400, lr=0.000511166, gnorm=0.402, loss_scale=1, train_wall=179, wall=22876
2021-03-14 15:58:23 | INFO | train_inner | epoch 001:  12515 / 20258 loss=3.985, nll_loss=2.329, ppl=5.02, wps=27924.6, ups=0.55, wpb=51175, bsz=2955.5, num_updates=12500, lr=0.000509117, gnorm=0.388, loss_scale=1, train_wall=180, wall=23059
2021-03-14 16:01:26 | INFO | train_inner | epoch 001:  12615 / 20258 loss=3.966, nll_loss=2.309, ppl=4.95, wps=27866.4, ups=0.55, wpb=50903.1, bsz=3053.2, num_updates=12600, lr=0.000507093, gnorm=0.383, loss_scale=2, train_wall=179, wall=23242
2021-03-14 16:04:28 | INFO | train_inner | epoch 001:  12715 / 20258 loss=3.998, nll_loss=2.344, ppl=5.08, wps=27845.7, ups=0.55, wpb=50602.3, bsz=2963.2, num_updates=12700, lr=0.000505092, gnorm=0.456, loss_scale=2, train_wall=179, wall=23423
2021-03-14 16:07:30 | INFO | train_inner | epoch 001:  12815 / 20258 loss=3.983, nll_loss=2.327, ppl=5.02, wps=27874.6, ups=0.55, wpb=50812.2, bsz=2905.1, num_updates=12800, lr=0.000503115, gnorm=0.403, loss_scale=2, train_wall=179, wall=23606
2021-03-14 16:10:33 | INFO | train_inner | epoch 001:  12915 / 20258 loss=3.989, nll_loss=2.335, ppl=5.04, wps=27960.7, ups=0.55, wpb=51133.9, bsz=3058.8, num_updates=12900, lr=0.000501161, gnorm=0.388, loss_scale=2, train_wall=179, wall=23789
2021-03-14 16:13:35 | INFO | train_inner | epoch 001:  13015 / 20258 loss=3.977, nll_loss=2.321, ppl=5, wps=27872.2, ups=0.55, wpb=50713.9, bsz=3074.4, num_updates=13000, lr=0.00049923, gnorm=0.38, loss_scale=2, train_wall=179, wall=23971
2021-03-14 16:16:37 | INFO | train_inner | epoch 001:  13115 / 20258 loss=3.979, nll_loss=2.324, ppl=5.01, wps=27869.3, ups=0.55, wpb=50814.4, bsz=3000.5, num_updates=13100, lr=0.000497321, gnorm=0.38, loss_scale=2, train_wall=179, wall=24153
2021-03-14 16:19:40 | INFO | train_inner | epoch 001:  13215 / 20258 loss=3.967, nll_loss=2.309, ppl=4.96, wps=27908.9, ups=0.55, wpb=50948, bsz=2943.6, num_updates=13200, lr=0.000495434, gnorm=0.372, loss_scale=2, train_wall=179, wall=24335
2021-03-14 16:22:42 | INFO | train_inner | epoch 001:  13315 / 20258 loss=3.976, nll_loss=2.32, ppl=4.99, wps=27808.6, ups=0.55, wpb=50529.9, bsz=2924.6, num_updates=13300, lr=0.000493568, gnorm=0.378, loss_scale=2, train_wall=179, wall=24517
2021-03-14 16:25:43 | INFO | train_inner | epoch 001:  13415 / 20258 loss=3.988, nll_loss=2.333, ppl=5.04, wps=27964.3, ups=0.55, wpb=50839.8, bsz=2869.1, num_updates=13400, lr=0.000491723, gnorm=0.408, loss_scale=2, train_wall=179, wall=24699
2021-03-14 16:27:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 16:28:48 | INFO | train_inner | epoch 001:  13516 / 20258 loss=3.965, nll_loss=2.309, ppl=4.95, wps=27676.6, ups=0.54, wpb=51014.6, bsz=3047.7, num_updates=13500, lr=0.000489898, gnorm=0.454, loss_scale=1, train_wall=181, wall=24883
2021-03-14 16:31:50 | INFO | train_inner | epoch 001:  13616 / 20258 loss=3.966, nll_loss=2.309, ppl=4.96, wps=27900.7, ups=0.55, wpb=50863.8, bsz=3023.5, num_updates=13600, lr=0.000488094, gnorm=0.445, loss_scale=1, train_wall=179, wall=25066
2021-03-14 16:34:52 | INFO | train_inner | epoch 001:  13716 / 20258 loss=3.963, nll_loss=2.306, ppl=4.95, wps=27856.6, ups=0.55, wpb=50785.6, bsz=3014.2, num_updates=13700, lr=0.000486309, gnorm=0.379, loss_scale=1, train_wall=179, wall=25248
2021-03-14 16:37:54 | INFO | train_inner | epoch 001:  13816 / 20258 loss=3.974, nll_loss=2.319, ppl=4.99, wps=27892.4, ups=0.55, wpb=50685.6, bsz=3001.7, num_updates=13800, lr=0.000484544, gnorm=0.365, loss_scale=1, train_wall=179, wall=25430
2021-03-14 16:40:56 | INFO | train_inner | epoch 001:  13916 / 20258 loss=3.953, nll_loss=2.295, ppl=4.91, wps=28063.5, ups=0.55, wpb=51171.8, bsz=2909.7, num_updates=13900, lr=0.000482798, gnorm=0.371, loss_scale=1, train_wall=180, wall=25612
2021-03-14 16:43:59 | INFO | train_inner | epoch 001:  14016 / 20258 loss=3.938, nll_loss=2.279, ppl=4.85, wps=27901.9, ups=0.55, wpb=50921.7, bsz=3068.1, num_updates=14000, lr=0.00048107, gnorm=0.391, loss_scale=1, train_wall=179, wall=25794
2021-03-14 16:47:01 | INFO | train_inner | epoch 001:  14116 / 20258 loss=3.952, nll_loss=2.296, ppl=4.91, wps=27871.6, ups=0.55, wpb=50821.3, bsz=3151.5, num_updates=14100, lr=0.000479361, gnorm=0.388, loss_scale=1, train_wall=179, wall=25977
2021-03-14 16:50:04 | INFO | train_inner | epoch 001:  14216 / 20258 loss=3.934, nll_loss=2.275, ppl=4.84, wps=27898.6, ups=0.55, wpb=51001.4, bsz=3103.2, num_updates=14200, lr=0.00047767, gnorm=0.355, loss_scale=1, train_wall=180, wall=26160
2021-03-14 16:53:06 | INFO | train_inner | epoch 001:  14316 / 20258 loss=3.951, nll_loss=2.294, ppl=4.9, wps=27926.8, ups=0.55, wpb=50902.6, bsz=3027.8, num_updates=14300, lr=0.000475997, gnorm=0.369, loss_scale=1, train_wall=179, wall=26342
2021-03-14 16:56:09 | INFO | train_inner | epoch 001:  14416 / 20258 loss=3.928, nll_loss=2.268, ppl=4.82, wps=27800.3, ups=0.55, wpb=50825.9, bsz=2992.7, num_updates=14400, lr=0.000474342, gnorm=0.377, loss_scale=1, train_wall=180, wall=26525
2021-03-14 16:59:11 | INFO | train_inner | epoch 001:  14516 / 20258 loss=3.944, nll_loss=2.286, ppl=4.88, wps=27910.1, ups=0.55, wpb=50793, bsz=3026, num_updates=14500, lr=0.000472703, gnorm=0.374, loss_scale=2, train_wall=179, wall=26707
2021-03-14 17:02:13 | INFO | train_inner | epoch 001:  14616 / 20258 loss=3.941, nll_loss=2.284, ppl=4.87, wps=28017.1, ups=0.55, wpb=51055.9, bsz=3130.6, num_updates=14600, lr=0.000471082, gnorm=0.37, loss_scale=2, train_wall=179, wall=26889
2021-03-14 17:05:16 | INFO | train_inner | epoch 001:  14716 / 20258 loss=3.936, nll_loss=2.278, ppl=4.85, wps=27985, ups=0.55, wpb=51129.7, bsz=3252.2, num_updates=14700, lr=0.000469476, gnorm=0.355, loss_scale=2, train_wall=179, wall=27072
2021-03-14 17:08:18 | INFO | train_inner | epoch 001:  14816 / 20258 loss=3.937, nll_loss=2.279, ppl=4.85, wps=27876.6, ups=0.55, wpb=50847.7, bsz=3030.1, num_updates=14800, lr=0.000467888, gnorm=0.473, loss_scale=2, train_wall=179, wall=27254
2021-03-14 17:11:21 | INFO | train_inner | epoch 001:  14916 / 20258 loss=3.923, nll_loss=2.263, ppl=4.8, wps=27902.7, ups=0.55, wpb=50872.1, bsz=3074.5, num_updates=14900, lr=0.000466315, gnorm=0.388, loss_scale=2, train_wall=179, wall=27436
2021-03-14 17:14:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 17:14:25 | INFO | train_inner | epoch 001:  15017 / 20258 loss=3.938, nll_loss=2.28, ppl=4.86, wps=27634.1, ups=0.54, wpb=50902, bsz=3113.8, num_updates=15000, lr=0.000464758, gnorm=0.374, loss_scale=1, train_wall=181, wall=27621
2021-03-14 17:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 17:14:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:43 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.358 | nll_loss 2.641 | ppl 6.24 | bleu 26.28 | wps 4386.4 | wpb 2432 | bsz 90.4 | num_updates 15000 | best_loss 4.358
2021-03-14 17:14:43 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-14 17:14:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:14:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:14:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:14:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 17:15:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 17:15:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 17:15:36 | INFO | valid1 | epoch 001 | valid on 'valid1' subset | loss 4.282 | nll_loss 2.584 | ppl 5.99 | bleu 24.99 | wps 4242.2 | wpb 2359.4 | bsz 106.4 | num_updates 15000 | best_loss 4.282
2021-03-14 17:15:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 17:15:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_1_15000.pt (epoch 1 @ 15000 updates, score 4.358) (writing took 6.194934321101755 seconds)
2021-03-14 17:17:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2021-03-14 17:18:46 | INFO | train_inner | epoch 001:  15118 / 20258 loss=3.927, nll_loss=2.269, ppl=4.82, wps=19476.5, ups=0.38, wpb=50796, bsz=3083.8, num_updates=15100, lr=0.000463217, gnorm=0.375, loss_scale=0.5, train_wall=181, wall=27881
2021-03-14 17:21:48 | INFO | train_inner | epoch 001:  15218 / 20258 loss=3.912, nll_loss=2.25, ppl=4.76, wps=27962.4, ups=0.55, wpb=50933.2, bsz=2982.6, num_updates=15200, lr=0.00046169, gnorm=0.366, loss_scale=0.5, train_wall=179, wall=28063
2021-03-14 17:24:50 | INFO | train_inner | epoch 001:  15318 / 20258 loss=3.929, nll_loss=2.271, ppl=4.83, wps=27902.9, ups=0.55, wpb=50886.2, bsz=3016.7, num_updates=15300, lr=0.000460179, gnorm=0.355, loss_scale=0.5, train_wall=179, wall=28246
2021-03-14 17:27:53 | INFO | train_inner | epoch 001:  15418 / 20258 loss=3.908, nll_loss=2.246, ppl=4.74, wps=27795.6, ups=0.55, wpb=50817.1, bsz=3039.1, num_updates=15400, lr=0.000458682, gnorm=0.369, loss_scale=0.5, train_wall=179, wall=28429
2021-03-14 17:30:56 | INFO | train_inner | epoch 001:  15518 / 20258 loss=3.923, nll_loss=2.263, ppl=4.8, wps=27837, ups=0.55, wpb=50869.9, bsz=2977.5, num_updates=15500, lr=0.0004572, gnorm=0.369, loss_scale=0.5, train_wall=179, wall=28611
2021-03-14 17:33:58 | INFO | train_inner | epoch 001:  15618 / 20258 loss=3.914, nll_loss=2.254, ppl=4.77, wps=27856.9, ups=0.55, wpb=50831, bsz=3068.2, num_updates=15600, lr=0.000455733, gnorm=0.485, loss_scale=0.5, train_wall=179, wall=28794
2021-03-14 17:37:01 | INFO | train_inner | epoch 001:  15718 / 20258 loss=3.897, nll_loss=2.235, ppl=4.71, wps=27947.1, ups=0.55, wpb=50992.6, bsz=3103.4, num_updates=15700, lr=0.000454279, gnorm=0.346, loss_scale=0.5, train_wall=180, wall=28976
2021-03-14 17:40:03 | INFO | train_inner | epoch 001:  15818 / 20258 loss=3.898, nll_loss=2.236, ppl=4.71, wps=27983, ups=0.55, wpb=51071.8, bsz=3137.8, num_updates=15800, lr=0.000452839, gnorm=0.356, loss_scale=0.5, train_wall=179, wall=29159
2021-03-14 17:43:06 | INFO | train_inner | epoch 001:  15918 / 20258 loss=3.912, nll_loss=2.252, ppl=4.76, wps=27865.6, ups=0.55, wpb=50800.8, bsz=3036.1, num_updates=15900, lr=0.000451413, gnorm=0.358, loss_scale=0.5, train_wall=179, wall=29341
2021-03-14 17:46:08 | INFO | train_inner | epoch 001:  16018 / 20258 loss=3.92, nll_loss=2.261, ppl=4.79, wps=27948, ups=0.55, wpb=50878.9, bsz=2961.3, num_updates=16000, lr=0.00045, gnorm=0.361, loss_scale=0.5, train_wall=179, wall=29523
2021-03-14 17:49:10 | INFO | train_inner | epoch 001:  16118 / 20258 loss=3.908, nll_loss=2.248, ppl=4.75, wps=28029.7, ups=0.55, wpb=51110.2, bsz=3097.7, num_updates=16100, lr=0.0004486, gnorm=0.349, loss_scale=1, train_wall=179, wall=29706
2021-03-14 17:52:12 | INFO | train_inner | epoch 001:  16218 / 20258 loss=3.908, nll_loss=2.247, ppl=4.75, wps=27935.5, ups=0.55, wpb=50893.9, bsz=2906.8, num_updates=16200, lr=0.000447214, gnorm=0.353, loss_scale=1, train_wall=179, wall=29888
2021-03-14 17:55:14 | INFO | train_inner | epoch 001:  16318 / 20258 loss=3.912, nll_loss=2.252, ppl=4.76, wps=28013.5, ups=0.55, wpb=51011.1, bsz=3009.3, num_updates=16300, lr=0.00044584, gnorm=0.37, loss_scale=1, train_wall=179, wall=30070
2021-03-14 17:58:17 | INFO | train_inner | epoch 001:  16418 / 20258 loss=3.903, nll_loss=2.242, ppl=4.73, wps=27911.7, ups=0.55, wpb=50870.6, bsz=3135, num_updates=16400, lr=0.000444478, gnorm=0.357, loss_scale=1, train_wall=179, wall=30252
2021-03-14 18:01:19 | INFO | train_inner | epoch 001:  16518 / 20258 loss=3.916, nll_loss=2.258, ppl=4.78, wps=28035.8, ups=0.55, wpb=51128.3, bsz=3025.4, num_updates=16500, lr=0.000443129, gnorm=0.359, loss_scale=1, train_wall=179, wall=30434
2021-03-14 18:04:21 | INFO | train_inner | epoch 001:  16618 / 20258 loss=3.893, nll_loss=2.231, ppl=4.7, wps=27808, ups=0.55, wpb=50739.5, bsz=3031.6, num_updates=16600, lr=0.000441793, gnorm=0.363, loss_scale=1, train_wall=179, wall=30617
2021-03-14 18:07:24 | INFO | train_inner | epoch 001:  16718 / 20258 loss=3.898, nll_loss=2.237, ppl=4.71, wps=27929.3, ups=0.55, wpb=50907.1, bsz=3084.6, num_updates=16700, lr=0.000440468, gnorm=0.368, loss_scale=1, train_wall=179, wall=30799
2021-03-14 18:10:26 | INFO | train_inner | epoch 001:  16818 / 20258 loss=3.913, nll_loss=2.255, ppl=4.77, wps=27904.1, ups=0.55, wpb=51009.2, bsz=3036.5, num_updates=16800, lr=0.000439155, gnorm=0.369, loss_scale=1, train_wall=179, wall=30982
2021-03-14 18:13:29 | INFO | train_inner | epoch 001:  16918 / 20258 loss=3.89, nll_loss=2.228, ppl=4.68, wps=27923.9, ups=0.55, wpb=50868.7, bsz=2952.4, num_updates=16900, lr=0.000437854, gnorm=0.375, loss_scale=1, train_wall=179, wall=31164
2021-03-14 18:16:30 | INFO | train_inner | epoch 001:  17018 / 20258 loss=3.903, nll_loss=2.243, ppl=4.73, wps=27950.5, ups=0.55, wpb=50779.2, bsz=2928.2, num_updates=17000, lr=0.000436564, gnorm=0.349, loss_scale=1, train_wall=179, wall=31346
2021-03-14 18:19:32 | INFO | train_inner | epoch 001:  17118 / 20258 loss=3.899, nll_loss=2.238, ppl=4.72, wps=27915.9, ups=0.55, wpb=50809.1, bsz=2791.7, num_updates=17100, lr=0.000435286, gnorm=0.357, loss_scale=1, train_wall=179, wall=31528
2021-03-14 18:22:34 | INFO | train_inner | epoch 001:  17218 / 20258 loss=3.907, nll_loss=2.248, ppl=4.75, wps=28076.9, ups=0.55, wpb=51107.4, bsz=3030.2, num_updates=17200, lr=0.000434019, gnorm=0.363, loss_scale=2, train_wall=179, wall=31710
2021-03-14 18:25:36 | INFO | train_inner | epoch 001:  17318 / 20258 loss=3.892, nll_loss=2.231, ppl=4.69, wps=28070.2, ups=0.55, wpb=51053.1, bsz=2980.5, num_updates=17300, lr=0.000432762, gnorm=0.349, loss_scale=2, train_wall=179, wall=31892
2021-03-14 18:28:39 | INFO | train_inner | epoch 001:  17418 / 20258 loss=3.872, nll_loss=2.208, ppl=4.62, wps=27687.8, ups=0.55, wpb=50493.5, bsz=2993.4, num_updates=17400, lr=0.000431517, gnorm=0.34, loss_scale=2, train_wall=179, wall=32074
2021-03-14 18:31:41 | INFO | train_inner | epoch 001:  17518 / 20258 loss=3.871, nll_loss=2.207, ppl=4.62, wps=27933, ups=0.55, wpb=51060.1, bsz=2983.1, num_updates=17500, lr=0.000430282, gnorm=0.359, loss_scale=2, train_wall=180, wall=32257
2021-03-14 18:34:43 | INFO | train_inner | epoch 001:  17618 / 20258 loss=3.882, nll_loss=2.22, ppl=4.66, wps=27886, ups=0.55, wpb=50694, bsz=3010.8, num_updates=17600, lr=0.000429058, gnorm=0.368, loss_scale=2, train_wall=179, wall=32439
2021-03-14 18:37:46 | INFO | train_inner | epoch 001:  17718 / 20258 loss=3.883, nll_loss=2.22, ppl=4.66, wps=28059.8, ups=0.55, wpb=51220.9, bsz=2921.2, num_updates=17700, lr=0.000427844, gnorm=0.344, loss_scale=2, train_wall=179, wall=32621
2021-03-14 18:40:48 | INFO | train_inner | epoch 001:  17818 / 20258 loss=3.891, nll_loss=2.23, ppl=4.69, wps=27842.4, ups=0.55, wpb=50657.7, bsz=2850.7, num_updates=17800, lr=0.000426641, gnorm=0.346, loss_scale=2, train_wall=179, wall=32803
2021-03-14 18:43:50 | INFO | train_inner | epoch 001:  17918 / 20258 loss=3.858, nll_loss=2.193, ppl=4.57, wps=27860, ups=0.55, wpb=50858.7, bsz=2999.1, num_updates=17900, lr=0.000425448, gnorm=0.339, loss_scale=2, train_wall=180, wall=32986
2021-03-14 18:46:53 | INFO | train_inner | epoch 001:  18018 / 20258 loss=3.869, nll_loss=2.205, ppl=4.61, wps=27885.4, ups=0.55, wpb=50852.2, bsz=2880.1, num_updates=18000, lr=0.000424264, gnorm=0.35, loss_scale=2, train_wall=179, wall=33168
2021-03-14 18:49:56 | INFO | train_inner | epoch 001:  18118 / 20258 loss=3.864, nll_loss=2.2, ppl=4.59, wps=27867.8, ups=0.55, wpb=51050.6, bsz=3024.3, num_updates=18100, lr=0.00042309, gnorm=0.35, loss_scale=2, train_wall=180, wall=33351
2021-03-14 18:52:58 | INFO | train_inner | epoch 001:  18218 / 20258 loss=3.881, nll_loss=2.219, ppl=4.65, wps=27982.2, ups=0.55, wpb=50921.6, bsz=2934.2, num_updates=18200, lr=0.000421927, gnorm=0.359, loss_scale=4, train_wall=179, wall=33533
2021-03-14 18:56:01 | INFO | train_inner | epoch 001:  18318 / 20258 loss=3.866, nll_loss=2.202, ppl=4.6, wps=28001.5, ups=0.55, wpb=51266.5, bsz=2959, num_updates=18300, lr=0.000420772, gnorm=0.338, loss_scale=4, train_wall=180, wall=33716
2021-03-14 18:59:03 | INFO | train_inner | epoch 001:  18418 / 20258 loss=3.852, nll_loss=2.187, ppl=4.55, wps=27862.5, ups=0.55, wpb=50843.5, bsz=3083.6, num_updates=18400, lr=0.000419627, gnorm=0.338, loss_scale=4, train_wall=179, wall=33899
2021-03-14 19:02:06 | INFO | train_inner | epoch 001:  18518 / 20258 loss=3.867, nll_loss=2.204, ppl=4.61, wps=27953.6, ups=0.55, wpb=50945.5, bsz=3012.1, num_updates=18500, lr=0.000418491, gnorm=0.35, loss_scale=4, train_wall=179, wall=34081
2021-03-14 19:05:08 | INFO | train_inner | epoch 001:  18618 / 20258 loss=3.856, nll_loss=2.192, ppl=4.57, wps=27838, ups=0.55, wpb=50895.8, bsz=3109.4, num_updates=18600, lr=0.000417365, gnorm=0.33, loss_scale=4, train_wall=179, wall=34264
2021-03-14 19:08:11 | INFO | train_inner | epoch 001:  18718 / 20258 loss=3.863, nll_loss=2.2, ppl=4.59, wps=27870.6, ups=0.55, wpb=50829.9, bsz=3024, num_updates=18700, lr=0.000416248, gnorm=0.339, loss_scale=4, train_wall=179, wall=34446
2021-03-14 19:11:13 | INFO | train_inner | epoch 001:  18818 / 20258 loss=3.868, nll_loss=2.205, ppl=4.61, wps=28057, ups=0.55, wpb=51241.2, bsz=2990.6, num_updates=18800, lr=0.000415139, gnorm=0.342, loss_scale=4, train_wall=179, wall=34629
2021-03-14 19:13:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-14 19:14:18 | INFO | train_inner | epoch 001:  18919 / 20258 loss=3.843, nll_loss=2.177, ppl=4.52, wps=27514.2, ups=0.54, wpb=50748.1, bsz=3038.3, num_updates=18900, lr=0.000414039, gnorm=0.336, loss_scale=2, train_wall=181, wall=34813
2021-03-14 19:17:20 | INFO | train_inner | epoch 001:  19019 / 20258 loss=3.875, nll_loss=2.213, ppl=4.64, wps=27907.9, ups=0.55, wpb=50895.4, bsz=2981.4, num_updates=19000, lr=0.000412948, gnorm=0.375, loss_scale=2, train_wall=179, wall=34996
2021-03-14 19:20:22 | INFO | train_inner | epoch 001:  19119 / 20258 loss=3.852, nll_loss=2.188, ppl=4.56, wps=27823.1, ups=0.55, wpb=50664.9, bsz=3090.2, num_updates=19100, lr=0.000411866, gnorm=0.348, loss_scale=2, train_wall=179, wall=35178
2021-03-14 19:23:25 | INFO | train_inner | epoch 001:  19219 / 20258 loss=3.86, nll_loss=2.196, ppl=4.58, wps=27866.2, ups=0.55, wpb=50949.5, bsz=3005.9, num_updates=19200, lr=0.000410792, gnorm=0.348, loss_scale=2, train_wall=179, wall=35361
2021-03-14 19:26:28 | INFO | train_inner | epoch 001:  19319 / 20258 loss=3.841, nll_loss=2.175, ppl=4.52, wps=27770.1, ups=0.55, wpb=50633.3, bsz=3076.6, num_updates=19300, lr=0.000409726, gnorm=0.348, loss_scale=2, train_wall=179, wall=35543
2021-03-14 19:29:30 | INFO | train_inner | epoch 001:  19419 / 20258 loss=3.844, nll_loss=2.178, ppl=4.53, wps=27922.4, ups=0.55, wpb=51015.7, bsz=2976.2, num_updates=19400, lr=0.000408669, gnorm=0.333, loss_scale=2, train_wall=180, wall=35726
2021-03-14 19:32:34 | INFO | train_inner | epoch 001:  19519 / 20258 loss=3.823, nll_loss=2.156, ppl=4.46, wps=27714.6, ups=0.54, wpb=50912.2, bsz=3142, num_updates=19500, lr=0.00040762, gnorm=0.35, loss_scale=2, train_wall=180, wall=35909
2021-03-14 19:35:36 | INFO | train_inner | epoch 001:  19619 / 20258 loss=3.852, nll_loss=2.188, ppl=4.56, wps=27900.5, ups=0.55, wpb=50859.4, bsz=3020.4, num_updates=19600, lr=0.000406579, gnorm=0.331, loss_scale=2, train_wall=179, wall=36092
2021-03-14 19:38:38 | INFO | train_inner | epoch 001:  19719 / 20258 loss=3.837, nll_loss=2.171, ppl=4.5, wps=27913, ups=0.55, wpb=50748.5, bsz=2948, num_updates=19700, lr=0.000405545, gnorm=0.325, loss_scale=2, train_wall=179, wall=36274
2021-03-14 19:41:41 | INFO | train_inner | epoch 001:  19819 / 20258 loss=3.836, nll_loss=2.17, ppl=4.5, wps=27830.2, ups=0.55, wpb=50787.5, bsz=3014.2, num_updates=19800, lr=0.00040452, gnorm=0.337, loss_scale=2, train_wall=179, wall=36456
2021-03-14 19:44:43 | INFO | train_inner | epoch 001:  19919 / 20258 loss=3.845, nll_loss=2.181, ppl=4.53, wps=27935.5, ups=0.55, wpb=51055, bsz=3096.9, num_updates=19900, lr=0.000403502, gnorm=0.326, loss_scale=4, train_wall=179, wall=36639
2021-03-14 19:47:46 | INFO | train_inner | epoch 001:  20019 / 20258 loss=3.848, nll_loss=2.183, ppl=4.54, wps=27748.6, ups=0.55, wpb=50614.4, bsz=2954.7, num_updates=20000, lr=0.000402492, gnorm=0.345, loss_scale=4, train_wall=179, wall=36821
2021-03-14 19:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 19:47:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:47:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:47:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:47:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:47:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:47:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:47:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:47:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:47:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:47:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:47:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:47:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:47:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:47:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:47:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:47:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:47:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:47:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:47:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:47:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:47:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:05 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.258 | nll_loss 2.545 | ppl 5.84 | bleu 27.11 | wps 4257.6 | wpb 2432 | bsz 90.4 | num_updates 20000 | best_loss 4.258
2021-03-14 19:48:05 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-14 19:48:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:48:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:48:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:48:57 | INFO | valid1 | epoch 001 | valid on 'valid1' subset | loss 4.207 | nll_loss 2.514 | ppl 5.71 | bleu 25.17 | wps 4249.9 | wpb 2359.4 | bsz 106.4 | num_updates 20000 | best_loss 4.207
2021-03-14 19:48:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 19:49:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_1_20000.pt (epoch 1 @ 20000 updates, score 4.258) (writing took 6.0993073030840605 seconds)
2021-03-14 19:52:05 | INFO | train_inner | epoch 001:  20119 / 20258 loss=3.847, nll_loss=2.183, ppl=4.54, wps=19604.5, ups=0.38, wpb=50932.2, bsz=2990.6, num_updates=20100, lr=0.00040149, gnorm=0.339, loss_scale=4, train_wall=179, wall=37081
2021-03-14 19:55:08 | INFO | train_inner | epoch 001:  20219 / 20258 loss=3.824, nll_loss=2.156, ppl=4.46, wps=27908.9, ups=0.55, wpb=50894.3, bsz=2971.1, num_updates=20200, lr=0.000400495, gnorm=0.327, loss_scale=4, train_wall=179, wall=37263
2021-03-14 19:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 19:56:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.27 | nll_loss 2.551 | ppl 5.86 | bleu 26.65 | wps 4382.5 | wpb 2432 | bsz 90.4 | num_updates 20239 | best_loss 4.258
2021-03-14 19:56:38 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-14 19:56:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:56:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:56:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:56:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:57:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:57:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:57:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:57:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 19:57:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 19:57:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 19:57:30 | INFO | valid1 | epoch 001 | valid on 'valid1' subset | loss 4.219 | nll_loss 2.522 | ppl 5.74 | bleu 25.13 | wps 4272.8 | wpb 2359.4 | bsz 106.4 | num_updates 20239 | best_loss 4.219
2021-03-14 19:57:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 19:57:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint1.pt (epoch 1 @ 20239 updates, score 4.27) (writing took 4.3849273638334125 seconds)
2021-03-14 19:57:34 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-03-14 19:57:34 | INFO | train | epoch 001 | loss 4.594 | nll_loss 3.011 | ppl 8.06 | wps 27577.1 | ups 0.54 | wpb 50905.8 | bsz 3009.9 | num_updates 20239 | lr 0.000400109 | gnorm 0.524 | loss_scale 4 | train_wall 36343 | wall 37410
2021-03-14 19:57:34 | INFO | fairseq.trainer | begin training epoch 2
2021-03-14 19:59:25 | INFO | train_inner | epoch 002:     61 / 20258 loss=3.854, nll_loss=2.191, ppl=4.56, wps=19778, ups=0.39, wpb=50922, bsz=2945.8, num_updates=20300, lr=0.000399507, gnorm=0.34, loss_scale=4, train_wall=179, wall=37521
2021-03-14 20:02:28 | INFO | train_inner | epoch 002:    161 / 20258 loss=3.832, nll_loss=2.165, ppl=4.49, wps=28019.1, ups=0.55, wpb=51174.4, bsz=2883.2, num_updates=20400, lr=0.000398527, gnorm=0.327, loss_scale=4, train_wall=180, wall=37703
2021-03-14 20:05:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-14 20:05:33 | INFO | train_inner | epoch 002:    262 / 20258 loss=3.822, nll_loss=2.154, ppl=4.45, wps=27608.5, ups=0.54, wpb=51017.2, bsz=2975.8, num_updates=20500, lr=0.000397553, gnorm=0.48, loss_scale=2, train_wall=182, wall=37888
2021-03-14 20:05:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 20:05:35 | INFO | train_inner | epoch 002:    263 / 20258 loss=None, nll_loss=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, loss_scale=1, train_wall=2, wall=37890
2021-03-14 20:06:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2021-03-14 20:08:38 | INFO | train_inner | epoch 002:    364 / 20258 loss=3.823, nll_loss=2.155, ppl=4.45, wps=27664.1, ups=0.54, wpb=50865.8, bsz=2920.1, num_updates=20600, lr=0.000396587, gnorm=0.402, loss_scale=0.5, train_wall=181, wall=38074
2021-03-14 20:11:41 | INFO | train_inner | epoch 002:    464 / 20258 loss=3.821, nll_loss=2.154, ppl=4.45, wps=27888.2, ups=0.55, wpb=50933.5, bsz=3035.8, num_updates=20700, lr=0.000395628, gnorm=0.327, loss_scale=0.5, train_wall=179, wall=38257
2021-03-14 20:14:43 | INFO | train_inner | epoch 002:    564 / 20258 loss=3.827, nll_loss=2.16, ppl=4.47, wps=27889.5, ups=0.55, wpb=50739.2, bsz=2927.3, num_updates=20800, lr=0.000394676, gnorm=0.332, loss_scale=0.5, train_wall=179, wall=38439
2021-03-14 20:17:45 | INFO | train_inner | epoch 002:    664 / 20258 loss=3.82, nll_loss=2.152, ppl=4.45, wps=27990.9, ups=0.55, wpb=51045.1, bsz=3021.4, num_updates=20900, lr=0.000393731, gnorm=0.326, loss_scale=0.5, train_wall=179, wall=38621
2021-03-14 20:20:47 | INFO | train_inner | epoch 002:    764 / 20258 loss=3.835, nll_loss=2.169, ppl=4.5, wps=27889.7, ups=0.55, wpb=50682.2, bsz=2950.6, num_updates=21000, lr=0.000392792, gnorm=0.33, loss_scale=0.5, train_wall=179, wall=38803
2021-03-14 20:23:49 | INFO | train_inner | epoch 002:    864 / 20258 loss=3.811, nll_loss=2.143, ppl=4.42, wps=27911.8, ups=0.55, wpb=50896.1, bsz=3033, num_updates=21100, lr=0.00039186, gnorm=0.321, loss_scale=0.5, train_wall=179, wall=38985
2021-03-14 20:26:52 | INFO | train_inner | epoch 002:    964 / 20258 loss=3.819, nll_loss=2.152, ppl=4.44, wps=27820.5, ups=0.55, wpb=50703.3, bsz=2989.7, num_updates=21200, lr=0.000390935, gnorm=0.324, loss_scale=0.5, train_wall=179, wall=39167
2021-03-14 20:29:54 | INFO | train_inner | epoch 002:   1064 / 20258 loss=3.817, nll_loss=2.15, ppl=4.44, wps=27898.4, ups=0.55, wpb=50957.8, bsz=3135, num_updates=21300, lr=0.000390016, gnorm=0.406, loss_scale=0.5, train_wall=179, wall=39350
2021-03-14 20:32:57 | INFO | train_inner | epoch 002:   1164 / 20258 loss=3.797, nll_loss=2.127, ppl=4.37, wps=27877.8, ups=0.55, wpb=50934.8, bsz=3009.5, num_updates=21400, lr=0.000389104, gnorm=0.329, loss_scale=0.5, train_wall=179, wall=39533
2021-03-14 20:35:59 | INFO | train_inner | epoch 002:   1264 / 20258 loss=3.829, nll_loss=2.163, ppl=4.48, wps=27979, ups=0.55, wpb=50942.8, bsz=3024.9, num_updates=21500, lr=0.000388198, gnorm=0.326, loss_scale=0.5, train_wall=179, wall=39715
2021-03-14 20:39:02 | INFO | train_inner | epoch 002:   1364 / 20258 loss=3.824, nll_loss=2.157, ppl=4.46, wps=27961.2, ups=0.55, wpb=51046.1, bsz=3035.8, num_updates=21600, lr=0.000387298, gnorm=0.324, loss_scale=1, train_wall=179, wall=39897
2021-03-14 20:42:04 | INFO | train_inner | epoch 002:   1464 / 20258 loss=3.823, nll_loss=2.156, ppl=4.46, wps=27840.5, ups=0.55, wpb=50800.5, bsz=2939.6, num_updates=21700, lr=0.000386405, gnorm=0.339, loss_scale=1, train_wall=179, wall=40080
2021-03-14 20:45:07 | INFO | train_inner | epoch 002:   1564 / 20258 loss=3.829, nll_loss=2.164, ppl=4.48, wps=28017.9, ups=0.55, wpb=51138, bsz=3104.5, num_updates=21800, lr=0.000385518, gnorm=0.394, loss_scale=1, train_wall=179, wall=40262
2021-03-14 20:48:10 | INFO | train_inner | epoch 002:   1664 / 20258 loss=3.8, nll_loss=2.13, ppl=4.38, wps=27988.9, ups=0.55, wpb=51236.5, bsz=3032.3, num_updates=21900, lr=0.000384636, gnorm=0.318, loss_scale=1, train_wall=180, wall=40445
2021-03-14 20:51:13 | INFO | train_inner | epoch 002:   1764 / 20258 loss=3.805, nll_loss=2.137, ppl=4.4, wps=27960.9, ups=0.55, wpb=51125.4, bsz=2982.4, num_updates=22000, lr=0.000383761, gnorm=0.335, loss_scale=1, train_wall=180, wall=40628
2021-03-14 20:54:15 | INFO | train_inner | epoch 002:   1864 / 20258 loss=3.817, nll_loss=2.15, ppl=4.44, wps=27824.4, ups=0.55, wpb=50665.8, bsz=2958.9, num_updates=22100, lr=0.000382892, gnorm=0.334, loss_scale=1, train_wall=179, wall=40810
2021-03-14 20:57:17 | INFO | train_inner | epoch 002:   1964 / 20258 loss=3.814, nll_loss=2.147, ppl=4.43, wps=27910.3, ups=0.55, wpb=50908, bsz=3030.5, num_updates=22200, lr=0.000382029, gnorm=0.322, loss_scale=1, train_wall=179, wall=40993
2021-03-14 21:00:19 | INFO | train_inner | epoch 002:   2064 / 20258 loss=3.814, nll_loss=2.147, ppl=4.43, wps=27802, ups=0.55, wpb=50695.6, bsz=3035.1, num_updates=22300, lr=0.000381171, gnorm=0.32, loss_scale=1, train_wall=179, wall=41175
2021-03-14 21:03:22 | INFO | train_inner | epoch 002:   2164 / 20258 loss=3.811, nll_loss=2.143, ppl=4.42, wps=27957.4, ups=0.55, wpb=51105.4, bsz=2976.4, num_updates=22400, lr=0.000380319, gnorm=0.321, loss_scale=1, train_wall=180, wall=41358
2021-03-14 21:06:25 | INFO | train_inner | epoch 002:   2264 / 20258 loss=3.808, nll_loss=2.139, ppl=4.4, wps=27913.6, ups=0.55, wpb=50912.1, bsz=2861.4, num_updates=22500, lr=0.000379473, gnorm=0.338, loss_scale=1, train_wall=179, wall=41540
2021-03-14 21:09:27 | INFO | train_inner | epoch 002:   2364 / 20258 loss=3.791, nll_loss=2.121, ppl=4.35, wps=27828.9, ups=0.55, wpb=50861.3, bsz=3077.8, num_updates=22600, lr=0.000378633, gnorm=0.375, loss_scale=2, train_wall=180, wall=41723
2021-03-14 21:12:30 | INFO | train_inner | epoch 002:   2464 / 20258 loss=3.797, nll_loss=2.128, ppl=4.37, wps=27796, ups=0.55, wpb=50813.1, bsz=3117.5, num_updates=22700, lr=0.000377798, gnorm=0.335, loss_scale=2, train_wall=179, wall=41906
2021-03-14 21:15:33 | INFO | train_inner | epoch 002:   2564 / 20258 loss=3.807, nll_loss=2.139, ppl=4.41, wps=27806.4, ups=0.55, wpb=50915.6, bsz=3177.8, num_updates=22800, lr=0.000376969, gnorm=0.319, loss_scale=2, train_wall=179, wall=42089
2021-03-14 21:18:36 | INFO | train_inner | epoch 002:   2664 / 20258 loss=3.801, nll_loss=2.133, ppl=4.39, wps=27918.9, ups=0.55, wpb=51037.5, bsz=3013.8, num_updates=22900, lr=0.000376145, gnorm=0.344, loss_scale=2, train_wall=179, wall=42272
2021-03-14 21:21:38 | INFO | train_inner | epoch 002:   2764 / 20258 loss=3.806, nll_loss=2.138, ppl=4.4, wps=27889.8, ups=0.55, wpb=50788.3, bsz=2945.3, num_updates=23000, lr=0.000375326, gnorm=0.33, loss_scale=2, train_wall=179, wall=42454
2021-03-14 21:24:41 | INFO | train_inner | epoch 002:   2864 / 20258 loss=3.792, nll_loss=2.123, ppl=4.36, wps=27854.1, ups=0.55, wpb=51008.4, bsz=3099, num_updates=23100, lr=0.000374513, gnorm=0.323, loss_scale=2, train_wall=180, wall=42637
2021-03-14 21:27:44 | INFO | train_inner | epoch 002:   2964 / 20258 loss=3.808, nll_loss=2.14, ppl=4.41, wps=27870.8, ups=0.55, wpb=50950.1, bsz=2971, num_updates=23200, lr=0.000373705, gnorm=0.325, loss_scale=2, train_wall=179, wall=42820
2021-03-14 21:30:47 | INFO | train_inner | epoch 002:   3064 / 20258 loss=3.794, nll_loss=2.125, ppl=4.36, wps=27812.7, ups=0.55, wpb=50924.6, bsz=3045.3, num_updates=23300, lr=0.000372902, gnorm=0.311, loss_scale=2, train_wall=180, wall=43003
2021-03-14 21:33:49 | INFO | train_inner | epoch 002:   3164 / 20258 loss=3.823, nll_loss=2.158, ppl=4.46, wps=27972.9, ups=0.55, wpb=50832.2, bsz=3081.2, num_updates=23400, lr=0.000372104, gnorm=0.318, loss_scale=2, train_wall=179, wall=43184
2021-03-14 21:36:51 | INFO | train_inner | epoch 002:   3264 / 20258 loss=3.809, nll_loss=2.142, ppl=4.41, wps=27940.3, ups=0.55, wpb=50931.8, bsz=3100.8, num_updates=23500, lr=0.000371312, gnorm=0.321, loss_scale=2, train_wall=179, wall=43367
2021-03-14 21:39:54 | INFO | train_inner | epoch 002:   3364 / 20258 loss=3.797, nll_loss=2.129, ppl=4.37, wps=27871.9, ups=0.55, wpb=50808.2, bsz=3082, num_updates=23600, lr=0.000370524, gnorm=0.313, loss_scale=4, train_wall=179, wall=43549
2021-03-14 21:42:55 | INFO | train_inner | epoch 002:   3464 / 20258 loss=3.805, nll_loss=2.137, ppl=4.4, wps=27866.4, ups=0.55, wpb=50644.9, bsz=2900, num_updates=23700, lr=0.000369742, gnorm=0.315, loss_scale=4, train_wall=179, wall=43731
2021-03-14 21:45:58 | INFO | train_inner | epoch 002:   3564 / 20258 loss=3.813, nll_loss=2.147, ppl=4.43, wps=27912.5, ups=0.55, wpb=50876.3, bsz=3088.5, num_updates=23800, lr=0.000368964, gnorm=0.318, loss_scale=4, train_wall=179, wall=43913
2021-03-14 21:49:00 | INFO | train_inner | epoch 002:   3664 / 20258 loss=3.787, nll_loss=2.116, ppl=4.34, wps=27878.7, ups=0.55, wpb=50883.5, bsz=2880.6, num_updates=23900, lr=0.000368191, gnorm=0.316, loss_scale=4, train_wall=179, wall=44096
2021-03-14 21:52:02 | INFO | train_inner | epoch 002:   3764 / 20258 loss=3.791, nll_loss=2.121, ppl=4.35, wps=27895.9, ups=0.55, wpb=50813.6, bsz=2913.6, num_updates=24000, lr=0.000367423, gnorm=0.331, loss_scale=4, train_wall=179, wall=44278
2021-03-14 21:55:05 | INFO | train_inner | epoch 002:   3864 / 20258 loss=3.788, nll_loss=2.118, ppl=4.34, wps=27856.4, ups=0.55, wpb=50813.4, bsz=3042.6, num_updates=24100, lr=0.00036666, gnorm=0.333, loss_scale=4, train_wall=179, wall=44460
2021-03-14 21:58:07 | INFO | train_inner | epoch 002:   3964 / 20258 loss=3.833, nll_loss=2.17, ppl=4.5, wps=27937.5, ups=0.55, wpb=50930.2, bsz=2990.2, num_updates=24200, lr=0.000365902, gnorm=0.329, loss_scale=4, train_wall=179, wall=44642
2021-03-14 22:01:10 | INFO | train_inner | epoch 002:   4064 / 20258 loss=3.778, nll_loss=2.106, ppl=4.31, wps=27915.5, ups=0.55, wpb=51006.5, bsz=2986.5, num_updates=24300, lr=0.000365148, gnorm=0.315, loss_scale=4, train_wall=180, wall=44825
2021-03-14 22:04:13 | INFO | train_inner | epoch 002:   4164 / 20258 loss=3.786, nll_loss=2.116, ppl=4.33, wps=27961, ups=0.55, wpb=51136.8, bsz=2970.2, num_updates=24400, lr=0.000364399, gnorm=0.313, loss_scale=4, train_wall=180, wall=45008
2021-03-14 22:07:15 | INFO | train_inner | epoch 002:   4264 / 20258 loss=3.792, nll_loss=2.123, ppl=4.36, wps=27900, ups=0.55, wpb=50982.7, bsz=3043.4, num_updates=24500, lr=0.000363655, gnorm=0.312, loss_scale=4, train_wall=180, wall=45191
2021-03-14 22:10:18 | INFO | train_inner | epoch 002:   4364 / 20258 loss=3.793, nll_loss=2.125, ppl=4.36, wps=27910, ups=0.55, wpb=50976, bsz=3019.2, num_updates=24600, lr=0.000362915, gnorm=0.311, loss_scale=4, train_wall=179, wall=45373
2021-03-14 22:12:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-14 22:13:22 | INFO | train_inner | epoch 002:   4465 / 20258 loss=3.775, nll_loss=2.104, ppl=4.3, wps=27604.9, ups=0.54, wpb=50838.5, bsz=3034.6, num_updates=24700, lr=0.00036218, gnorm=0.32, loss_scale=4, train_wall=181, wall=45558
2021-03-14 22:16:25 | INFO | train_inner | epoch 002:   4565 / 20258 loss=3.796, nll_loss=2.129, ppl=4.37, wps=27863, ups=0.55, wpb=50885.2, bsz=3205.4, num_updates=24800, lr=0.000361449, gnorm=0.315, loss_scale=4, train_wall=179, wall=45740
2021-03-14 22:19:27 | INFO | train_inner | epoch 002:   4665 / 20258 loss=3.779, nll_loss=2.109, ppl=4.31, wps=27844.9, ups=0.55, wpb=50844.9, bsz=3095.5, num_updates=24900, lr=0.000360722, gnorm=0.315, loss_scale=4, train_wall=179, wall=45923
2021-03-14 22:22:30 | INFO | train_inner | epoch 002:   4765 / 20258 loss=3.783, nll_loss=2.113, ppl=4.33, wps=27893, ups=0.55, wpb=50979.3, bsz=3009.2, num_updates=25000, lr=0.00036, gnorm=0.306, loss_scale=4, train_wall=180, wall=46106
2021-03-14 22:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-14 22:22:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.21 | nll_loss 2.485 | ppl 5.6 | bleu 27.33 | wps 4383.8 | wpb 2432 | bsz 90.4 | num_updates 25000 | best_loss 4.21
2021-03-14 22:22:48 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-14 22:22:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:22:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:22:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:22:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-14 22:23:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-14 22:23:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-14 22:23:41 | INFO | valid1 | epoch 002 | valid on 'valid1' subset | loss 4.164 | nll_loss 2.458 | ppl 5.49 | bleu 25.77 | wps 4240.6 | wpb 2359.4 | bsz 106.4 | num_updates 25000 | best_loss 4.164
2021-03-14 22:23:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-14 22:23:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_2_25000.pt (epoch 2 @ 25000 updates, score 4.21) (writing took 8.103702226886526 seconds)
2021-03-14 22:26:52 | INFO | train_inner | epoch 002:   4865 / 20258 loss=3.774, nll_loss=2.103, ppl=4.3, wps=19467.7, ups=0.38, wpb=51048, bsz=3033.6, num_updates=25100, lr=0.000359282, gnorm=0.314, loss_scale=4, train_wall=180, wall=46368
2021-03-14 22:29:54 | INFO | train_inner | epoch 002:   4965 / 20258 loss=3.787, nll_loss=2.118, ppl=4.34, wps=27857.6, ups=0.55, wpb=50746.3, bsz=2968.6, num_updates=25200, lr=0.000358569, gnorm=0.321, loss_scale=4, train_wall=179, wall=46550
2021-03-14 22:32:57 | INFO | train_inner | epoch 002:   5065 / 20258 loss=3.796, nll_loss=2.128, ppl=4.37, wps=27908.6, ups=0.55, wpb=51013.5, bsz=2989.7, num_updates=25300, lr=0.000357859, gnorm=0.313, loss_scale=4, train_wall=180, wall=46733
2021-03-14 22:35:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-14 22:36:02 | INFO | train_inner | epoch 002:   5166 / 20258 loss=3.79, nll_loss=2.122, ppl=4.35, wps=27692, ups=0.54, wpb=51137.3, bsz=3026.7, num_updates=25400, lr=0.000357154, gnorm=0.318, loss_scale=2, train_wall=181, wall=46917
2021-03-14 22:39:05 | INFO | train_inner | epoch 002:   5266 / 20258 loss=3.768, nll_loss=2.096, ppl=4.27, wps=27857.9, ups=0.55, wpb=51060.9, bsz=2929.8, num_updates=25500, lr=0.000356453, gnorm=0.311, loss_scale=2, train_wall=180, wall=47101
2021-03-14 22:41:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 22:42:09 | INFO | train_inner | epoch 002:   5367 / 20258 loss=3.777, nll_loss=2.107, ppl=4.31, wps=27682, ups=0.54, wpb=50999.6, bsz=3008.4, num_updates=25600, lr=0.000355756, gnorm=0.304, loss_scale=1, train_wall=181, wall=47285
2021-03-14 22:45:12 | INFO | train_inner | epoch 002:   5467 / 20258 loss=3.77, nll_loss=2.098, ppl=4.28, wps=27855.3, ups=0.55, wpb=50750.7, bsz=2980.6, num_updates=25700, lr=0.000355063, gnorm=0.308, loss_scale=1, train_wall=179, wall=47467
2021-03-14 22:48:15 | INFO | train_inner | epoch 002:   5567 / 20258 loss=3.769, nll_loss=2.098, ppl=4.28, wps=27898.8, ups=0.55, wpb=51067.9, bsz=2963.2, num_updates=25800, lr=0.000354375, gnorm=0.31, loss_scale=1, train_wall=180, wall=47650
2021-03-14 22:51:18 | INFO | train_inner | epoch 002:   5667 / 20258 loss=3.771, nll_loss=2.1, ppl=4.29, wps=27910.7, ups=0.55, wpb=51058.7, bsz=3011, num_updates=25900, lr=0.00035369, gnorm=0.318, loss_scale=1, train_wall=180, wall=47833
2021-03-14 22:54:20 | INFO | train_inner | epoch 002:   5767 / 20258 loss=3.796, nll_loss=2.129, ppl=4.37, wps=27986.9, ups=0.55, wpb=51019.7, bsz=2947.8, num_updates=26000, lr=0.000353009, gnorm=0.313, loss_scale=1, train_wall=179, wall=48015
2021-03-14 22:57:22 | INFO | train_inner | epoch 002:   5867 / 20258 loss=3.786, nll_loss=2.116, ppl=4.34, wps=27882.7, ups=0.55, wpb=50845.9, bsz=2892.1, num_updates=26100, lr=0.000352332, gnorm=0.319, loss_scale=1, train_wall=179, wall=48198
2021-03-14 23:00:25 | INFO | train_inner | epoch 002:   5967 / 20258 loss=3.762, nll_loss=2.091, ppl=4.26, wps=27784.4, ups=0.55, wpb=50713.1, bsz=3085.6, num_updates=26200, lr=0.000351659, gnorm=0.401, loss_scale=1, train_wall=179, wall=48380
2021-03-14 23:03:27 | INFO | train_inner | epoch 002:   6067 / 20258 loss=3.782, nll_loss=2.113, ppl=4.32, wps=27916.5, ups=0.55, wpb=50977.1, bsz=3027.3, num_updates=26300, lr=0.00035099, gnorm=0.324, loss_scale=1, train_wall=179, wall=48563
2021-03-14 23:06:30 | INFO | train_inner | epoch 002:   6167 / 20258 loss=3.763, nll_loss=2.091, ppl=4.26, wps=27892.5, ups=0.55, wpb=50821.9, bsz=3071.9, num_updates=26400, lr=0.000350325, gnorm=0.309, loss_scale=1, train_wall=179, wall=48745
2021-03-14 23:09:32 | INFO | train_inner | epoch 002:   6267 / 20258 loss=3.777, nll_loss=2.108, ppl=4.31, wps=27885.2, ups=0.55, wpb=50816.6, bsz=2972.3, num_updates=26500, lr=0.000349663, gnorm=0.3, loss_scale=1, train_wall=179, wall=48927
2021-03-14 23:12:34 | INFO | train_inner | epoch 002:   6367 / 20258 loss=3.769, nll_loss=2.097, ppl=4.28, wps=27920.6, ups=0.55, wpb=50947.8, bsz=2925.2, num_updates=26600, lr=0.000349005, gnorm=0.315, loss_scale=2, train_wall=180, wall=49110
2021-03-14 23:13:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-14 23:14:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2021-03-14 23:15:40 | INFO | train_inner | epoch 002:   6469 / 20258 loss=3.771, nll_loss=2.102, ppl=4.29, wps=27254.9, ups=0.54, wpb=50673.2, bsz=3012, num_updates=26700, lr=0.000348351, gnorm=0.328, loss_scale=0.5, train_wall=183, wall=49296
2021-03-14 23:18:42 | INFO | train_inner | epoch 002:   6569 / 20258 loss=3.774, nll_loss=2.104, ppl=4.3, wps=27928.4, ups=0.55, wpb=50799.8, bsz=2963.8, num_updates=26800, lr=0.0003477, gnorm=0.32, loss_scale=0.5, train_wall=179, wall=49478
2021-03-14 23:21:45 | INFO | train_inner | epoch 002:   6669 / 20258 loss=3.765, nll_loss=2.095, ppl=4.27, wps=27764.5, ups=0.55, wpb=50741.8, bsz=2987.9, num_updates=26900, lr=0.000347053, gnorm=0.34, loss_scale=0.5, train_wall=179, wall=49660
2021-03-14 23:24:48 | INFO | train_inner | epoch 002:   6769 / 20258 loss=3.771, nll_loss=2.101, ppl=4.29, wps=27901.3, ups=0.55, wpb=50964.2, bsz=2989.2, num_updates=27000, lr=0.00034641, gnorm=0.515, loss_scale=0.5, train_wall=180, wall=49843
2021-03-14 23:27:49 | INFO | train_inner | epoch 002:   6869 / 20258 loss=3.779, nll_loss=2.109, ppl=4.31, wps=27851.5, ups=0.55, wpb=50586.6, bsz=2927.5, num_updates=27100, lr=0.00034577, gnorm=0.328, loss_scale=0.5, train_wall=178, wall=50025
2021-03-14 23:30:51 | INFO | train_inner | epoch 002:   6969 / 20258 loss=3.767, nll_loss=2.096, ppl=4.28, wps=27921.5, ups=0.55, wpb=50891, bsz=2923.7, num_updates=27200, lr=0.000345134, gnorm=0.352, loss_scale=0.5, train_wall=179, wall=50207
2021-03-14 23:33:54 | INFO | train_inner | epoch 002:   7069 / 20258 loss=3.767, nll_loss=2.097, ppl=4.28, wps=27876.6, ups=0.55, wpb=50980.8, bsz=3091.1, num_updates=27300, lr=0.000344502, gnorm=0.317, loss_scale=0.5, train_wall=180, wall=50390
2021-03-14 23:36:57 | INFO | train_inner | epoch 002:   7169 / 20258 loss=3.759, nll_loss=2.088, ppl=4.25, wps=27694.3, ups=0.55, wpb=50483.3, bsz=2879.3, num_updates=27400, lr=0.000343872, gnorm=0.314, loss_scale=0.5, train_wall=179, wall=50572
2021-03-14 23:39:59 | INFO | train_inner | epoch 002:   7269 / 20258 loss=3.757, nll_loss=2.086, ppl=4.24, wps=27872.2, ups=0.55, wpb=50932.3, bsz=3039.4, num_updates=27500, lr=0.000343247, gnorm=0.316, loss_scale=0.5, train_wall=179, wall=50755
2021-03-14 23:43:02 | INFO | train_inner | epoch 002:   7369 / 20258 loss=3.77, nll_loss=2.101, ppl=4.29, wps=27853.4, ups=0.55, wpb=50738.3, bsz=3130.7, num_updates=27600, lr=0.000342624, gnorm=0.307, loss_scale=0.5, train_wall=179, wall=50937
2021-03-14 23:46:05 | INFO | train_inner | epoch 002:   7469 / 20258 loss=3.757, nll_loss=2.086, ppl=4.25, wps=27842.9, ups=0.55, wpb=51024.3, bsz=3092.2, num_updates=27700, lr=0.000342005, gnorm=0.305, loss_scale=1, train_wall=180, wall=51120
2021-03-14 23:49:09 | INFO | train_inner | epoch 002:   7569 / 20258 loss=3.742, nll_loss=2.069, ppl=4.19, wps=27799.3, ups=0.54, wpb=51078.1, bsz=3032.2, num_updates=27800, lr=0.000341389, gnorm=0.303, loss_scale=1, train_wall=180, wall=51304
2021-03-14 23:52:11 | INFO | train_inner | epoch 002:   7669 / 20258 loss=3.777, nll_loss=2.108, ppl=4.31, wps=27862.6, ups=0.55, wpb=50707.2, bsz=2862.6, num_updates=27900, lr=0.000340777, gnorm=0.307, loss_scale=1, train_wall=179, wall=51486
2021-03-14 23:55:13 | INFO | train_inner | epoch 002:   7769 / 20258 loss=3.746, nll_loss=2.073, ppl=4.21, wps=27765.4, ups=0.55, wpb=50586.8, bsz=2927.5, num_updates=28000, lr=0.000340168, gnorm=0.331, loss_scale=1, train_wall=179, wall=51668
2021-03-14 23:58:15 | INFO | train_inner | epoch 002:   7869 / 20258 loss=3.755, nll_loss=2.084, ppl=4.24, wps=27925, ups=0.55, wpb=50925, bsz=3007.5, num_updates=28100, lr=0.000339562, gnorm=0.304, loss_scale=1, train_wall=179, wall=51851
2021-03-15 00:01:17 | INFO | train_inner | epoch 002:   7969 / 20258 loss=3.753, nll_loss=2.081, ppl=4.23, wps=27919.7, ups=0.55, wpb=50878.3, bsz=3067.3, num_updates=28200, lr=0.00033896, gnorm=0.324, loss_scale=1, train_wall=179, wall=52033
2021-03-15 00:04:20 | INFO | train_inner | epoch 002:   8069 / 20258 loss=3.75, nll_loss=2.079, ppl=4.22, wps=27938, ups=0.55, wpb=51041.9, bsz=3103.8, num_updates=28300, lr=0.00033836, gnorm=0.297, loss_scale=1, train_wall=180, wall=52216
2021-03-15 00:07:22 | INFO | train_inner | epoch 002:   8169 / 20258 loss=3.769, nll_loss=2.1, ppl=4.29, wps=27926.5, ups=0.55, wpb=50942.9, bsz=3036.4, num_updates=28400, lr=0.000337764, gnorm=0.306, loss_scale=1, train_wall=179, wall=52398
2021-03-15 00:10:25 | INFO | train_inner | epoch 002:   8269 / 20258 loss=3.752, nll_loss=2.081, ppl=4.23, wps=27883.3, ups=0.55, wpb=50908.8, bsz=3025.8, num_updates=28500, lr=0.000337171, gnorm=0.431, loss_scale=1, train_wall=180, wall=52581
2021-03-15 00:13:28 | INFO | train_inner | epoch 002:   8369 / 20258 loss=3.75, nll_loss=2.078, ppl=4.22, wps=27828.6, ups=0.55, wpb=50799.3, bsz=3021.1, num_updates=28600, lr=0.000336581, gnorm=0.299, loss_scale=1, train_wall=179, wall=52763
2021-03-15 00:16:31 | INFO | train_inner | epoch 002:   8469 / 20258 loss=3.736, nll_loss=2.063, ppl=4.18, wps=27894.7, ups=0.55, wpb=51130, bsz=3051.5, num_updates=28700, lr=0.000335994, gnorm=0.304, loss_scale=2, train_wall=180, wall=52946
2021-03-15 00:19:33 | INFO | train_inner | epoch 002:   8569 / 20258 loss=3.755, nll_loss=2.084, ppl=4.24, wps=27851.4, ups=0.55, wpb=50676.8, bsz=2943.6, num_updates=28800, lr=0.00033541, gnorm=0.3, loss_scale=2, train_wall=179, wall=53128
2021-03-15 00:22:35 | INFO | train_inner | epoch 002:   8669 / 20258 loss=3.751, nll_loss=2.079, ppl=4.22, wps=27913.4, ups=0.55, wpb=50880.2, bsz=3006.6, num_updates=28900, lr=0.000334829, gnorm=0.31, loss_scale=2, train_wall=179, wall=53311
2021-03-15 00:25:37 | INFO | train_inner | epoch 002:   8769 / 20258 loss=3.763, nll_loss=2.092, ppl=4.26, wps=27925.4, ups=0.55, wpb=50837.1, bsz=2907, num_updates=29000, lr=0.000334252, gnorm=0.307, loss_scale=2, train_wall=179, wall=53493
2021-03-15 00:28:39 | INFO | train_inner | epoch 002:   8869 / 20258 loss=3.742, nll_loss=2.069, ppl=4.2, wps=27816, ups=0.55, wpb=50645.7, bsz=3027.4, num_updates=29100, lr=0.000333677, gnorm=0.303, loss_scale=2, train_wall=179, wall=53675
2021-03-15 00:31:42 | INFO | train_inner | epoch 002:   8969 / 20258 loss=3.76, nll_loss=2.089, ppl=4.25, wps=27829.8, ups=0.55, wpb=50813.9, bsz=2949, num_updates=29200, lr=0.000333105, gnorm=0.301, loss_scale=2, train_wall=179, wall=53857
2021-03-15 00:34:44 | INFO | train_inner | epoch 002:   9069 / 20258 loss=3.76, nll_loss=2.09, ppl=4.26, wps=27843.9, ups=0.55, wpb=50707.2, bsz=2953, num_updates=29300, lr=0.000332536, gnorm=0.315, loss_scale=2, train_wall=179, wall=54039
2021-03-15 00:37:47 | INFO | train_inner | epoch 002:   9169 / 20258 loss=3.746, nll_loss=2.074, ppl=4.21, wps=28003.4, ups=0.55, wpb=51295.4, bsz=3026.5, num_updates=29400, lr=0.00033197, gnorm=0.307, loss_scale=2, train_wall=180, wall=54223
2021-03-15 00:40:50 | INFO | train_inner | epoch 002:   9269 / 20258 loss=3.745, nll_loss=2.073, ppl=4.21, wps=27960.9, ups=0.55, wpb=51063, bsz=3024.8, num_updates=29500, lr=0.000331407, gnorm=0.298, loss_scale=2, train_wall=179, wall=54405
2021-03-15 00:43:53 | INFO | train_inner | epoch 002:   9369 / 20258 loss=3.754, nll_loss=2.083, ppl=4.24, wps=27879.3, ups=0.55, wpb=51061.9, bsz=2985.4, num_updates=29600, lr=0.000330847, gnorm=0.306, loss_scale=2, train_wall=180, wall=54588
2021-03-15 00:46:56 | INFO | train_inner | epoch 002:   9469 / 20258 loss=3.736, nll_loss=2.064, ppl=4.18, wps=27863.4, ups=0.55, wpb=50990.6, bsz=3157.1, num_updates=29700, lr=0.000330289, gnorm=0.297, loss_scale=2, train_wall=179, wall=54771
2021-03-15 00:49:59 | INFO | train_inner | epoch 002:   9569 / 20258 loss=3.727, nll_loss=2.053, ppl=4.15, wps=27685.2, ups=0.55, wpb=50722.4, bsz=2989, num_updates=29800, lr=0.000329734, gnorm=0.304, loss_scale=4, train_wall=180, wall=54955
2021-03-15 00:53:02 | INFO | train_inner | epoch 002:   9669 / 20258 loss=3.747, nll_loss=2.076, ppl=4.22, wps=27816.8, ups=0.55, wpb=50871.8, bsz=3105, num_updates=29900, lr=0.000329183, gnorm=0.307, loss_scale=4, train_wall=179, wall=55138
2021-03-15 00:56:04 | INFO | train_inner | epoch 002:   9769 / 20258 loss=3.738, nll_loss=2.065, ppl=4.18, wps=27867.4, ups=0.55, wpb=50739, bsz=2974.7, num_updates=30000, lr=0.000328634, gnorm=0.298, loss_scale=4, train_wall=179, wall=55320
2021-03-15 00:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 00:56:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:23 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.153 | nll_loss 2.435 | ppl 5.41 | bleu 27.59 | wps 4330.5 | wpb 2432 | bsz 90.4 | num_updates 30000 | best_loss 4.153
2021-03-15 00:56:23 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 00:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:56:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 00:56:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 00:56:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 00:57:15 | INFO | valid1 | epoch 002 | valid on 'valid1' subset | loss 4.121 | nll_loss 2.424 | ppl 5.37 | bleu 25.97 | wps 4220.9 | wpb 2359.4 | bsz 106.4 | num_updates 30000 | best_loss 4.121
2021-03-15 00:57:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 00:57:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_2_30000.pt (epoch 2 @ 30000 updates, score 4.153) (writing took 6.4138228869996965 seconds)
2021-03-15 01:00:25 | INFO | train_inner | epoch 002:   9869 / 20258 loss=3.747, nll_loss=2.075, ppl=4.21, wps=19543.6, ups=0.38, wpb=50970.8, bsz=2992.2, num_updates=30100, lr=0.000328087, gnorm=0.302, loss_scale=4, train_wall=180, wall=55580
2021-03-15 01:03:27 | INFO | train_inner | epoch 002:   9969 / 20258 loss=3.75, nll_loss=2.079, ppl=4.22, wps=27957.2, ups=0.55, wpb=51035.3, bsz=2899, num_updates=30200, lr=0.000327544, gnorm=0.297, loss_scale=4, train_wall=180, wall=55763
2021-03-15 01:06:30 | INFO | train_inner | epoch 002:  10069 / 20258 loss=3.743, nll_loss=2.072, ppl=4.21, wps=27800.7, ups=0.55, wpb=50864.4, bsz=3231.3, num_updates=30300, lr=0.000327003, gnorm=0.308, loss_scale=4, train_wall=180, wall=55946
2021-03-15 01:09:33 | INFO | train_inner | epoch 002:  10169 / 20258 loss=3.738, nll_loss=2.065, ppl=4.19, wps=27963.5, ups=0.55, wpb=51072.6, bsz=2962.6, num_updates=30400, lr=0.000326464, gnorm=0.322, loss_scale=4, train_wall=180, wall=56129
2021-03-15 01:12:35 | INFO | train_inner | epoch 002:  10269 / 20258 loss=3.739, nll_loss=2.067, ppl=4.19, wps=27878.3, ups=0.55, wpb=50837.8, bsz=3059.8, num_updates=30500, lr=0.000325929, gnorm=0.293, loss_scale=4, train_wall=179, wall=56311
2021-03-15 01:15:38 | INFO | train_inner | epoch 002:  10369 / 20258 loss=3.748, nll_loss=2.078, ppl=4.22, wps=27887.3, ups=0.55, wpb=50940.5, bsz=3136.2, num_updates=30600, lr=0.000325396, gnorm=0.293, loss_scale=4, train_wall=180, wall=56494
2021-03-15 01:18:41 | INFO | train_inner | epoch 002:  10469 / 20258 loss=3.733, nll_loss=2.06, ppl=4.17, wps=27881, ups=0.55, wpb=50932.4, bsz=3011, num_updates=30700, lr=0.000324865, gnorm=0.308, loss_scale=4, train_wall=179, wall=56676
2021-03-15 01:21:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 01:21:44 | INFO | train_inner | epoch 002:  10570 / 20258 loss=3.744, nll_loss=2.072, ppl=4.21, wps=27689.5, ups=0.54, wpb=50851.1, bsz=2939.9, num_updates=30800, lr=0.000324337, gnorm=0.31, loss_scale=4, train_wall=181, wall=56860
2021-03-15 01:24:48 | INFO | train_inner | epoch 002:  10670 / 20258 loss=3.742, nll_loss=2.07, ppl=4.2, wps=27981.7, ups=0.55, wpb=51262.7, bsz=3073, num_updates=30900, lr=0.000323812, gnorm=0.303, loss_scale=4, train_wall=180, wall=57043
2021-03-15 01:27:50 | INFO | train_inner | epoch 002:  10770 / 20258 loss=3.732, nll_loss=2.059, ppl=4.17, wps=27779, ups=0.55, wpb=50679.9, bsz=3002.9, num_updates=31000, lr=0.00032329, gnorm=0.294, loss_scale=4, train_wall=179, wall=57226
2021-03-15 01:30:53 | INFO | train_inner | epoch 002:  10870 / 20258 loss=3.727, nll_loss=2.054, ppl=4.15, wps=27800.1, ups=0.55, wpb=50783.3, bsz=3103.7, num_updates=31100, lr=0.000322769, gnorm=0.301, loss_scale=4, train_wall=179, wall=57408
2021-03-15 01:33:55 | INFO | train_inner | epoch 002:  10970 / 20258 loss=3.751, nll_loss=2.081, ppl=4.23, wps=27947.8, ups=0.55, wpb=51005.1, bsz=3096.9, num_updates=31200, lr=0.000322252, gnorm=0.303, loss_scale=4, train_wall=179, wall=57591
2021-03-15 01:36:58 | INFO | train_inner | epoch 002:  11070 / 20258 loss=3.738, nll_loss=2.066, ppl=4.19, wps=27974, ups=0.55, wpb=51048, bsz=2937.6, num_updates=31300, lr=0.000321737, gnorm=0.297, loss_scale=4, train_wall=179, wall=57773
2021-03-15 01:40:01 | INFO | train_inner | epoch 002:  11170 / 20258 loss=3.723, nll_loss=2.049, ppl=4.14, wps=27823.2, ups=0.55, wpb=50933.6, bsz=3099.3, num_updates=31400, lr=0.000321224, gnorm=0.291, loss_scale=4, train_wall=180, wall=57956
2021-03-15 01:43:03 | INFO | train_inner | epoch 002:  11270 / 20258 loss=3.724, nll_loss=2.05, ppl=4.14, wps=27837.5, ups=0.55, wpb=50849.1, bsz=3001.9, num_updates=31500, lr=0.000320713, gnorm=0.292, loss_scale=4, train_wall=180, wall=58139
2021-03-15 01:46:05 | INFO | train_inner | epoch 002:  11370 / 20258 loss=3.757, nll_loss=2.087, ppl=4.25, wps=27971.9, ups=0.55, wpb=50847.6, bsz=2917.5, num_updates=31600, lr=0.000320206, gnorm=0.312, loss_scale=4, train_wall=179, wall=58321
2021-03-15 01:47:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-15 01:49:10 | INFO | train_inner | epoch 002:  11471 / 20258 loss=3.756, nll_loss=2.086, ppl=4.24, wps=27589.6, ups=0.54, wpb=50922.2, bsz=2960, num_updates=31700, lr=0.0003197, gnorm=0.309, loss_scale=2, train_wall=181, wall=58505
2021-03-15 01:52:13 | INFO | train_inner | epoch 002:  11571 / 20258 loss=3.731, nll_loss=2.058, ppl=4.16, wps=27968.6, ups=0.55, wpb=51124, bsz=2972.6, num_updates=31800, lr=0.000319197, gnorm=0.297, loss_scale=2, train_wall=180, wall=58688
2021-03-15 01:55:15 | INFO | train_inner | epoch 002:  11671 / 20258 loss=3.738, nll_loss=2.066, ppl=4.19, wps=27902.2, ups=0.55, wpb=50914.8, bsz=3058.2, num_updates=31900, lr=0.000318696, gnorm=0.315, loss_scale=2, train_wall=180, wall=58871
2021-03-15 01:58:18 | INFO | train_inner | epoch 002:  11771 / 20258 loss=3.72, nll_loss=2.046, ppl=4.13, wps=27961.5, ups=0.55, wpb=51268.3, bsz=3099.3, num_updates=32000, lr=0.000318198, gnorm=0.302, loss_scale=2, train_wall=180, wall=59054
2021-03-15 02:01:21 | INFO | train_inner | epoch 002:  11871 / 20258 loss=3.733, nll_loss=2.06, ppl=4.17, wps=27885.2, ups=0.55, wpb=50864.9, bsz=2890.5, num_updates=32100, lr=0.000317702, gnorm=0.293, loss_scale=2, train_wall=179, wall=59236
2021-03-15 02:04:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-15 02:04:25 | INFO | train_inner | epoch 002:  11972 / 20258 loss=3.735, nll_loss=2.062, ppl=4.18, wps=27630, ups=0.54, wpb=50983.9, bsz=2926.5, num_updates=32200, lr=0.000317208, gnorm=0.293, loss_scale=1, train_wall=181, wall=59421
2021-03-15 02:07:28 | INFO | train_inner | epoch 002:  12072 / 20258 loss=3.724, nll_loss=2.05, ppl=4.14, wps=27854.9, ups=0.55, wpb=50946.4, bsz=3035.1, num_updates=32300, lr=0.000316717, gnorm=0.288, loss_scale=1, train_wall=180, wall=59604
2021-03-15 02:10:31 | INFO | train_inner | epoch 002:  12172 / 20258 loss=3.725, nll_loss=2.052, ppl=4.15, wps=27912.5, ups=0.55, wpb=50962.1, bsz=2916.2, num_updates=32400, lr=0.000316228, gnorm=0.301, loss_scale=1, train_wall=180, wall=59786
2021-03-15 02:13:33 | INFO | train_inner | epoch 002:  12272 / 20258 loss=3.733, nll_loss=2.06, ppl=4.17, wps=27867.8, ups=0.55, wpb=50777.4, bsz=2996.2, num_updates=32500, lr=0.000315741, gnorm=0.296, loss_scale=1, train_wall=179, wall=59969
2021-03-15 02:16:36 | INFO | train_inner | epoch 002:  12372 / 20258 loss=3.723, nll_loss=2.048, ppl=4.14, wps=27917.6, ups=0.55, wpb=51212.8, bsz=2971.3, num_updates=32600, lr=0.000315256, gnorm=0.299, loss_scale=1, train_wall=180, wall=60152
2021-03-15 02:19:40 | INFO | train_inner | epoch 002:  12472 / 20258 loss=3.732, nll_loss=2.059, ppl=4.17, wps=27933.3, ups=0.55, wpb=51172.4, bsz=3008.7, num_updates=32700, lr=0.000314774, gnorm=0.291, loss_scale=1, train_wall=180, wall=60335
2021-03-15 02:22:43 | INFO | train_inner | epoch 002:  12572 / 20258 loss=3.744, nll_loss=2.074, ppl=4.21, wps=27904.6, ups=0.55, wpb=51065.5, bsz=3089.8, num_updates=32800, lr=0.000314294, gnorm=0.304, loss_scale=1, train_wall=179, wall=60518
2021-03-15 02:25:46 | INFO | train_inner | epoch 002:  12672 / 20258 loss=3.73, nll_loss=2.058, ppl=4.16, wps=27864.3, ups=0.55, wpb=51032.6, bsz=3084.5, num_updates=32900, lr=0.000313816, gnorm=0.296, loss_scale=1, train_wall=180, wall=60701
2021-03-15 02:28:49 | INFO | train_inner | epoch 002:  12772 / 20258 loss=3.72, nll_loss=2.046, ppl=4.13, wps=27871, ups=0.55, wpb=51044.6, bsz=3062.7, num_updates=33000, lr=0.00031334, gnorm=0.311, loss_scale=1, train_wall=180, wall=60884
2021-03-15 02:31:51 | INFO | train_inner | epoch 002:  12872 / 20258 loss=3.731, nll_loss=2.058, ppl=4.17, wps=27952.4, ups=0.55, wpb=50984.4, bsz=2977.6, num_updates=33100, lr=0.000312866, gnorm=0.293, loss_scale=1, train_wall=179, wall=61067
2021-03-15 02:34:54 | INFO | train_inner | epoch 002:  12972 / 20258 loss=3.728, nll_loss=2.055, ppl=4.15, wps=27936.2, ups=0.55, wpb=50886, bsz=2905, num_updates=33200, lr=0.000312395, gnorm=0.295, loss_scale=1, train_wall=179, wall=61249
2021-03-15 02:37:56 | INFO | train_inner | epoch 002:  13072 / 20258 loss=3.712, nll_loss=2.037, ppl=4.1, wps=27865.9, ups=0.55, wpb=50986.3, bsz=2985.4, num_updates=33300, lr=0.000311925, gnorm=0.3, loss_scale=2, train_wall=180, wall=61432
2021-03-15 02:40:59 | INFO | train_inner | epoch 002:  13172 / 20258 loss=3.715, nll_loss=2.04, ppl=4.11, wps=27819.7, ups=0.55, wpb=50803.4, bsz=3001, num_updates=33400, lr=0.000311458, gnorm=0.299, loss_scale=2, train_wall=180, wall=61615
2021-03-15 02:44:02 | INFO | train_inner | epoch 002:  13272 / 20258 loss=3.729, nll_loss=2.056, ppl=4.16, wps=27788.3, ups=0.55, wpb=50747, bsz=2991.3, num_updates=33500, lr=0.000310993, gnorm=0.299, loss_scale=2, train_wall=179, wall=61797
2021-03-15 02:47:04 | INFO | train_inner | epoch 002:  13372 / 20258 loss=3.705, nll_loss=2.03, ppl=4.08, wps=27774.8, ups=0.55, wpb=50621.2, bsz=2996.3, num_updates=33600, lr=0.00031053, gnorm=0.3, loss_scale=2, train_wall=179, wall=61979
2021-03-15 02:50:07 | INFO | train_inner | epoch 002:  13472 / 20258 loss=3.721, nll_loss=2.048, ppl=4.14, wps=27857.6, ups=0.55, wpb=50918.9, bsz=3051.7, num_updates=33700, lr=0.000310068, gnorm=0.298, loss_scale=2, train_wall=179, wall=62162
2021-03-15 02:53:09 | INFO | train_inner | epoch 002:  13572 / 20258 loss=3.726, nll_loss=2.054, ppl=4.15, wps=27907.7, ups=0.55, wpb=50916.3, bsz=3048.2, num_updates=33800, lr=0.000309609, gnorm=0.291, loss_scale=2, train_wall=179, wall=62345
2021-03-15 02:56:12 | INFO | train_inner | epoch 002:  13672 / 20258 loss=3.723, nll_loss=2.051, ppl=4.14, wps=27968, ups=0.55, wpb=51060.9, bsz=3065.4, num_updates=33900, lr=0.000309152, gnorm=0.292, loss_scale=2, train_wall=179, wall=62527
2021-03-15 02:59:14 | INFO | train_inner | epoch 002:  13772 / 20258 loss=3.736, nll_loss=2.065, ppl=4.18, wps=27963.1, ups=0.55, wpb=50941.6, bsz=3079.1, num_updates=34000, lr=0.000308697, gnorm=0.291, loss_scale=2, train_wall=179, wall=62709
2021-03-15 03:02:16 | INFO | train_inner | epoch 002:  13872 / 20258 loss=3.729, nll_loss=2.057, ppl=4.16, wps=27958.4, ups=0.55, wpb=51009.5, bsz=3065.8, num_updates=34100, lr=0.000308244, gnorm=0.294, loss_scale=2, train_wall=179, wall=62892
2021-03-15 03:05:19 | INFO | train_inner | epoch 002:  13972 / 20258 loss=3.706, nll_loss=2.031, ppl=4.09, wps=27956.6, ups=0.55, wpb=51082.2, bsz=3016, num_updates=34200, lr=0.000307794, gnorm=0.307, loss_scale=2, train_wall=180, wall=63075
2021-03-15 03:08:22 | INFO | train_inner | epoch 002:  14072 / 20258 loss=3.7, nll_loss=2.024, ppl=4.07, wps=27839.2, ups=0.55, wpb=50844.5, bsz=3008.8, num_updates=34300, lr=0.000307344, gnorm=0.295, loss_scale=4, train_wall=180, wall=63257
2021-03-15 03:11:24 | INFO | train_inner | epoch 002:  14172 / 20258 loss=3.718, nll_loss=2.045, ppl=4.13, wps=27933.9, ups=0.55, wpb=50844.8, bsz=2982.4, num_updates=34400, lr=0.000306897, gnorm=0.29, loss_scale=4, train_wall=179, wall=63439
2021-03-15 03:13:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-15 03:13:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-15 03:14:29 | INFO | train_inner | epoch 002:  14274 / 20258 loss=3.733, nll_loss=2.061, ppl=4.17, wps=27499, ups=0.54, wpb=50949.2, bsz=2935.9, num_updates=34500, lr=0.000306452, gnorm=0.308, loss_scale=1, train_wall=182, wall=63625
2021-03-15 03:17:32 | INFO | train_inner | epoch 002:  14374 / 20258 loss=3.715, nll_loss=2.041, ppl=4.12, wps=27871.5, ups=0.55, wpb=50894.5, bsz=2943.7, num_updates=34600, lr=0.000306009, gnorm=0.295, loss_scale=1, train_wall=180, wall=63807
2021-03-15 03:20:35 | INFO | train_inner | epoch 002:  14474 / 20258 loss=3.701, nll_loss=2.025, ppl=4.07, wps=27803.1, ups=0.55, wpb=51003.6, bsz=3043.7, num_updates=34700, lr=0.000305568, gnorm=0.298, loss_scale=1, train_wall=180, wall=63991
2021-03-15 03:23:37 | INFO | train_inner | epoch 002:  14574 / 20258 loss=3.703, nll_loss=2.028, ppl=4.08, wps=27796.7, ups=0.55, wpb=50619.9, bsz=3069, num_updates=34800, lr=0.000305129, gnorm=0.3, loss_scale=1, train_wall=179, wall=64173
2021-03-15 03:26:40 | INFO | train_inner | epoch 002:  14674 / 20258 loss=3.723, nll_loss=2.051, ppl=4.14, wps=28000.2, ups=0.55, wpb=51043, bsz=2999.4, num_updates=34900, lr=0.000304691, gnorm=0.301, loss_scale=1, train_wall=179, wall=64355
2021-03-15 03:29:42 | INFO | train_inner | epoch 002:  14774 / 20258 loss=3.708, nll_loss=2.033, ppl=4.09, wps=27948.2, ups=0.55, wpb=50956.9, bsz=3039.4, num_updates=35000, lr=0.000304256, gnorm=0.299, loss_scale=1, train_wall=179, wall=64537
2021-03-15 03:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 03:29:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:29:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:29:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:29:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:29:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:29:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:29:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:29:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:29:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:29:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:29:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:29:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:29:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:29:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:29:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:29:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:29:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:29:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:29:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:29:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:29:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:00 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.129 | nll_loss 2.407 | ppl 5.3 | bleu 27.97 | wps 4361 | wpb 2432 | bsz 90.4 | num_updates 35000 | best_loss 4.129
2021-03-15 03:30:00 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 03:30:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 03:30:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 03:30:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 03:30:54 | INFO | valid1 | epoch 002 | valid on 'valid1' subset | loss 4.098 | nll_loss 2.399 | ppl 5.28 | bleu 26.06 | wps 4150.6 | wpb 2359.4 | bsz 106.4 | num_updates 35000 | best_loss 4.098
2021-03-15 03:30:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 03:31:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_2_35000.pt (epoch 2 @ 35000 updates, score 4.129) (writing took 6.317792800022289 seconds)
2021-03-15 03:34:02 | INFO | train_inner | epoch 002:  14874 / 20258 loss=3.716, nll_loss=2.042, ppl=4.12, wps=19589, ups=0.38, wpb=50999.5, bsz=2960.4, num_updates=35100, lr=0.000303822, gnorm=0.344, loss_scale=1, train_wall=179, wall=64798
2021-03-15 03:37:05 | INFO | train_inner | epoch 002:  14974 / 20258 loss=3.696, nll_loss=2.02, ppl=4.05, wps=27919.2, ups=0.55, wpb=50959.2, bsz=2923.4, num_updates=35200, lr=0.00030339, gnorm=0.322, loss_scale=1, train_wall=180, wall=64980
2021-03-15 03:40:07 | INFO | train_inner | epoch 002:  15074 / 20258 loss=3.702, nll_loss=2.026, ppl=4.07, wps=27742.4, ups=0.55, wpb=50473.3, bsz=3010.4, num_updates=35300, lr=0.00030296, gnorm=0.294, loss_scale=1, train_wall=179, wall=65162
2021-03-15 03:43:09 | INFO | train_inner | epoch 002:  15174 / 20258 loss=3.727, nll_loss=2.054, ppl=4.15, wps=28003.9, ups=0.55, wpb=51006.4, bsz=3017.8, num_updates=35400, lr=0.000302532, gnorm=0.29, loss_scale=1, train_wall=179, wall=65344
2021-03-15 03:46:12 | INFO | train_inner | epoch 002:  15274 / 20258 loss=3.715, nll_loss=2.042, ppl=4.12, wps=27943.8, ups=0.55, wpb=51088.1, bsz=3046.3, num_updates=35500, lr=0.000302105, gnorm=0.289, loss_scale=2, train_wall=180, wall=65527
2021-03-15 03:49:13 | INFO | train_inner | epoch 002:  15374 / 20258 loss=3.72, nll_loss=2.046, ppl=4.13, wps=27872.3, ups=0.55, wpb=50647.2, bsz=2860.1, num_updates=35600, lr=0.000301681, gnorm=0.284, loss_scale=2, train_wall=179, wall=65709
2021-03-15 03:52:16 | INFO | train_inner | epoch 002:  15474 / 20258 loss=3.72, nll_loss=2.047, ppl=4.13, wps=27953.1, ups=0.55, wpb=51102.9, bsz=3067, num_updates=35700, lr=0.000301258, gnorm=0.291, loss_scale=2, train_wall=180, wall=65892
2021-03-15 03:55:18 | INFO | train_inner | epoch 002:  15574 / 20258 loss=3.709, nll_loss=2.035, ppl=4.1, wps=27888.3, ups=0.55, wpb=50746.2, bsz=3061.7, num_updates=35800, lr=0.000300837, gnorm=0.298, loss_scale=2, train_wall=179, wall=66074
2021-03-15 03:58:20 | INFO | train_inner | epoch 002:  15674 / 20258 loss=3.708, nll_loss=2.034, ppl=4.1, wps=27938.9, ups=0.55, wpb=50894.6, bsz=3078.7, num_updates=35900, lr=0.000300418, gnorm=0.292, loss_scale=2, train_wall=179, wall=66256
2021-03-15 04:01:22 | INFO | train_inner | epoch 002:  15774 / 20258 loss=3.753, nll_loss=2.084, ppl=4.24, wps=27943.1, ups=0.55, wpb=50656.6, bsz=2941.8, num_updates=36000, lr=0.0003, gnorm=0.295, loss_scale=2, train_wall=178, wall=66437
2021-03-15 04:04:24 | INFO | train_inner | epoch 002:  15874 / 20258 loss=3.692, nll_loss=2.016, ppl=4.04, wps=27815.8, ups=0.55, wpb=50824.9, bsz=3082.3, num_updates=36100, lr=0.000299584, gnorm=0.288, loss_scale=2, train_wall=180, wall=66620
2021-03-15 04:07:26 | INFO | train_inner | epoch 002:  15974 / 20258 loss=3.694, nll_loss=2.019, ppl=4.05, wps=27805.9, ups=0.55, wpb=50604.3, bsz=3069.8, num_updates=36200, lr=0.00029917, gnorm=0.291, loss_scale=2, train_wall=179, wall=66802
2021-03-15 04:10:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-15 04:10:30 | INFO | train_inner | epoch 002:  16075 / 20258 loss=3.725, nll_loss=2.053, ppl=4.15, wps=27728.1, ups=0.54, wpb=50925.3, bsz=3106.8, num_updates=36300, lr=0.000298758, gnorm=0.354, loss_scale=1, train_wall=181, wall=66985
2021-03-15 04:13:32 | INFO | train_inner | epoch 002:  16175 / 20258 loss=3.732, nll_loss=2.061, ppl=4.17, wps=28024.4, ups=0.55, wpb=51066.2, bsz=2936.6, num_updates=36400, lr=0.000298347, gnorm=0.318, loss_scale=1, train_wall=179, wall=67168
2021-03-15 04:16:35 | INFO | train_inner | epoch 002:  16275 / 20258 loss=3.719, nll_loss=2.046, ppl=4.13, wps=27974.4, ups=0.55, wpb=51025.3, bsz=3052.7, num_updates=36500, lr=0.000297938, gnorm=0.294, loss_scale=1, train_wall=179, wall=67350
2021-03-15 04:19:36 | INFO | train_inner | epoch 002:  16375 / 20258 loss=3.72, nll_loss=2.047, ppl=4.13, wps=27978.3, ups=0.55, wpb=50810.1, bsz=2931.7, num_updates=36600, lr=0.000297531, gnorm=0.287, loss_scale=1, train_wall=179, wall=67532
2021-03-15 04:22:38 | INFO | train_inner | epoch 002:  16475 / 20258 loss=3.703, nll_loss=2.029, ppl=4.08, wps=27924.9, ups=0.55, wpb=50898.9, bsz=3037, num_updates=36700, lr=0.000297125, gnorm=0.288, loss_scale=1, train_wall=179, wall=67714
2021-03-15 04:25:40 | INFO | train_inner | epoch 002:  16575 / 20258 loss=3.704, nll_loss=2.029, ppl=4.08, wps=27854.5, ups=0.55, wpb=50592.5, bsz=3051.4, num_updates=36800, lr=0.000296721, gnorm=0.356, loss_scale=1, train_wall=179, wall=67896
2021-03-15 04:28:43 | INFO | train_inner | epoch 002:  16675 / 20258 loss=3.695, nll_loss=2.019, ppl=4.05, wps=27926.3, ups=0.55, wpb=51047.6, bsz=3019.3, num_updates=36900, lr=0.000296319, gnorm=0.291, loss_scale=1, train_wall=180, wall=68078
2021-03-15 04:31:46 | INFO | train_inner | epoch 002:  16775 / 20258 loss=3.699, nll_loss=2.023, ppl=4.07, wps=27809.3, ups=0.55, wpb=50885, bsz=2965.6, num_updates=37000, lr=0.000295918, gnorm=0.291, loss_scale=1, train_wall=179, wall=68261
2021-03-15 04:34:48 | INFO | train_inner | epoch 002:  16875 / 20258 loss=3.696, nll_loss=2.02, ppl=4.06, wps=27874.7, ups=0.55, wpb=50849.6, bsz=2970.4, num_updates=37100, lr=0.000295519, gnorm=0.295, loss_scale=1, train_wall=179, wall=68444
2021-03-15 04:37:51 | INFO | train_inner | epoch 002:  16975 / 20258 loss=3.704, nll_loss=2.029, ppl=4.08, wps=27879.5, ups=0.55, wpb=50852.6, bsz=2921.7, num_updates=37200, lr=0.000295122, gnorm=0.296, loss_scale=1, train_wall=179, wall=68626
2021-03-15 04:40:54 | INFO | train_inner | epoch 002:  17075 / 20258 loss=3.712, nll_loss=2.039, ppl=4.11, wps=27951.8, ups=0.55, wpb=51195.2, bsz=3056.6, num_updates=37300, lr=0.000294726, gnorm=0.284, loss_scale=1, train_wall=180, wall=68809
2021-03-15 04:43:56 | INFO | train_inner | epoch 002:  17175 / 20258 loss=3.705, nll_loss=2.031, ppl=4.09, wps=27851.7, ups=0.55, wpb=50717.3, bsz=3013, num_updates=37400, lr=0.000294331, gnorm=0.3, loss_scale=2, train_wall=179, wall=68991
2021-03-15 04:46:58 | INFO | train_inner | epoch 002:  17275 / 20258 loss=3.722, nll_loss=2.051, ppl=4.14, wps=27849.8, ups=0.55, wpb=50731.3, bsz=3058.2, num_updates=37500, lr=0.000293939, gnorm=0.289, loss_scale=2, train_wall=179, wall=69174
2021-03-15 04:50:01 | INFO | train_inner | epoch 002:  17375 / 20258 loss=3.699, nll_loss=2.024, ppl=4.07, wps=27767.9, ups=0.55, wpb=50715.1, bsz=3011.4, num_updates=37600, lr=0.000293548, gnorm=0.289, loss_scale=2, train_wall=179, wall=69356
2021-03-15 04:53:03 | INFO | train_inner | epoch 002:  17475 / 20258 loss=3.715, nll_loss=2.042, ppl=4.12, wps=27790, ups=0.55, wpb=50792, bsz=3077.3, num_updates=37700, lr=0.000293158, gnorm=0.289, loss_scale=2, train_wall=179, wall=69539
2021-03-15 04:56:06 | INFO | train_inner | epoch 002:  17575 / 20258 loss=3.696, nll_loss=2.02, ppl=4.06, wps=27895.8, ups=0.55, wpb=50909, bsz=2991.9, num_updates=37800, lr=0.00029277, gnorm=0.285, loss_scale=2, train_wall=179, wall=69722
2021-03-15 04:59:08 | INFO | train_inner | epoch 002:  17675 / 20258 loss=3.71, nll_loss=2.037, ppl=4.1, wps=27850.7, ups=0.55, wpb=50652.7, bsz=3052, num_updates=37900, lr=0.000292384, gnorm=0.292, loss_scale=2, train_wall=179, wall=69903
2021-03-15 05:02:10 | INFO | train_inner | epoch 002:  17775 / 20258 loss=3.713, nll_loss=2.04, ppl=4.11, wps=27823.2, ups=0.55, wpb=50788.6, bsz=3000.2, num_updates=38000, lr=0.000291999, gnorm=0.286, loss_scale=2, train_wall=179, wall=70086
2021-03-15 05:05:13 | INFO | train_inner | epoch 002:  17875 / 20258 loss=3.696, nll_loss=2.021, ppl=4.06, wps=27866.5, ups=0.55, wpb=50859.3, bsz=2982.7, num_updates=38100, lr=0.000291615, gnorm=0.283, loss_scale=2, train_wall=179, wall=70268
2021-03-15 05:08:16 | INFO | train_inner | epoch 002:  17975 / 20258 loss=3.71, nll_loss=2.036, ppl=4.1, wps=27781.8, ups=0.55, wpb=50726.8, bsz=2969.4, num_updates=38200, lr=0.000291233, gnorm=0.3, loss_scale=2, train_wall=179, wall=70451
2021-03-15 05:11:18 | INFO | train_inner | epoch 002:  18075 / 20258 loss=3.698, nll_loss=2.023, ppl=4.07, wps=27866.2, ups=0.55, wpb=50954.9, bsz=3126.1, num_updates=38300, lr=0.000290853, gnorm=0.288, loss_scale=2, train_wall=180, wall=70634
2021-03-15 05:14:20 | INFO | train_inner | epoch 002:  18175 / 20258 loss=3.7, nll_loss=2.026, ppl=4.07, wps=27832.5, ups=0.55, wpb=50666.2, bsz=2943.8, num_updates=38400, lr=0.000290474, gnorm=0.285, loss_scale=4, train_wall=179, wall=70816
2021-03-15 05:17:24 | INFO | train_inner | epoch 002:  18275 / 20258 loss=3.704, nll_loss=2.03, ppl=4.08, wps=27939.6, ups=0.55, wpb=51183.8, bsz=3046.4, num_updates=38500, lr=0.000290096, gnorm=0.279, loss_scale=4, train_wall=180, wall=70999
2021-03-15 05:20:26 | INFO | train_inner | epoch 002:  18375 / 20258 loss=3.699, nll_loss=2.024, ppl=4.07, wps=27822.1, ups=0.55, wpb=50843.7, bsz=2992.1, num_updates=38600, lr=0.00028972, gnorm=0.291, loss_scale=4, train_wall=180, wall=71182
2021-03-15 05:23:29 | INFO | train_inner | epoch 002:  18475 / 20258 loss=3.698, nll_loss=2.023, ppl=4.07, wps=27893.5, ups=0.55, wpb=50963.3, bsz=3017.3, num_updates=38700, lr=0.000289346, gnorm=0.287, loss_scale=4, train_wall=179, wall=71365
2021-03-15 05:26:32 | INFO | train_inner | epoch 002:  18575 / 20258 loss=3.69, nll_loss=2.015, ppl=4.04, wps=27900.9, ups=0.55, wpb=50976.9, bsz=3091.8, num_updates=38800, lr=0.000288973, gnorm=0.287, loss_scale=4, train_wall=180, wall=71547
2021-03-15 05:29:35 | INFO | train_inner | epoch 002:  18675 / 20258 loss=3.691, nll_loss=2.016, ppl=4.04, wps=27899.9, ups=0.55, wpb=51040.8, bsz=2980, num_updates=38900, lr=0.000288601, gnorm=0.311, loss_scale=4, train_wall=180, wall=71730
2021-03-15 05:32:37 | INFO | train_inner | epoch 002:  18775 / 20258 loss=3.719, nll_loss=2.047, ppl=4.13, wps=28000.7, ups=0.55, wpb=51048.9, bsz=3008.6, num_updates=39000, lr=0.000288231, gnorm=0.279, loss_scale=4, train_wall=179, wall=71913
2021-03-15 05:35:41 | INFO | train_inner | epoch 002:  18875 / 20258 loss=3.701, nll_loss=2.027, ppl=4.07, wps=27875.7, ups=0.54, wpb=51199.2, bsz=2958, num_updates=39100, lr=0.000287862, gnorm=0.281, loss_scale=4, train_wall=180, wall=72096
2021-03-15 05:38:44 | INFO | train_inner | epoch 002:  18975 / 20258 loss=3.681, nll_loss=2.004, ppl=4.01, wps=27912.2, ups=0.55, wpb=51105.6, bsz=3090.6, num_updates=39200, lr=0.000287494, gnorm=0.283, loss_scale=4, train_wall=180, wall=72279
2021-03-15 05:41:46 | INFO | train_inner | epoch 002:  19075 / 20258 loss=3.693, nll_loss=2.018, ppl=4.05, wps=27852.9, ups=0.55, wpb=50628.6, bsz=2969.3, num_updates=39300, lr=0.000287128, gnorm=0.303, loss_scale=4, train_wall=179, wall=72461
2021-03-15 05:44:48 | INFO | train_inner | epoch 002:  19175 / 20258 loss=3.695, nll_loss=2.02, ppl=4.06, wps=27934.6, ups=0.55, wpb=50998.5, bsz=3117.8, num_updates=39400, lr=0.000286764, gnorm=0.31, loss_scale=8, train_wall=180, wall=72644
2021-03-15 05:47:50 | INFO | train_inner | epoch 002:  19275 / 20258 loss=3.69, nll_loss=2.014, ppl=4.04, wps=27846.1, ups=0.55, wpb=50748.1, bsz=2976.7, num_updates=39500, lr=0.000286401, gnorm=0.288, loss_scale=8, train_wall=179, wall=72826
2021-03-15 05:50:53 | INFO | train_inner | epoch 002:  19375 / 20258 loss=3.688, nll_loss=2.012, ppl=4.03, wps=27844.6, ups=0.55, wpb=50873, bsz=3015.7, num_updates=39600, lr=0.000286039, gnorm=0.293, loss_scale=8, train_wall=179, wall=73009
2021-03-15 05:53:56 | INFO | train_inner | epoch 002:  19475 / 20258 loss=3.704, nll_loss=2.031, ppl=4.09, wps=27916.2, ups=0.55, wpb=50963.4, bsz=3017.9, num_updates=39700, lr=0.000285678, gnorm=0.279, loss_scale=8, train_wall=179, wall=73191
2021-03-15 05:56:58 | INFO | train_inner | epoch 002:  19575 / 20258 loss=3.697, nll_loss=2.022, ppl=4.06, wps=28006.1, ups=0.55, wpb=51137.4, bsz=2957, num_updates=39800, lr=0.000285319, gnorm=0.289, loss_scale=8, train_wall=180, wall=73374
2021-03-15 06:00:00 | INFO | train_inner | epoch 002:  19675 / 20258 loss=3.7, nll_loss=2.025, ppl=4.07, wps=27994.6, ups=0.55, wpb=50880.5, bsz=2922.7, num_updates=39900, lr=0.000284961, gnorm=0.284, loss_scale=8, train_wall=179, wall=73556
2021-03-15 06:03:03 | INFO | train_inner | epoch 002:  19775 / 20258 loss=3.68, nll_loss=2.003, ppl=4.01, wps=27914.3, ups=0.55, wpb=50978.3, bsz=3016, num_updates=40000, lr=0.000284605, gnorm=0.289, loss_scale=8, train_wall=180, wall=73738
2021-03-15 06:03:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 06:03:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:21 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.099 | nll_loss 2.38 | ppl 5.2 | bleu 28.28 | wps 4321.4 | wpb 2432 | bsz 90.4 | num_updates 40000 | best_loss 4.099
2021-03-15 06:03:21 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 06:03:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:03:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:03:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:03:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:04:14 | INFO | valid1 | epoch 002 | valid on 'valid1' subset | loss 4.07 | nll_loss 2.373 | ppl 5.18 | bleu 26.49 | wps 4198.6 | wpb 2359.4 | bsz 106.4 | num_updates 40000 | best_loss 4.07
2021-03-15 06:04:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 06:04:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_2_40000.pt (epoch 2 @ 40000 updates, score 4.099) (writing took 6.286315233912319 seconds)
2021-03-15 06:07:23 | INFO | train_inner | epoch 002:  19875 / 20258 loss=3.689, nll_loss=2.013, ppl=4.04, wps=19498.4, ups=0.38, wpb=50709.8, bsz=2911.5, num_updates=40100, lr=0.00028425, gnorm=0.291, loss_scale=8, train_wall=179, wall=73998
2021-03-15 06:10:25 | INFO | train_inner | epoch 002:  19975 / 20258 loss=3.703, nll_loss=2.03, ppl=4.08, wps=27941.4, ups=0.55, wpb=50924, bsz=2988.7, num_updates=40200, lr=0.000283896, gnorm=0.311, loss_scale=8, train_wall=179, wall=74180
2021-03-15 06:11:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 06:13:29 | INFO | train_inner | epoch 002:  20076 / 20258 loss=3.671, nll_loss=1.993, ppl=3.98, wps=27547.5, ups=0.54, wpb=50792.7, bsz=3041.6, num_updates=40300, lr=0.000283544, gnorm=0.317, loss_scale=4, train_wall=181, wall=74365
2021-03-15 06:16:32 | INFO | train_inner | epoch 002:  20176 / 20258 loss=3.689, nll_loss=2.013, ppl=4.04, wps=27861.7, ups=0.55, wpb=50937.5, bsz=3014.3, num_updates=40400, lr=0.000283193, gnorm=0.284, loss_scale=4, train_wall=179, wall=74548
2021-03-15 06:19:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 06:19:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.103 | nll_loss 2.382 | ppl 5.21 | bleu 27.94 | wps 4419.4 | wpb 2432 | bsz 90.4 | num_updates 40482 | best_loss 4.099
2021-03-15 06:19:20 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 06:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 06:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 06:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 06:20:13 | INFO | valid1 | epoch 002 | valid on 'valid1' subset | loss 4.081 | nll_loss 2.381 | ppl 5.21 | bleu 26.09 | wps 4251.9 | wpb 2359.4 | bsz 106.4 | num_updates 40482 | best_loss 4.081
2021-03-15 06:20:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 06:20:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint2.pt (epoch 2 @ 40482 updates, score 4.103) (writing took 4.46414773282595 seconds)
2021-03-15 06:20:17 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-03-15 06:20:17 | INFO | train | epoch 002 | loss 3.749 | nll_loss 2.077 | ppl 4.22 | wps 27580.7 | ups 0.54 | wpb 50906.3 | bsz 3010.3 | num_updates 40482 | lr 0.000282906 | gnorm 0.311 | loss_scale 4 | train_wall 36330 | wall 74773
2021-03-15 06:20:17 | INFO | fairseq.trainer | begin training epoch 3
2021-03-15 06:20:50 | INFO | train_inner | epoch 003:     18 / 20258 loss=3.676, nll_loss=1.999, ppl=4, wps=19773.1, ups=0.39, wpb=50973.4, bsz=3030.1, num_updates=40500, lr=0.000282843, gnorm=0.297, loss_scale=4, train_wall=180, wall=74805
2021-03-15 06:23:53 | INFO | train_inner | epoch 003:    118 / 20258 loss=3.661, nll_loss=1.981, ppl=3.95, wps=27916.4, ups=0.55, wpb=50983.7, bsz=3007.8, num_updates=40600, lr=0.000282494, gnorm=0.274, loss_scale=4, train_wall=180, wall=74988
2021-03-15 06:26:55 | INFO | train_inner | epoch 003:    218 / 20258 loss=3.661, nll_loss=1.982, ppl=3.95, wps=27853.6, ups=0.55, wpb=50768.9, bsz=3029.7, num_updates=40700, lr=0.000282147, gnorm=0.294, loss_scale=4, train_wall=179, wall=75170
2021-03-15 06:29:57 | INFO | train_inner | epoch 003:    318 / 20258 loss=3.67, nll_loss=1.991, ppl=3.98, wps=27955.8, ups=0.55, wpb=50968.3, bsz=2955.6, num_updates=40800, lr=0.000281801, gnorm=0.274, loss_scale=4, train_wall=179, wall=75353
2021-03-15 06:32:59 | INFO | train_inner | epoch 003:    418 / 20258 loss=3.682, nll_loss=2.006, ppl=4.02, wps=27911.4, ups=0.55, wpb=50887.7, bsz=3049, num_updates=40900, lr=0.000281456, gnorm=0.287, loss_scale=4, train_wall=179, wall=75535
2021-03-15 06:36:02 | INFO | train_inner | epoch 003:    518 / 20258 loss=3.668, nll_loss=1.99, ppl=3.97, wps=27826.6, ups=0.55, wpb=50854.6, bsz=3235.4, num_updates=41000, lr=0.000281113, gnorm=0.286, loss_scale=4, train_wall=179, wall=75718
2021-03-15 06:39:04 | INFO | train_inner | epoch 003:    618 / 20258 loss=3.686, nll_loss=2.009, ppl=4.03, wps=27813, ups=0.55, wpb=50583.2, bsz=2848.2, num_updates=41100, lr=0.000280771, gnorm=0.287, loss_scale=4, train_wall=179, wall=75900
2021-03-15 06:42:07 | INFO | train_inner | epoch 003:    718 / 20258 loss=3.667, nll_loss=1.988, ppl=3.97, wps=27993.1, ups=0.55, wpb=51074, bsz=3021.2, num_updates=41200, lr=0.00028043, gnorm=0.29, loss_scale=4, train_wall=180, wall=76082
2021-03-15 06:45:10 | INFO | train_inner | epoch 003:    818 / 20258 loss=3.673, nll_loss=1.995, ppl=3.99, wps=27852.2, ups=0.54, wpb=51202, bsz=3118.3, num_updates=41300, lr=0.00028009, gnorm=0.294, loss_scale=8, train_wall=180, wall=76266
2021-03-15 06:48:13 | INFO | train_inner | epoch 003:    918 / 20258 loss=3.679, nll_loss=2.002, ppl=4.01, wps=27811.4, ups=0.55, wpb=50681.9, bsz=3013.3, num_updates=41400, lr=0.000279751, gnorm=0.282, loss_scale=8, train_wall=179, wall=76448
2021-03-15 06:51:15 | INFO | train_inner | epoch 003:   1018 / 20258 loss=3.677, nll_loss=1.999, ppl=4, wps=27932.2, ups=0.55, wpb=50838.9, bsz=2925.8, num_updates=41500, lr=0.000279414, gnorm=0.283, loss_scale=8, train_wall=179, wall=76630
2021-03-15 06:54:17 | INFO | train_inner | epoch 003:   1118 / 20258 loss=3.673, nll_loss=1.995, ppl=3.99, wps=27946.7, ups=0.55, wpb=51078, bsz=2990.7, num_updates=41600, lr=0.000279078, gnorm=0.292, loss_scale=8, train_wall=180, wall=76813
2021-03-15 06:57:21 | INFO | train_inner | epoch 003:   1218 / 20258 loss=3.66, nll_loss=1.981, ppl=3.95, wps=27730.3, ups=0.55, wpb=50801.2, bsz=3087.6, num_updates=41700, lr=0.000278743, gnorm=0.281, loss_scale=8, train_wall=180, wall=76996
2021-03-15 07:00:23 | INFO | train_inner | epoch 003:   1318 / 20258 loss=3.686, nll_loss=2.01, ppl=4.03, wps=27944.9, ups=0.55, wpb=51055, bsz=3001.7, num_updates=41800, lr=0.00027841, gnorm=0.284, loss_scale=8, train_wall=179, wall=77179
2021-03-15 07:03:25 | INFO | train_inner | epoch 003:   1418 / 20258 loss=3.69, nll_loss=2.015, ppl=4.04, wps=27990.2, ups=0.55, wpb=50963.7, bsz=3048.8, num_updates=41900, lr=0.000278077, gnorm=0.283, loss_scale=8, train_wall=179, wall=77361
2021-03-15 07:06:27 | INFO | train_inner | epoch 003:   1518 / 20258 loss=3.659, nll_loss=1.98, ppl=3.94, wps=27924.3, ups=0.55, wpb=50829.8, bsz=3023, num_updates=42000, lr=0.000277746, gnorm=0.283, loss_scale=8, train_wall=179, wall=77543
2021-03-15 07:09:30 | INFO | train_inner | epoch 003:   1618 / 20258 loss=3.676, nll_loss=1.999, ppl=4, wps=27819.7, ups=0.55, wpb=50766.2, bsz=2997.5, num_updates=42100, lr=0.000277416, gnorm=0.283, loss_scale=8, train_wall=179, wall=77725
2021-03-15 07:12:32 | INFO | train_inner | epoch 003:   1718 / 20258 loss=3.668, nll_loss=1.989, ppl=3.97, wps=27987.7, ups=0.55, wpb=51101.7, bsz=2982.2, num_updates=42200, lr=0.000277087, gnorm=0.276, loss_scale=8, train_wall=179, wall=77908
2021-03-15 07:14:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 07:15:37 | INFO | train_inner | epoch 003:   1819 / 20258 loss=3.663, nll_loss=1.984, ppl=3.96, wps=27507.2, ups=0.54, wpb=50771.5, bsz=3016.3, num_updates=42300, lr=0.000276759, gnorm=0.291, loss_scale=8, train_wall=181, wall=78093
2021-03-15 07:18:40 | INFO | train_inner | epoch 003:   1919 / 20258 loss=3.687, nll_loss=2.012, ppl=4.03, wps=27885.1, ups=0.55, wpb=50983.8, bsz=3043.3, num_updates=42400, lr=0.000276433, gnorm=0.276, loss_scale=8, train_wall=180, wall=78275
2021-03-15 07:21:42 | INFO | train_inner | epoch 003:   2019 / 20258 loss=3.678, nll_loss=2, ppl=4, wps=28064.5, ups=0.55, wpb=51237.4, bsz=2972.7, num_updates=42500, lr=0.000276107, gnorm=0.295, loss_scale=8, train_wall=180, wall=78458
2021-03-15 07:24:45 | INFO | train_inner | epoch 003:   2119 / 20258 loss=3.668, nll_loss=1.99, ppl=3.97, wps=27896.4, ups=0.55, wpb=51055.2, bsz=3073.2, num_updates=42600, lr=0.000275783, gnorm=0.281, loss_scale=8, train_wall=180, wall=78641
2021-03-15 07:27:48 | INFO | train_inner | epoch 003:   2219 / 20258 loss=3.67, nll_loss=1.992, ppl=3.98, wps=27831.4, ups=0.55, wpb=50870.5, bsz=3049, num_updates=42700, lr=0.00027546, gnorm=0.281, loss_scale=8, train_wall=180, wall=78824
2021-03-15 07:30:51 | INFO | train_inner | epoch 003:   2319 / 20258 loss=3.685, nll_loss=2.01, ppl=4.03, wps=27771.9, ups=0.55, wpb=50728.4, bsz=3022.8, num_updates=42800, lr=0.000275138, gnorm=0.285, loss_scale=8, train_wall=179, wall=79006
2021-03-15 07:33:54 | INFO | train_inner | epoch 003:   2419 / 20258 loss=3.676, nll_loss=1.999, ppl=4, wps=27946.7, ups=0.55, wpb=51119.8, bsz=2998.4, num_updates=42900, lr=0.000274817, gnorm=0.28, loss_scale=8, train_wall=180, wall=79189
2021-03-15 07:36:56 | INFO | train_inner | epoch 003:   2519 / 20258 loss=3.656, nll_loss=1.976, ppl=3.93, wps=27918.1, ups=0.55, wpb=50979.1, bsz=3023.3, num_updates=43000, lr=0.000274497, gnorm=0.283, loss_scale=8, train_wall=179, wall=79372
2021-03-15 07:39:59 | INFO | train_inner | epoch 003:   2619 / 20258 loss=3.672, nll_loss=1.995, ppl=3.99, wps=27920.2, ups=0.55, wpb=50867.9, bsz=3105.8, num_updates=43100, lr=0.000274179, gnorm=0.286, loss_scale=8, train_wall=179, wall=79554
2021-03-15 07:43:01 | INFO | train_inner | epoch 003:   2719 / 20258 loss=3.66, nll_loss=1.981, ppl=3.95, wps=27911.1, ups=0.55, wpb=50915.3, bsz=2906.2, num_updates=43200, lr=0.000273861, gnorm=0.29, loss_scale=8, train_wall=179, wall=79737
2021-03-15 07:46:04 | INFO | train_inner | epoch 003:   2819 / 20258 loss=3.674, nll_loss=1.997, ppl=3.99, wps=27896.2, ups=0.55, wpb=50946.3, bsz=3025.7, num_updates=43300, lr=0.000273545, gnorm=0.284, loss_scale=16, train_wall=180, wall=79919
2021-03-15 07:46:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 07:49:08 | INFO | train_inner | epoch 003:   2920 / 20258 loss=3.677, nll_loss=2, ppl=4, wps=27657.7, ups=0.54, wpb=50840, bsz=2907, num_updates=43400, lr=0.00027323, gnorm=0.29, loss_scale=8, train_wall=181, wall=80103
2021-03-15 07:52:10 | INFO | train_inner | epoch 003:   3020 / 20258 loss=3.666, nll_loss=1.989, ppl=3.97, wps=27904.9, ups=0.55, wpb=50967.8, bsz=3043.7, num_updates=43500, lr=0.000272915, gnorm=0.277, loss_scale=8, train_wall=180, wall=80286
2021-03-15 07:55:13 | INFO | train_inner | epoch 003:   3120 / 20258 loss=3.681, nll_loss=2.005, ppl=4.02, wps=27904.4, ups=0.55, wpb=50929.8, bsz=3209.6, num_updates=43600, lr=0.000272602, gnorm=0.28, loss_scale=8, train_wall=179, wall=80468
2021-03-15 07:58:15 | INFO | train_inner | epoch 003:   3220 / 20258 loss=3.667, nll_loss=1.989, ppl=3.97, wps=27885, ups=0.55, wpb=50942.8, bsz=3153.9, num_updates=43700, lr=0.00027229, gnorm=0.274, loss_scale=8, train_wall=180, wall=80651
2021-03-15 08:01:18 | INFO | train_inner | epoch 003:   3320 / 20258 loss=3.644, nll_loss=1.964, ppl=3.9, wps=27880, ups=0.55, wpb=50987.9, bsz=2934.2, num_updates=43800, lr=0.000271979, gnorm=0.305, loss_scale=8, train_wall=180, wall=80834
2021-03-15 08:04:21 | INFO | train_inner | epoch 003:   3420 / 20258 loss=3.678, nll_loss=2.002, ppl=4.01, wps=27927.3, ups=0.55, wpb=50985.9, bsz=3119.8, num_updates=43900, lr=0.000271669, gnorm=0.279, loss_scale=8, train_wall=179, wall=81016
2021-03-15 08:07:24 | INFO | train_inner | epoch 003:   3520 / 20258 loss=3.678, nll_loss=2.001, ppl=4, wps=27840.3, ups=0.55, wpb=50866.9, bsz=2887.7, num_updates=44000, lr=0.00027136, gnorm=0.283, loss_scale=8, train_wall=179, wall=81199
2021-03-15 08:10:27 | INFO | train_inner | epoch 003:   3620 / 20258 loss=3.668, nll_loss=1.99, ppl=3.97, wps=27810.7, ups=0.55, wpb=50883.7, bsz=3047.4, num_updates=44100, lr=0.000271052, gnorm=0.29, loss_scale=8, train_wall=179, wall=81382
2021-03-15 08:13:29 | INFO | train_inner | epoch 003:   3720 / 20258 loss=3.656, nll_loss=1.977, ppl=3.94, wps=27832.1, ups=0.55, wpb=50850.2, bsz=3168.4, num_updates=44200, lr=0.000270746, gnorm=0.284, loss_scale=8, train_wall=180, wall=81565
2021-03-15 08:16:32 | INFO | train_inner | epoch 003:   3820 / 20258 loss=3.658, nll_loss=1.979, ppl=3.94, wps=27752.6, ups=0.55, wpb=50603.7, bsz=3059.4, num_updates=44300, lr=0.00027044, gnorm=0.278, loss_scale=8, train_wall=179, wall=81747
2021-03-15 08:19:34 | INFO | train_inner | epoch 003:   3920 / 20258 loss=3.677, nll_loss=2, ppl=4, wps=27778.1, ups=0.55, wpb=50706.2, bsz=2969.4, num_updates=44400, lr=0.000270135, gnorm=0.281, loss_scale=16, train_wall=179, wall=81930
2021-03-15 08:21:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 08:22:38 | INFO | train_inner | epoch 003:   4021 / 20258 loss=3.666, nll_loss=1.988, ppl=3.97, wps=27463.4, ups=0.54, wpb=50494.2, bsz=2980.6, num_updates=44500, lr=0.000269831, gnorm=0.289, loss_scale=8, train_wall=181, wall=82113
2021-03-15 08:25:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 08:25:42 | INFO | train_inner | epoch 003:   4122 / 20258 loss=3.67, nll_loss=1.993, ppl=3.98, wps=27716, ups=0.54, wpb=51131.3, bsz=3023, num_updates=44600, lr=0.000269529, gnorm=0.292, loss_scale=4, train_wall=181, wall=82298
2021-03-15 08:28:45 | INFO | train_inner | epoch 003:   4222 / 20258 loss=3.66, nll_loss=1.982, ppl=3.95, wps=27860.2, ups=0.55, wpb=50874.5, bsz=2999.7, num_updates=44700, lr=0.000269227, gnorm=0.278, loss_scale=4, train_wall=179, wall=82481
2021-03-15 08:31:48 | INFO | train_inner | epoch 003:   4322 / 20258 loss=3.665, nll_loss=1.987, ppl=3.96, wps=27883.8, ups=0.55, wpb=50973.5, bsz=2990.1, num_updates=44800, lr=0.000268926, gnorm=0.29, loss_scale=4, train_wall=179, wall=82663
2021-03-15 08:34:51 | INFO | train_inner | epoch 003:   4422 / 20258 loss=3.661, nll_loss=1.983, ppl=3.95, wps=27931, ups=0.55, wpb=51135.7, bsz=3105, num_updates=44900, lr=0.000268627, gnorm=0.278, loss_scale=4, train_wall=180, wall=82846
2021-03-15 08:37:54 | INFO | train_inner | epoch 003:   4522 / 20258 loss=3.66, nll_loss=1.982, ppl=3.95, wps=27779.6, ups=0.55, wpb=50749.4, bsz=2893.4, num_updates=45000, lr=0.000268328, gnorm=0.284, loss_scale=4, train_wall=179, wall=83029
2021-03-15 08:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 08:37:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:37:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:37:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:37:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:37:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:37:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:37:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:37:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:37:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:37:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:37:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:37:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:37:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:37:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:37:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:37:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:37:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:37:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:37:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:37:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:37:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:13 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.073 | nll_loss 2.357 | ppl 5.12 | bleu 28.29 | wps 4345.9 | wpb 2432 | bsz 90.4 | num_updates 45000 | best_loss 4.073
2021-03-15 08:38:13 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 08:38:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:38:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 08:38:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 08:38:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 08:39:05 | INFO | valid1 | epoch 003 | valid on 'valid1' subset | loss 4.049 | nll_loss 2.354 | ppl 5.11 | bleu 26.58 | wps 4231.4 | wpb 2359.4 | bsz 106.4 | num_updates 45000 | best_loss 4.049
2021-03-15 08:39:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 08:39:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_3_45000.pt (epoch 3 @ 45000 updates, score 4.073) (writing took 6.349995088065043 seconds)
2021-03-15 08:42:14 | INFO | train_inner | epoch 003:   4622 / 20258 loss=3.669, nll_loss=1.992, ppl=3.98, wps=19641.9, ups=0.38, wpb=51167, bsz=3063.1, num_updates=45100, lr=0.000268031, gnorm=0.278, loss_scale=4, train_wall=180, wall=83290
2021-03-15 08:45:17 | INFO | train_inner | epoch 003:   4722 / 20258 loss=3.662, nll_loss=1.984, ppl=3.95, wps=27943.7, ups=0.55, wpb=51162.2, bsz=3007.5, num_updates=45200, lr=0.000267734, gnorm=0.28, loss_scale=4, train_wall=180, wall=83473
2021-03-15 08:48:20 | INFO | train_inner | epoch 003:   4822 / 20258 loss=3.653, nll_loss=1.974, ppl=3.93, wps=27823.9, ups=0.55, wpb=50848.5, bsz=2923.8, num_updates=45300, lr=0.000267438, gnorm=0.284, loss_scale=4, train_wall=180, wall=83655
2021-03-15 08:51:23 | INFO | train_inner | epoch 003:   4922 / 20258 loss=3.669, nll_loss=1.992, ppl=3.98, wps=27824.4, ups=0.55, wpb=50858.3, bsz=2937.1, num_updates=45400, lr=0.000267143, gnorm=0.281, loss_scale=4, train_wall=179, wall=83838
2021-03-15 08:54:25 | INFO | train_inner | epoch 003:   5022 / 20258 loss=3.639, nll_loss=1.958, ppl=3.88, wps=27888.1, ups=0.55, wpb=50957.9, bsz=3008.5, num_updates=45500, lr=0.00026685, gnorm=0.28, loss_scale=4, train_wall=180, wall=84021
2021-03-15 08:57:28 | INFO | train_inner | epoch 003:   5122 / 20258 loss=3.661, nll_loss=1.983, ppl=3.95, wps=27932.6, ups=0.55, wpb=50929.4, bsz=2987.8, num_updates=45600, lr=0.000266557, gnorm=0.273, loss_scale=4, train_wall=179, wall=84203
2021-03-15 09:00:30 | INFO | train_inner | epoch 003:   5222 / 20258 loss=3.673, nll_loss=1.997, ppl=3.99, wps=27832.3, ups=0.55, wpb=50704.8, bsz=3093.3, num_updates=45700, lr=0.000266265, gnorm=0.285, loss_scale=8, train_wall=179, wall=84386
2021-03-15 09:03:32 | INFO | train_inner | epoch 003:   5322 / 20258 loss=3.649, nll_loss=1.969, ppl=3.92, wps=27811.3, ups=0.55, wpb=50726.9, bsz=2990.6, num_updates=45800, lr=0.000265974, gnorm=0.284, loss_scale=8, train_wall=180, wall=84568
2021-03-15 09:06:35 | INFO | train_inner | epoch 003:   5422 / 20258 loss=3.647, nll_loss=1.967, ppl=3.91, wps=27943, ups=0.55, wpb=51067, bsz=2981.8, num_updates=45900, lr=0.000265684, gnorm=0.279, loss_scale=8, train_wall=180, wall=84751
2021-03-15 09:09:37 | INFO | train_inner | epoch 003:   5522 / 20258 loss=3.668, nll_loss=1.99, ppl=3.97, wps=27824.2, ups=0.55, wpb=50639.2, bsz=2951.2, num_updates=46000, lr=0.000265396, gnorm=0.28, loss_scale=8, train_wall=179, wall=84933
2021-03-15 09:12:39 | INFO | train_inner | epoch 003:   5622 / 20258 loss=3.656, nll_loss=1.977, ppl=3.94, wps=27905.8, ups=0.55, wpb=50857.8, bsz=2925.4, num_updates=46100, lr=0.000265108, gnorm=0.282, loss_scale=8, train_wall=179, wall=85115
2021-03-15 09:15:42 | INFO | train_inner | epoch 003:   5722 / 20258 loss=3.645, nll_loss=1.965, ppl=3.9, wps=27958.8, ups=0.55, wpb=51125.4, bsz=3104.1, num_updates=46200, lr=0.00026482, gnorm=0.282, loss_scale=8, train_wall=180, wall=85298
2021-03-15 09:18:45 | INFO | train_inner | epoch 003:   5822 / 20258 loss=3.668, nll_loss=1.991, ppl=3.97, wps=27991, ups=0.55, wpb=51014.2, bsz=2915.3, num_updates=46300, lr=0.000264534, gnorm=0.275, loss_scale=8, train_wall=179, wall=85480
2021-03-15 09:21:47 | INFO | train_inner | epoch 003:   5922 / 20258 loss=3.653, nll_loss=1.974, ppl=3.93, wps=27788.7, ups=0.55, wpb=50690.6, bsz=2998.2, num_updates=46400, lr=0.000264249, gnorm=0.278, loss_scale=8, train_wall=179, wall=85662
2021-03-15 09:24:49 | INFO | train_inner | epoch 003:   6022 / 20258 loss=3.67, nll_loss=1.993, ppl=3.98, wps=28029, ups=0.55, wpb=51113.9, bsz=2967.4, num_updates=46500, lr=0.000263965, gnorm=0.275, loss_scale=8, train_wall=179, wall=85845
2021-03-15 09:27:52 | INFO | train_inner | epoch 003:   6122 / 20258 loss=3.659, nll_loss=1.981, ppl=3.95, wps=27896.9, ups=0.55, wpb=50934.2, bsz=2912.9, num_updates=46600, lr=0.000263681, gnorm=0.285, loss_scale=8, train_wall=179, wall=86027
2021-03-15 09:30:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 09:30:57 | INFO | train_inner | epoch 003:   6223 / 20258 loss=3.651, nll_loss=1.972, ppl=3.92, wps=27635.8, ups=0.54, wpb=51038.9, bsz=3075.3, num_updates=46700, lr=0.000263399, gnorm=0.289, loss_scale=8, train_wall=182, wall=86212
2021-03-15 09:33:59 | INFO | train_inner | epoch 003:   6323 / 20258 loss=3.661, nll_loss=1.983, ppl=3.95, wps=27910.9, ups=0.55, wpb=50862.7, bsz=2999.9, num_updates=46800, lr=0.000263117, gnorm=0.277, loss_scale=8, train_wall=179, wall=86394
2021-03-15 09:35:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 09:37:03 | INFO | train_inner | epoch 003:   6424 / 20258 loss=3.667, nll_loss=1.991, ppl=3.97, wps=27517.2, ups=0.54, wpb=50793.2, bsz=3115.1, num_updates=46900, lr=0.000262837, gnorm=0.376, loss_scale=4, train_wall=181, wall=86579
2021-03-15 09:40:06 | INFO | train_inner | epoch 003:   6524 / 20258 loss=3.659, nll_loss=1.981, ppl=3.95, wps=27862.7, ups=0.55, wpb=50937.6, bsz=3025.4, num_updates=47000, lr=0.000262557, gnorm=0.312, loss_scale=4, train_wall=179, wall=86762
2021-03-15 09:43:09 | INFO | train_inner | epoch 003:   6624 / 20258 loss=3.641, nll_loss=1.961, ppl=3.89, wps=27870.8, ups=0.55, wpb=51072.8, bsz=3073.8, num_updates=47100, lr=0.000262278, gnorm=0.282, loss_scale=4, train_wall=180, wall=86945
2021-03-15 09:46:12 | INFO | train_inner | epoch 003:   6724 / 20258 loss=3.655, nll_loss=1.976, ppl=3.93, wps=27843, ups=0.55, wpb=50969.1, bsz=3118.8, num_updates=47200, lr=0.000262, gnorm=0.28, loss_scale=4, train_wall=180, wall=87128
2021-03-15 09:49:15 | INFO | train_inner | epoch 003:   6824 / 20258 loss=3.656, nll_loss=1.977, ppl=3.94, wps=27873.9, ups=0.55, wpb=51000.9, bsz=2946.1, num_updates=47300, lr=0.000261723, gnorm=0.284, loss_scale=4, train_wall=179, wall=87311
2021-03-15 09:52:18 | INFO | train_inner | epoch 003:   6924 / 20258 loss=3.675, nll_loss=1.999, ppl=4, wps=27966.4, ups=0.55, wpb=50979.8, bsz=2993.8, num_updates=47400, lr=0.000261447, gnorm=0.287, loss_scale=4, train_wall=179, wall=87493
2021-03-15 09:55:20 | INFO | train_inner | epoch 003:   7024 / 20258 loss=3.647, nll_loss=1.968, ppl=3.91, wps=27875.6, ups=0.55, wpb=50935.4, bsz=3085, num_updates=47500, lr=0.000261171, gnorm=0.282, loss_scale=4, train_wall=180, wall=87676
2021-03-15 09:58:23 | INFO | train_inner | epoch 003:   7124 / 20258 loss=3.641, nll_loss=1.96, ppl=3.89, wps=27890.4, ups=0.55, wpb=50994.9, bsz=3048.6, num_updates=47600, lr=0.000260897, gnorm=0.274, loss_scale=4, train_wall=180, wall=87859
2021-03-15 10:01:26 | INFO | train_inner | epoch 003:   7224 / 20258 loss=3.659, nll_loss=1.981, ppl=3.95, wps=27997.7, ups=0.55, wpb=51041, bsz=3020.7, num_updates=47700, lr=0.000260623, gnorm=0.28, loss_scale=4, train_wall=179, wall=88041
2021-03-15 10:04:29 | INFO | train_inner | epoch 003:   7324 / 20258 loss=3.651, nll_loss=1.972, ppl=3.92, wps=27891.9, ups=0.55, wpb=51062.7, bsz=3064.6, num_updates=47800, lr=0.000260351, gnorm=0.288, loss_scale=4, train_wall=180, wall=88224
2021-03-15 10:07:32 | INFO | train_inner | epoch 003:   7424 / 20258 loss=3.639, nll_loss=1.959, ppl=3.89, wps=27846.5, ups=0.55, wpb=50956.8, bsz=3102.8, num_updates=47900, lr=0.000260079, gnorm=0.27, loss_scale=8, train_wall=180, wall=88407
2021-03-15 10:10:35 | INFO | train_inner | epoch 003:   7524 / 20258 loss=3.642, nll_loss=1.962, ppl=3.9, wps=27906.4, ups=0.55, wpb=51058.3, bsz=3007.7, num_updates=48000, lr=0.000259808, gnorm=0.279, loss_scale=8, train_wall=180, wall=88590
2021-03-15 10:13:37 | INFO | train_inner | epoch 003:   7624 / 20258 loss=3.661, nll_loss=1.983, ppl=3.95, wps=27755.2, ups=0.55, wpb=50705.9, bsz=2980.6, num_updates=48100, lr=0.000259537, gnorm=0.275, loss_scale=8, train_wall=179, wall=88773
2021-03-15 10:16:40 | INFO | train_inner | epoch 003:   7724 / 20258 loss=3.657, nll_loss=1.979, ppl=3.94, wps=27899.7, ups=0.55, wpb=50826, bsz=2895.3, num_updates=48200, lr=0.000259268, gnorm=0.275, loss_scale=8, train_wall=179, wall=88955
2021-03-15 10:19:42 | INFO | train_inner | epoch 003:   7824 / 20258 loss=3.661, nll_loss=1.983, ppl=3.95, wps=27874, ups=0.55, wpb=50971, bsz=3069.1, num_updates=48300, lr=0.000259, gnorm=0.278, loss_scale=8, train_wall=180, wall=89138
2021-03-15 10:22:45 | INFO | train_inner | epoch 003:   7924 / 20258 loss=3.653, nll_loss=1.975, ppl=3.93, wps=27896.9, ups=0.55, wpb=50931.2, bsz=2949.7, num_updates=48400, lr=0.000258732, gnorm=0.279, loss_scale=8, train_wall=180, wall=89320
2021-03-15 10:25:47 | INFO | train_inner | epoch 003:   8024 / 20258 loss=3.662, nll_loss=1.985, ppl=3.96, wps=27887.5, ups=0.55, wpb=50869.8, bsz=3038.7, num_updates=48500, lr=0.000258465, gnorm=0.273, loss_scale=8, train_wall=180, wall=89503
2021-03-15 10:28:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 10:28:52 | INFO | train_inner | epoch 003:   8125 / 20258 loss=3.667, nll_loss=1.991, ppl=3.97, wps=27632.7, ups=0.54, wpb=50908, bsz=3086.2, num_updates=48600, lr=0.000258199, gnorm=0.277, loss_scale=4, train_wall=181, wall=89687
2021-03-15 10:31:54 | INFO | train_inner | epoch 003:   8225 / 20258 loss=3.671, nll_loss=1.995, ppl=3.99, wps=27918.4, ups=0.55, wpb=50885, bsz=3037.2, num_updates=48700, lr=0.000257934, gnorm=0.289, loss_scale=4, train_wall=179, wall=89869
2021-03-15 10:34:57 | INFO | train_inner | epoch 003:   8325 / 20258 loss=3.639, nll_loss=1.96, ppl=3.89, wps=27704.4, ups=0.55, wpb=50653.6, bsz=3081.6, num_updates=48800, lr=0.000257669, gnorm=0.282, loss_scale=4, train_wall=180, wall=90052
2021-03-15 10:37:59 | INFO | train_inner | epoch 003:   8425 / 20258 loss=3.653, nll_loss=1.975, ppl=3.93, wps=27795.7, ups=0.55, wpb=50792.5, bsz=3034.4, num_updates=48900, lr=0.000257406, gnorm=0.279, loss_scale=4, train_wall=179, wall=90235
2021-03-15 10:41:03 | INFO | train_inner | epoch 003:   8525 / 20258 loss=3.649, nll_loss=1.97, ppl=3.92, wps=27750.7, ups=0.55, wpb=50865.5, bsz=3060.9, num_updates=49000, lr=0.000257143, gnorm=0.272, loss_scale=4, train_wall=180, wall=90418
2021-03-15 10:44:05 | INFO | train_inner | epoch 003:   8625 / 20258 loss=3.648, nll_loss=1.97, ppl=3.92, wps=27863.8, ups=0.55, wpb=50885.4, bsz=3052.8, num_updates=49100, lr=0.000256881, gnorm=0.277, loss_scale=4, train_wall=179, wall=90601
2021-03-15 10:47:09 | INFO | train_inner | epoch 003:   8725 / 20258 loss=3.66, nll_loss=1.983, ppl=3.95, wps=27800.9, ups=0.55, wpb=50952, bsz=3011.2, num_updates=49200, lr=0.00025662, gnorm=0.283, loss_scale=4, train_wall=180, wall=90784
2021-03-15 10:50:11 | INFO | train_inner | epoch 003:   8825 / 20258 loss=3.664, nll_loss=1.987, ppl=3.96, wps=27911, ups=0.55, wpb=51029.3, bsz=2976.5, num_updates=49300, lr=0.000256359, gnorm=0.281, loss_scale=4, train_wall=179, wall=90967
2021-03-15 10:53:14 | INFO | train_inner | epoch 003:   8925 / 20258 loss=3.665, nll_loss=1.988, ppl=3.97, wps=27816.2, ups=0.55, wpb=50672.3, bsz=3046.6, num_updates=49400, lr=0.0002561, gnorm=0.284, loss_scale=4, train_wall=179, wall=91149
2021-03-15 10:56:16 | INFO | train_inner | epoch 003:   9025 / 20258 loss=3.658, nll_loss=1.98, ppl=3.94, wps=27874.2, ups=0.55, wpb=50923.5, bsz=2983.8, num_updates=49500, lr=0.000255841, gnorm=0.28, loss_scale=4, train_wall=180, wall=91332
2021-03-15 10:59:19 | INFO | train_inner | epoch 003:   9125 / 20258 loss=3.658, nll_loss=1.981, ppl=3.95, wps=27816.3, ups=0.55, wpb=50698.1, bsz=3067.8, num_updates=49600, lr=0.000255583, gnorm=0.278, loss_scale=4, train_wall=179, wall=91514
2021-03-15 11:02:22 | INFO | train_inner | epoch 003:   9225 / 20258 loss=3.643, nll_loss=1.963, ppl=3.9, wps=27872.2, ups=0.55, wpb=50990.7, bsz=3013.6, num_updates=49700, lr=0.000255326, gnorm=0.282, loss_scale=8, train_wall=180, wall=91697
2021-03-15 11:04:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 11:04:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-15 11:04:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-15 11:05:30 | INFO | train_inner | epoch 003:   9328 / 20258 loss=3.671, nll_loss=1.995, ppl=3.99, wps=27064, ups=0.53, wpb=50929.8, bsz=2958.7, num_updates=49800, lr=0.000255069, gnorm=0.33, loss_scale=1, train_wall=185, wall=91885
2021-03-15 11:08:33 | INFO | train_inner | epoch 003:   9428 / 20258 loss=3.644, nll_loss=1.964, ppl=3.9, wps=27835.7, ups=0.55, wpb=51052.8, bsz=2973.6, num_updates=49900, lr=0.000254813, gnorm=0.274, loss_scale=1, train_wall=180, wall=92069
2021-03-15 11:11:36 | INFO | train_inner | epoch 003:   9528 / 20258 loss=3.664, nll_loss=1.987, ppl=3.96, wps=27879.1, ups=0.55, wpb=50860.3, bsz=2967.2, num_updates=50000, lr=0.000254558, gnorm=0.282, loss_scale=1, train_wall=179, wall=92251
2021-03-15 11:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 11:11:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:54 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.059 | nll_loss 2.339 | ppl 5.06 | bleu 28.67 | wps 4386.2 | wpb 2432 | bsz 90.4 | num_updates 50000 | best_loss 4.059
2021-03-15 11:11:54 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 11:11:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:11:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:11:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:11:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 11:12:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 11:12:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 11:12:47 | INFO | valid1 | epoch 003 | valid on 'valid1' subset | loss 4.043 | nll_loss 2.347 | ppl 5.09 | bleu 26.45 | wps 4224.1 | wpb 2359.4 | bsz 106.4 | num_updates 50000 | best_loss 4.043
2021-03-15 11:12:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 11:12:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_3_50000.pt (epoch 3 @ 50000 updates, score 4.059) (writing took 6.20583716686815 seconds)
2021-03-15 11:15:55 | INFO | train_inner | epoch 003:   9628 / 20258 loss=3.667, nll_loss=1.991, ppl=3.97, wps=19612.8, ups=0.39, wpb=50894.7, bsz=3024.9, num_updates=50100, lr=0.000254304, gnorm=0.282, loss_scale=1, train_wall=179, wall=92511
2021-03-15 11:18:58 | INFO | train_inner | epoch 003:   9728 / 20258 loss=3.642, nll_loss=1.963, ppl=3.9, wps=27967.4, ups=0.55, wpb=51097.1, bsz=3023.8, num_updates=50200, lr=0.000254051, gnorm=0.271, loss_scale=1, train_wall=180, wall=92693
2021-03-15 11:22:00 | INFO | train_inner | epoch 003:   9828 / 20258 loss=3.649, nll_loss=1.97, ppl=3.92, wps=27889, ups=0.55, wpb=50952.7, bsz=2922.9, num_updates=50300, lr=0.000253798, gnorm=0.284, loss_scale=1, train_wall=180, wall=92876
2021-03-15 11:25:04 | INFO | train_inner | epoch 003:   9928 / 20258 loss=3.633, nll_loss=1.953, ppl=3.87, wps=27778.7, ups=0.55, wpb=50935.3, bsz=3075.1, num_updates=50400, lr=0.000253546, gnorm=0.277, loss_scale=1, train_wall=180, wall=93059
2021-03-15 11:28:06 | INFO | train_inner | epoch 003:  10028 / 20258 loss=3.627, nll_loss=1.945, ppl=3.85, wps=27886.8, ups=0.55, wpb=50847.7, bsz=2985.5, num_updates=50500, lr=0.000253295, gnorm=0.274, loss_scale=1, train_wall=180, wall=93242
2021-03-15 11:31:09 | INFO | train_inner | epoch 003:  10128 / 20258 loss=3.646, nll_loss=1.966, ppl=3.91, wps=27958.4, ups=0.55, wpb=51167.4, bsz=2972.7, num_updates=50600, lr=0.000253045, gnorm=0.278, loss_scale=1, train_wall=180, wall=93425
2021-03-15 11:34:12 | INFO | train_inner | epoch 003:  10228 / 20258 loss=3.649, nll_loss=1.971, ppl=3.92, wps=27843.4, ups=0.55, wpb=50795.6, bsz=3007.4, num_updates=50700, lr=0.000252795, gnorm=0.28, loss_scale=1, train_wall=179, wall=93607
2021-03-15 11:37:13 | INFO | train_inner | epoch 003:  10328 / 20258 loss=3.657, nll_loss=1.979, ppl=3.94, wps=27937.5, ups=0.55, wpb=50769.1, bsz=2932.7, num_updates=50800, lr=0.000252546, gnorm=0.281, loss_scale=2, train_wall=179, wall=93789
2021-03-15 11:40:15 | INFO | train_inner | epoch 003:  10428 / 20258 loss=3.643, nll_loss=1.963, ppl=3.9, wps=27666, ups=0.55, wpb=50347.2, bsz=2943.6, num_updates=50900, lr=0.000252298, gnorm=0.284, loss_scale=2, train_wall=178, wall=93971
2021-03-15 11:43:18 | INFO | train_inner | epoch 003:  10528 / 20258 loss=3.639, nll_loss=1.96, ppl=3.89, wps=27960.8, ups=0.55, wpb=51107.6, bsz=3076.2, num_updates=51000, lr=0.00025205, gnorm=0.271, loss_scale=2, train_wall=180, wall=94154
2021-03-15 11:46:21 | INFO | train_inner | epoch 003:  10628 / 20258 loss=3.649, nll_loss=1.971, ppl=3.92, wps=27723.4, ups=0.55, wpb=50595.5, bsz=3010.4, num_updates=51100, lr=0.000251804, gnorm=0.271, loss_scale=2, train_wall=179, wall=94336
2021-03-15 11:49:23 | INFO | train_inner | epoch 003:  10728 / 20258 loss=3.643, nll_loss=1.963, ppl=3.9, wps=27822.9, ups=0.55, wpb=50772.4, bsz=2895.8, num_updates=51200, lr=0.000251558, gnorm=0.28, loss_scale=2, train_wall=179, wall=94519
2021-03-15 11:52:26 | INFO | train_inner | epoch 003:  10828 / 20258 loss=3.625, nll_loss=1.943, ppl=3.85, wps=27843.5, ups=0.55, wpb=50830.2, bsz=2912.7, num_updates=51300, lr=0.000251312, gnorm=0.275, loss_scale=2, train_wall=179, wall=94701
2021-03-15 11:53:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-15 11:55:30 | INFO | train_inner | epoch 003:  10929 / 20258 loss=3.633, nll_loss=1.953, ppl=3.87, wps=27496.1, ups=0.54, wpb=50723.2, bsz=3092.6, num_updates=51400, lr=0.000251068, gnorm=0.274, loss_scale=1, train_wall=181, wall=94886
2021-03-15 11:58:33 | INFO | train_inner | epoch 003:  11029 / 20258 loss=3.624, nll_loss=1.942, ppl=3.84, wps=27935.8, ups=0.55, wpb=51176, bsz=3017.4, num_updates=51500, lr=0.000250824, gnorm=0.275, loss_scale=1, train_wall=180, wall=95069
2021-03-15 12:01:36 | INFO | train_inner | epoch 003:  11129 / 20258 loss=3.66, nll_loss=1.983, ppl=3.95, wps=28044.5, ups=0.55, wpb=51100.3, bsz=3076, num_updates=51600, lr=0.000250581, gnorm=0.272, loss_scale=1, train_wall=179, wall=95251
2021-03-15 12:04:38 | INFO | train_inner | epoch 003:  11229 / 20258 loss=3.636, nll_loss=1.956, ppl=3.88, wps=27856.9, ups=0.55, wpb=50749, bsz=3047.8, num_updates=51700, lr=0.000250338, gnorm=0.281, loss_scale=1, train_wall=179, wall=95433
2021-03-15 12:07:40 | INFO | train_inner | epoch 003:  11329 / 20258 loss=3.659, nll_loss=1.982, ppl=3.95, wps=28003.8, ups=0.55, wpb=51014.8, bsz=2968.4, num_updates=51800, lr=0.000250097, gnorm=0.279, loss_scale=1, train_wall=179, wall=95615
2021-03-15 12:10:43 | INFO | train_inner | epoch 003:  11429 / 20258 loss=3.639, nll_loss=1.959, ppl=3.89, wps=27804.5, ups=0.55, wpb=50857.2, bsz=3089.9, num_updates=51900, lr=0.000249855, gnorm=0.282, loss_scale=1, train_wall=179, wall=95798
2021-03-15 12:13:45 | INFO | train_inner | epoch 003:  11529 / 20258 loss=3.635, nll_loss=1.955, ppl=3.88, wps=28004.1, ups=0.55, wpb=51154.3, bsz=2938.7, num_updates=52000, lr=0.000249615, gnorm=0.296, loss_scale=1, train_wall=180, wall=95981
2021-03-15 12:16:48 | INFO | train_inner | epoch 003:  11629 / 20258 loss=3.629, nll_loss=1.948, ppl=3.86, wps=27891.1, ups=0.55, wpb=50841.1, bsz=3000.8, num_updates=52100, lr=0.000249375, gnorm=0.279, loss_scale=1, train_wall=179, wall=96163
2021-03-15 12:19:50 | INFO | train_inner | epoch 003:  11729 / 20258 loss=3.653, nll_loss=1.975, ppl=3.93, wps=27866.4, ups=0.55, wpb=50813.9, bsz=2927.3, num_updates=52200, lr=0.000249136, gnorm=0.286, loss_scale=1, train_wall=179, wall=96346
2021-03-15 12:22:52 | INFO | train_inner | epoch 003:  11829 / 20258 loss=3.641, nll_loss=1.962, ppl=3.9, wps=27846.5, ups=0.55, wpb=50773.7, bsz=3008.2, num_updates=52300, lr=0.000248898, gnorm=0.324, loss_scale=1, train_wall=179, wall=96528
2021-03-15 12:25:55 | INFO | train_inner | epoch 003:  11929 / 20258 loss=3.658, nll_loss=1.981, ppl=3.95, wps=27919.8, ups=0.55, wpb=51039.8, bsz=2975.5, num_updates=52400, lr=0.000248661, gnorm=0.332, loss_scale=2, train_wall=180, wall=96711
2021-03-15 12:28:58 | INFO | train_inner | epoch 003:  12029 / 20258 loss=3.63, nll_loss=1.95, ppl=3.86, wps=27875.8, ups=0.55, wpb=50887.7, bsz=3030.1, num_updates=52500, lr=0.000248424, gnorm=0.308, loss_scale=2, train_wall=179, wall=96893
2021-03-15 12:32:00 | INFO | train_inner | epoch 003:  12129 / 20258 loss=3.634, nll_loss=1.954, ppl=3.87, wps=27784.7, ups=0.55, wpb=50726.3, bsz=3036.7, num_updates=52600, lr=0.000248187, gnorm=0.286, loss_scale=2, train_wall=179, wall=97076
2021-03-15 12:35:03 | INFO | train_inner | epoch 003:  12229 / 20258 loss=3.641, nll_loss=1.962, ppl=3.9, wps=27780.9, ups=0.55, wpb=50711.8, bsz=3070.1, num_updates=52700, lr=0.000247952, gnorm=0.276, loss_scale=2, train_wall=179, wall=97258
2021-03-15 12:38:05 | INFO | train_inner | epoch 003:  12329 / 20258 loss=3.657, nll_loss=1.979, ppl=3.94, wps=27808.6, ups=0.55, wpb=50750.3, bsz=3023.3, num_updates=52800, lr=0.000247717, gnorm=0.272, loss_scale=2, train_wall=179, wall=97441
2021-03-15 12:41:08 | INFO | train_inner | epoch 003:  12429 / 20258 loss=3.632, nll_loss=1.951, ppl=3.87, wps=27805.3, ups=0.55, wpb=50858.5, bsz=2931.5, num_updates=52900, lr=0.000247483, gnorm=0.281, loss_scale=2, train_wall=180, wall=97624
2021-03-15 12:44:11 | INFO | train_inner | epoch 003:  12529 / 20258 loss=3.636, nll_loss=1.956, ppl=3.88, wps=27828.1, ups=0.55, wpb=50819, bsz=2991.2, num_updates=53000, lr=0.000247249, gnorm=0.275, loss_scale=2, train_wall=179, wall=97806
2021-03-15 12:47:13 | INFO | train_inner | epoch 003:  12629 / 20258 loss=3.648, nll_loss=1.97, ppl=3.92, wps=27826.8, ups=0.55, wpb=50632.6, bsz=2969.1, num_updates=53100, lr=0.000247016, gnorm=0.274, loss_scale=2, train_wall=179, wall=97988
2021-03-15 12:50:15 | INFO | train_inner | epoch 003:  12729 / 20258 loss=3.647, nll_loss=1.97, ppl=3.92, wps=27953.2, ups=0.55, wpb=51016.1, bsz=3079.4, num_updates=53200, lr=0.000246784, gnorm=0.298, loss_scale=2, train_wall=179, wall=98171
2021-03-15 12:53:18 | INFO | train_inner | epoch 003:  12829 / 20258 loss=3.642, nll_loss=1.964, ppl=3.9, wps=27879.8, ups=0.55, wpb=50909.8, bsz=3042.2, num_updates=53300, lr=0.000246552, gnorm=0.275, loss_scale=2, train_wall=179, wall=98354
2021-03-15 12:56:21 | INFO | train_inner | epoch 003:  12929 / 20258 loss=3.635, nll_loss=1.955, ppl=3.88, wps=27937.8, ups=0.55, wpb=51038.8, bsz=3088.9, num_updates=53400, lr=0.000246321, gnorm=0.275, loss_scale=4, train_wall=179, wall=98536
2021-03-15 12:59:23 | INFO | train_inner | epoch 003:  13029 / 20258 loss=3.639, nll_loss=1.96, ppl=3.89, wps=27958.6, ups=0.55, wpb=50985.9, bsz=3032.6, num_updates=53500, lr=0.000246091, gnorm=0.271, loss_scale=4, train_wall=179, wall=98719
2021-03-15 13:02:25 | INFO | train_inner | epoch 003:  13129 / 20258 loss=3.639, nll_loss=1.96, ppl=3.89, wps=27925.2, ups=0.55, wpb=50868.7, bsz=2923.4, num_updates=53600, lr=0.000245861, gnorm=0.27, loss_scale=4, train_wall=179, wall=98901
2021-03-15 13:05:27 | INFO | train_inner | epoch 003:  13229 / 20258 loss=3.646, nll_loss=1.968, ppl=3.91, wps=27864.1, ups=0.55, wpb=50719.4, bsz=2986.2, num_updates=53700, lr=0.000245632, gnorm=0.278, loss_scale=4, train_wall=179, wall=99083
2021-03-15 13:08:29 | INFO | train_inner | epoch 003:  13329 / 20258 loss=3.628, nll_loss=1.947, ppl=3.86, wps=27994.4, ups=0.55, wpb=51008.8, bsz=2978.4, num_updates=53800, lr=0.000245404, gnorm=0.282, loss_scale=4, train_wall=179, wall=99265
2021-03-15 13:11:32 | INFO | train_inner | epoch 003:  13429 / 20258 loss=3.661, nll_loss=1.985, ppl=3.96, wps=27919.1, ups=0.55, wpb=50912.5, bsz=2957, num_updates=53900, lr=0.000245176, gnorm=0.278, loss_scale=4, train_wall=179, wall=99447
2021-03-15 13:14:35 | INFO | train_inner | epoch 003:  13529 / 20258 loss=3.636, nll_loss=1.957, ppl=3.88, wps=27998.4, ups=0.55, wpb=51172.8, bsz=3011.9, num_updates=54000, lr=0.000244949, gnorm=0.279, loss_scale=4, train_wall=180, wall=99630
2021-03-15 13:17:37 | INFO | train_inner | epoch 003:  13629 / 20258 loss=3.635, nll_loss=1.956, ppl=3.88, wps=27898, ups=0.55, wpb=50870.5, bsz=2977.8, num_updates=54100, lr=0.000244722, gnorm=0.272, loss_scale=4, train_wall=179, wall=99812
2021-03-15 13:20:39 | INFO | train_inner | epoch 003:  13729 / 20258 loss=3.618, nll_loss=1.936, ppl=3.83, wps=27860.8, ups=0.55, wpb=50677.7, bsz=2998.1, num_updates=54200, lr=0.000244497, gnorm=0.273, loss_scale=4, train_wall=179, wall=99994
2021-03-15 13:23:42 | INFO | train_inner | epoch 003:  13829 / 20258 loss=3.634, nll_loss=1.954, ppl=3.87, wps=27954.2, ups=0.55, wpb=51269.5, bsz=2895.3, num_updates=54300, lr=0.000244271, gnorm=0.278, loss_scale=4, train_wall=180, wall=100178
2021-03-15 13:26:45 | INFO | train_inner | epoch 003:  13929 / 20258 loss=3.644, nll_loss=1.965, ppl=3.91, wps=27840.3, ups=0.55, wpb=50856.3, bsz=2989, num_updates=54400, lr=0.000244047, gnorm=0.285, loss_scale=4, train_wall=179, wall=100360
2021-03-15 13:29:47 | INFO | train_inner | epoch 003:  14029 / 20258 loss=3.654, nll_loss=1.977, ppl=3.94, wps=27882.3, ups=0.55, wpb=50835.7, bsz=3008.3, num_updates=54500, lr=0.000243823, gnorm=0.277, loss_scale=8, train_wall=179, wall=100543
2021-03-15 13:32:50 | INFO | train_inner | epoch 003:  14129 / 20258 loss=3.641, nll_loss=1.962, ppl=3.9, wps=27948.5, ups=0.55, wpb=50974.8, bsz=2980.7, num_updates=54600, lr=0.000243599, gnorm=0.272, loss_scale=8, train_wall=179, wall=100725
2021-03-15 13:35:53 | INFO | train_inner | epoch 003:  14229 / 20258 loss=3.636, nll_loss=1.956, ppl=3.88, wps=27909.6, ups=0.55, wpb=51054, bsz=3038.1, num_updates=54700, lr=0.000243377, gnorm=0.274, loss_scale=8, train_wall=180, wall=100908
2021-03-15 13:38:55 | INFO | train_inner | epoch 003:  14329 / 20258 loss=3.633, nll_loss=1.953, ppl=3.87, wps=27736.7, ups=0.55, wpb=50688.7, bsz=3004.8, num_updates=54800, lr=0.000243154, gnorm=0.283, loss_scale=8, train_wall=179, wall=101091
2021-03-15 13:41:58 | INFO | train_inner | epoch 003:  14429 / 20258 loss=3.617, nll_loss=1.935, ppl=3.82, wps=27835.7, ups=0.55, wpb=50842.3, bsz=3102.2, num_updates=54900, lr=0.000242933, gnorm=0.269, loss_scale=8, train_wall=180, wall=101273
2021-03-15 13:45:01 | INFO | train_inner | epoch 003:  14529 / 20258 loss=3.633, nll_loss=1.953, ppl=3.87, wps=27893.9, ups=0.55, wpb=51059.4, bsz=3051.3, num_updates=55000, lr=0.000242712, gnorm=0.282, loss_scale=8, train_wall=180, wall=101457
2021-03-15 13:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 13:45:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:20 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.039 | nll_loss 2.321 | ppl 5 | bleu 28.68 | wps 4321.7 | wpb 2432 | bsz 90.4 | num_updates 55000 | best_loss 4.039
2021-03-15 13:45:20 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 13:45:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:45:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 13:45:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 13:45:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 13:46:13 | INFO | valid1 | epoch 003 | valid on 'valid1' subset | loss 4.019 | nll_loss 2.324 | ppl 5.01 | bleu 26.68 | wps 4195.5 | wpb 2359.4 | bsz 106.4 | num_updates 55000 | best_loss 4.019
2021-03-15 13:46:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 13:46:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_3_55000.pt (epoch 3 @ 55000 updates, score 4.039) (writing took 6.2547301321756095 seconds)
2021-03-15 13:49:21 | INFO | train_inner | epoch 003:  14629 / 20258 loss=3.627, nll_loss=1.946, ppl=3.85, wps=19537.2, ups=0.38, wpb=50874.7, bsz=2888.1, num_updates=55100, lr=0.000242492, gnorm=0.273, loss_scale=8, train_wall=179, wall=101717
2021-03-15 13:52:24 | INFO | train_inner | epoch 003:  14729 / 20258 loss=3.625, nll_loss=1.944, ppl=3.85, wps=27909, ups=0.55, wpb=51024.1, bsz=2874.4, num_updates=55200, lr=0.000242272, gnorm=0.278, loss_scale=8, train_wall=180, wall=101900
2021-03-15 13:55:27 | INFO | train_inner | epoch 003:  14829 / 20258 loss=3.629, nll_loss=1.949, ppl=3.86, wps=27867.9, ups=0.55, wpb=50847.4, bsz=2927.9, num_updates=55300, lr=0.000242053, gnorm=0.274, loss_scale=8, train_wall=179, wall=102082
2021-03-15 13:58:29 | INFO | train_inner | epoch 003:  14929 / 20258 loss=3.625, nll_loss=1.945, ppl=3.85, wps=27903.8, ups=0.55, wpb=50875.8, bsz=3024.1, num_updates=55400, lr=0.000241834, gnorm=0.268, loss_scale=8, train_wall=179, wall=102265
2021-03-15 14:01:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 14:01:33 | INFO | train_inner | epoch 003:  15030 / 20258 loss=3.643, nll_loss=1.965, ppl=3.9, wps=27615, ups=0.54, wpb=50888.9, bsz=3065.8, num_updates=55500, lr=0.000241616, gnorm=0.284, loss_scale=8, train_wall=181, wall=102449
2021-03-15 14:04:35 | INFO | train_inner | epoch 003:  15130 / 20258 loss=3.64, nll_loss=1.961, ppl=3.89, wps=27786, ups=0.55, wpb=50575.1, bsz=2847.7, num_updates=55600, lr=0.000241399, gnorm=0.279, loss_scale=8, train_wall=179, wall=102631
2021-03-15 14:07:38 | INFO | train_inner | epoch 003:  15230 / 20258 loss=3.627, nll_loss=1.947, ppl=3.85, wps=27879.6, ups=0.55, wpb=51011.7, bsz=2918.5, num_updates=55700, lr=0.000241182, gnorm=0.269, loss_scale=8, train_wall=180, wall=102814
2021-03-15 14:10:41 | INFO | train_inner | epoch 003:  15330 / 20258 loss=3.641, nll_loss=1.963, ppl=3.9, wps=27926.5, ups=0.55, wpb=51015.3, bsz=2983, num_updates=55800, lr=0.000240966, gnorm=0.285, loss_scale=8, train_wall=179, wall=102997
2021-03-15 14:10:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 14:13:45 | INFO | train_inner | epoch 003:  15431 / 20258 loss=3.632, nll_loss=1.952, ppl=3.87, wps=27556.1, ups=0.54, wpb=50813.6, bsz=3093.4, num_updates=55900, lr=0.00024075, gnorm=0.28, loss_scale=4, train_wall=181, wall=103181
2021-03-15 14:16:48 | INFO | train_inner | epoch 003:  15531 / 20258 loss=3.638, nll_loss=1.959, ppl=3.89, wps=27939.3, ups=0.55, wpb=51029, bsz=3044.5, num_updates=56000, lr=0.000240535, gnorm=0.269, loss_scale=4, train_wall=180, wall=103364
2021-03-15 14:19:50 | INFO | train_inner | epoch 003:  15631 / 20258 loss=3.625, nll_loss=1.944, ppl=3.85, wps=27803.1, ups=0.55, wpb=50673.1, bsz=2869.3, num_updates=56100, lr=0.000240321, gnorm=0.276, loss_scale=4, train_wall=179, wall=103546
2021-03-15 14:22:53 | INFO | train_inner | epoch 003:  15731 / 20258 loss=3.623, nll_loss=1.943, ppl=3.84, wps=27893.7, ups=0.55, wpb=50956.8, bsz=2982.8, num_updates=56200, lr=0.000240107, gnorm=0.285, loss_scale=4, train_wall=180, wall=103728
2021-03-15 14:25:57 | INFO | train_inner | epoch 003:  15831 / 20258 loss=3.627, nll_loss=1.946, ppl=3.85, wps=27844.9, ups=0.54, wpb=51119.8, bsz=2917.8, num_updates=56300, lr=0.000239893, gnorm=0.275, loss_scale=4, train_wall=180, wall=103912
2021-03-15 14:28:59 | INFO | train_inner | epoch 003:  15931 / 20258 loss=3.64, nll_loss=1.961, ppl=3.89, wps=27917.9, ups=0.55, wpb=50892.8, bsz=2918.1, num_updates=56400, lr=0.000239681, gnorm=0.274, loss_scale=4, train_wall=179, wall=104094
2021-03-15 14:32:01 | INFO | train_inner | epoch 003:  16031 / 20258 loss=3.637, nll_loss=1.958, ppl=3.88, wps=27763.5, ups=0.55, wpb=50705.4, bsz=2991.3, num_updates=56500, lr=0.000239468, gnorm=0.321, loss_scale=4, train_wall=179, wall=104277
2021-03-15 14:35:05 | INFO | train_inner | epoch 003:  16131 / 20258 loss=3.612, nll_loss=1.93, ppl=3.81, wps=27772.3, ups=0.55, wpb=50870.8, bsz=3037.7, num_updates=56600, lr=0.000239257, gnorm=0.273, loss_scale=4, train_wall=180, wall=104460
2021-03-15 14:38:08 | INFO | train_inner | epoch 003:  16231 / 20258 loss=3.62, nll_loss=1.939, ppl=3.83, wps=27733.7, ups=0.55, wpb=50785.7, bsz=3095.8, num_updates=56700, lr=0.000239046, gnorm=0.281, loss_scale=4, train_wall=180, wall=104643
2021-03-15 14:41:10 | INFO | train_inner | epoch 003:  16331 / 20258 loss=3.648, nll_loss=1.97, ppl=3.92, wps=27961.2, ups=0.55, wpb=51044.2, bsz=2979.4, num_updates=56800, lr=0.000238835, gnorm=0.271, loss_scale=4, train_wall=179, wall=104826
2021-03-15 14:44:14 | INFO | train_inner | epoch 003:  16431 / 20258 loss=3.626, nll_loss=1.945, ppl=3.85, wps=27854.6, ups=0.54, wpb=51131.2, bsz=3050.5, num_updates=56900, lr=0.000238625, gnorm=0.271, loss_scale=8, train_wall=180, wall=105009
2021-03-15 14:47:17 | INFO | train_inner | epoch 003:  16531 / 20258 loss=3.638, nll_loss=1.959, ppl=3.89, wps=27855.1, ups=0.55, wpb=50994.3, bsz=3073.4, num_updates=57000, lr=0.000238416, gnorm=0.273, loss_scale=8, train_wall=180, wall=105193
2021-03-15 14:50:20 | INFO | train_inner | epoch 003:  16631 / 20258 loss=3.624, nll_loss=1.944, ppl=3.85, wps=27828.2, ups=0.54, wpb=51066.3, bsz=3062.2, num_updates=57100, lr=0.000238207, gnorm=0.272, loss_scale=8, train_wall=180, wall=105376
2021-03-15 14:53:23 | INFO | train_inner | epoch 003:  16731 / 20258 loss=3.634, nll_loss=1.955, ppl=3.88, wps=27927.4, ups=0.55, wpb=50998.8, bsz=3001.7, num_updates=57200, lr=0.000237999, gnorm=0.283, loss_scale=8, train_wall=179, wall=105559
2021-03-15 14:56:25 | INFO | train_inner | epoch 003:  16831 / 20258 loss=3.623, nll_loss=1.943, ppl=3.84, wps=27819.6, ups=0.55, wpb=50713.3, bsz=3016.6, num_updates=57300, lr=0.000237791, gnorm=0.274, loss_scale=8, train_wall=179, wall=105741
2021-03-15 14:59:28 | INFO | train_inner | epoch 003:  16931 / 20258 loss=3.635, nll_loss=1.956, ppl=3.88, wps=27721, ups=0.55, wpb=50683.2, bsz=3040.5, num_updates=57400, lr=0.000237584, gnorm=0.277, loss_scale=8, train_wall=179, wall=105924
2021-03-15 15:02:31 | INFO | train_inner | epoch 003:  17031 / 20258 loss=3.615, nll_loss=1.933, ppl=3.82, wps=27831.9, ups=0.55, wpb=50941.2, bsz=2981, num_updates=57500, lr=0.000237377, gnorm=0.276, loss_scale=8, train_wall=180, wall=106107
2021-03-15 15:05:34 | INFO | train_inner | epoch 003:  17131 / 20258 loss=3.624, nll_loss=1.943, ppl=3.85, wps=27797.6, ups=0.55, wpb=50874.1, bsz=3034.9, num_updates=57600, lr=0.000237171, gnorm=0.27, loss_scale=8, train_wall=180, wall=106290
2021-03-15 15:08:37 | INFO | train_inner | epoch 003:  17231 / 20258 loss=3.622, nll_loss=1.941, ppl=3.84, wps=27913, ups=0.55, wpb=51048.4, bsz=3027.4, num_updates=57700, lr=0.000236965, gnorm=0.277, loss_scale=8, train_wall=180, wall=106473
2021-03-15 15:11:40 | INFO | train_inner | epoch 003:  17331 / 20258 loss=3.646, nll_loss=1.969, ppl=3.91, wps=27796.2, ups=0.55, wpb=50787.2, bsz=2961.4, num_updates=57800, lr=0.00023676, gnorm=0.286, loss_scale=8, train_wall=179, wall=106655
2021-03-15 15:13:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 15:14:45 | INFO | train_inner | epoch 003:  17432 / 20258 loss=3.633, nll_loss=1.954, ppl=3.87, wps=27702.6, ups=0.54, wpb=51261.1, bsz=3042.9, num_updates=57900, lr=0.000236556, gnorm=0.273, loss_scale=8, train_wall=182, wall=106840
2021-03-15 15:17:48 | INFO | train_inner | epoch 003:  17532 / 20258 loss=3.62, nll_loss=1.939, ppl=3.83, wps=27787.2, ups=0.55, wpb=50893.3, bsz=3100.6, num_updates=58000, lr=0.000236352, gnorm=0.276, loss_scale=8, train_wall=180, wall=107024
2021-03-15 15:20:51 | INFO | train_inner | epoch 003:  17632 / 20258 loss=3.631, nll_loss=1.952, ppl=3.87, wps=27794.5, ups=0.55, wpb=50708.2, bsz=3014.2, num_updates=58100, lr=0.000236148, gnorm=0.28, loss_scale=8, train_wall=179, wall=107206
2021-03-15 15:23:54 | INFO | train_inner | epoch 003:  17732 / 20258 loss=3.626, nll_loss=1.946, ppl=3.85, wps=27868, ups=0.55, wpb=51054.1, bsz=3026.9, num_updates=58200, lr=0.000235945, gnorm=0.27, loss_scale=8, train_wall=180, wall=107389
2021-03-15 15:26:57 | INFO | train_inner | epoch 003:  17832 / 20258 loss=3.634, nll_loss=1.955, ppl=3.88, wps=27936.9, ups=0.55, wpb=51069.6, bsz=2905.9, num_updates=58300, lr=0.000235743, gnorm=0.275, loss_scale=8, train_wall=179, wall=107572
2021-03-15 15:29:58 | INFO | train_inner | epoch 003:  17932 / 20258 loss=3.636, nll_loss=1.957, ppl=3.88, wps=27850.8, ups=0.55, wpb=50637.2, bsz=2966.2, num_updates=58400, lr=0.000235541, gnorm=0.28, loss_scale=8, train_wall=179, wall=107754
2021-03-15 15:33:01 | INFO | train_inner | epoch 003:  18032 / 20258 loss=3.622, nll_loss=1.942, ppl=3.84, wps=27877, ups=0.55, wpb=50865.2, bsz=3045.9, num_updates=58500, lr=0.000235339, gnorm=0.272, loss_scale=8, train_wall=179, wall=107936
2021-03-15 15:36:03 | INFO | train_inner | epoch 003:  18132 / 20258 loss=3.609, nll_loss=1.927, ppl=3.8, wps=27884.4, ups=0.55, wpb=50931.3, bsz=2991.3, num_updates=58600, lr=0.000235138, gnorm=0.27, loss_scale=8, train_wall=180, wall=108119
2021-03-15 15:39:05 | INFO | train_inner | epoch 003:  18232 / 20258 loss=3.608, nll_loss=1.926, ppl=3.8, wps=27796.1, ups=0.55, wpb=50589.4, bsz=2958.2, num_updates=58700, lr=0.000234938, gnorm=0.274, loss_scale=8, train_wall=179, wall=108301
2021-03-15 15:42:09 | INFO | train_inner | epoch 003:  18332 / 20258 loss=3.613, nll_loss=1.931, ppl=3.81, wps=27803.4, ups=0.55, wpb=50911.8, bsz=3097.7, num_updates=58800, lr=0.000234738, gnorm=0.281, loss_scale=8, train_wall=180, wall=108484
2021-03-15 15:45:12 | INFO | train_inner | epoch 003:  18432 / 20258 loss=3.616, nll_loss=1.935, ppl=3.82, wps=27853.9, ups=0.55, wpb=51030.9, bsz=2963, num_updates=58900, lr=0.000234539, gnorm=0.277, loss_scale=16, train_wall=180, wall=108667
2021-03-15 15:46:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 15:48:17 | INFO | train_inner | epoch 003:  18533 / 20258 loss=3.605, nll_loss=1.922, ppl=3.79, wps=27524.5, ups=0.54, wpb=50843.4, bsz=3065.9, num_updates=59000, lr=0.00023434, gnorm=0.274, loss_scale=8, train_wall=182, wall=108852
2021-03-15 15:51:20 | INFO | train_inner | epoch 003:  18633 / 20258 loss=3.622, nll_loss=1.941, ppl=3.84, wps=27873.2, ups=0.55, wpb=51009.5, bsz=3049.5, num_updates=59100, lr=0.000234142, gnorm=0.272, loss_scale=8, train_wall=180, wall=109035
2021-03-15 15:54:23 | INFO | train_inner | epoch 003:  18733 / 20258 loss=3.629, nll_loss=1.95, ppl=3.86, wps=27966, ups=0.55, wpb=51183, bsz=3043, num_updates=59200, lr=0.000233944, gnorm=0.277, loss_scale=8, train_wall=180, wall=109218
2021-03-15 15:57:26 | INFO | train_inner | epoch 003:  18833 / 20258 loss=3.633, nll_loss=1.954, ppl=3.87, wps=27915.4, ups=0.55, wpb=51123.6, bsz=3003.5, num_updates=59300, lr=0.000233747, gnorm=0.279, loss_scale=8, train_wall=179, wall=109401
2021-03-15 16:00:28 | INFO | train_inner | epoch 003:  18933 / 20258 loss=3.63, nll_loss=1.951, ppl=3.87, wps=27705.1, ups=0.55, wpb=50509.1, bsz=3019.4, num_updates=59400, lr=0.00023355, gnorm=0.277, loss_scale=8, train_wall=179, wall=109584
2021-03-15 16:03:31 | INFO | train_inner | epoch 003:  19033 / 20258 loss=3.623, nll_loss=1.943, ppl=3.85, wps=27792.6, ups=0.55, wpb=50886.9, bsz=3091.6, num_updates=59500, lr=0.000233353, gnorm=0.271, loss_scale=8, train_wall=180, wall=109767
2021-03-15 16:06:33 | INFO | train_inner | epoch 003:  19133 / 20258 loss=3.631, nll_loss=1.952, ppl=3.87, wps=27880.7, ups=0.55, wpb=50706.8, bsz=2907.2, num_updates=59600, lr=0.000233157, gnorm=0.279, loss_scale=8, train_wall=179, wall=109948
2021-03-15 16:09:35 | INFO | train_inner | epoch 003:  19233 / 20258 loss=3.644, nll_loss=1.967, ppl=3.91, wps=27857.2, ups=0.55, wpb=50759.7, bsz=3073, num_updates=59700, lr=0.000232962, gnorm=0.277, loss_scale=8, train_wall=179, wall=110131
2021-03-15 16:12:38 | INFO | train_inner | epoch 003:  19333 / 20258 loss=3.624, nll_loss=1.944, ppl=3.85, wps=27934.1, ups=0.55, wpb=51137.7, bsz=3040.6, num_updates=59800, lr=0.000232767, gnorm=0.272, loss_scale=8, train_wall=180, wall=110314
2021-03-15 16:15:41 | INFO | train_inner | epoch 003:  19433 / 20258 loss=3.633, nll_loss=1.953, ppl=3.87, wps=27825.8, ups=0.55, wpb=50780.5, bsz=2914.1, num_updates=59900, lr=0.000232573, gnorm=0.28, loss_scale=8, train_wall=179, wall=110496
2021-03-15 16:18:44 | INFO | train_inner | epoch 003:  19533 / 20258 loss=3.607, nll_loss=1.925, ppl=3.8, wps=27781.1, ups=0.55, wpb=50789.7, bsz=2910.3, num_updates=60000, lr=0.000232379, gnorm=0.27, loss_scale=16, train_wall=179, wall=110679
2021-03-15 16:18:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 16:18:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:18:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:18:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:18:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:18:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:18:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:18:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:18:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:18:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:18:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:18:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:18:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:18:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:18:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:18:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:18:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:18:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:18:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:02 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.031 | nll_loss 2.312 | ppl 4.96 | bleu 28.65 | wps 4387.4 | wpb 2432 | bsz 90.4 | num_updates 60000 | best_loss 4.031
2021-03-15 16:19:02 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 16:19:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:19:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:19:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:19:54 | INFO | valid1 | epoch 003 | valid on 'valid1' subset | loss 4.015 | nll_loss 2.318 | ppl 4.99 | bleu 26.68 | wps 4245.6 | wpb 2359.4 | bsz 106.4 | num_updates 60000 | best_loss 4.015
2021-03-15 16:19:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 16:20:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_3_60000.pt (epoch 3 @ 60000 updates, score 4.031) (writing took 7.778342426987365 seconds)
2021-03-15 16:23:05 | INFO | train_inner | epoch 003:  19633 / 20258 loss=3.598, nll_loss=1.915, ppl=3.77, wps=19527.2, ups=0.38, wpb=51137.3, bsz=3135.1, num_updates=60100, lr=0.000232186, gnorm=0.272, loss_scale=16, train_wall=180, wall=110941
2021-03-15 16:23:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 16:26:10 | INFO | train_inner | epoch 003:  19734 / 20258 loss=3.638, nll_loss=1.96, ppl=3.89, wps=27593.9, ups=0.54, wpb=50862, bsz=2976.8, num_updates=60200, lr=0.000231993, gnorm=0.28, loss_scale=8, train_wall=181, wall=111125
2021-03-15 16:29:13 | INFO | train_inner | epoch 003:  19834 / 20258 loss=3.619, nll_loss=1.938, ppl=3.83, wps=27870.2, ups=0.55, wpb=51054.8, bsz=3018.6, num_updates=60300, lr=0.0002318, gnorm=0.274, loss_scale=8, train_wall=180, wall=111308
2021-03-15 16:32:16 | INFO | train_inner | epoch 003:  19934 / 20258 loss=3.621, nll_loss=1.941, ppl=3.84, wps=27859.4, ups=0.55, wpb=50860.7, bsz=2988.3, num_updates=60400, lr=0.000231608, gnorm=0.273, loss_scale=8, train_wall=180, wall=111491
2021-03-15 16:35:18 | INFO | train_inner | epoch 003:  20034 / 20258 loss=3.622, nll_loss=1.942, ppl=3.84, wps=27933.4, ups=0.55, wpb=51022, bsz=3051.5, num_updates=60500, lr=0.000231417, gnorm=0.275, loss_scale=8, train_wall=180, wall=111674
2021-03-15 16:38:21 | INFO | train_inner | epoch 003:  20134 / 20258 loss=3.635, nll_loss=1.957, ppl=3.88, wps=27940.3, ups=0.55, wpb=51153.4, bsz=3060.5, num_updates=60600, lr=0.000231226, gnorm=0.274, loss_scale=8, train_wall=180, wall=111857
2021-03-15 16:41:24 | INFO | train_inner | epoch 003:  20234 / 20258 loss=3.616, nll_loss=1.936, ppl=3.83, wps=27795.2, ups=0.55, wpb=50814.5, bsz=3058.5, num_updates=60700, lr=0.000231035, gnorm=0.274, loss_scale=8, train_wall=180, wall=112040
2021-03-15 16:42:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 16:42:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:26 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.03 | nll_loss 2.312 | ppl 4.96 | bleu 28.64 | wps 4401.4 | wpb 2432 | bsz 90.4 | num_updates 60724 | best_loss 4.03
2021-03-15 16:42:26 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 16:42:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:42:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 16:42:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 16:42:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 16:43:18 | INFO | valid1 | epoch 003 | valid on 'valid1' subset | loss 4.014 | nll_loss 2.32 | ppl 4.99 | bleu 26.68 | wps 4248.7 | wpb 2359.4 | bsz 106.4 | num_updates 60724 | best_loss 4.014
2021-03-15 16:43:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 16:43:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint3.pt (epoch 3 @ 60724 updates, score 4.03) (writing took 7.819914879044518 seconds)
2021-03-15 16:43:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-03-15 16:43:26 | INFO | train | epoch 003 | loss 3.647 | nll_loss 1.968 | ppl 3.91 | wps 27559.8 | ups 0.54 | wpb 50905.6 | bsz 3010.5 | num_updates 60724 | lr 0.00023099 | gnorm 0.281 | loss_scale 8 | train_wall 36349 | wall 112162
2021-03-15 16:43:26 | INFO | fairseq.trainer | begin training epoch 4
2021-03-15 16:45:45 | INFO | train_inner | epoch 004:     76 / 20258 loss=3.616, nll_loss=1.934, ppl=3.82, wps=19458.6, ups=0.38, wpb=50727.3, bsz=2935.2, num_updates=60800, lr=0.000230845, gnorm=0.269, loss_scale=8, train_wall=179, wall=112300
2021-03-15 16:48:47 | INFO | train_inner | epoch 004:    176 / 20258 loss=3.611, nll_loss=1.929, ppl=3.81, wps=27784.6, ups=0.55, wpb=50568.6, bsz=2925.7, num_updates=60900, lr=0.000230656, gnorm=0.276, loss_scale=8, train_wall=179, wall=112482
2021-03-15 16:51:49 | INFO | train_inner | epoch 004:    276 / 20258 loss=3.612, nll_loss=1.931, ppl=3.81, wps=27871.8, ups=0.55, wpb=50903.4, bsz=3018.2, num_updates=61000, lr=0.000230466, gnorm=0.28, loss_scale=8, train_wall=180, wall=112665
2021-03-15 16:54:53 | INFO | train_inner | epoch 004:    376 / 20258 loss=3.599, nll_loss=1.915, ppl=3.77, wps=27760.5, ups=0.55, wpb=50857.2, bsz=3063.6, num_updates=61100, lr=0.000230278, gnorm=0.27, loss_scale=8, train_wall=180, wall=112848
2021-03-15 16:57:55 | INFO | train_inner | epoch 004:    476 / 20258 loss=3.615, nll_loss=1.934, ppl=3.82, wps=27904.1, ups=0.55, wpb=50999.9, bsz=3025.7, num_updates=61200, lr=0.000230089, gnorm=0.275, loss_scale=16, train_wall=179, wall=113031
2021-03-15 16:58:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 17:01:00 | INFO | train_inner | epoch 004:    577 / 20258 loss=3.609, nll_loss=1.927, ppl=3.8, wps=27595, ups=0.54, wpb=50900, bsz=3059, num_updates=61300, lr=0.000229902, gnorm=0.278, loss_scale=8, train_wall=181, wall=113215
2021-03-15 17:04:02 | INFO | train_inner | epoch 004:    677 / 20258 loss=3.592, nll_loss=1.907, ppl=3.75, wps=27773.8, ups=0.55, wpb=50621.9, bsz=3059.8, num_updates=61400, lr=0.000229714, gnorm=0.274, loss_scale=8, train_wall=179, wall=113398
2021-03-15 17:07:05 | INFO | train_inner | epoch 004:    777 / 20258 loss=3.605, nll_loss=1.922, ppl=3.79, wps=27918.5, ups=0.55, wpb=50960.6, bsz=2935, num_updates=61500, lr=0.000229528, gnorm=0.268, loss_scale=8, train_wall=179, wall=113580
2021-03-15 17:10:08 | INFO | train_inner | epoch 004:    877 / 20258 loss=3.599, nll_loss=1.916, ppl=3.77, wps=27784.9, ups=0.55, wpb=50946.9, bsz=3039.4, num_updates=61600, lr=0.000229341, gnorm=0.27, loss_scale=8, train_wall=180, wall=113764
2021-03-15 17:13:10 | INFO | train_inner | epoch 004:    977 / 20258 loss=3.606, nll_loss=1.923, ppl=3.79, wps=27925.2, ups=0.55, wpb=50703.9, bsz=2826.1, num_updates=61700, lr=0.000229155, gnorm=0.282, loss_scale=8, train_wall=179, wall=113945
2021-03-15 17:16:12 | INFO | train_inner | epoch 004:   1077 / 20258 loss=3.605, nll_loss=1.922, ppl=3.79, wps=27950.4, ups=0.55, wpb=50871.3, bsz=2906.9, num_updates=61800, lr=0.00022897, gnorm=0.277, loss_scale=8, train_wall=179, wall=114127
2021-03-15 17:19:14 | INFO | train_inner | epoch 004:   1177 / 20258 loss=3.602, nll_loss=1.919, ppl=3.78, wps=27878.3, ups=0.55, wpb=50891.3, bsz=3091.7, num_updates=61900, lr=0.000228785, gnorm=0.271, loss_scale=8, train_wall=179, wall=114310
2021-03-15 17:22:17 | INFO | train_inner | epoch 004:   1277 / 20258 loss=3.595, nll_loss=1.91, ppl=3.76, wps=27952.3, ups=0.55, wpb=51012.4, bsz=2930.6, num_updates=62000, lr=0.0002286, gnorm=0.269, loss_scale=8, train_wall=180, wall=114492
2021-03-15 17:25:20 | INFO | train_inner | epoch 004:   1377 / 20258 loss=3.614, nll_loss=1.932, ppl=3.82, wps=27930.7, ups=0.55, wpb=51097.3, bsz=3050.8, num_updates=62100, lr=0.000228416, gnorm=0.27, loss_scale=8, train_wall=180, wall=114675
2021-03-15 17:28:22 | INFO | train_inner | epoch 004:   1477 / 20258 loss=3.617, nll_loss=1.936, ppl=3.83, wps=27843.8, ups=0.55, wpb=50786, bsz=3030.1, num_updates=62200, lr=0.000228232, gnorm=0.271, loss_scale=8, train_wall=179, wall=114857
2021-03-15 17:29:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 17:31:27 | INFO | train_inner | epoch 004:   1578 / 20258 loss=3.611, nll_loss=1.929, ppl=3.81, wps=27585.9, ups=0.54, wpb=51055.1, bsz=3050.4, num_updates=62300, lr=0.000228049, gnorm=0.265, loss_scale=8, train_wall=182, wall=115043
2021-03-15 17:34:29 | INFO | train_inner | epoch 004:   1678 / 20258 loss=3.609, nll_loss=1.927, ppl=3.8, wps=27840.1, ups=0.55, wpb=50759.7, bsz=3079.3, num_updates=62400, lr=0.000227866, gnorm=0.27, loss_scale=8, train_wall=179, wall=115225
2021-03-15 17:37:31 | INFO | train_inner | epoch 004:   1778 / 20258 loss=3.612, nll_loss=1.931, ppl=3.81, wps=27875.5, ups=0.55, wpb=50713, bsz=2961.3, num_updates=62500, lr=0.000227684, gnorm=0.27, loss_scale=8, train_wall=179, wall=115407
2021-03-15 17:40:33 | INFO | train_inner | epoch 004:   1878 / 20258 loss=3.615, nll_loss=1.933, ppl=3.82, wps=27880.5, ups=0.55, wpb=50798.8, bsz=2899.4, num_updates=62600, lr=0.000227502, gnorm=0.272, loss_scale=8, train_wall=179, wall=115589
2021-03-15 17:43:36 | INFO | train_inner | epoch 004:   1978 / 20258 loss=3.601, nll_loss=1.918, ppl=3.78, wps=27821.2, ups=0.55, wpb=50783.9, bsz=3116.7, num_updates=62700, lr=0.000227321, gnorm=0.273, loss_scale=8, train_wall=179, wall=115772
2021-03-15 17:46:39 | INFO | train_inner | epoch 004:   2078 / 20258 loss=3.595, nll_loss=1.912, ppl=3.76, wps=27785.4, ups=0.55, wpb=50929.7, bsz=3110.9, num_updates=62800, lr=0.00022714, gnorm=0.272, loss_scale=8, train_wall=180, wall=115955
2021-03-15 17:49:42 | INFO | train_inner | epoch 004:   2178 / 20258 loss=3.618, nll_loss=1.938, ppl=3.83, wps=27902.6, ups=0.55, wpb=50882.6, bsz=3093.7, num_updates=62900, lr=0.000226959, gnorm=0.272, loss_scale=8, train_wall=179, wall=116137
2021-03-15 17:52:44 | INFO | train_inner | epoch 004:   2278 / 20258 loss=3.613, nll_loss=1.932, ppl=3.81, wps=27863.9, ups=0.55, wpb=50873.6, bsz=2994.6, num_updates=63000, lr=0.000226779, gnorm=0.271, loss_scale=8, train_wall=179, wall=116320
2021-03-15 17:55:47 | INFO | train_inner | epoch 004:   2378 / 20258 loss=3.598, nll_loss=1.915, ppl=3.77, wps=27936.2, ups=0.55, wpb=50925.9, bsz=3060.6, num_updates=63100, lr=0.000226599, gnorm=0.271, loss_scale=8, train_wall=179, wall=116502
2021-03-15 17:58:49 | INFO | train_inner | epoch 004:   2478 / 20258 loss=3.611, nll_loss=1.93, ppl=3.81, wps=27888.3, ups=0.55, wpb=50935.1, bsz=2971.7, num_updates=63200, lr=0.00022642, gnorm=0.272, loss_scale=8, train_wall=179, wall=116685
2021-03-15 18:01:52 | INFO | train_inner | epoch 004:   2578 / 20258 loss=3.613, nll_loss=1.931, ppl=3.81, wps=27905, ups=0.55, wpb=50952.8, bsz=3051.5, num_updates=63300, lr=0.000226241, gnorm=0.272, loss_scale=16, train_wall=179, wall=116867
2021-03-15 18:04:55 | INFO | train_inner | epoch 004:   2678 / 20258 loss=3.614, nll_loss=1.932, ppl=3.81, wps=27924.1, ups=0.55, wpb=51071.7, bsz=2887.2, num_updates=63400, lr=0.000226062, gnorm=0.273, loss_scale=16, train_wall=180, wall=117050
2021-03-15 18:07:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 18:07:59 | INFO | train_inner | epoch 004:   2779 / 20258 loss=3.608, nll_loss=1.926, ppl=3.8, wps=27630.6, ups=0.54, wpb=50834.2, bsz=2999.4, num_updates=63500, lr=0.000225884, gnorm=0.274, loss_scale=8, train_wall=181, wall=117234
2021-03-15 18:11:02 | INFO | train_inner | epoch 004:   2879 / 20258 loss=3.601, nll_loss=1.918, ppl=3.78, wps=27833.1, ups=0.55, wpb=50894.4, bsz=2941.3, num_updates=63600, lr=0.000225706, gnorm=0.275, loss_scale=8, train_wall=180, wall=117417
2021-03-15 18:14:04 | INFO | train_inner | epoch 004:   2979 / 20258 loss=3.591, nll_loss=1.906, ppl=3.75, wps=27780.2, ups=0.55, wpb=50741, bsz=2995.8, num_updates=63700, lr=0.000225529, gnorm=0.272, loss_scale=8, train_wall=179, wall=117600
2021-03-15 18:17:07 | INFO | train_inner | epoch 004:   3079 / 20258 loss=3.606, nll_loss=1.923, ppl=3.79, wps=27999.5, ups=0.55, wpb=51214.6, bsz=3087.2, num_updates=63800, lr=0.000225352, gnorm=0.274, loss_scale=8, train_wall=180, wall=117783
2021-03-15 18:20:10 | INFO | train_inner | epoch 004:   3179 / 20258 loss=3.596, nll_loss=1.912, ppl=3.76, wps=27821.8, ups=0.55, wpb=50752.3, bsz=2982.6, num_updates=63900, lr=0.000225176, gnorm=0.273, loss_scale=8, train_wall=179, wall=117965
2021-03-15 18:23:13 | INFO | train_inner | epoch 004:   3279 / 20258 loss=3.598, nll_loss=1.915, ppl=3.77, wps=27927.2, ups=0.54, wpb=51263.6, bsz=3159.2, num_updates=64000, lr=0.000225, gnorm=0.275, loss_scale=8, train_wall=180, wall=118149
2021-03-15 18:26:16 | INFO | train_inner | epoch 004:   3379 / 20258 loss=3.594, nll_loss=1.91, ppl=3.76, wps=27868.1, ups=0.55, wpb=50981.4, bsz=3073.7, num_updates=64100, lr=0.000224824, gnorm=0.27, loss_scale=8, train_wall=180, wall=118332
2021-03-15 18:29:19 | INFO | train_inner | epoch 004:   3479 / 20258 loss=3.6, nll_loss=1.917, ppl=3.78, wps=27851.7, ups=0.55, wpb=51044.1, bsz=3089.2, num_updates=64200, lr=0.000224649, gnorm=0.273, loss_scale=8, train_wall=180, wall=118515
2021-03-15 18:32:22 | INFO | train_inner | epoch 004:   3579 / 20258 loss=3.602, nll_loss=1.918, ppl=3.78, wps=27955.9, ups=0.55, wpb=51114.7, bsz=2921.8, num_updates=64300, lr=0.000224475, gnorm=0.268, loss_scale=8, train_wall=180, wall=118698
2021-03-15 18:35:25 | INFO | train_inner | epoch 004:   3679 / 20258 loss=3.593, nll_loss=1.909, ppl=3.75, wps=27882.1, ups=0.55, wpb=51012.9, bsz=3013.9, num_updates=64400, lr=0.0002243, gnorm=0.267, loss_scale=8, train_wall=180, wall=118881
2021-03-15 18:38:28 | INFO | train_inner | epoch 004:   3779 / 20258 loss=3.601, nll_loss=1.918, ppl=3.78, wps=27840.1, ups=0.55, wpb=50797.3, bsz=3069, num_updates=64500, lr=0.000224126, gnorm=0.284, loss_scale=8, train_wall=179, wall=119063
2021-03-15 18:41:31 | INFO | train_inner | epoch 004:   3879 / 20258 loss=3.614, nll_loss=1.933, ppl=3.82, wps=27816.5, ups=0.55, wpb=51012.3, bsz=3020.6, num_updates=64600, lr=0.000223953, gnorm=0.27, loss_scale=16, train_wall=180, wall=119246
2021-03-15 18:43:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 18:44:35 | INFO | train_inner | epoch 004:   3980 / 20258 loss=3.61, nll_loss=1.929, ppl=3.81, wps=27488.5, ups=0.54, wpb=50597.2, bsz=3006.8, num_updates=64700, lr=0.00022378, gnorm=0.269, loss_scale=8, train_wall=181, wall=119431
2021-03-15 18:47:37 | INFO | train_inner | epoch 004:   4080 / 20258 loss=3.597, nll_loss=1.913, ppl=3.77, wps=27835.2, ups=0.55, wpb=50681.2, bsz=2956.4, num_updates=64800, lr=0.000223607, gnorm=0.267, loss_scale=8, train_wall=179, wall=119613
2021-03-15 18:50:40 | INFO | train_inner | epoch 004:   4180 / 20258 loss=3.588, nll_loss=1.903, ppl=3.74, wps=27862.2, ups=0.55, wpb=50849.4, bsz=3008.1, num_updates=64900, lr=0.000223434, gnorm=0.274, loss_scale=8, train_wall=180, wall=119795
2021-03-15 18:53:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 18:53:44 | INFO | train_inner | epoch 004:   4281 / 20258 loss=3.606, nll_loss=1.924, ppl=3.8, wps=27656.5, ups=0.54, wpb=50953.5, bsz=3094.2, num_updates=65000, lr=0.000223263, gnorm=0.271, loss_scale=4, train_wall=181, wall=119979
2021-03-15 18:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 18:53:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:53:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:53:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:53:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:53:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:53:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:53:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:53:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:53:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:53:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:53:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:53:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:53:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:53:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:53:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:53:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:53:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:53:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:53:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:53:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:53:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:02 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.023 | nll_loss 2.305 | ppl 4.94 | bleu 28.88 | wps 4354.5 | wpb 2432 | bsz 90.4 | num_updates 65000 | best_loss 4.023
2021-03-15 18:54:02 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 18:54:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 18:54:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 18:54:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 18:54:55 | INFO | valid1 | epoch 004 | valid on 'valid1' subset | loss 4.005 | nll_loss 2.31 | ppl 4.96 | bleu 26.79 | wps 4245.3 | wpb 2359.4 | bsz 106.4 | num_updates 65000 | best_loss 4.005
2021-03-15 18:54:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 18:55:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_4_65000.pt (epoch 4 @ 65000 updates, score 4.023) (writing took 6.556757814018056 seconds)
2021-03-15 18:58:04 | INFO | train_inner | epoch 004:   4381 / 20258 loss=3.594, nll_loss=1.91, ppl=3.76, wps=19520.5, ups=0.38, wpb=50816.4, bsz=2905.5, num_updates=65100, lr=0.000223091, gnorm=0.284, loss_scale=4, train_wall=180, wall=120240
2021-03-15 19:01:07 | INFO | train_inner | epoch 004:   4481 / 20258 loss=3.61, nll_loss=1.928, ppl=3.81, wps=27900.2, ups=0.55, wpb=50987.2, bsz=3027.7, num_updates=65200, lr=0.00022292, gnorm=0.275, loss_scale=4, train_wall=179, wall=120422
2021-03-15 19:04:09 | INFO | train_inner | epoch 004:   4581 / 20258 loss=3.617, nll_loss=1.936, ppl=3.83, wps=28015.4, ups=0.55, wpb=51079.4, bsz=2882.6, num_updates=65300, lr=0.000222749, gnorm=0.276, loss_scale=4, train_wall=179, wall=120605
2021-03-15 19:07:12 | INFO | train_inner | epoch 004:   4681 / 20258 loss=3.609, nll_loss=1.927, ppl=3.8, wps=27872.1, ups=0.55, wpb=50839.6, bsz=2907.7, num_updates=65400, lr=0.000222579, gnorm=0.279, loss_scale=4, train_wall=179, wall=120787
2021-03-15 19:10:14 | INFO | train_inner | epoch 004:   4781 / 20258 loss=3.598, nll_loss=1.915, ppl=3.77, wps=27932.4, ups=0.55, wpb=51064.1, bsz=3040.8, num_updates=65500, lr=0.000222409, gnorm=0.273, loss_scale=4, train_wall=180, wall=120970
2021-03-15 19:13:17 | INFO | train_inner | epoch 004:   4881 / 20258 loss=3.617, nll_loss=1.936, ppl=3.83, wps=28009.7, ups=0.55, wpb=51146.6, bsz=2922.2, num_updates=65600, lr=0.000222239, gnorm=0.279, loss_scale=4, train_wall=180, wall=121153
2021-03-15 19:16:20 | INFO | train_inner | epoch 004:   4981 / 20258 loss=3.624, nll_loss=1.944, ppl=3.85, wps=27830.7, ups=0.55, wpb=50847.7, bsz=3081.6, num_updates=65700, lr=0.00022207, gnorm=0.279, loss_scale=4, train_wall=179, wall=121335
2021-03-15 19:19:22 | INFO | train_inner | epoch 004:   5081 / 20258 loss=3.596, nll_loss=1.913, ppl=3.77, wps=27873.6, ups=0.55, wpb=50753.7, bsz=3033, num_updates=65800, lr=0.000221901, gnorm=0.275, loss_scale=4, train_wall=179, wall=121517
2021-03-15 19:22:24 | INFO | train_inner | epoch 004:   5181 / 20258 loss=3.603, nll_loss=1.92, ppl=3.78, wps=27834.8, ups=0.55, wpb=50810.7, bsz=3034.1, num_updates=65900, lr=0.000221733, gnorm=0.276, loss_scale=4, train_wall=179, wall=121700
2021-03-15 19:25:27 | INFO | train_inner | epoch 004:   5281 / 20258 loss=3.616, nll_loss=1.936, ppl=3.83, wps=27950.7, ups=0.55, wpb=51014.1, bsz=2996.9, num_updates=66000, lr=0.000221565, gnorm=0.268, loss_scale=4, train_wall=179, wall=121882
2021-03-15 19:28:30 | INFO | train_inner | epoch 004:   5381 / 20258 loss=3.599, nll_loss=1.916, ppl=3.77, wps=27938.8, ups=0.55, wpb=51074.4, bsz=2924.7, num_updates=66100, lr=0.000221397, gnorm=0.27, loss_scale=8, train_wall=180, wall=122065
2021-03-15 19:31:32 | INFO | train_inner | epoch 004:   5481 / 20258 loss=3.607, nll_loss=1.924, ppl=3.8, wps=27982.2, ups=0.55, wpb=50946.6, bsz=2948.6, num_updates=66200, lr=0.00022123, gnorm=0.278, loss_scale=8, train_wall=179, wall=122247
2021-03-15 19:34:35 | INFO | train_inner | epoch 004:   5581 / 20258 loss=3.587, nll_loss=1.903, ppl=3.74, wps=27691, ups=0.55, wpb=50671.7, bsz=3015.4, num_updates=66300, lr=0.000221063, gnorm=0.274, loss_scale=8, train_wall=180, wall=122430
2021-03-15 19:37:38 | INFO | train_inner | epoch 004:   5681 / 20258 loss=3.609, nll_loss=1.927, ppl=3.8, wps=27816.2, ups=0.55, wpb=50961.6, bsz=2951.4, num_updates=66400, lr=0.000220896, gnorm=0.274, loss_scale=8, train_wall=180, wall=122614
2021-03-15 19:40:41 | INFO | train_inner | epoch 004:   5781 / 20258 loss=3.618, nll_loss=1.937, ppl=3.83, wps=27832.4, ups=0.55, wpb=50840.4, bsz=2975.5, num_updates=66500, lr=0.00022073, gnorm=0.278, loss_scale=8, train_wall=179, wall=122796
2021-03-15 19:43:43 | INFO | train_inner | epoch 004:   5881 / 20258 loss=3.607, nll_loss=1.925, ppl=3.8, wps=27781.8, ups=0.55, wpb=50710.5, bsz=2970.2, num_updates=66600, lr=0.000220564, gnorm=0.274, loss_scale=8, train_wall=179, wall=122979
2021-03-15 19:46:45 | INFO | train_inner | epoch 004:   5981 / 20258 loss=3.615, nll_loss=1.935, ppl=3.82, wps=27828.5, ups=0.55, wpb=50638.6, bsz=2998.4, num_updates=66700, lr=0.000220399, gnorm=0.283, loss_scale=8, train_wall=179, wall=123161
2021-03-15 19:49:48 | INFO | train_inner | epoch 004:   6081 / 20258 loss=3.593, nll_loss=1.909, ppl=3.76, wps=27886.7, ups=0.55, wpb=51012.2, bsz=3035, num_updates=66800, lr=0.000220234, gnorm=0.266, loss_scale=8, train_wall=180, wall=123344
2021-03-15 19:52:51 | INFO | train_inner | epoch 004:   6181 / 20258 loss=3.6, nll_loss=1.917, ppl=3.78, wps=27927.3, ups=0.55, wpb=51056.3, bsz=3062.1, num_updates=66900, lr=0.000220069, gnorm=0.268, loss_scale=8, train_wall=180, wall=123526
2021-03-15 19:55:53 | INFO | train_inner | epoch 004:   6281 / 20258 loss=3.598, nll_loss=1.915, ppl=3.77, wps=27822.6, ups=0.55, wpb=50779.2, bsz=3000.9, num_updates=67000, lr=0.000219905, gnorm=0.271, loss_scale=8, train_wall=179, wall=123709
2021-03-15 19:57:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 19:58:57 | INFO | train_inner | epoch 004:   6382 / 20258 loss=3.591, nll_loss=1.907, ppl=3.75, wps=27671.1, ups=0.54, wpb=50885.7, bsz=3009.8, num_updates=67100, lr=0.000219741, gnorm=0.268, loss_scale=8, train_wall=181, wall=123893
2021-03-15 20:02:00 | INFO | train_inner | epoch 004:   6482 / 20258 loss=3.599, nll_loss=1.916, ppl=3.77, wps=27862.3, ups=0.55, wpb=50861.2, bsz=3134.7, num_updates=67200, lr=0.000219578, gnorm=0.27, loss_scale=8, train_wall=179, wall=124075
2021-03-15 20:05:02 | INFO | train_inner | epoch 004:   6582 / 20258 loss=3.611, nll_loss=1.93, ppl=3.81, wps=27944, ups=0.55, wpb=50912.7, bsz=3072.5, num_updates=67300, lr=0.000219414, gnorm=0.274, loss_scale=8, train_wall=179, wall=124258
2021-03-15 20:08:05 | INFO | train_inner | epoch 004:   6682 / 20258 loss=3.595, nll_loss=1.912, ppl=3.76, wps=27809.6, ups=0.55, wpb=50874.9, bsz=3085.4, num_updates=67400, lr=0.000219251, gnorm=0.27, loss_scale=8, train_wall=180, wall=124441
2021-03-15 20:11:07 | INFO | train_inner | epoch 004:   6782 / 20258 loss=3.616, nll_loss=1.935, ppl=3.82, wps=27932.9, ups=0.55, wpb=50875.3, bsz=2979, num_updates=67500, lr=0.000219089, gnorm=0.27, loss_scale=8, train_wall=179, wall=124623
2021-03-15 20:14:10 | INFO | train_inner | epoch 004:   6882 / 20258 loss=3.591, nll_loss=1.907, ppl=3.75, wps=27864, ups=0.55, wpb=50945.7, bsz=2991.5, num_updates=67600, lr=0.000218927, gnorm=0.27, loss_scale=8, train_wall=180, wall=124806
2021-03-15 20:17:12 | INFO | train_inner | epoch 004:   6982 / 20258 loss=3.618, nll_loss=1.937, ppl=3.83, wps=27979.8, ups=0.55, wpb=50860.9, bsz=2907.1, num_updates=67700, lr=0.000218765, gnorm=0.274, loss_scale=8, train_wall=179, wall=124987
2021-03-15 20:20:14 | INFO | train_inner | epoch 004:   7082 / 20258 loss=3.608, nll_loss=1.926, ppl=3.8, wps=27961.3, ups=0.55, wpb=51024.2, bsz=2935.5, num_updates=67800, lr=0.000218604, gnorm=0.27, loss_scale=8, train_wall=179, wall=125170
2021-03-15 20:23:17 | INFO | train_inner | epoch 004:   7182 / 20258 loss=3.609, nll_loss=1.928, ppl=3.8, wps=27954.4, ups=0.55, wpb=51040.7, bsz=2941.8, num_updates=67900, lr=0.000218443, gnorm=0.274, loss_scale=8, train_wall=179, wall=125352
2021-03-15 20:26:20 | INFO | train_inner | epoch 004:   7282 / 20258 loss=3.592, nll_loss=1.908, ppl=3.75, wps=27922.3, ups=0.54, wpb=51239.8, bsz=3114.4, num_updates=68000, lr=0.000218282, gnorm=0.269, loss_scale=8, train_wall=180, wall=125536
2021-03-15 20:29:23 | INFO | train_inner | epoch 004:   7382 / 20258 loss=3.61, nll_loss=1.93, ppl=3.81, wps=27912.1, ups=0.55, wpb=50913.6, bsz=3044.6, num_updates=68100, lr=0.000218122, gnorm=0.276, loss_scale=16, train_wall=179, wall=125718
2021-03-15 20:29:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-15 20:32:28 | INFO | train_inner | epoch 004:   7483 / 20258 loss=3.595, nll_loss=1.912, ppl=3.76, wps=27583.9, ups=0.54, wpb=51136.7, bsz=3054.2, num_updates=68200, lr=0.000217962, gnorm=0.275, loss_scale=8, train_wall=182, wall=125904
2021-03-15 20:35:31 | INFO | train_inner | epoch 004:   7583 / 20258 loss=3.591, nll_loss=1.908, ppl=3.75, wps=27903, ups=0.55, wpb=50998.1, bsz=3095.9, num_updates=68300, lr=0.000217802, gnorm=0.264, loss_scale=8, train_wall=180, wall=126086
2021-03-15 20:38:34 | INFO | train_inner | epoch 004:   7683 / 20258 loss=3.597, nll_loss=1.914, ppl=3.77, wps=27908.2, ups=0.55, wpb=51023.1, bsz=2995.6, num_updates=68400, lr=0.000217643, gnorm=0.267, loss_scale=8, train_wall=180, wall=126269
2021-03-15 20:41:36 | INFO | train_inner | epoch 004:   7783 / 20258 loss=3.609, nll_loss=1.927, ppl=3.8, wps=27970.3, ups=0.55, wpb=50983, bsz=2918.6, num_updates=68500, lr=0.000217484, gnorm=0.27, loss_scale=8, train_wall=179, wall=126452
2021-03-15 20:44:38 | INFO | train_inner | epoch 004:   7883 / 20258 loss=3.586, nll_loss=1.902, ppl=3.74, wps=27807.2, ups=0.55, wpb=50640.8, bsz=2949, num_updates=68600, lr=0.000217325, gnorm=0.281, loss_scale=8, train_wall=179, wall=126634
2021-03-15 20:47:40 | INFO | train_inner | epoch 004:   7983 / 20258 loss=3.595, nll_loss=1.912, ppl=3.76, wps=27790.7, ups=0.55, wpb=50642.7, bsz=3017.3, num_updates=68700, lr=0.000217167, gnorm=0.27, loss_scale=8, train_wall=179, wall=126816
2021-03-15 20:50:42 | INFO | train_inner | epoch 004:   8083 / 20258 loss=3.62, nll_loss=1.941, ppl=3.84, wps=27915.5, ups=0.55, wpb=50798.4, bsz=3136.6, num_updates=68800, lr=0.000217009, gnorm=0.269, loss_scale=8, train_wall=179, wall=126998
2021-03-15 20:53:45 | INFO | train_inner | epoch 004:   8183 / 20258 loss=3.592, nll_loss=1.908, ppl=3.75, wps=27894.4, ups=0.55, wpb=50955.4, bsz=2984.5, num_updates=68900, lr=0.000216852, gnorm=0.271, loss_scale=8, train_wall=180, wall=127181
2021-03-15 20:56:47 | INFO | train_inner | epoch 004:   8283 / 20258 loss=3.604, nll_loss=1.922, ppl=3.79, wps=27761.6, ups=0.55, wpb=50621.8, bsz=3007.6, num_updates=69000, lr=0.000216695, gnorm=0.273, loss_scale=8, train_wall=179, wall=127363
2021-03-15 20:58:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 20:59:52 | INFO | train_inner | epoch 004:   8384 / 20258 loss=3.596, nll_loss=1.914, ppl=3.77, wps=27665.3, ups=0.54, wpb=51144.8, bsz=3060.2, num_updates=69100, lr=0.000216538, gnorm=0.272, loss_scale=4, train_wall=182, wall=127548
2021-03-15 21:02:55 | INFO | train_inner | epoch 004:   8484 / 20258 loss=3.589, nll_loss=1.906, ppl=3.75, wps=27878.5, ups=0.55, wpb=50915.1, bsz=3098.6, num_updates=69200, lr=0.000216381, gnorm=0.274, loss_scale=4, train_wall=180, wall=127730
2021-03-15 21:05:57 | INFO | train_inner | epoch 004:   8584 / 20258 loss=3.596, nll_loss=1.913, ppl=3.77, wps=27866.8, ups=0.55, wpb=50886.1, bsz=2960.7, num_updates=69300, lr=0.000216225, gnorm=0.281, loss_scale=4, train_wall=179, wall=127913
2021-03-15 21:09:00 | INFO | train_inner | epoch 004:   8684 / 20258 loss=3.603, nll_loss=1.922, ppl=3.79, wps=27910.8, ups=0.55, wpb=50855.8, bsz=3016.3, num_updates=69400, lr=0.000216069, gnorm=0.272, loss_scale=4, train_wall=179, wall=128095
2021-03-15 21:12:02 | INFO | train_inner | epoch 004:   8784 / 20258 loss=3.607, nll_loss=1.925, ppl=3.8, wps=27900.1, ups=0.55, wpb=50928.4, bsz=3045, num_updates=69500, lr=0.000215914, gnorm=0.272, loss_scale=4, train_wall=180, wall=128278
2021-03-15 21:15:05 | INFO | train_inner | epoch 004:   8884 / 20258 loss=3.594, nll_loss=1.911, ppl=3.76, wps=27890.3, ups=0.55, wpb=50868.7, bsz=2969, num_updates=69600, lr=0.000215758, gnorm=0.277, loss_scale=4, train_wall=179, wall=128460
2021-03-15 21:18:07 | INFO | train_inner | epoch 004:   8984 / 20258 loss=3.59, nll_loss=1.906, ppl=3.75, wps=27876.3, ups=0.55, wpb=50948.2, bsz=2954.6, num_updates=69700, lr=0.000215604, gnorm=0.266, loss_scale=4, train_wall=180, wall=128643
2021-03-15 21:21:09 | INFO | train_inner | epoch 004:   9084 / 20258 loss=3.58, nll_loss=1.895, ppl=3.72, wps=27787.3, ups=0.55, wpb=50603.5, bsz=2957.3, num_updates=69800, lr=0.000215449, gnorm=0.274, loss_scale=4, train_wall=179, wall=128825
2021-03-15 21:24:12 | INFO | train_inner | epoch 004:   9184 / 20258 loss=3.597, nll_loss=1.914, ppl=3.77, wps=28029.5, ups=0.55, wpb=51165.6, bsz=2976.6, num_updates=69900, lr=0.000215295, gnorm=0.271, loss_scale=4, train_wall=180, wall=129008
2021-03-15 21:27:14 | INFO | train_inner | epoch 004:   9284 / 20258 loss=3.593, nll_loss=1.91, ppl=3.76, wps=27797.9, ups=0.55, wpb=50662.6, bsz=3087, num_updates=70000, lr=0.000215141, gnorm=0.271, loss_scale=4, train_wall=179, wall=129190
2021-03-15 21:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-15 21:27:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:33 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.001 | nll_loss 2.282 | ppl 4.86 | bleu 28.86 | wps 4420.2 | wpb 2432 | bsz 90.4 | num_updates 70000 | best_loss 4.001
2021-03-15 21:27:33 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-15 21:27:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:27:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-15 21:27:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-15 21:27:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-15 21:28:25 | INFO | valid1 | epoch 004 | valid on 'valid1' subset | loss 3.988 | nll_loss 2.292 | ppl 4.9 | bleu 27.05 | wps 4259.1 | wpb 2359.4 | bsz 106.4 | num_updates 70000 | best_loss 3.988
2021-03-15 21:28:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-15 21:28:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_4_70000.pt (epoch 4 @ 70000 updates, score 4.001) (writing took 6.358626340981573 seconds)
2021-03-15 21:31:34 | INFO | train_inner | epoch 004:   9384 / 20258 loss=3.59, nll_loss=1.907, ppl=3.75, wps=19585.1, ups=0.39, wpb=50778.3, bsz=2971.8, num_updates=70100, lr=0.000214988, gnorm=0.275, loss_scale=8, train_wall=179, wall=129449
2021-03-15 21:34:36 | INFO | train_inner | epoch 004:   9484 / 20258 loss=3.608, nll_loss=1.927, ppl=3.8, wps=27917.5, ups=0.55, wpb=50969.3, bsz=2984.7, num_updates=70200, lr=0.000214834, gnorm=0.274, loss_scale=8, train_wall=179, wall=129632
2021-03-15 21:37:39 | INFO | train_inner | epoch 004:   9584 / 20258 loss=3.61, nll_loss=1.929, ppl=3.81, wps=27919.2, ups=0.55, wpb=51056.2, bsz=3019, num_updates=70300, lr=0.000214682, gnorm=0.268, loss_scale=8, train_wall=179, wall=129815
2021-03-15 21:40:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-15 21:40:45 | INFO | train_inner | epoch 004:   9685 / 20258 loss=3.576, nll_loss=1.891, ppl=3.71, wps=27443.6, ups=0.54, wpb=50912.6, bsz=3074.1, num_updates=70400, lr=0.000214529, gnorm=0.266, loss_scale=4, train_wall=182, wall=130000
2021-03-15 21:42:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-15 21:43:49 | INFO | train_inner | epoch 004:   9786 / 20258 loss=3.6, nll_loss=1.918, ppl=3.78, wps=27724.1, ups=0.54, wpb=51241, bsz=3057, num_updates=70500, lr=0.000214377, gnorm=0.267, loss_scale=2, train_wall=182, wall=130185
2021-03-15 21:46:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-15 21:46:54 | INFO | train_inner | epoch 004:   9887 / 20258 loss=3.585, nll_loss=1.901, ppl=3.73, wps=27577, ups=0.54, wpb=50932.3, bsz=3025.9, num_updates=70600, lr=0.000214225, gnorm=0.274, loss_scale=1, train_wall=182, wall=130370
2021-03-15 21:47:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2021-03-15 21:49:58 | INFO | train_inner | epoch 004:   9988 / 20258 loss=3.584, nll_loss=1.899, ppl=3.73, wps=27618.4, ups=0.54, wpb=50913.4, bsz=2938.2, num_updates=70700, lr=0.000214073, gnorm=0.419, loss_scale=0.5, train_wall=181, wall=130554
2021-03-15 21:53:01 | INFO | train_inner | epoch 004:  10088 / 20258 loss=3.594, nll_loss=1.911, ppl=3.76, wps=28023.9, ups=0.55, wpb=51181.7, bsz=2939.3, num_updates=70800, lr=0.000213922, gnorm=0.269, loss_scale=0.5, train_wall=179, wall=130737
2021-03-15 21:56:04 | INFO | train_inner | epoch 004:  10188 / 20258 loss=3.585, nll_loss=1.9, ppl=3.73, wps=27847.2, ups=0.55, wpb=50954.9, bsz=2921.2, num_updates=70900, lr=0.000213771, gnorm=0.273, loss_scale=0.5, train_wall=180, wall=130920
2021-03-15 21:59:06 | INFO | train_inner | epoch 004:  10288 / 20258 loss=3.595, nll_loss=1.912, ppl=3.76, wps=27868.6, ups=0.55, wpb=50830.6, bsz=2946.5, num_updates=71000, lr=0.000213621, gnorm=0.267, loss_scale=0.5, train_wall=179, wall=131102
2021-03-15 22:02:09 | INFO | train_inner | epoch 004:  10388 / 20258 loss=3.594, nll_loss=1.911, ppl=3.76, wps=27860.6, ups=0.55, wpb=50772.8, bsz=3046.6, num_updates=71100, lr=0.00021347, gnorm=0.274, loss_scale=0.5, train_wall=179, wall=131284
2021-03-15 22:05:12 | INFO | train_inner | epoch 004:  10488 / 20258 loss=3.588, nll_loss=1.905, ppl=3.74, wps=27872.8, ups=0.55, wpb=51058, bsz=3019.4, num_updates=71200, lr=0.00021332, gnorm=0.266, loss_scale=0.5, train_wall=180, wall=131467
2021-03-15 22:08:14 | INFO | train_inner | epoch 004:  10588 / 20258 loss=3.599, nll_loss=1.916, ppl=3.77, wps=27890.5, ups=0.55, wpb=50859.2, bsz=2899.8, num_updates=71300, lr=0.000213171, gnorm=0.272, loss_scale=0.5, train_wall=179, wall=131650
2021-03-15 22:11:16 | INFO | train_inner | epoch 004:  10688 / 20258 loss=3.599, nll_loss=1.917, ppl=3.78, wps=27903.5, ups=0.55, wpb=50798, bsz=3050.2, num_updates=71400, lr=0.000213021, gnorm=0.264, loss_scale=0.5, train_wall=179, wall=131832
2021-03-15 22:14:18 | INFO | train_inner | epoch 004:  10788 / 20258 loss=3.606, nll_loss=1.924, ppl=3.79, wps=27993.7, ups=0.55, wpb=50905.2, bsz=2878.6, num_updates=71500, lr=0.000212872, gnorm=0.277, loss_scale=0.5, train_wall=179, wall=132014
2021-03-15 22:17:20 | INFO | train_inner | epoch 004:  10888 / 20258 loss=3.584, nll_loss=1.9, ppl=3.73, wps=27853.4, ups=0.55, wpb=50773.5, bsz=2950, num_updates=71600, lr=0.000212724, gnorm=0.288, loss_scale=0.5, train_wall=179, wall=132196
2021-03-15 22:20:23 | INFO | train_inner | epoch 004:  10988 / 20258 loss=3.606, nll_loss=1.924, ppl=3.8, wps=27841.2, ups=0.55, wpb=50740.4, bsz=3077.8, num_updates=71700, lr=0.000212575, gnorm=0.275, loss_scale=1, train_wall=179, wall=132378
2021-03-15 22:23:25 | INFO | train_inner | epoch 004:  11088 / 20258 loss=3.598, nll_loss=1.915, ppl=3.77, wps=27896.7, ups=0.55, wpb=50847.3, bsz=2917.4, num_updates=71800, lr=0.000212427, gnorm=0.276, loss_scale=1, train_wall=179, wall=132560
2021-03-15 22:26:28 | INFO | train_inner | epoch 004:  11188 / 20258 loss=3.58, nll_loss=1.895, ppl=3.72, wps=27908.2, ups=0.55, wpb=51000.7, bsz=2941.9, num_updates=71900, lr=0.00021228, gnorm=0.267, loss_scale=1, train_wall=180, wall=132743
2021-03-15 22:29:30 | INFO | train_inner | epoch 004:  11288 / 20258 loss=3.57, nll_loss=1.885, ppl=3.69, wps=27905.2, ups=0.55, wpb=50820.1, bsz=2996.7, num_updates=72000, lr=0.000212132, gnorm=0.27, loss_scale=1, train_wall=179, wall=132925
2021-03-15 22:32:32 | INFO | train_inner | epoch 004:  11388 / 20258 loss=3.595, nll_loss=1.913, ppl=3.77, wps=27870, ups=0.55, wpb=50736.5, bsz=3069.7, num_updates=72100, lr=0.000211985, gnorm=0.279, loss_scale=1, train_wall=179, wall=133107
2021-03-15 22:35:34 | INFO | train_inner | epoch 004:  11488 / 20258 loss=3.606, nll_loss=1.924, ppl=3.8, wps=28022, ups=0.55, wpb=51003.1, bsz=2948.5, num_updates=72200, lr=0.000211838, gnorm=0.273, loss_scale=1, train_wall=179, wall=133289
2021-03-15 22:38:36 | INFO | train_inner | epoch 004:  11588 / 20258 loss=3.603, nll_loss=1.921, ppl=3.79, wps=27978.7, ups=0.55, wpb=50999.2, bsz=2867, num_updates=72300, lr=0.000211691, gnorm=0.271, loss_scale=1, train_wall=179, wall=133472
2021-03-15 22:41:38 | INFO | train_inner | epoch 004:  11688 / 20258 loss=3.574, nll_loss=1.889, ppl=3.71, wps=27885, ups=0.55, wpb=50819.3, bsz=3068.6, num_updates=72400, lr=0.000211545, gnorm=0.267, loss_scale=1, train_wall=179, wall=133654
2021-03-15 22:44:41 | INFO | train_inner | epoch 004:  11788 / 20258 loss=3.562, nll_loss=1.876, ppl=3.67, wps=27913.6, ups=0.55, wpb=50926.6, bsz=2962.2, num_updates=72500, lr=0.000211399, gnorm=0.272, loss_scale=1, train_wall=179, wall=133836
2021-03-15 22:47:44 | INFO | train_inner | epoch 004:  11888 / 20258 loss=3.582, nll_loss=1.898, ppl=3.73, wps=27915.7, ups=0.55, wpb=51122.2, bsz=2964.2, num_updates=72600, lr=0.000211254, gnorm=0.267, loss_scale=1, train_wall=180, wall=134019
2021-03-15 22:50:47 | INFO | train_inner | epoch 004:  11988 / 20258 loss=3.596, nll_loss=1.915, ppl=3.77, wps=27780.5, ups=0.55, wpb=50865.1, bsz=3189.8, num_updates=72700, lr=0.000211108, gnorm=0.271, loss_scale=2, train_wall=179, wall=134203
2021-03-15 22:53:49 | INFO | train_inner | epoch 004:  12088 / 20258 loss=3.587, nll_loss=1.903, ppl=3.74, wps=27879.8, ups=0.55, wpb=50770.5, bsz=2900.1, num_updates=72800, lr=0.000210963, gnorm=0.267, loss_scale=2, train_wall=179, wall=134385
2021-03-15 22:56:52 | INFO | train_inner | epoch 004:  12188 / 20258 loss=3.6, nll_loss=1.918, ppl=3.78, wps=28051.4, ups=0.55, wpb=51162.5, bsz=2975.7, num_updates=72900, lr=0.000210819, gnorm=0.278, loss_scale=2, train_wall=179, wall=134567
2021-03-15 22:59:54 | INFO | train_inner | epoch 004:  12288 / 20258 loss=3.589, nll_loss=1.907, ppl=3.75, wps=27853.7, ups=0.55, wpb=50768.7, bsz=3139.3, num_updates=73000, lr=0.000210674, gnorm=0.273, loss_scale=2, train_wall=179, wall=134749
2021-03-15 23:02:56 | INFO | train_inner | epoch 004:  12388 / 20258 loss=3.592, nll_loss=1.909, ppl=3.75, wps=27877.1, ups=0.55, wpb=50917.2, bsz=2903, num_updates=73100, lr=0.00021053, gnorm=0.27, loss_scale=2, train_wall=179, wall=134932
2021-03-15 23:05:59 | INFO | train_inner | epoch 004:  12488 / 20258 loss=3.595, nll_loss=1.913, ppl=3.77, wps=27869, ups=0.55, wpb=50889.1, bsz=3069.9, num_updates=73200, lr=0.000210386, gnorm=0.266, loss_scale=2, train_wall=179, wall=135115
2021-03-15 23:09:01 | INFO | train_inner | epoch 004:  12588 / 20258 loss=3.589, nll_loss=1.906, ppl=3.75, wps=27907.6, ups=0.55, wpb=50745.8, bsz=3005.8, num_updates=73300, lr=0.000210243, gnorm=0.271, loss_scale=2, train_wall=179, wall=135296
2021-03-15 23:12:03 | INFO | train_inner | epoch 004:  12688 / 20258 loss=3.602, nll_loss=1.92, ppl=3.78, wps=27941.1, ups=0.55, wpb=50751.7, bsz=2860.2, num_updates=73400, lr=0.000210099, gnorm=0.276, loss_scale=2, train_wall=179, wall=135478
2021-03-15 23:15:05 | INFO | train_inner | epoch 004:  12788 / 20258 loss=3.578, nll_loss=1.893, ppl=3.71, wps=27880.6, ups=0.55, wpb=50893.9, bsz=2996.3, num_updates=73500, lr=0.000209956, gnorm=0.272, loss_scale=2, train_wall=179, wall=135661
2021-03-15 23:18:08 | INFO | train_inner | epoch 004:  12888 / 20258 loss=3.568, nll_loss=1.882, ppl=3.69, wps=27842.5, ups=0.55, wpb=50832.3, bsz=3046.2, num_updates=73600, lr=0.000209814, gnorm=0.27, loss_scale=2, train_wall=179, wall=135843
2021-03-15 23:21:10 | INFO | train_inner | epoch 004:  12988 / 20258 loss=3.584, nll_loss=1.9, ppl=3.73, wps=27926.6, ups=0.55, wpb=50923.6, bsz=3117.1, num_updates=73700, lr=0.000209671, gnorm=0.275, loss_scale=4, train_wall=179, wall=136025
2021-03-15 23:24:12 | INFO | train_inner | epoch 004:  13088 / 20258 loss=3.584, nll_loss=1.9, ppl=3.73, wps=27835.3, ups=0.55, wpb=50771.2, bsz=2999.3, num_updates=73800, lr=0.000209529, gnorm=0.273, loss_scale=4, train_wall=179, wall=136208
2021-03-15 23:27:15 | INFO | train_inner | epoch 004:  13188 / 20258 loss=3.566, nll_loss=1.88, ppl=3.68, wps=27805.5, ups=0.55, wpb=50907.7, bsz=3084.4, num_updates=73900, lr=0.000209387, gnorm=0.267, loss_scale=4, train_wall=180, wall=136391
2021-03-15 23:30:19 | INFO | train_inner | epoch 004:  13288 / 20258 loss=3.584, nll_loss=1.901, ppl=3.73, wps=27761.1, ups=0.55, wpb=50853.9, bsz=3081.8, num_updates=74000, lr=0.000209246, gnorm=0.27, loss_scale=4, train_wall=180, wall=136574
2021-03-15 23:33:21 | INFO | train_inner | epoch 004:  13388 / 20258 loss=3.593, nll_loss=1.911, ppl=3.76, wps=27855.6, ups=0.55, wpb=50851.8, bsz=3058.2, num_updates=74100, lr=0.000209105, gnorm=0.273, loss_scale=4, train_wall=179, wall=136757
2021-03-15 23:36:23 | INFO | train_inner | epoch 004:  13488 / 20258 loss=3.59, nll_loss=1.908, ppl=3.75, wps=27753.6, ups=0.55, wpb=50565.6, bsz=3053, num_updates=74200, lr=0.000208964, gnorm=0.271, loss_scale=4, train_wall=179, wall=136939
2021-03-15 23:39:26 | INFO | train_inner | epoch 004:  13588 / 20258 loss=3.588, nll_loss=1.905, ppl=3.75, wps=27746.1, ups=0.55, wpb=50713.9, bsz=3028, num_updates=74300, lr=0.000208823, gnorm=0.272, loss_scale=4, train_wall=179, wall=137122
2021-03-15 23:42:29 | INFO | train_inner | epoch 004:  13688 / 20258 loss=3.601, nll_loss=1.919, ppl=3.78, wps=27850.5, ups=0.55, wpb=50896.5, bsz=3035.9, num_updates=74400, lr=0.000208683, gnorm=0.274, loss_scale=4, train_wall=179, wall=137304
2021-03-15 23:45:31 | INFO | train_inner | epoch 004:  13788 / 20258 loss=3.583, nll_loss=1.9, ppl=3.73, wps=28023.8, ups=0.55, wpb=51129.9, bsz=3044.7, num_updates=74500, lr=0.000208542, gnorm=0.27, loss_scale=4, train_wall=179, wall=137487
2021-03-15 23:48:34 | INFO | train_inner | epoch 004:  13888 / 20258 loss=3.593, nll_loss=1.91, ppl=3.76, wps=27920.1, ups=0.55, wpb=50944.4, bsz=3062.2, num_updates=74600, lr=0.000208403, gnorm=0.272, loss_scale=4, train_wall=179, wall=137669
2021-03-15 23:51:36 | INFO | train_inner | epoch 004:  13988 / 20258 loss=3.599, nll_loss=1.917, ppl=3.78, wps=27932.7, ups=0.55, wpb=50869.9, bsz=2970.3, num_updates=74700, lr=0.000208263, gnorm=0.274, loss_scale=4, train_wall=179, wall=137851
2021-03-15 23:54:39 | INFO | train_inner | epoch 004:  14088 / 20258 loss=3.58, nll_loss=1.896, ppl=3.72, wps=27929.7, ups=0.55, wpb=51006.8, bsz=3063.1, num_updates=74800, lr=0.000208124, gnorm=0.268, loss_scale=8, train_wall=179, wall=138034
2021-03-15 23:57:42 | INFO | train_inner | epoch 004:  14188 / 20258 loss=3.584, nll_loss=1.9, ppl=3.73, wps=27849.9, ups=0.55, wpb=51090, bsz=2985.5, num_updates=74900, lr=0.000207985, gnorm=0.275, loss_scale=8, train_wall=180, wall=138218
2021-03-15 23:59:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 00:00:47 | INFO | train_inner | epoch 004:  14289 / 20258 loss=3.588, nll_loss=1.905, ppl=3.74, wps=27696.3, ups=0.54, wpb=51140.7, bsz=2910.4, num_updates=75000, lr=0.000207846, gnorm=0.27, loss_scale=4, train_wall=181, wall=138402
2021-03-16 00:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 00:00:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:00:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:00:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:00:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:00:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:00:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:00:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:00:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:00:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:00:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:00:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:00:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:00:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:00:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:00:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:00:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:00:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:00:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:00:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:00:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:00:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.997 | nll_loss 2.279 | ppl 4.85 | bleu 29.01 | wps 4463.9 | wpb 2432 | bsz 90.4 | num_updates 75000 | best_loss 3.997
2021-03-16 00:01:05 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 00:01:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 00:01:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 00:01:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 00:01:56 | INFO | valid1 | epoch 004 | valid on 'valid1' subset | loss 3.987 | nll_loss 2.293 | ppl 4.9 | bleu 27.11 | wps 4314.2 | wpb 2359.4 | bsz 106.4 | num_updates 75000 | best_loss 3.987
2021-03-16 00:01:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 00:02:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_4_75000.pt (epoch 4 @ 75000 updates, score 3.997) (writing took 6.373141799122095 seconds)
2021-03-16 00:05:06 | INFO | train_inner | epoch 004:  14389 / 20258 loss=3.581, nll_loss=1.897, ppl=3.73, wps=19688.6, ups=0.39, wpb=50961.4, bsz=3038.6, num_updates=75100, lr=0.000207708, gnorm=0.267, loss_scale=4, train_wall=180, wall=138661
2021-03-16 00:08:07 | INFO | train_inner | epoch 004:  14489 / 20258 loss=3.594, nll_loss=1.912, ppl=3.76, wps=27894.6, ups=0.55, wpb=50672.1, bsz=2947.7, num_updates=75200, lr=0.00020757, gnorm=0.278, loss_scale=4, train_wall=179, wall=138843
2021-03-16 00:11:10 | INFO | train_inner | epoch 004:  14589 / 20258 loss=3.581, nll_loss=1.897, ppl=3.72, wps=27860.7, ups=0.55, wpb=50833.6, bsz=2889.8, num_updates=75300, lr=0.000207432, gnorm=0.271, loss_scale=4, train_wall=179, wall=139025
2021-03-16 00:14:12 | INFO | train_inner | epoch 004:  14689 / 20258 loss=3.583, nll_loss=1.9, ppl=3.73, wps=27854.2, ups=0.55, wpb=50782.8, bsz=2957.4, num_updates=75400, lr=0.000207294, gnorm=0.267, loss_scale=4, train_wall=179, wall=139207
2021-03-16 00:17:15 | INFO | train_inner | epoch 004:  14789 / 20258 loss=3.582, nll_loss=1.898, ppl=3.73, wps=27868.8, ups=0.55, wpb=50887.6, bsz=3023.9, num_updates=75500, lr=0.000207157, gnorm=0.27, loss_scale=4, train_wall=179, wall=139390
2021-03-16 00:20:17 | INFO | train_inner | epoch 004:  14889 / 20258 loss=3.581, nll_loss=1.898, ppl=3.73, wps=27874.5, ups=0.55, wpb=50940.5, bsz=3167.9, num_updates=75600, lr=0.00020702, gnorm=0.268, loss_scale=4, train_wall=180, wall=139573
2021-03-16 00:23:20 | INFO | train_inner | epoch 004:  14989 / 20258 loss=3.588, nll_loss=1.905, ppl=3.74, wps=27877.6, ups=0.55, wpb=50974.7, bsz=3119, num_updates=75700, lr=0.000206883, gnorm=0.273, loss_scale=4, train_wall=180, wall=139756
2021-03-16 00:26:23 | INFO | train_inner | epoch 004:  15089 / 20258 loss=3.575, nll_loss=1.89, ppl=3.71, wps=27810.5, ups=0.55, wpb=50896.5, bsz=3029.8, num_updates=75800, lr=0.000206746, gnorm=0.272, loss_scale=4, train_wall=180, wall=139939
2021-03-16 00:29:26 | INFO | train_inner | epoch 004:  15189 / 20258 loss=3.577, nll_loss=1.892, ppl=3.71, wps=27922.1, ups=0.55, wpb=50921.8, bsz=2927.1, num_updates=75900, lr=0.00020661, gnorm=0.279, loss_scale=4, train_wall=179, wall=140121
2021-03-16 00:32:28 | INFO | train_inner | epoch 004:  15289 / 20258 loss=3.57, nll_loss=1.885, ppl=3.69, wps=27847.7, ups=0.55, wpb=50831.3, bsz=3029.6, num_updates=76000, lr=0.000206474, gnorm=0.272, loss_scale=8, train_wall=180, wall=140304
2021-03-16 00:35:31 | INFO | train_inner | epoch 004:  15389 / 20258 loss=3.581, nll_loss=1.898, ppl=3.73, wps=27989.8, ups=0.55, wpb=51202.8, bsz=3090.1, num_updates=76100, lr=0.000206338, gnorm=0.27, loss_scale=8, train_wall=180, wall=140487
2021-03-16 00:38:34 | INFO | train_inner | epoch 004:  15489 / 20258 loss=3.594, nll_loss=1.912, ppl=3.76, wps=27848.3, ups=0.55, wpb=50990.9, bsz=2987.4, num_updates=76200, lr=0.000206203, gnorm=0.266, loss_scale=8, train_wall=180, wall=140670
2021-03-16 00:41:36 | INFO | train_inner | epoch 004:  15589 / 20258 loss=3.596, nll_loss=1.914, ppl=3.77, wps=27816.8, ups=0.55, wpb=50494.9, bsz=2930.1, num_updates=76300, lr=0.000206068, gnorm=0.272, loss_scale=8, train_wall=179, wall=140851
2021-03-16 00:44:38 | INFO | train_inner | epoch 004:  15689 / 20258 loss=3.592, nll_loss=1.91, ppl=3.76, wps=27891.9, ups=0.55, wpb=50997.9, bsz=3057.2, num_updates=76400, lr=0.000205933, gnorm=0.266, loss_scale=8, train_wall=180, wall=141034
2021-03-16 00:47:41 | INFO | train_inner | epoch 004:  15789 / 20258 loss=3.585, nll_loss=1.901, ppl=3.74, wps=27940, ups=0.55, wpb=50894.9, bsz=2919.9, num_updates=76500, lr=0.000205798, gnorm=0.273, loss_scale=8, train_wall=179, wall=141216
2021-03-16 00:50:44 | INFO | train_inner | epoch 004:  15889 / 20258 loss=3.574, nll_loss=1.889, ppl=3.7, wps=27892, ups=0.55, wpb=51021.7, bsz=2987.5, num_updates=76600, lr=0.000205664, gnorm=0.284, loss_scale=8, train_wall=180, wall=141399
2021-03-16 00:53:46 | INFO | train_inner | epoch 004:  15989 / 20258 loss=3.596, nll_loss=1.915, ppl=3.77, wps=27849.2, ups=0.55, wpb=50856.4, bsz=3010.5, num_updates=76700, lr=0.00020553, gnorm=0.269, loss_scale=8, train_wall=179, wall=141582
2021-03-16 00:56:50 | INFO | train_inner | epoch 004:  16089 / 20258 loss=3.575, nll_loss=1.891, ppl=3.71, wps=27741.6, ups=0.55, wpb=50884.3, bsz=3068.4, num_updates=76800, lr=0.000205396, gnorm=0.269, loss_scale=8, train_wall=180, wall=141765
2021-03-16 00:59:52 | INFO | train_inner | epoch 004:  16189 / 20258 loss=3.592, nll_loss=1.91, ppl=3.76, wps=27873.8, ups=0.55, wpb=50831.8, bsz=3057.8, num_updates=76900, lr=0.000205262, gnorm=0.269, loss_scale=8, train_wall=179, wall=141948
2021-03-16 01:02:55 | INFO | train_inner | epoch 004:  16289 / 20258 loss=3.574, nll_loss=1.89, ppl=3.71, wps=27876.9, ups=0.55, wpb=50924.8, bsz=2989.2, num_updates=77000, lr=0.000205129, gnorm=0.27, loss_scale=8, train_wall=180, wall=142130
2021-03-16 01:04:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 01:05:59 | INFO | train_inner | epoch 004:  16390 / 20258 loss=3.587, nll_loss=1.904, ppl=3.74, wps=27556.1, ups=0.54, wpb=50866.2, bsz=2943.9, num_updates=77100, lr=0.000204996, gnorm=0.277, loss_scale=8, train_wall=181, wall=142315
2021-03-16 01:09:02 | INFO | train_inner | epoch 004:  16490 / 20258 loss=3.577, nll_loss=1.893, ppl=3.71, wps=27878.2, ups=0.55, wpb=50941.7, bsz=3052.4, num_updates=77200, lr=0.000204863, gnorm=0.27, loss_scale=8, train_wall=180, wall=142498
2021-03-16 01:09:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 01:10:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-16 01:12:08 | INFO | train_inner | epoch 004:  16592 / 20258 loss=3.606, nll_loss=1.925, ppl=3.8, wps=27445, ups=0.54, wpb=51097.2, bsz=3008.6, num_updates=77300, lr=0.000204731, gnorm=0.278, loss_scale=2, train_wall=183, wall=142684
2021-03-16 01:15:11 | INFO | train_inner | epoch 004:  16692 / 20258 loss=3.589, nll_loss=1.906, ppl=3.75, wps=27940.6, ups=0.55, wpb=50956.3, bsz=3029.3, num_updates=77400, lr=0.000204598, gnorm=0.277, loss_scale=2, train_wall=179, wall=142866
2021-03-16 01:18:13 | INFO | train_inner | epoch 004:  16792 / 20258 loss=3.578, nll_loss=1.894, ppl=3.72, wps=27953.1, ups=0.55, wpb=51017.6, bsz=2999.8, num_updates=77500, lr=0.000204466, gnorm=0.273, loss_scale=2, train_wall=179, wall=143049
2021-03-16 01:21:15 | INFO | train_inner | epoch 004:  16892 / 20258 loss=3.58, nll_loss=1.896, ppl=3.72, wps=27941.4, ups=0.55, wpb=50938.4, bsz=2967, num_updates=77600, lr=0.000204334, gnorm=0.271, loss_scale=2, train_wall=179, wall=143231
2021-03-16 01:24:18 | INFO | train_inner | epoch 004:  16992 / 20258 loss=3.604, nll_loss=1.924, ppl=3.79, wps=28004.8, ups=0.55, wpb=51067.6, bsz=2951, num_updates=77700, lr=0.000204203, gnorm=0.271, loss_scale=2, train_wall=179, wall=143413
2021-03-16 01:27:20 | INFO | train_inner | epoch 004:  17092 / 20258 loss=3.593, nll_loss=1.911, ppl=3.76, wps=27999.3, ups=0.55, wpb=51176.1, bsz=3038.6, num_updates=77800, lr=0.000204072, gnorm=0.268, loss_scale=2, train_wall=180, wall=143596
2021-03-16 01:30:23 | INFO | train_inner | epoch 004:  17192 / 20258 loss=3.59, nll_loss=1.908, ppl=3.75, wps=27964.6, ups=0.55, wpb=50979.5, bsz=3004.4, num_updates=77900, lr=0.000203941, gnorm=0.275, loss_scale=2, train_wall=179, wall=143778
2021-03-16 01:33:25 | INFO | train_inner | epoch 004:  17292 / 20258 loss=3.598, nll_loss=1.917, ppl=3.78, wps=27966.2, ups=0.55, wpb=50942.4, bsz=2973.1, num_updates=78000, lr=0.00020381, gnorm=0.269, loss_scale=2, train_wall=179, wall=143960
2021-03-16 01:36:28 | INFO | train_inner | epoch 004:  17392 / 20258 loss=3.586, nll_loss=1.904, ppl=3.74, wps=27907.1, ups=0.55, wpb=51095, bsz=3097.9, num_updates=78100, lr=0.000203679, gnorm=0.278, loss_scale=2, train_wall=180, wall=144144
2021-03-16 01:39:30 | INFO | train_inner | epoch 004:  17492 / 20258 loss=3.588, nll_loss=1.905, ppl=3.74, wps=27955.7, ups=0.55, wpb=50949.4, bsz=2938.9, num_updates=78200, lr=0.000203549, gnorm=0.272, loss_scale=2, train_wall=179, wall=144326
2021-03-16 01:42:32 | INFO | train_inner | epoch 004:  17592 / 20258 loss=3.575, nll_loss=1.89, ppl=3.71, wps=27862.4, ups=0.55, wpb=50721.2, bsz=3090.6, num_updates=78300, lr=0.000203419, gnorm=0.271, loss_scale=4, train_wall=179, wall=144508
2021-03-16 01:45:36 | INFO | train_inner | epoch 004:  17692 / 20258 loss=3.582, nll_loss=1.899, ppl=3.73, wps=27853.1, ups=0.55, wpb=51024.9, bsz=3137, num_updates=78400, lr=0.000203289, gnorm=0.274, loss_scale=4, train_wall=180, wall=144691
2021-03-16 01:48:38 | INFO | train_inner | epoch 004:  17792 / 20258 loss=3.584, nll_loss=1.901, ppl=3.73, wps=28033.1, ups=0.55, wpb=51091.4, bsz=3107.5, num_updates=78500, lr=0.00020316, gnorm=0.268, loss_scale=4, train_wall=179, wall=144873
2021-03-16 01:50:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-16 01:51:42 | INFO | train_inner | epoch 004:  17893 / 20258 loss=3.578, nll_loss=1.894, ppl=3.72, wps=27625.1, ups=0.54, wpb=50966.1, bsz=3060.5, num_updates=78600, lr=0.00020303, gnorm=0.288, loss_scale=2, train_wall=181, wall=145058
2021-03-16 01:52:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-16 01:54:46 | INFO | train_inner | epoch 004:  17994 / 20258 loss=3.589, nll_loss=1.906, ppl=3.75, wps=27601.9, ups=0.54, wpb=50736.9, bsz=2924.2, num_updates=78700, lr=0.000202901, gnorm=0.387, loss_scale=1, train_wall=181, wall=145242
2021-03-16 01:57:49 | INFO | train_inner | epoch 004:  18094 / 20258 loss=3.575, nll_loss=1.891, ppl=3.71, wps=28033.9, ups=0.55, wpb=51179.5, bsz=2981.1, num_updates=78800, lr=0.000202773, gnorm=0.265, loss_scale=1, train_wall=180, wall=145424
2021-03-16 02:00:51 | INFO | train_inner | epoch 004:  18194 / 20258 loss=3.599, nll_loss=1.918, ppl=3.78, wps=27841.4, ups=0.55, wpb=50744.1, bsz=2971.2, num_updates=78900, lr=0.000202644, gnorm=0.286, loss_scale=1, train_wall=179, wall=145606
2021-03-16 02:03:53 | INFO | train_inner | epoch 004:  18294 / 20258 loss=3.587, nll_loss=1.905, ppl=3.74, wps=27999, ups=0.55, wpb=50987.5, bsz=2993.6, num_updates=79000, lr=0.000202516, gnorm=0.268, loss_scale=1, train_wall=179, wall=145789
2021-03-16 02:06:55 | INFO | train_inner | epoch 004:  18394 / 20258 loss=3.581, nll_loss=1.897, ppl=3.73, wps=27973.9, ups=0.55, wpb=51009.4, bsz=2920.3, num_updates=79100, lr=0.000202388, gnorm=0.269, loss_scale=1, train_wall=179, wall=145971
2021-03-16 02:09:58 | INFO | train_inner | epoch 004:  18494 / 20258 loss=3.572, nll_loss=1.888, ppl=3.7, wps=27888.3, ups=0.55, wpb=50942.6, bsz=3048.2, num_updates=79200, lr=0.00020226, gnorm=0.273, loss_scale=1, train_wall=179, wall=146154
2021-03-16 02:13:00 | INFO | train_inner | epoch 004:  18594 / 20258 loss=3.586, nll_loss=1.904, ppl=3.74, wps=27845.4, ups=0.55, wpb=50704.6, bsz=2918.8, num_updates=79300, lr=0.000202132, gnorm=0.274, loss_scale=1, train_wall=179, wall=146336
2021-03-16 02:16:03 | INFO | train_inner | epoch 004:  18694 / 20258 loss=3.588, nll_loss=1.905, ppl=3.75, wps=27923.5, ups=0.55, wpb=50976.4, bsz=3079.1, num_updates=79400, lr=0.000202005, gnorm=0.272, loss_scale=1, train_wall=179, wall=146518
2021-03-16 02:19:05 | INFO | train_inner | epoch 004:  18794 / 20258 loss=3.587, nll_loss=1.904, ppl=3.74, wps=27887.7, ups=0.55, wpb=50712.7, bsz=2955.3, num_updates=79500, lr=0.000201878, gnorm=0.279, loss_scale=1, train_wall=179, wall=146700
2021-03-16 02:22:07 | INFO | train_inner | epoch 004:  18894 / 20258 loss=3.567, nll_loss=1.882, ppl=3.69, wps=27860.3, ups=0.55, wpb=50710.9, bsz=3032.6, num_updates=79600, lr=0.000201751, gnorm=0.271, loss_scale=1, train_wall=179, wall=146882
2021-03-16 02:25:09 | INFO | train_inner | epoch 004:  18994 / 20258 loss=3.591, nll_loss=1.909, ppl=3.76, wps=27887.4, ups=0.55, wpb=50977.8, bsz=3067.2, num_updates=79700, lr=0.000201625, gnorm=0.276, loss_scale=2, train_wall=179, wall=147065
2021-03-16 02:27:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-16 02:28:13 | INFO | train_inner | epoch 004:  19095 / 20258 loss=3.584, nll_loss=1.901, ppl=3.73, wps=27497.5, ups=0.54, wpb=50585.4, bsz=3023.4, num_updates=79800, lr=0.000201498, gnorm=0.337, loss_scale=1, train_wall=181, wall=147249
2021-03-16 02:31:16 | INFO | train_inner | epoch 004:  19195 / 20258 loss=3.586, nll_loss=1.904, ppl=3.74, wps=27844.1, ups=0.55, wpb=50761.9, bsz=2976.4, num_updates=79900, lr=0.000201372, gnorm=0.443, loss_scale=1, train_wall=179, wall=147431
2021-03-16 02:34:18 | INFO | train_inner | epoch 004:  19295 / 20258 loss=3.588, nll_loss=1.905, ppl=3.75, wps=27979, ups=0.55, wpb=50987.2, bsz=3068.4, num_updates=80000, lr=0.000201246, gnorm=0.27, loss_scale=1, train_wall=179, wall=147613
2021-03-16 02:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 02:34:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:37 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.98 | nll_loss 2.262 | ppl 4.8 | bleu 29.26 | wps 4360.3 | wpb 2432 | bsz 90.4 | num_updates 80000 | best_loss 3.98
2021-03-16 02:34:37 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 02:34:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:34:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:34:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:34:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:35:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:35:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:35:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:35:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 02:35:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 02:35:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 02:35:30 | INFO | valid1 | epoch 004 | valid on 'valid1' subset | loss 3.977 | nll_loss 2.284 | ppl 4.87 | bleu 26.9 | wps 4241.8 | wpb 2359.4 | bsz 106.4 | num_updates 80000 | best_loss 3.977
2021-03-16 02:35:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 02:35:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_4_80000.pt (epoch 4 @ 80000 updates, score 3.98) (writing took 8.121101464144886 seconds)
2021-03-16 02:38:41 | INFO | train_inner | epoch 004:  19395 / 20258 loss=3.574, nll_loss=1.89, ppl=3.71, wps=19446.5, ups=0.38, wpb=51107.8, bsz=3162.3, num_updates=80100, lr=0.00020112, gnorm=0.272, loss_scale=1, train_wall=179, wall=147876
2021-03-16 02:41:43 | INFO | train_inner | epoch 004:  19495 / 20258 loss=3.589, nll_loss=1.907, ppl=3.75, wps=27861.1, ups=0.55, wpb=50871.9, bsz=3111.8, num_updates=80200, lr=0.000200995, gnorm=0.343, loss_scale=1, train_wall=179, wall=148059
2021-03-16 02:44:46 | INFO | train_inner | epoch 004:  19595 / 20258 loss=3.591, nll_loss=1.909, ppl=3.76, wps=27943.7, ups=0.55, wpb=51079.2, bsz=3051.4, num_updates=80300, lr=0.00020087, gnorm=0.27, loss_scale=1, train_wall=180, wall=148242
2021-03-16 02:47:48 | INFO | train_inner | epoch 004:  19695 / 20258 loss=3.584, nll_loss=1.901, ppl=3.73, wps=27989.6, ups=0.55, wpb=50939.4, bsz=2909, num_updates=80400, lr=0.000200745, gnorm=0.273, loss_scale=1, train_wall=179, wall=148424
2021-03-16 02:50:51 | INFO | train_inner | epoch 004:  19795 / 20258 loss=3.589, nll_loss=1.907, ppl=3.75, wps=27916.3, ups=0.55, wpb=50984.1, bsz=3136.2, num_updates=80500, lr=0.00020062, gnorm=0.266, loss_scale=1, train_wall=179, wall=148606
2021-03-16 02:53:53 | INFO | train_inner | epoch 004:  19895 / 20258 loss=3.59, nll_loss=1.909, ppl=3.75, wps=27856, ups=0.55, wpb=50804.9, bsz=3166.3, num_updates=80600, lr=0.000200496, gnorm=0.274, loss_scale=1, train_wall=179, wall=148789
2021-03-16 02:56:55 | INFO | train_inner | epoch 004:  19995 / 20258 loss=3.578, nll_loss=1.894, ppl=3.72, wps=27876.9, ups=0.55, wpb=50833.2, bsz=2898, num_updates=80700, lr=0.000200371, gnorm=0.27, loss_scale=1, train_wall=179, wall=148971
2021-03-16 02:59:58 | INFO | train_inner | epoch 004:  20095 / 20258 loss=3.574, nll_loss=1.89, ppl=3.71, wps=27844.8, ups=0.55, wpb=50785.1, bsz=3017.9, num_updates=80800, lr=0.000200247, gnorm=0.273, loss_scale=1, train_wall=179, wall=149153
2021-03-16 03:03:00 | INFO | train_inner | epoch 004:  20195 / 20258 loss=3.592, nll_loss=1.91, ppl=3.76, wps=27924.9, ups=0.55, wpb=50950.3, bsz=3070.9, num_updates=80900, lr=0.000200124, gnorm=0.27, loss_scale=2, train_wall=179, wall=149336
2021-03-16 03:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 03:04:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:04:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:04:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:04:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:04:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:04:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:04:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:04:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:04:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:04:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:04:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:04:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:04:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:04:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:04:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:04:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:04:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:04:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:04:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:04:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:04:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:14 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.983 | nll_loss 2.265 | ppl 4.81 | bleu 29.08 | wps 4382.2 | wpb 2432 | bsz 90.4 | num_updates 80963 | best_loss 3.98
2021-03-16 03:05:14 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 03:05:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:05:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 03:05:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 03:05:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 03:06:07 | INFO | valid1 | epoch 004 | valid on 'valid1' subset | loss 3.976 | nll_loss 2.281 | ppl 4.86 | bleu 26.99 | wps 4163.4 | wpb 2359.4 | bsz 106.4 | num_updates 80963 | best_loss 3.976
2021-03-16 03:06:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 03:06:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint4.pt (epoch 4 @ 80963 updates, score 3.983) (writing took 4.709641230059788 seconds)
2021-03-16 03:06:12 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-03-16 03:06:12 | INFO | train | epoch 004 | loss 3.594 | nll_loss 1.912 | ppl 3.76 | wps 27572.7 | ups 0.54 | wpb 50905.7 | bsz 3010.3 | num_updates 80963 | lr 0.000200046 | gnorm 0.275 | loss_scale 2 | train_wall 36336 | wall 149527
2021-03-16 03:06:12 | INFO | fairseq.trainer | begin training epoch 5
2021-03-16 03:07:19 | INFO | train_inner | epoch 005:     37 / 20258 loss=3.568, nll_loss=1.882, ppl=3.69, wps=19661.3, ups=0.39, wpb=50949.8, bsz=2989.4, num_updates=81000, lr=0.0002, gnorm=0.266, loss_scale=2, train_wall=179, wall=149595
2021-03-16 03:10:22 | INFO | train_inner | epoch 005:    137 / 20258 loss=3.55, nll_loss=1.863, ppl=3.64, wps=27935.3, ups=0.55, wpb=51070.2, bsz=3098.2, num_updates=81100, lr=0.000199877, gnorm=0.27, loss_scale=2, train_wall=180, wall=149778
2021-03-16 03:13:24 | INFO | train_inner | epoch 005:    237 / 20258 loss=3.571, nll_loss=1.886, ppl=3.7, wps=27896.3, ups=0.55, wpb=50629, bsz=3007.4, num_updates=81200, lr=0.000199754, gnorm=0.274, loss_scale=2, train_wall=179, wall=149959
2021-03-16 03:16:26 | INFO | train_inner | epoch 005:    337 / 20258 loss=3.575, nll_loss=1.891, ppl=3.71, wps=28025.9, ups=0.55, wpb=51070.2, bsz=3025.4, num_updates=81300, lr=0.000199631, gnorm=0.269, loss_scale=2, train_wall=179, wall=150141
2021-03-16 03:19:28 | INFO | train_inner | epoch 005:    437 / 20258 loss=3.581, nll_loss=1.897, ppl=3.72, wps=27967.4, ups=0.55, wpb=50808.5, bsz=2874, num_updates=81400, lr=0.000199508, gnorm=0.266, loss_scale=2, train_wall=179, wall=150323
2021-03-16 03:22:30 | INFO | train_inner | epoch 005:    537 / 20258 loss=3.565, nll_loss=1.879, ppl=3.68, wps=27866.7, ups=0.55, wpb=50777.1, bsz=3022.8, num_updates=81500, lr=0.000199386, gnorm=0.268, loss_scale=2, train_wall=179, wall=150505
2021-03-16 03:25:32 | INFO | train_inner | epoch 005:    637 / 20258 loss=3.574, nll_loss=1.89, ppl=3.71, wps=27794.8, ups=0.55, wpb=50548.6, bsz=2962.8, num_updates=81600, lr=0.000199263, gnorm=0.268, loss_scale=2, train_wall=179, wall=150687
2021-03-16 03:28:34 | INFO | train_inner | epoch 005:    737 / 20258 loss=3.565, nll_loss=1.879, ppl=3.68, wps=27830.7, ups=0.55, wpb=50849.2, bsz=2967.6, num_updates=81700, lr=0.000199141, gnorm=0.265, loss_scale=2, train_wall=179, wall=150870
2021-03-16 03:31:37 | INFO | train_inner | epoch 005:    837 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27916, ups=0.55, wpb=51019.8, bsz=3034.4, num_updates=81800, lr=0.00019902, gnorm=0.266, loss_scale=2, train_wall=179, wall=151053
2021-03-16 03:34:39 | INFO | train_inner | epoch 005:    937 / 20258 loss=3.564, nll_loss=1.877, ppl=3.67, wps=28003.8, ups=0.55, wpb=51018.2, bsz=2808.6, num_updates=81900, lr=0.000198898, gnorm=0.275, loss_scale=4, train_wall=179, wall=151235
2021-03-16 03:37:42 | INFO | train_inner | epoch 005:   1037 / 20258 loss=3.556, nll_loss=1.869, ppl=3.65, wps=27951.8, ups=0.55, wpb=50991.2, bsz=3121.2, num_updates=82000, lr=0.000198777, gnorm=0.268, loss_scale=4, train_wall=179, wall=151417
2021-03-16 03:40:44 | INFO | train_inner | epoch 005:   1137 / 20258 loss=3.58, nll_loss=1.896, ppl=3.72, wps=27995.9, ups=0.55, wpb=50876.2, bsz=2928.6, num_updates=82100, lr=0.000198656, gnorm=0.273, loss_scale=4, train_wall=179, wall=151599
2021-03-16 03:43:46 | INFO | train_inner | epoch 005:   1237 / 20258 loss=3.563, nll_loss=1.877, ppl=3.67, wps=27876.2, ups=0.55, wpb=50890.6, bsz=3074, num_updates=82200, lr=0.000198535, gnorm=0.27, loss_scale=4, train_wall=180, wall=151782
2021-03-16 03:46:48 | INFO | train_inner | epoch 005:   1337 / 20258 loss=3.569, nll_loss=1.884, ppl=3.69, wps=27947.8, ups=0.55, wpb=50968, bsz=3009.1, num_updates=82300, lr=0.000198414, gnorm=0.268, loss_scale=4, train_wall=179, wall=151964
2021-03-16 03:49:51 | INFO | train_inner | epoch 005:   1437 / 20258 loss=3.584, nll_loss=1.901, ppl=3.73, wps=28090.5, ups=0.55, wpb=51247.5, bsz=3027.9, num_updates=82400, lr=0.000198294, gnorm=0.266, loss_scale=4, train_wall=179, wall=152146
2021-03-16 03:52:54 | INFO | train_inner | epoch 005:   1537 / 20258 loss=3.569, nll_loss=1.884, ppl=3.69, wps=27894.9, ups=0.55, wpb=50985.5, bsz=3061.3, num_updates=82500, lr=0.000198173, gnorm=0.273, loss_scale=4, train_wall=180, wall=152329
2021-03-16 03:55:56 | INFO | train_inner | epoch 005:   1637 / 20258 loss=3.569, nll_loss=1.884, ppl=3.69, wps=27954.4, ups=0.55, wpb=51095.9, bsz=2987, num_updates=82600, lr=0.000198053, gnorm=0.269, loss_scale=4, train_wall=180, wall=152512
2021-03-16 03:58:58 | INFO | train_inner | epoch 005:   1737 / 20258 loss=3.569, nll_loss=1.883, ppl=3.69, wps=28041.3, ups=0.55, wpb=51022, bsz=3077.2, num_updates=82700, lr=0.000197934, gnorm=0.269, loss_scale=4, train_wall=179, wall=152694
2021-03-16 04:02:01 | INFO | train_inner | epoch 005:   1837 / 20258 loss=3.573, nll_loss=1.888, ppl=3.7, wps=27930.6, ups=0.55, wpb=51013.7, bsz=3165.5, num_updates=82800, lr=0.000197814, gnorm=0.27, loss_scale=4, train_wall=179, wall=152877
2021-03-16 04:05:05 | INFO | train_inner | epoch 005:   1937 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27855.8, ups=0.54, wpb=51223.6, bsz=3056, num_updates=82900, lr=0.000197695, gnorm=0.264, loss_scale=8, train_wall=180, wall=153060
2021-03-16 04:08:08 | INFO | train_inner | epoch 005:   2037 / 20258 loss=3.546, nll_loss=1.858, ppl=3.62, wps=27977.5, ups=0.55, wpb=51193.6, bsz=2978.8, num_updates=83000, lr=0.000197576, gnorm=0.27, loss_scale=8, train_wall=180, wall=153243
2021-03-16 04:11:11 | INFO | train_inner | epoch 005:   2137 / 20258 loss=3.548, nll_loss=1.86, ppl=3.63, wps=27814.2, ups=0.55, wpb=51021.8, bsz=3027.2, num_updates=83100, lr=0.000197457, gnorm=0.272, loss_scale=8, train_wall=180, wall=153427
2021-03-16 04:14:15 | INFO | train_inner | epoch 005:   2237 / 20258 loss=3.543, nll_loss=1.855, ppl=3.62, wps=27767.5, ups=0.55, wpb=50900.4, bsz=3016.2, num_updates=83200, lr=0.000197338, gnorm=0.267, loss_scale=8, train_wall=180, wall=153610
2021-03-16 04:17:18 | INFO | train_inner | epoch 005:   2337 / 20258 loss=3.545, nll_loss=1.858, ppl=3.62, wps=27859.9, ups=0.54, wpb=51130.4, bsz=3110.6, num_updates=83300, lr=0.00019722, gnorm=0.269, loss_scale=8, train_wall=180, wall=153794
2021-03-16 04:20:21 | INFO | train_inner | epoch 005:   2437 / 20258 loss=3.586, nll_loss=1.903, ppl=3.74, wps=28013.9, ups=0.55, wpb=51148, bsz=2977.5, num_updates=83400, lr=0.000197101, gnorm=0.274, loss_scale=8, train_wall=179, wall=153976
2021-03-16 04:23:24 | INFO | train_inner | epoch 005:   2537 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27915.9, ups=0.55, wpb=51019.8, bsz=2987, num_updates=83500, lr=0.000196983, gnorm=0.267, loss_scale=8, train_wall=180, wall=154159
2021-03-16 04:26:26 | INFO | train_inner | epoch 005:   2637 / 20258 loss=3.566, nll_loss=1.881, ppl=3.68, wps=27934, ups=0.55, wpb=50953.9, bsz=3149.9, num_updates=83600, lr=0.000196865, gnorm=0.274, loss_scale=8, train_wall=179, wall=154341
2021-03-16 04:29:29 | INFO | train_inner | epoch 005:   2737 / 20258 loss=3.567, nll_loss=1.882, ppl=3.69, wps=27911, ups=0.55, wpb=51043.4, bsz=2990.5, num_updates=83700, lr=0.000196748, gnorm=0.264, loss_scale=8, train_wall=179, wall=154524
2021-03-16 04:32:31 | INFO | train_inner | epoch 005:   2837 / 20258 loss=3.555, nll_loss=1.868, ppl=3.65, wps=27957.6, ups=0.55, wpb=50960.8, bsz=3029.1, num_updates=83800, lr=0.00019663, gnorm=0.268, loss_scale=8, train_wall=180, wall=154707
2021-03-16 04:35:34 | INFO | train_inner | epoch 005:   2937 / 20258 loss=3.562, nll_loss=1.877, ppl=3.67, wps=27918.4, ups=0.55, wpb=51082.6, bsz=3104.1, num_updates=83900, lr=0.000196513, gnorm=0.269, loss_scale=16, train_wall=180, wall=154890
2021-03-16 04:38:37 | INFO | train_inner | epoch 005:   3037 / 20258 loss=3.565, nll_loss=1.88, ppl=3.68, wps=27949.4, ups=0.55, wpb=51164.7, bsz=3075.8, num_updates=84000, lr=0.000196396, gnorm=0.266, loss_scale=16, train_wall=180, wall=155073
2021-03-16 04:39:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 04:41:41 | INFO | train_inner | epoch 005:   3138 / 20258 loss=3.574, nll_loss=1.89, ppl=3.71, wps=27692.1, ups=0.54, wpb=50881.7, bsz=2920.2, num_updates=84100, lr=0.000196279, gnorm=0.272, loss_scale=8, train_wall=181, wall=155256
2021-03-16 04:44:43 | INFO | train_inner | epoch 005:   3238 / 20258 loss=3.56, nll_loss=1.874, ppl=3.67, wps=28025.6, ups=0.55, wpb=51056, bsz=2895.9, num_updates=84200, lr=0.000196163, gnorm=0.263, loss_scale=8, train_wall=179, wall=155439
2021-03-16 04:47:45 | INFO | train_inner | epoch 005:   3338 / 20258 loss=3.574, nll_loss=1.89, ppl=3.71, wps=27921.5, ups=0.55, wpb=50820.9, bsz=3065.9, num_updates=84300, lr=0.000196046, gnorm=0.268, loss_scale=8, train_wall=179, wall=155621
2021-03-16 04:50:47 | INFO | train_inner | epoch 005:   3438 / 20258 loss=3.56, nll_loss=1.874, ppl=3.67, wps=27648.8, ups=0.55, wpb=50321.7, bsz=2966.1, num_updates=84400, lr=0.00019593, gnorm=0.273, loss_scale=8, train_wall=179, wall=155803
2021-03-16 04:53:50 | INFO | train_inner | epoch 005:   3538 / 20258 loss=3.584, nll_loss=1.901, ppl=3.74, wps=27971.6, ups=0.55, wpb=51077.3, bsz=3016, num_updates=84500, lr=0.000195814, gnorm=0.277, loss_scale=8, train_wall=180, wall=155985
2021-03-16 04:54:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 04:56:54 | INFO | train_inner | epoch 005:   3639 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27624.4, ups=0.54, wpb=50988.4, bsz=3068.8, num_updates=84600, lr=0.000195698, gnorm=0.271, loss_scale=4, train_wall=181, wall=156170
2021-03-16 04:59:57 | INFO | train_inner | epoch 005:   3739 / 20258 loss=3.55, nll_loss=1.863, ppl=3.64, wps=27929.1, ups=0.55, wpb=51101.2, bsz=3001.3, num_updates=84700, lr=0.000195583, gnorm=0.266, loss_scale=4, train_wall=180, wall=156353
2021-03-16 05:02:59 | INFO | train_inner | epoch 005:   3839 / 20258 loss=3.594, nll_loss=1.912, ppl=3.76, wps=27997, ups=0.55, wpb=51011.5, bsz=3053.7, num_updates=84800, lr=0.000195468, gnorm=0.272, loss_scale=4, train_wall=179, wall=156535
2021-03-16 05:06:02 | INFO | train_inner | epoch 005:   3939 / 20258 loss=3.567, nll_loss=1.881, ppl=3.68, wps=27870.3, ups=0.55, wpb=50799.3, bsz=2946.4, num_updates=84900, lr=0.000195352, gnorm=0.267, loss_scale=4, train_wall=179, wall=156717
2021-03-16 05:09:04 | INFO | train_inner | epoch 005:   4039 / 20258 loss=3.579, nll_loss=1.896, ppl=3.72, wps=28023.4, ups=0.55, wpb=51131.7, bsz=2903.6, num_updates=85000, lr=0.000195237, gnorm=0.271, loss_scale=4, train_wall=180, wall=156900
2021-03-16 05:09:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 05:09:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:23 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.978 | nll_loss 2.26 | ppl 4.79 | bleu 29.18 | wps 4306.8 | wpb 2432 | bsz 90.4 | num_updates 85000 | best_loss 3.978
2021-03-16 05:09:23 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 05:09:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:09:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 05:09:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 05:09:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 05:10:16 | INFO | valid1 | epoch 005 | valid on 'valid1' subset | loss 3.967 | nll_loss 2.272 | ppl 4.83 | bleu 27.38 | wps 4190.5 | wpb 2359.4 | bsz 106.4 | num_updates 85000 | best_loss 3.967
2021-03-16 05:10:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 05:10:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_5_85000.pt (epoch 5 @ 85000 updates, score 3.978) (writing took 6.269618567777798 seconds)
2021-03-16 05:13:25 | INFO | train_inner | epoch 005:   4139 / 20258 loss=3.567, nll_loss=1.882, ppl=3.68, wps=19527.8, ups=0.38, wpb=50951.6, bsz=2996.6, num_updates=85100, lr=0.000195123, gnorm=0.273, loss_scale=4, train_wall=179, wall=157161
2021-03-16 05:16:28 | INFO | train_inner | epoch 005:   4239 / 20258 loss=3.563, nll_loss=1.877, ppl=3.67, wps=27926, ups=0.55, wpb=50947.2, bsz=2985.8, num_updates=85200, lr=0.000195008, gnorm=0.265, loss_scale=4, train_wall=179, wall=157343
2021-03-16 05:19:30 | INFO | train_inner | epoch 005:   4339 / 20258 loss=3.557, nll_loss=1.87, ppl=3.66, wps=27939.3, ups=0.55, wpb=50935.9, bsz=2986.5, num_updates=85300, lr=0.000194894, gnorm=0.29, loss_scale=4, train_wall=179, wall=157525
2021-03-16 05:22:32 | INFO | train_inner | epoch 005:   4439 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27912.6, ups=0.55, wpb=50806.2, bsz=3021.4, num_updates=85400, lr=0.00019478, gnorm=0.267, loss_scale=4, train_wall=179, wall=157707
2021-03-16 05:25:34 | INFO | train_inner | epoch 005:   4539 / 20258 loss=3.583, nll_loss=1.9, ppl=3.73, wps=27985.1, ups=0.55, wpb=51030.7, bsz=3031, num_updates=85500, lr=0.000194666, gnorm=0.265, loss_scale=4, train_wall=179, wall=157890
2021-03-16 05:28:36 | INFO | train_inner | epoch 005:   4639 / 20258 loss=3.56, nll_loss=1.874, ppl=3.66, wps=27929, ups=0.55, wpb=50867.5, bsz=3039.4, num_updates=85600, lr=0.000194552, gnorm=0.273, loss_scale=8, train_wall=179, wall=158072
2021-03-16 05:31:39 | INFO | train_inner | epoch 005:   4739 / 20258 loss=3.561, nll_loss=1.876, ppl=3.67, wps=27847.1, ups=0.55, wpb=50754.9, bsz=2916, num_updates=85700, lr=0.000194438, gnorm=0.269, loss_scale=8, train_wall=179, wall=158254
2021-03-16 05:34:42 | INFO | train_inner | epoch 005:   4839 / 20258 loss=3.561, nll_loss=1.876, ppl=3.67, wps=27896.1, ups=0.55, wpb=51025.8, bsz=3089.8, num_updates=85800, lr=0.000194325, gnorm=0.264, loss_scale=8, train_wall=180, wall=158437
2021-03-16 05:37:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 05:37:46 | INFO | train_inner | epoch 005:   4940 / 20258 loss=3.587, nll_loss=1.904, ppl=3.74, wps=27679, ups=0.54, wpb=51007.3, bsz=2939.9, num_updates=85900, lr=0.000194212, gnorm=0.269, loss_scale=4, train_wall=181, wall=158621
2021-03-16 05:40:48 | INFO | train_inner | epoch 005:   5040 / 20258 loss=3.57, nll_loss=1.885, ppl=3.69, wps=27850.7, ups=0.55, wpb=50848.3, bsz=3078.7, num_updates=86000, lr=0.000194099, gnorm=0.268, loss_scale=4, train_wall=179, wall=158804
2021-03-16 05:43:51 | INFO | train_inner | epoch 005:   5140 / 20258 loss=3.562, nll_loss=1.877, ppl=3.67, wps=27928.4, ups=0.55, wpb=50907.8, bsz=2993.9, num_updates=86100, lr=0.000193986, gnorm=0.275, loss_scale=4, train_wall=179, wall=158986
2021-03-16 05:46:53 | INFO | train_inner | epoch 005:   5240 / 20258 loss=3.565, nll_loss=1.879, ppl=3.68, wps=27810.7, ups=0.55, wpb=50829.6, bsz=2937.5, num_updates=86200, lr=0.000193874, gnorm=0.273, loss_scale=4, train_wall=179, wall=159169
2021-03-16 05:49:56 | INFO | train_inner | epoch 005:   5340 / 20258 loss=3.551, nll_loss=1.864, ppl=3.64, wps=27873.5, ups=0.55, wpb=50930, bsz=3011.6, num_updates=86300, lr=0.000193761, gnorm=0.274, loss_scale=4, train_wall=180, wall=159352
2021-03-16 05:52:59 | INFO | train_inner | epoch 005:   5440 / 20258 loss=3.56, nll_loss=1.874, ppl=3.67, wps=27841.9, ups=0.55, wpb=50956.3, bsz=2913.4, num_updates=86400, lr=0.000193649, gnorm=0.274, loss_scale=4, train_wall=180, wall=159535
2021-03-16 05:56:02 | INFO | train_inner | epoch 005:   5540 / 20258 loss=3.548, nll_loss=1.861, ppl=3.63, wps=27874.5, ups=0.55, wpb=50823.3, bsz=2959.6, num_updates=86500, lr=0.000193537, gnorm=0.269, loss_scale=4, train_wall=179, wall=159717
2021-03-16 05:59:04 | INFO | train_inner | epoch 005:   5640 / 20258 loss=3.555, nll_loss=1.868, ppl=3.65, wps=27898.2, ups=0.55, wpb=50890.7, bsz=2898.6, num_updates=86600, lr=0.000193425, gnorm=0.27, loss_scale=4, train_wall=179, wall=159899
2021-03-16 06:02:07 | INFO | train_inner | epoch 005:   5740 / 20258 loss=3.552, nll_loss=1.865, ppl=3.64, wps=27912.7, ups=0.55, wpb=51119.4, bsz=2991.7, num_updates=86700, lr=0.000193314, gnorm=0.266, loss_scale=4, train_wall=180, wall=160083
2021-03-16 06:05:10 | INFO | train_inner | epoch 005:   5840 / 20258 loss=3.557, nll_loss=1.872, ppl=3.66, wps=27873, ups=0.55, wpb=51049.1, bsz=3244.6, num_updates=86800, lr=0.000193202, gnorm=0.267, loss_scale=4, train_wall=180, wall=160266
2021-03-16 06:08:12 | INFO | train_inner | epoch 005:   5940 / 20258 loss=3.561, nll_loss=1.875, ppl=3.67, wps=27848.4, ups=0.55, wpb=50674, bsz=2964.9, num_updates=86900, lr=0.000193091, gnorm=0.267, loss_scale=4, train_wall=179, wall=160448
2021-03-16 06:11:14 | INFO | train_inner | epoch 005:   6040 / 20258 loss=3.56, nll_loss=1.875, ppl=3.67, wps=27911.6, ups=0.55, wpb=50871.5, bsz=2996.9, num_updates=87000, lr=0.00019298, gnorm=0.271, loss_scale=8, train_wall=179, wall=160630
2021-03-16 06:14:17 | INFO | train_inner | epoch 005:   6140 / 20258 loss=3.569, nll_loss=1.884, ppl=3.69, wps=28045.4, ups=0.55, wpb=51180, bsz=2955.6, num_updates=87100, lr=0.000192869, gnorm=0.266, loss_scale=8, train_wall=179, wall=160812
2021-03-16 06:17:20 | INFO | train_inner | epoch 005:   6240 / 20258 loss=3.554, nll_loss=1.868, ppl=3.65, wps=27936.1, ups=0.55, wpb=51076.7, bsz=3070, num_updates=87200, lr=0.000192759, gnorm=0.268, loss_scale=8, train_wall=180, wall=160995
2021-03-16 06:20:22 | INFO | train_inner | epoch 005:   6340 / 20258 loss=3.555, nll_loss=1.869, ppl=3.65, wps=27795.9, ups=0.55, wpb=50723.4, bsz=3022.2, num_updates=87300, lr=0.000192648, gnorm=0.274, loss_scale=8, train_wall=179, wall=161178
2021-03-16 06:23:25 | INFO | train_inner | epoch 005:   6440 / 20258 loss=3.56, nll_loss=1.874, ppl=3.67, wps=27810.3, ups=0.55, wpb=50856.8, bsz=3020.3, num_updates=87400, lr=0.000192538, gnorm=0.272, loss_scale=8, train_wall=180, wall=161361
2021-03-16 06:26:28 | INFO | train_inner | epoch 005:   6540 / 20258 loss=3.568, nll_loss=1.883, ppl=3.69, wps=27969.2, ups=0.55, wpb=51077.3, bsz=3030.9, num_updates=87500, lr=0.000192428, gnorm=0.269, loss_scale=8, train_wall=180, wall=161543
2021-03-16 06:29:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 06:29:33 | INFO | train_inner | epoch 005:   6641 / 20258 loss=3.569, nll_loss=1.885, ppl=3.69, wps=27604.7, ups=0.54, wpb=51154.9, bsz=3159.5, num_updates=87600, lr=0.000192318, gnorm=0.266, loss_scale=4, train_wall=182, wall=161729
2021-03-16 06:32:35 | INFO | train_inner | epoch 005:   6741 / 20258 loss=3.557, nll_loss=1.87, ppl=3.66, wps=27789.9, ups=0.55, wpb=50601.1, bsz=2857.7, num_updates=87700, lr=0.000192209, gnorm=0.272, loss_scale=4, train_wall=179, wall=161911
2021-03-16 06:35:38 | INFO | train_inner | epoch 005:   6841 / 20258 loss=3.55, nll_loss=1.864, ppl=3.64, wps=27838.6, ups=0.55, wpb=51004.1, bsz=3028, num_updates=87800, lr=0.000192099, gnorm=0.267, loss_scale=4, train_wall=180, wall=162094
2021-03-16 06:38:40 | INFO | train_inner | epoch 005:   6941 / 20258 loss=3.575, nll_loss=1.892, ppl=3.71, wps=27787.3, ups=0.55, wpb=50566.8, bsz=2896.6, num_updates=87900, lr=0.00019199, gnorm=0.277, loss_scale=4, train_wall=178, wall=162276
2021-03-16 06:41:43 | INFO | train_inner | epoch 005:   7041 / 20258 loss=3.565, nll_loss=1.88, ppl=3.68, wps=27829.2, ups=0.55, wpb=50830, bsz=2949.9, num_updates=88000, lr=0.000191881, gnorm=0.275, loss_scale=4, train_wall=179, wall=162459
2021-03-16 06:44:46 | INFO | train_inner | epoch 005:   7141 / 20258 loss=3.572, nll_loss=1.888, ppl=3.7, wps=27828.6, ups=0.55, wpb=50815.7, bsz=3063.5, num_updates=88100, lr=0.000191772, gnorm=0.272, loss_scale=4, train_wall=179, wall=162641
2021-03-16 06:47:48 | INFO | train_inner | epoch 005:   7241 / 20258 loss=3.566, nll_loss=1.882, ppl=3.69, wps=27896, ups=0.55, wpb=50913.4, bsz=3022.9, num_updates=88200, lr=0.000191663, gnorm=0.267, loss_scale=4, train_wall=179, wall=162824
2021-03-16 06:50:51 | INFO | train_inner | epoch 005:   7341 / 20258 loss=3.566, nll_loss=1.882, ppl=3.69, wps=27814.3, ups=0.55, wpb=50808.7, bsz=3049.1, num_updates=88300, lr=0.000191554, gnorm=0.274, loss_scale=4, train_wall=179, wall=163006
2021-03-16 06:53:54 | INFO | train_inner | epoch 005:   7441 / 20258 loss=3.567, nll_loss=1.883, ppl=3.69, wps=27909.3, ups=0.55, wpb=51086.4, bsz=3077.2, num_updates=88400, lr=0.000191446, gnorm=0.292, loss_scale=4, train_wall=180, wall=163189
2021-03-16 06:56:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-16 06:56:58 | INFO | train_inner | epoch 005:   7542 / 20258 loss=3.56, nll_loss=1.874, ppl=3.67, wps=27477.4, ups=0.54, wpb=50578.3, bsz=2923, num_updates=88500, lr=0.000191338, gnorm=0.267, loss_scale=2, train_wall=181, wall=163373
2021-03-16 07:00:00 | INFO | train_inner | epoch 005:   7642 / 20258 loss=3.564, nll_loss=1.879, ppl=3.68, wps=27930.8, ups=0.55, wpb=50754.5, bsz=3007, num_updates=88600, lr=0.00019123, gnorm=0.269, loss_scale=2, train_wall=179, wall=163555
2021-03-16 07:03:02 | INFO | train_inner | epoch 005:   7742 / 20258 loss=3.567, nll_loss=1.882, ppl=3.69, wps=27900.6, ups=0.55, wpb=50850.2, bsz=2957, num_updates=88700, lr=0.000191122, gnorm=0.283, loss_scale=2, train_wall=179, wall=163737
2021-03-16 07:06:05 | INFO | train_inner | epoch 005:   7842 / 20258 loss=3.568, nll_loss=1.884, ppl=3.69, wps=27804.6, ups=0.55, wpb=50832.1, bsz=3022.6, num_updates=88800, lr=0.000191014, gnorm=0.265, loss_scale=2, train_wall=179, wall=163920
2021-03-16 07:09:07 | INFO | train_inner | epoch 005:   7942 / 20258 loss=3.555, nll_loss=1.868, ppl=3.65, wps=27804.1, ups=0.55, wpb=50769.5, bsz=2965.8, num_updates=88900, lr=0.000190907, gnorm=0.272, loss_scale=2, train_wall=179, wall=164103
2021-03-16 07:12:10 | INFO | train_inner | epoch 005:   8042 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27994.1, ups=0.55, wpb=51020.5, bsz=3061, num_updates=89000, lr=0.0001908, gnorm=0.273, loss_scale=2, train_wall=179, wall=164285
2021-03-16 07:15:11 | INFO | train_inner | epoch 005:   8142 / 20258 loss=3.573, nll_loss=1.889, ppl=3.7, wps=27912.3, ups=0.55, wpb=50778.2, bsz=2938.6, num_updates=89100, lr=0.000190693, gnorm=0.272, loss_scale=2, train_wall=179, wall=164467
2021-03-16 07:18:14 | INFO | train_inner | epoch 005:   8242 / 20258 loss=3.56, nll_loss=1.874, ppl=3.67, wps=27968.5, ups=0.55, wpb=51146.6, bsz=2981.3, num_updates=89200, lr=0.000190586, gnorm=0.274, loss_scale=2, train_wall=180, wall=164650
2021-03-16 07:21:17 | INFO | train_inner | epoch 005:   8342 / 20258 loss=3.56, nll_loss=1.874, ppl=3.67, wps=28007.2, ups=0.55, wpb=51071, bsz=2857.3, num_updates=89300, lr=0.000190479, gnorm=0.265, loss_scale=2, train_wall=179, wall=164832
2021-03-16 07:24:19 | INFO | train_inner | epoch 005:   8442 / 20258 loss=3.549, nll_loss=1.862, ppl=3.64, wps=27805.1, ups=0.55, wpb=50713.4, bsz=2995.9, num_updates=89400, lr=0.000190372, gnorm=0.267, loss_scale=2, train_wall=179, wall=165015
2021-03-16 07:27:22 | INFO | train_inner | epoch 005:   8542 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27799.2, ups=0.55, wpb=50715.2, bsz=2984.4, num_updates=89500, lr=0.000190266, gnorm=0.283, loss_scale=2, train_wall=179, wall=165197
2021-03-16 07:30:24 | INFO | train_inner | epoch 005:   8642 / 20258 loss=3.544, nll_loss=1.857, ppl=3.62, wps=27699.9, ups=0.55, wpb=50576.8, bsz=2936.9, num_updates=89600, lr=0.00019016, gnorm=0.273, loss_scale=4, train_wall=179, wall=165380
2021-03-16 07:33:27 | INFO | train_inner | epoch 005:   8742 / 20258 loss=3.558, nll_loss=1.872, ppl=3.66, wps=27758.8, ups=0.55, wpb=50655.8, bsz=2919.5, num_updates=89700, lr=0.000190054, gnorm=0.271, loss_scale=4, train_wall=179, wall=165562
2021-03-16 07:36:29 | INFO | train_inner | epoch 005:   8842 / 20258 loss=3.57, nll_loss=1.886, ppl=3.7, wps=27864.5, ups=0.55, wpb=50743.3, bsz=2994.6, num_updates=89800, lr=0.000189948, gnorm=0.267, loss_scale=4, train_wall=179, wall=165744
2021-03-16 07:39:32 | INFO | train_inner | epoch 005:   8942 / 20258 loss=3.536, nll_loss=1.847, ppl=3.6, wps=27766, ups=0.55, wpb=50838.8, bsz=2986.8, num_updates=89900, lr=0.000189842, gnorm=0.272, loss_scale=4, train_wall=179, wall=165927
2021-03-16 07:42:34 | INFO | train_inner | epoch 005:   9042 / 20258 loss=3.577, nll_loss=1.893, ppl=3.71, wps=27863.3, ups=0.55, wpb=50671.3, bsz=2954.4, num_updates=90000, lr=0.000189737, gnorm=0.275, loss_scale=4, train_wall=179, wall=166109
2021-03-16 07:42:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 07:42:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:52 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.969 | nll_loss 2.255 | ppl 4.77 | bleu 29.37 | wps 4280.4 | wpb 2432 | bsz 90.4 | num_updates 90000 | best_loss 3.969
2021-03-16 07:42:52 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 07:42:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:42:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:42:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:42:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 07:43:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 07:43:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 07:43:45 | INFO | valid1 | epoch 005 | valid on 'valid1' subset | loss 3.959 | nll_loss 2.269 | ppl 4.82 | bleu 27.25 | wps 4227.8 | wpb 2359.4 | bsz 106.4 | num_updates 90000 | best_loss 3.959
2021-03-16 07:43:45 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 07:43:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_5_90000.pt (epoch 5 @ 90000 updates, score 3.969) (writing took 6.324508207151666 seconds)
2021-03-16 07:46:54 | INFO | train_inner | epoch 005:   9142 / 20258 loss=3.567, nll_loss=1.882, ppl=3.69, wps=19532.8, ups=0.38, wpb=50927.6, bsz=2977.8, num_updates=90100, lr=0.000189631, gnorm=0.27, loss_scale=4, train_wall=179, wall=166370
2021-03-16 07:49:57 | INFO | train_inner | epoch 005:   9242 / 20258 loss=3.581, nll_loss=1.899, ppl=3.73, wps=27896.2, ups=0.55, wpb=50831.8, bsz=3165.6, num_updates=90200, lr=0.000189526, gnorm=0.269, loss_scale=4, train_wall=179, wall=166552
2021-03-16 07:52:59 | INFO | train_inner | epoch 005:   9342 / 20258 loss=3.556, nll_loss=1.87, ppl=3.66, wps=27884.6, ups=0.55, wpb=50940.7, bsz=3117.4, num_updates=90300, lr=0.000189421, gnorm=0.275, loss_scale=4, train_wall=179, wall=166735
2021-03-16 07:56:02 | INFO | train_inner | epoch 005:   9442 / 20258 loss=3.564, nll_loss=1.879, ppl=3.68, wps=27836.5, ups=0.55, wpb=50803.1, bsz=3048.8, num_updates=90400, lr=0.000189316, gnorm=0.27, loss_scale=4, train_wall=179, wall=166917
2021-03-16 07:59:05 | INFO | train_inner | epoch 005:   9542 / 20258 loss=3.556, nll_loss=1.87, ppl=3.65, wps=27957.5, ups=0.55, wpb=51098.1, bsz=3015.1, num_updates=90500, lr=0.000189212, gnorm=0.272, loss_scale=4, train_wall=180, wall=167100
2021-03-16 08:02:07 | INFO | train_inner | epoch 005:   9642 / 20258 loss=3.563, nll_loss=1.878, ppl=3.68, wps=27883.6, ups=0.55, wpb=50981.5, bsz=3032.9, num_updates=90600, lr=0.000189107, gnorm=0.266, loss_scale=8, train_wall=179, wall=167283
2021-03-16 08:05:10 | INFO | train_inner | epoch 005:   9742 / 20258 loss=3.567, nll_loss=1.882, ppl=3.69, wps=27915.7, ups=0.55, wpb=50863.2, bsz=2870, num_updates=90700, lr=0.000189003, gnorm=0.275, loss_scale=8, train_wall=179, wall=167465
2021-03-16 08:08:13 | INFO | train_inner | epoch 005:   9842 / 20258 loss=3.569, nll_loss=1.885, ppl=3.69, wps=27876.3, ups=0.55, wpb=51011.6, bsz=2999.3, num_updates=90800, lr=0.000188899, gnorm=0.269, loss_scale=8, train_wall=179, wall=167648
2021-03-16 08:11:15 | INFO | train_inner | epoch 005:   9942 / 20258 loss=3.567, nll_loss=1.883, ppl=3.69, wps=27807.2, ups=0.55, wpb=50661, bsz=3111.3, num_updates=90900, lr=0.000188795, gnorm=0.272, loss_scale=8, train_wall=179, wall=167830
2021-03-16 08:14:18 | INFO | train_inner | epoch 005:  10042 / 20258 loss=3.557, nll_loss=1.871, ppl=3.66, wps=27800.7, ups=0.55, wpb=50805.2, bsz=3002.5, num_updates=91000, lr=0.000188691, gnorm=0.264, loss_scale=8, train_wall=180, wall=168013
2021-03-16 08:17:21 | INFO | train_inner | epoch 005:  10142 / 20258 loss=3.57, nll_loss=1.886, ppl=3.7, wps=27968.1, ups=0.55, wpb=51240.9, bsz=3123, num_updates=91100, lr=0.000188588, gnorm=0.269, loss_scale=8, train_wall=180, wall=168196
2021-03-16 08:20:23 | INFO | train_inner | epoch 005:  10242 / 20258 loss=3.582, nll_loss=1.899, ppl=3.73, wps=27873.4, ups=0.55, wpb=50774.6, bsz=2898.2, num_updates=91200, lr=0.000188484, gnorm=0.279, loss_scale=8, train_wall=179, wall=168378
2021-03-16 08:23:26 | INFO | train_inner | epoch 005:  10342 / 20258 loss=3.558, nll_loss=1.873, ppl=3.66, wps=27920.2, ups=0.55, wpb=51088.3, bsz=2971.9, num_updates=91300, lr=0.000188381, gnorm=0.266, loss_scale=8, train_wall=180, wall=168561
2021-03-16 08:26:29 | INFO | train_inner | epoch 005:  10442 / 20258 loss=3.553, nll_loss=1.866, ppl=3.65, wps=28053.1, ups=0.55, wpb=51387.8, bsz=3038.5, num_updates=91400, lr=0.000188278, gnorm=0.265, loss_scale=8, train_wall=180, wall=168745
2021-03-16 08:29:32 | INFO | train_inner | epoch 005:  10542 / 20258 loss=3.549, nll_loss=1.862, ppl=3.64, wps=27838.9, ups=0.55, wpb=51044.6, bsz=3058.8, num_updates=91500, lr=0.000188175, gnorm=0.272, loss_scale=8, train_wall=180, wall=168928
2021-03-16 08:32:35 | INFO | train_inner | epoch 005:  10642 / 20258 loss=3.569, nll_loss=1.885, ppl=3.69, wps=27860.9, ups=0.55, wpb=50854.3, bsz=2997.3, num_updates=91600, lr=0.000188072, gnorm=0.271, loss_scale=16, train_wall=179, wall=169110
2021-03-16 08:35:38 | INFO | train_inner | epoch 005:  10742 / 20258 loss=3.55, nll_loss=1.863, ppl=3.64, wps=27911.3, ups=0.55, wpb=51019.5, bsz=2965.1, num_updates=91700, lr=0.00018797, gnorm=0.273, loss_scale=16, train_wall=180, wall=169293
2021-03-16 08:38:41 | INFO | train_inner | epoch 005:  10842 / 20258 loss=3.542, nll_loss=1.855, ppl=3.62, wps=27870.5, ups=0.55, wpb=50961.5, bsz=3090.9, num_updates=91800, lr=0.000187867, gnorm=0.265, loss_scale=16, train_wall=180, wall=169476
2021-03-16 08:41:42 | INFO | train_inner | epoch 005:  10942 / 20258 loss=3.551, nll_loss=1.865, ppl=3.64, wps=27815.8, ups=0.55, wpb=50577.3, bsz=3053.9, num_updates=91900, lr=0.000187765, gnorm=0.269, loss_scale=16, train_wall=179, wall=169658
2021-03-16 08:41:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 08:42:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 08:44:49 | INFO | train_inner | epoch 005:  11044 / 20258 loss=3.557, nll_loss=1.872, ppl=3.66, wps=27308.6, ups=0.54, wpb=50906.2, bsz=3083, num_updates=92000, lr=0.000187663, gnorm=0.265, loss_scale=4, train_wall=183, wall=169844
2021-03-16 08:47:51 | INFO | train_inner | epoch 005:  11144 / 20258 loss=3.564, nll_loss=1.879, ppl=3.68, wps=27865, ups=0.55, wpb=50749.4, bsz=3011.6, num_updates=92100, lr=0.000187561, gnorm=0.27, loss_scale=4, train_wall=179, wall=170027
2021-03-16 08:50:53 | INFO | train_inner | epoch 005:  11244 / 20258 loss=3.563, nll_loss=1.878, ppl=3.68, wps=27853.7, ups=0.55, wpb=50753, bsz=2895.7, num_updates=92200, lr=0.000187459, gnorm=0.269, loss_scale=4, train_wall=179, wall=170209
2021-03-16 08:53:56 | INFO | train_inner | epoch 005:  11344 / 20258 loss=3.559, nll_loss=1.874, ppl=3.66, wps=27834.3, ups=0.55, wpb=50797.5, bsz=2978.2, num_updates=92300, lr=0.000187358, gnorm=0.27, loss_scale=4, train_wall=179, wall=170391
2021-03-16 08:56:58 | INFO | train_inner | epoch 005:  11444 / 20258 loss=3.57, nll_loss=1.887, ppl=3.7, wps=27845.4, ups=0.55, wpb=50797.3, bsz=3041.8, num_updates=92400, lr=0.000187256, gnorm=0.282, loss_scale=4, train_wall=179, wall=170574
2021-03-16 09:00:01 | INFO | train_inner | epoch 005:  11544 / 20258 loss=3.565, nll_loss=1.881, ppl=3.68, wps=27872.1, ups=0.55, wpb=50990.1, bsz=3054.7, num_updates=92500, lr=0.000187155, gnorm=0.266, loss_scale=4, train_wall=179, wall=170757
2021-03-16 09:03:03 | INFO | train_inner | epoch 005:  11644 / 20258 loss=3.565, nll_loss=1.881, ppl=3.68, wps=27917, ups=0.55, wpb=50867.2, bsz=3038.7, num_updates=92600, lr=0.000187054, gnorm=0.276, loss_scale=4, train_wall=179, wall=170939
2021-03-16 09:06:06 | INFO | train_inner | epoch 005:  11744 / 20258 loss=3.566, nll_loss=1.882, ppl=3.69, wps=27822.4, ups=0.55, wpb=50761.1, bsz=3132.6, num_updates=92700, lr=0.000186953, gnorm=0.268, loss_scale=4, train_wall=179, wall=171121
2021-03-16 09:09:08 | INFO | train_inner | epoch 005:  11844 / 20258 loss=3.549, nll_loss=1.862, ppl=3.63, wps=27865.7, ups=0.55, wpb=50914.2, bsz=2932.6, num_updates=92800, lr=0.000186852, gnorm=0.264, loss_scale=4, train_wall=180, wall=171304
2021-03-16 09:12:11 | INFO | train_inner | epoch 005:  11944 / 20258 loss=3.556, nll_loss=1.87, ppl=3.66, wps=27893.1, ups=0.55, wpb=50937.9, bsz=2942.8, num_updates=92900, lr=0.000186752, gnorm=0.272, loss_scale=4, train_wall=180, wall=171487
2021-03-16 09:15:13 | INFO | train_inner | epoch 005:  12044 / 20258 loss=3.559, nll_loss=1.873, ppl=3.66, wps=27795.5, ups=0.55, wpb=50683.5, bsz=2965.3, num_updates=93000, lr=0.000186651, gnorm=0.275, loss_scale=8, train_wall=179, wall=171669
2021-03-16 09:18:16 | INFO | train_inner | epoch 005:  12144 / 20258 loss=3.542, nll_loss=1.854, ppl=3.62, wps=27884.2, ups=0.55, wpb=50953.9, bsz=2967.9, num_updates=93100, lr=0.000186551, gnorm=0.268, loss_scale=8, train_wall=180, wall=171852
2021-03-16 09:21:19 | INFO | train_inner | epoch 005:  12244 / 20258 loss=3.554, nll_loss=1.868, ppl=3.65, wps=27869.4, ups=0.55, wpb=50907.8, bsz=3060.1, num_updates=93200, lr=0.000186451, gnorm=0.267, loss_scale=8, train_wall=180, wall=172034
2021-03-16 09:24:22 | INFO | train_inner | epoch 005:  12344 / 20258 loss=3.548, nll_loss=1.862, ppl=3.63, wps=27845.9, ups=0.55, wpb=51065, bsz=2956.7, num_updates=93300, lr=0.000186351, gnorm=0.267, loss_scale=8, train_wall=180, wall=172218
2021-03-16 09:27:24 | INFO | train_inner | epoch 005:  12444 / 20258 loss=3.584, nll_loss=1.902, ppl=3.74, wps=27961.4, ups=0.55, wpb=50893.5, bsz=2914.9, num_updates=93400, lr=0.000186251, gnorm=0.274, loss_scale=8, train_wall=179, wall=172400
2021-03-16 09:30:26 | INFO | train_inner | epoch 005:  12544 / 20258 loss=3.549, nll_loss=1.862, ppl=3.64, wps=27846.4, ups=0.55, wpb=50711.5, bsz=2987.6, num_updates=93500, lr=0.000186152, gnorm=0.269, loss_scale=8, train_wall=179, wall=172582
2021-03-16 09:33:29 | INFO | train_inner | epoch 005:  12644 / 20258 loss=3.566, nll_loss=1.882, ppl=3.69, wps=27801.4, ups=0.55, wpb=50686.9, bsz=2973.4, num_updates=93600, lr=0.000186052, gnorm=0.273, loss_scale=8, train_wall=179, wall=172764
2021-03-16 09:36:31 | INFO | train_inner | epoch 005:  12744 / 20258 loss=3.567, nll_loss=1.883, ppl=3.69, wps=28050.1, ups=0.55, wpb=51123.8, bsz=2897.2, num_updates=93700, lr=0.000185953, gnorm=0.268, loss_scale=8, train_wall=179, wall=172946
2021-03-16 09:39:34 | INFO | train_inner | epoch 005:  12844 / 20258 loss=3.554, nll_loss=1.868, ppl=3.65, wps=27745.8, ups=0.55, wpb=50892.3, bsz=3083.1, num_updates=93800, lr=0.000185854, gnorm=0.265, loss_scale=8, train_wall=180, wall=173130
2021-03-16 09:42:37 | INFO | train_inner | epoch 005:  12944 / 20258 loss=3.549, nll_loss=1.862, ppl=3.63, wps=27876.3, ups=0.55, wpb=50988.7, bsz=2974.3, num_updates=93900, lr=0.000185755, gnorm=0.264, loss_scale=8, train_wall=180, wall=173313
2021-03-16 09:45:40 | INFO | train_inner | epoch 005:  13044 / 20258 loss=3.548, nll_loss=1.861, ppl=3.63, wps=27855.5, ups=0.55, wpb=50897.8, bsz=3070, num_updates=94000, lr=0.000185656, gnorm=0.271, loss_scale=16, train_wall=179, wall=173495
2021-03-16 09:48:43 | INFO | train_inner | epoch 005:  13144 / 20258 loss=3.551, nll_loss=1.865, ppl=3.64, wps=27913.8, ups=0.55, wpb=51017.5, bsz=2939.8, num_updates=94100, lr=0.000185557, gnorm=0.267, loss_scale=16, train_wall=180, wall=173678
2021-03-16 09:51:45 | INFO | train_inner | epoch 005:  13244 / 20258 loss=3.553, nll_loss=1.867, ppl=3.65, wps=27840.3, ups=0.55, wpb=50834.3, bsz=2999.3, num_updates=94200, lr=0.000185459, gnorm=0.272, loss_scale=16, train_wall=179, wall=173861
2021-03-16 09:54:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 09:54:49 | INFO | train_inner | epoch 005:  13345 / 20258 loss=3.571, nll_loss=1.887, ppl=3.7, wps=27626.4, ups=0.54, wpb=50842.9, bsz=3027.7, num_updates=94300, lr=0.00018536, gnorm=0.27, loss_scale=8, train_wall=181, wall=174045
2021-03-16 09:57:52 | INFO | train_inner | epoch 005:  13445 / 20258 loss=3.544, nll_loss=1.857, ppl=3.62, wps=27861.8, ups=0.55, wpb=50964.1, bsz=2982.6, num_updates=94400, lr=0.000185262, gnorm=0.27, loss_scale=8, train_wall=180, wall=174228
2021-03-16 10:00:55 | INFO | train_inner | epoch 005:  13545 / 20258 loss=3.555, nll_loss=1.87, ppl=3.66, wps=27790, ups=0.55, wpb=50767.9, bsz=3061.5, num_updates=94500, lr=0.000185164, gnorm=0.27, loss_scale=8, train_wall=180, wall=174410
2021-03-16 10:03:57 | INFO | train_inner | epoch 005:  13645 / 20258 loss=3.565, nll_loss=1.88, ppl=3.68, wps=27811.2, ups=0.55, wpb=50747.6, bsz=3034.7, num_updates=94600, lr=0.000185066, gnorm=0.267, loss_scale=8, train_wall=179, wall=174593
2021-03-16 10:07:01 | INFO | train_inner | epoch 005:  13745 / 20258 loss=3.558, nll_loss=1.873, ppl=3.66, wps=27945, ups=0.55, wpb=51175.8, bsz=3003.4, num_updates=94700, lr=0.000184968, gnorm=0.268, loss_scale=8, train_wall=180, wall=174776
2021-03-16 10:10:04 | INFO | train_inner | epoch 005:  13845 / 20258 loss=3.555, nll_loss=1.869, ppl=3.65, wps=27869.1, ups=0.55, wpb=51051.4, bsz=3119.2, num_updates=94800, lr=0.000184871, gnorm=0.266, loss_scale=8, train_wall=180, wall=174959
2021-03-16 10:13:06 | INFO | train_inner | epoch 005:  13945 / 20258 loss=3.571, nll_loss=1.887, ppl=3.7, wps=27982.8, ups=0.55, wpb=51014.8, bsz=3018.2, num_updates=94900, lr=0.000184773, gnorm=0.272, loss_scale=8, train_wall=179, wall=175142
2021-03-16 10:16:08 | INFO | train_inner | epoch 005:  14045 / 20258 loss=3.551, nll_loss=1.865, ppl=3.64, wps=27936.3, ups=0.55, wpb=50897, bsz=3132.7, num_updates=95000, lr=0.000184676, gnorm=0.272, loss_scale=8, train_wall=179, wall=175324
2021-03-16 10:16:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 10:16:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:27 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.962 | nll_loss 2.247 | ppl 4.75 | bleu 29.17 | wps 4350 | wpb 2432 | bsz 90.4 | num_updates 95000 | best_loss 3.962
2021-03-16 10:16:27 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 10:16:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:16:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 10:16:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 10:16:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 10:17:19 | INFO | valid1 | epoch 005 | valid on 'valid1' subset | loss 3.957 | nll_loss 2.265 | ppl 4.81 | bleu 27.11 | wps 4231 | wpb 2359.4 | bsz 106.4 | num_updates 95000 | best_loss 3.957
2021-03-16 10:17:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 10:17:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_5_95000.pt (epoch 5 @ 95000 updates, score 3.962) (writing took 8.752208895981312 seconds)
2021-03-16 10:20:30 | INFO | train_inner | epoch 005:  14145 / 20258 loss=3.557, nll_loss=1.871, ppl=3.66, wps=19443.9, ups=0.38, wpb=50956.2, bsz=3010.2, num_updates=95100, lr=0.000184579, gnorm=0.282, loss_scale=8, train_wall=179, wall=175586
2021-03-16 10:23:33 | INFO | train_inner | epoch 005:  14245 / 20258 loss=3.567, nll_loss=1.883, ppl=3.69, wps=27800.9, ups=0.55, wpb=50711.3, bsz=2985.9, num_updates=95200, lr=0.000184482, gnorm=0.268, loss_scale=8, train_wall=179, wall=175768
2021-03-16 10:26:36 | INFO | train_inner | epoch 005:  14345 / 20258 loss=3.571, nll_loss=1.887, ppl=3.7, wps=27970.9, ups=0.55, wpb=51240.2, bsz=3072, num_updates=95300, lr=0.000184385, gnorm=0.267, loss_scale=16, train_wall=180, wall=175951
2021-03-16 10:29:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 10:29:40 | INFO | train_inner | epoch 005:  14446 / 20258 loss=3.562, nll_loss=1.877, ppl=3.67, wps=27606.1, ups=0.54, wpb=50872.9, bsz=3086.2, num_updates=95400, lr=0.000184289, gnorm=0.27, loss_scale=8, train_wall=181, wall=176136
2021-03-16 10:32:42 | INFO | train_inner | epoch 005:  14546 / 20258 loss=3.568, nll_loss=1.884, ppl=3.69, wps=27917.7, ups=0.55, wpb=50863.5, bsz=2953.9, num_updates=95500, lr=0.000184192, gnorm=0.269, loss_scale=8, train_wall=179, wall=176318
2021-03-16 10:35:45 | INFO | train_inner | epoch 005:  14646 / 20258 loss=3.565, nll_loss=1.88, ppl=3.68, wps=27904.8, ups=0.55, wpb=51005.3, bsz=3017.9, num_updates=95600, lr=0.000184096, gnorm=0.27, loss_scale=8, train_wall=179, wall=176501
2021-03-16 10:38:48 | INFO | train_inner | epoch 005:  14746 / 20258 loss=3.551, nll_loss=1.864, ppl=3.64, wps=27917.5, ups=0.55, wpb=50918.4, bsz=2966.5, num_updates=95700, lr=0.000183999, gnorm=0.264, loss_scale=8, train_wall=179, wall=176683
2021-03-16 10:41:50 | INFO | train_inner | epoch 005:  14846 / 20258 loss=3.559, nll_loss=1.874, ppl=3.67, wps=27889.9, ups=0.55, wpb=50912.6, bsz=3147, num_updates=95800, lr=0.000183903, gnorm=0.27, loss_scale=8, train_wall=179, wall=176866
2021-03-16 10:44:52 | INFO | train_inner | epoch 005:  14946 / 20258 loss=3.558, nll_loss=1.873, ppl=3.66, wps=27892.8, ups=0.55, wpb=50760.9, bsz=2963.1, num_updates=95900, lr=0.000183807, gnorm=0.272, loss_scale=8, train_wall=179, wall=177048
2021-03-16 10:47:55 | INFO | train_inner | epoch 005:  15046 / 20258 loss=3.549, nll_loss=1.862, ppl=3.64, wps=27939.9, ups=0.55, wpb=51148.2, bsz=2904.2, num_updates=96000, lr=0.000183712, gnorm=0.273, loss_scale=8, train_wall=180, wall=177231
2021-03-16 10:48:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 10:51:01 | INFO | train_inner | epoch 005:  15147 / 20258 loss=3.538, nll_loss=1.85, ppl=3.61, wps=27624.5, ups=0.54, wpb=51234.6, bsz=2937.3, num_updates=96100, lr=0.000183616, gnorm=0.274, loss_scale=4, train_wall=182, wall=177416
2021-03-16 10:54:03 | INFO | train_inner | epoch 005:  15247 / 20258 loss=3.549, nll_loss=1.864, ppl=3.64, wps=27901.2, ups=0.55, wpb=50953, bsz=3120.3, num_updates=96200, lr=0.000183521, gnorm=0.273, loss_scale=4, train_wall=180, wall=177599
2021-03-16 10:57:06 | INFO | train_inner | epoch 005:  15347 / 20258 loss=3.547, nll_loss=1.86, ppl=3.63, wps=27960.6, ups=0.55, wpb=51093.1, bsz=2939.7, num_updates=96300, lr=0.000183425, gnorm=0.268, loss_scale=4, train_wall=180, wall=177782
2021-03-16 11:00:08 | INFO | train_inner | epoch 005:  15447 / 20258 loss=3.556, nll_loss=1.871, ppl=3.66, wps=27823.4, ups=0.55, wpb=50720.1, bsz=2986.6, num_updates=96400, lr=0.00018333, gnorm=0.27, loss_scale=4, train_wall=179, wall=177964
2021-03-16 11:03:10 | INFO | train_inner | epoch 005:  15547 / 20258 loss=3.57, nll_loss=1.887, ppl=3.7, wps=27884.8, ups=0.55, wpb=50720.4, bsz=3094.6, num_updates=96500, lr=0.000183235, gnorm=0.267, loss_scale=4, train_wall=179, wall=178146
2021-03-16 11:06:12 | INFO | train_inner | epoch 005:  15647 / 20258 loss=3.567, nll_loss=1.882, ppl=3.69, wps=27945.6, ups=0.55, wpb=50794.9, bsz=2912.5, num_updates=96600, lr=0.00018314, gnorm=0.274, loss_scale=4, train_wall=179, wall=178327
2021-03-16 11:09:14 | INFO | train_inner | epoch 005:  15747 / 20258 loss=3.554, nll_loss=1.868, ppl=3.65, wps=27785.7, ups=0.55, wpb=50579.6, bsz=3003.1, num_updates=96700, lr=0.000183046, gnorm=0.269, loss_scale=4, train_wall=179, wall=178510
2021-03-16 11:12:16 | INFO | train_inner | epoch 005:  15847 / 20258 loss=3.559, nll_loss=1.874, ppl=3.66, wps=27861.6, ups=0.55, wpb=50769.2, bsz=2986, num_updates=96800, lr=0.000182951, gnorm=0.269, loss_scale=4, train_wall=179, wall=178692
2021-03-16 11:15:19 | INFO | train_inner | epoch 005:  15947 / 20258 loss=3.557, nll_loss=1.872, ppl=3.66, wps=27887.5, ups=0.55, wpb=50964.4, bsz=3086.1, num_updates=96900, lr=0.000182857, gnorm=0.269, loss_scale=4, train_wall=180, wall=178874
2021-03-16 11:18:22 | INFO | train_inner | epoch 005:  16047 / 20258 loss=3.539, nll_loss=1.852, ppl=3.61, wps=27847.3, ups=0.55, wpb=50890.7, bsz=3150.6, num_updates=97000, lr=0.000182762, gnorm=0.267, loss_scale=4, train_wall=179, wall=179057
2021-03-16 11:21:24 | INFO | train_inner | epoch 005:  16147 / 20258 loss=3.544, nll_loss=1.858, ppl=3.62, wps=27907.8, ups=0.55, wpb=50853.3, bsz=2958.6, num_updates=97100, lr=0.000182668, gnorm=0.268, loss_scale=8, train_wall=179, wall=179239
2021-03-16 11:24:26 | INFO | train_inner | epoch 005:  16247 / 20258 loss=3.562, nll_loss=1.877, ppl=3.67, wps=27875.4, ups=0.55, wpb=50742.2, bsz=2972.8, num_updates=97200, lr=0.000182574, gnorm=0.272, loss_scale=8, train_wall=179, wall=179421
2021-03-16 11:27:28 | INFO | train_inner | epoch 005:  16347 / 20258 loss=3.577, nll_loss=1.895, ppl=3.72, wps=27917.5, ups=0.55, wpb=50946.4, bsz=3135.3, num_updates=97300, lr=0.00018248, gnorm=0.27, loss_scale=8, train_wall=179, wall=179604
2021-03-16 11:30:31 | INFO | train_inner | epoch 005:  16447 / 20258 loss=3.564, nll_loss=1.88, ppl=3.68, wps=27919.8, ups=0.55, wpb=50992.9, bsz=3061.9, num_updates=97400, lr=0.000182387, gnorm=0.273, loss_scale=8, train_wall=180, wall=179787
2021-03-16 11:33:34 | INFO | train_inner | epoch 005:  16547 / 20258 loss=3.535, nll_loss=1.847, ppl=3.6, wps=27828.3, ups=0.55, wpb=50836.4, bsz=3067.7, num_updates=97500, lr=0.000182293, gnorm=0.264, loss_scale=8, train_wall=180, wall=179969
2021-03-16 11:36:37 | INFO | train_inner | epoch 005:  16647 / 20258 loss=3.544, nll_loss=1.858, ppl=3.62, wps=27804.8, ups=0.55, wpb=51015.9, bsz=3009.3, num_updates=97600, lr=0.0001822, gnorm=0.267, loss_scale=8, train_wall=180, wall=180153
2021-03-16 11:39:40 | INFO | train_inner | epoch 005:  16747 / 20258 loss=3.541, nll_loss=1.854, ppl=3.61, wps=27860.9, ups=0.55, wpb=50992.1, bsz=2923.8, num_updates=97700, lr=0.000182106, gnorm=0.271, loss_scale=8, train_wall=180, wall=180336
2021-03-16 11:42:43 | INFO | train_inner | epoch 005:  16847 / 20258 loss=3.549, nll_loss=1.863, ppl=3.64, wps=27848.8, ups=0.55, wpb=50961.2, bsz=3080.3, num_updates=97800, lr=0.000182013, gnorm=0.266, loss_scale=8, train_wall=180, wall=180519
2021-03-16 11:45:46 | INFO | train_inner | epoch 005:  16947 / 20258 loss=3.543, nll_loss=1.856, ppl=3.62, wps=27931.9, ups=0.55, wpb=51016.1, bsz=3005.2, num_updates=97900, lr=0.00018192, gnorm=0.273, loss_scale=8, train_wall=179, wall=180701
2021-03-16 11:48:48 | INFO | train_inner | epoch 005:  17047 / 20258 loss=3.56, nll_loss=1.875, ppl=3.67, wps=27988.8, ups=0.55, wpb=51007.7, bsz=2956.6, num_updates=98000, lr=0.000181827, gnorm=0.267, loss_scale=8, train_wall=179, wall=180884
2021-03-16 11:51:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 11:51:52 | INFO | train_inner | epoch 005:  17148 / 20258 loss=3.566, nll_loss=1.882, ppl=3.69, wps=27685.9, ups=0.54, wpb=50868.3, bsz=2965.4, num_updates=98100, lr=0.000181735, gnorm=0.273, loss_scale=8, train_wall=181, wall=181067
2021-03-16 11:54:54 | INFO | train_inner | epoch 005:  17248 / 20258 loss=3.555, nll_loss=1.869, ppl=3.65, wps=27860.1, ups=0.55, wpb=50774.3, bsz=2930.2, num_updates=98200, lr=0.000181642, gnorm=0.267, loss_scale=8, train_wall=179, wall=181250
2021-03-16 11:57:56 | INFO | train_inner | epoch 005:  17348 / 20258 loss=3.559, nll_loss=1.874, ppl=3.67, wps=27901, ups=0.55, wpb=50820.7, bsz=3006, num_updates=98300, lr=0.00018155, gnorm=0.269, loss_scale=8, train_wall=179, wall=181432
2021-03-16 12:00:59 | INFO | train_inner | epoch 005:  17448 / 20258 loss=3.56, nll_loss=1.875, ppl=3.67, wps=27923.3, ups=0.55, wpb=50880.1, bsz=2968.9, num_updates=98400, lr=0.000181458, gnorm=0.275, loss_scale=8, train_wall=179, wall=181614
2021-03-16 12:04:01 | INFO | train_inner | epoch 005:  17548 / 20258 loss=3.564, nll_loss=1.88, ppl=3.68, wps=27859.6, ups=0.55, wpb=50844.2, bsz=2968.3, num_updates=98500, lr=0.000181365, gnorm=0.27, loss_scale=8, train_wall=179, wall=181797
2021-03-16 12:07:04 | INFO | train_inner | epoch 005:  17648 / 20258 loss=3.547, nll_loss=1.861, ppl=3.63, wps=27858.1, ups=0.55, wpb=50868.5, bsz=3037, num_updates=98600, lr=0.000181273, gnorm=0.268, loss_scale=8, train_wall=179, wall=181979
2021-03-16 12:10:06 | INFO | train_inner | epoch 005:  17748 / 20258 loss=3.565, nll_loss=1.881, ppl=3.68, wps=27900.1, ups=0.55, wpb=50777.8, bsz=2988.7, num_updates=98700, lr=0.000181182, gnorm=0.268, loss_scale=8, train_wall=179, wall=182161
2021-03-16 12:13:07 | INFO | train_inner | epoch 005:  17848 / 20258 loss=3.554, nll_loss=1.869, ppl=3.65, wps=27800.9, ups=0.55, wpb=50534.5, bsz=3038.9, num_updates=98800, lr=0.00018109, gnorm=0.274, loss_scale=8, train_wall=179, wall=182343
2021-03-16 12:16:10 | INFO | train_inner | epoch 005:  17948 / 20258 loss=3.545, nll_loss=1.859, ppl=3.63, wps=27852.9, ups=0.55, wpb=50933.7, bsz=2976.2, num_updates=98900, lr=0.000180998, gnorm=0.271, loss_scale=8, train_wall=180, wall=182526
2021-03-16 12:19:12 | INFO | train_inner | epoch 005:  18048 / 20258 loss=3.577, nll_loss=1.894, ppl=3.72, wps=27869.1, ups=0.55, wpb=50703.1, bsz=3018.9, num_updates=99000, lr=0.000180907, gnorm=0.271, loss_scale=8, train_wall=179, wall=182708
2021-03-16 12:22:15 | INFO | train_inner | epoch 005:  18148 / 20258 loss=3.547, nll_loss=1.861, ppl=3.63, wps=27868.5, ups=0.55, wpb=50982.2, bsz=3154.4, num_updates=99100, lr=0.000180816, gnorm=0.264, loss_scale=8, train_wall=179, wall=182891
2021-03-16 12:25:18 | INFO | train_inner | epoch 005:  18248 / 20258 loss=3.548, nll_loss=1.862, ppl=3.64, wps=27983.6, ups=0.55, wpb=51072.3, bsz=3147.6, num_updates=99200, lr=0.000180724, gnorm=0.268, loss_scale=16, train_wall=180, wall=183073
2021-03-16 12:28:20 | INFO | train_inner | epoch 005:  18348 / 20258 loss=3.549, nll_loss=1.863, ppl=3.64, wps=27871, ups=0.55, wpb=50784.7, bsz=3002.4, num_updates=99300, lr=0.000180633, gnorm=0.268, loss_scale=16, train_wall=179, wall=183255
2021-03-16 12:31:22 | INFO | train_inner | epoch 005:  18448 / 20258 loss=3.546, nll_loss=1.86, ppl=3.63, wps=27864.3, ups=0.55, wpb=50780.5, bsz=3040.2, num_updates=99400, lr=0.000180542, gnorm=0.274, loss_scale=16, train_wall=179, wall=183438
2021-03-16 12:33:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 12:34:27 | INFO | train_inner | epoch 005:  18549 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=27494.3, ups=0.54, wpb=50809.8, bsz=3095.9, num_updates=99500, lr=0.000180452, gnorm=0.267, loss_scale=8, train_wall=182, wall=183622
2021-03-16 12:35:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 12:37:31 | INFO | train_inner | epoch 005:  18650 / 20258 loss=3.554, nll_loss=1.868, ppl=3.65, wps=27627, ups=0.54, wpb=50842.8, bsz=3077.9, num_updates=99600, lr=0.000180361, gnorm=0.289, loss_scale=4, train_wall=181, wall=183806
2021-03-16 12:40:33 | INFO | train_inner | epoch 005:  18750 / 20258 loss=3.563, nll_loss=1.879, ppl=3.68, wps=27924.2, ups=0.55, wpb=50798, bsz=2986.3, num_updates=99700, lr=0.000180271, gnorm=0.284, loss_scale=4, train_wall=179, wall=183988
2021-03-16 12:43:35 | INFO | train_inner | epoch 005:  18850 / 20258 loss=3.536, nll_loss=1.848, ppl=3.6, wps=27837, ups=0.55, wpb=50791.1, bsz=3091, num_updates=99800, lr=0.00018018, gnorm=0.27, loss_scale=4, train_wall=179, wall=184171
2021-03-16 12:46:38 | INFO | train_inner | epoch 005:  18950 / 20258 loss=3.549, nll_loss=1.863, ppl=3.64, wps=27914.8, ups=0.55, wpb=51131.4, bsz=2981.1, num_updates=99900, lr=0.00018009, gnorm=0.267, loss_scale=4, train_wall=180, wall=184354
2021-03-16 12:49:41 | INFO | train_inner | epoch 005:  19050 / 20258 loss=3.544, nll_loss=1.857, ppl=3.62, wps=27942.9, ups=0.55, wpb=50933.7, bsz=2929.4, num_updates=100000, lr=0.00018, gnorm=0.267, loss_scale=4, train_wall=179, wall=184536
2021-03-16 12:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 12:49:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:49:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:49:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:49:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:49:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:49:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:49:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:49:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:49:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:49:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:49:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:49:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:49:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:49:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:49:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:49:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:49:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:49:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:49:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:49:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:49:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:49:59 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.953 | nll_loss 2.237 | ppl 4.71 | bleu 29.56 | wps 4347.4 | wpb 2432 | bsz 90.4 | num_updates 100000 | best_loss 3.953
2021-03-16 12:49:59 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 12:50:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 12:50:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 12:50:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 12:50:52 | INFO | valid1 | epoch 005 | valid on 'valid1' subset | loss 3.952 | nll_loss 2.26 | ppl 4.79 | bleu 27.28 | wps 4203.8 | wpb 2359.4 | bsz 106.4 | num_updates 100000 | best_loss 3.952
2021-03-16 12:50:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 12:51:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_5_100000.pt (epoch 5 @ 100000 updates, score 3.953) (writing took 8.648817579029128 seconds)
2021-03-16 12:54:04 | INFO | train_inner | epoch 005:  19150 / 20258 loss=3.557, nll_loss=1.872, ppl=3.66, wps=19341.3, ups=0.38, wpb=50833, bsz=3006, num_updates=100100, lr=0.00017991, gnorm=0.275, loss_scale=4, train_wall=179, wall=184799
2021-03-16 12:57:06 | INFO | train_inner | epoch 005:  19250 / 20258 loss=3.548, nll_loss=1.862, ppl=3.64, wps=27898.2, ups=0.55, wpb=50976.8, bsz=3018.6, num_updates=100200, lr=0.00017982, gnorm=0.274, loss_scale=4, train_wall=180, wall=184982
2021-03-16 13:00:09 | INFO | train_inner | epoch 005:  19350 / 20258 loss=3.556, nll_loss=1.872, ppl=3.66, wps=27749.2, ups=0.55, wpb=50736.5, bsz=3109.5, num_updates=100300, lr=0.000179731, gnorm=0.27, loss_scale=4, train_wall=179, wall=185165
2021-03-16 13:03:11 | INFO | train_inner | epoch 005:  19450 / 20258 loss=3.563, nll_loss=1.879, ppl=3.68, wps=27952.6, ups=0.55, wpb=50927.2, bsz=3018.5, num_updates=100400, lr=0.000179641, gnorm=0.268, loss_scale=4, train_wall=179, wall=185347
2021-03-16 13:06:16 | INFO | train_inner | epoch 005:  19550 / 20258 loss=3.553, nll_loss=1.867, ppl=3.65, wps=27706.1, ups=0.54, wpb=51047.3, bsz=2889.4, num_updates=100500, lr=0.000179552, gnorm=0.271, loss_scale=4, train_wall=181, wall=185531
2021-03-16 13:08:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 13:09:21 | INFO | train_inner | epoch 005:  19651 / 20258 loss=3.557, nll_loss=1.873, ppl=3.66, wps=27605.4, ups=0.54, wpb=51089.4, bsz=3173.6, num_updates=100600, lr=0.000179462, gnorm=0.273, loss_scale=4, train_wall=182, wall=185716
2021-03-16 13:12:25 | INFO | train_inner | epoch 005:  19751 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=27631.3, ups=0.54, wpb=50836, bsz=2891.4, num_updates=100700, lr=0.000179373, gnorm=0.272, loss_scale=4, train_wall=181, wall=185900
2021-03-16 13:15:29 | INFO | train_inner | epoch 005:  19851 / 20258 loss=3.548, nll_loss=1.862, ppl=3.64, wps=27652.7, ups=0.54, wpb=50879.7, bsz=3003.6, num_updates=100800, lr=0.000179284, gnorm=0.268, loss_scale=4, train_wall=181, wall=186084
2021-03-16 13:18:32 | INFO | train_inner | epoch 005:  19951 / 20258 loss=3.556, nll_loss=1.871, ppl=3.66, wps=27714.3, ups=0.54, wpb=50929.2, bsz=3003.4, num_updates=100900, lr=0.000179195, gnorm=0.268, loss_scale=4, train_wall=181, wall=186268
2021-03-16 13:21:35 | INFO | train_inner | epoch 005:  20051 / 20258 loss=3.545, nll_loss=1.858, ppl=3.63, wps=27875.7, ups=0.55, wpb=50900.8, bsz=2987.2, num_updates=101000, lr=0.000179107, gnorm=0.265, loss_scale=4, train_wall=180, wall=186451
2021-03-16 13:24:37 | INFO | train_inner | epoch 005:  20151 / 20258 loss=3.565, nll_loss=1.881, ppl=3.68, wps=27874.6, ups=0.55, wpb=50765.8, bsz=3027.4, num_updates=101100, lr=0.000179018, gnorm=0.29, loss_scale=4, train_wall=179, wall=186633
2021-03-16 13:27:39 | INFO | train_inner | epoch 005:  20251 / 20258 loss=3.576, nll_loss=1.893, ppl=3.71, wps=27920.2, ups=0.55, wpb=50741.9, bsz=2934.1, num_updates=101200, lr=0.00017893, gnorm=0.27, loss_scale=4, train_wall=179, wall=186814
2021-03-16 13:27:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 13:27:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:27:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:27:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:27:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:27:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:27:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:27:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:27:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:27:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:27:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:27:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:27:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:27:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:27:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:27:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:27:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:27:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:27:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:27:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:27:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:27:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:10 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.957 | nll_loss 2.242 | ppl 4.73 | bleu 29.18 | wps 4346.9 | wpb 2432 | bsz 90.4 | num_updates 101207 | best_loss 3.953
2021-03-16 13:28:10 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 13:28:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:28:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 13:28:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 13:28:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 13:29:03 | INFO | valid1 | epoch 005 | valid on 'valid1' subset | loss 3.958 | nll_loss 2.265 | ppl 4.81 | bleu 26.99 | wps 4232.7 | wpb 2359.4 | bsz 106.4 | num_updates 101207 | best_loss 3.953
2021-03-16 13:29:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 13:29:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint5.pt (epoch 5 @ 101207 updates, score 3.957) (writing took 4.7076884820126 seconds)
2021-03-16 13:29:08 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-03-16 13:29:08 | INFO | train | epoch 005 | loss 3.56 | nll_loss 1.875 | ppl 3.67 | wps 27572.6 | ups 0.54 | wpb 50906.2 | bsz 3010.1 | num_updates 101207 | lr 0.000178923 | gnorm 0.27 | loss_scale 4 | train_wall 36342 | wall 186903
2021-03-16 13:29:08 | INFO | fairseq.trainer | begin training epoch 6
2021-03-16 13:31:58 | INFO | train_inner | epoch 006:     93 / 20258 loss=3.533, nll_loss=1.844, ppl=3.59, wps=19649, ups=0.39, wpb=50851.1, bsz=3051, num_updates=101300, lr=0.000178841, gnorm=0.279, loss_scale=4, train_wall=180, wall=187073
2021-03-16 13:35:01 | INFO | train_inner | epoch 006:    193 / 20258 loss=3.526, nll_loss=1.837, ppl=3.57, wps=27878, ups=0.55, wpb=51017.5, bsz=3082.8, num_updates=101400, lr=0.000178753, gnorm=0.281, loss_scale=4, train_wall=180, wall=187256
2021-03-16 13:38:04 | INFO | train_inner | epoch 006:    293 / 20258 loss=3.534, nll_loss=1.846, ppl=3.59, wps=27807.4, ups=0.55, wpb=51012.6, bsz=3010.9, num_updates=101500, lr=0.000178665, gnorm=0.274, loss_scale=4, train_wall=180, wall=187440
2021-03-16 13:39:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-16 13:41:10 | INFO | train_inner | epoch 006:    394 / 20258 loss=3.533, nll_loss=1.844, ppl=3.59, wps=27208.3, ups=0.54, wpb=50701.2, bsz=2917.1, num_updates=101600, lr=0.000178577, gnorm=0.266, loss_scale=2, train_wall=183, wall=187626
2021-03-16 13:44:13 | INFO | train_inner | epoch 006:    494 / 20258 loss=3.55, nll_loss=1.864, ppl=3.64, wps=27717.4, ups=0.55, wpb=50679.9, bsz=2912.4, num_updates=101700, lr=0.000178489, gnorm=0.27, loss_scale=2, train_wall=180, wall=187809
2021-03-16 13:47:16 | INFO | train_inner | epoch 006:    594 / 20258 loss=3.55, nll_loss=1.864, ppl=3.64, wps=27798.4, ups=0.55, wpb=50918.9, bsz=3066.4, num_updates=101800, lr=0.000178402, gnorm=0.27, loss_scale=2, train_wall=180, wall=187992
2021-03-16 13:50:18 | INFO | train_inner | epoch 006:    694 / 20258 loss=3.529, nll_loss=1.84, ppl=3.58, wps=27834.7, ups=0.55, wpb=50631.7, bsz=2978.2, num_updates=101900, lr=0.000178314, gnorm=0.266, loss_scale=2, train_wall=179, wall=188174
2021-03-16 13:53:21 | INFO | train_inner | epoch 006:    794 / 20258 loss=3.537, nll_loss=1.85, ppl=3.6, wps=27882.2, ups=0.55, wpb=50842.6, bsz=2999.3, num_updates=102000, lr=0.000178227, gnorm=0.27, loss_scale=2, train_wall=179, wall=188356
2021-03-16 13:56:24 | INFO | train_inner | epoch 006:    894 / 20258 loss=3.543, nll_loss=1.856, ppl=3.62, wps=28008.2, ups=0.55, wpb=51191.7, bsz=3046.9, num_updates=102100, lr=0.000178139, gnorm=0.269, loss_scale=2, train_wall=180, wall=188539
2021-03-16 13:59:27 | INFO | train_inner | epoch 006:    994 / 20258 loss=3.518, nll_loss=1.828, ppl=3.55, wps=27904.2, ups=0.55, wpb=51183.1, bsz=3195.5, num_updates=102200, lr=0.000178052, gnorm=0.267, loss_scale=2, train_wall=180, wall=188722
2021-03-16 14:02:30 | INFO | train_inner | epoch 006:   1094 / 20258 loss=3.525, nll_loss=1.836, ppl=3.57, wps=27934.9, ups=0.55, wpb=51004.6, bsz=3048.6, num_updates=102300, lr=0.000177965, gnorm=0.266, loss_scale=2, train_wall=180, wall=188905
2021-03-16 14:05:32 | INFO | train_inner | epoch 006:   1194 / 20258 loss=3.524, nll_loss=1.834, ppl=3.57, wps=27902.9, ups=0.55, wpb=50900, bsz=3037.7, num_updates=102400, lr=0.000177878, gnorm=0.267, loss_scale=2, train_wall=179, wall=189087
2021-03-16 14:08:35 | INFO | train_inner | epoch 006:   1294 / 20258 loss=3.542, nll_loss=1.855, ppl=3.62, wps=28022.5, ups=0.55, wpb=51166.1, bsz=2987.9, num_updates=102500, lr=0.000177791, gnorm=0.271, loss_scale=2, train_wall=180, wall=189270
2021-03-16 14:11:37 | INFO | train_inner | epoch 006:   1394 / 20258 loss=3.53, nll_loss=1.841, ppl=3.58, wps=27867.3, ups=0.55, wpb=50981.5, bsz=2991.6, num_updates=102600, lr=0.000177705, gnorm=0.268, loss_scale=4, train_wall=180, wall=189453
2021-03-16 14:14:41 | INFO | train_inner | epoch 006:   1494 / 20258 loss=3.55, nll_loss=1.864, ppl=3.64, wps=27805.9, ups=0.55, wpb=50898.2, bsz=2973.2, num_updates=102700, lr=0.000177618, gnorm=0.274, loss_scale=4, train_wall=180, wall=189636
2021-03-16 14:17:43 | INFO | train_inner | epoch 006:   1594 / 20258 loss=3.54, nll_loss=1.853, ppl=3.61, wps=27737.4, ups=0.55, wpb=50642.2, bsz=2988.3, num_updates=102800, lr=0.000177532, gnorm=0.269, loss_scale=4, train_wall=180, wall=189819
2021-03-16 14:20:48 | INFO | train_inner | epoch 006:   1694 / 20258 loss=3.532, nll_loss=1.843, ppl=3.59, wps=27698.8, ups=0.54, wpb=51119.3, bsz=2991.5, num_updates=102900, lr=0.000177445, gnorm=0.269, loss_scale=4, train_wall=181, wall=190003
2021-03-16 14:23:52 | INFO | train_inner | epoch 006:   1794 / 20258 loss=3.529, nll_loss=1.841, ppl=3.58, wps=27647.6, ups=0.54, wpb=50907.1, bsz=3127.2, num_updates=103000, lr=0.000177359, gnorm=0.275, loss_scale=4, train_wall=181, wall=190187
2021-03-16 14:26:55 | INFO | train_inner | epoch 006:   1894 / 20258 loss=3.514, nll_loss=1.823, ppl=3.54, wps=27820.7, ups=0.55, wpb=50983.6, bsz=2979, num_updates=103100, lr=0.000177273, gnorm=0.269, loss_scale=4, train_wall=180, wall=190371
2021-03-16 14:29:57 | INFO | train_inner | epoch 006:   1994 / 20258 loss=3.536, nll_loss=1.848, ppl=3.6, wps=27875.3, ups=0.55, wpb=50765.3, bsz=2898.5, num_updates=103200, lr=0.000177187, gnorm=0.273, loss_scale=4, train_wall=179, wall=190553
2021-03-16 14:32:59 | INFO | train_inner | epoch 006:   2094 / 20258 loss=3.542, nll_loss=1.855, ppl=3.62, wps=27912.9, ups=0.55, wpb=50889.2, bsz=2969.4, num_updates=103300, lr=0.000177102, gnorm=0.267, loss_scale=4, train_wall=179, wall=190735
2021-03-16 14:36:02 | INFO | train_inner | epoch 006:   2194 / 20258 loss=3.545, nll_loss=1.858, ppl=3.62, wps=27927.1, ups=0.55, wpb=50989, bsz=2918.8, num_updates=103400, lr=0.000177016, gnorm=0.274, loss_scale=4, train_wall=180, wall=190918
2021-03-16 14:39:05 | INFO | train_inner | epoch 006:   2294 / 20258 loss=3.543, nll_loss=1.857, ppl=3.62, wps=28011.2, ups=0.55, wpb=51166.5, bsz=3037.4, num_updates=103500, lr=0.00017693, gnorm=0.271, loss_scale=4, train_wall=180, wall=191100
2021-03-16 14:42:07 | INFO | train_inner | epoch 006:   2394 / 20258 loss=3.542, nll_loss=1.854, ppl=3.62, wps=27992.7, ups=0.55, wpb=50974.2, bsz=2932.7, num_updates=103600, lr=0.000176845, gnorm=0.271, loss_scale=8, train_wall=179, wall=191282
2021-03-16 14:45:09 | INFO | train_inner | epoch 006:   2494 / 20258 loss=3.543, nll_loss=1.856, ppl=3.62, wps=27795.2, ups=0.55, wpb=50753.9, bsz=3071.7, num_updates=103700, lr=0.00017676, gnorm=0.269, loss_scale=8, train_wall=180, wall=191465
2021-03-16 14:48:13 | INFO | train_inner | epoch 006:   2594 / 20258 loss=3.538, nll_loss=1.85, ppl=3.6, wps=27950.4, ups=0.55, wpb=51257, bsz=2985.1, num_updates=103800, lr=0.000176674, gnorm=0.268, loss_scale=8, train_wall=180, wall=191648
2021-03-16 14:51:16 | INFO | train_inner | epoch 006:   2694 / 20258 loss=3.54, nll_loss=1.852, ppl=3.61, wps=27898.3, ups=0.55, wpb=50985, bsz=3065.9, num_updates=103900, lr=0.000176589, gnorm=0.273, loss_scale=8, train_wall=180, wall=191831
2021-03-16 14:54:18 | INFO | train_inner | epoch 006:   2794 / 20258 loss=3.534, nll_loss=1.846, ppl=3.6, wps=27919, ups=0.55, wpb=50982.6, bsz=3057.9, num_updates=104000, lr=0.000176505, gnorm=0.274, loss_scale=8, train_wall=180, wall=192014
2021-03-16 14:57:21 | INFO | train_inner | epoch 006:   2894 / 20258 loss=3.547, nll_loss=1.861, ppl=3.63, wps=27786.3, ups=0.55, wpb=50890, bsz=2965, num_updates=104100, lr=0.00017642, gnorm=0.273, loss_scale=8, train_wall=180, wall=192197
2021-03-16 15:00:24 | INFO | train_inner | epoch 006:   2994 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=27785.2, ups=0.55, wpb=50772.7, bsz=2922.1, num_updates=104200, lr=0.000176335, gnorm=0.271, loss_scale=8, train_wall=180, wall=192380
2021-03-16 15:02:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 15:03:28 | INFO | train_inner | epoch 006:   3095 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=27558.3, ups=0.54, wpb=50703, bsz=2979, num_updates=104300, lr=0.00017625, gnorm=0.274, loss_scale=4, train_wall=181, wall=192564
2021-03-16 15:06:31 | INFO | train_inner | epoch 006:   3195 / 20258 loss=3.521, nll_loss=1.832, ppl=3.56, wps=27835, ups=0.55, wpb=50962.6, bsz=3030.8, num_updates=104400, lr=0.000176166, gnorm=0.271, loss_scale=4, train_wall=180, wall=192747
2021-03-16 15:09:34 | INFO | train_inner | epoch 006:   3295 / 20258 loss=3.535, nll_loss=1.847, ppl=3.6, wps=27822.8, ups=0.55, wpb=50827.2, bsz=3044.2, num_updates=104500, lr=0.000176082, gnorm=0.271, loss_scale=4, train_wall=180, wall=192929
2021-03-16 15:12:36 | INFO | train_inner | epoch 006:   3395 / 20258 loss=3.541, nll_loss=1.854, ppl=3.62, wps=28002.4, ups=0.55, wpb=51020.8, bsz=3022.1, num_updates=104600, lr=0.000175998, gnorm=0.268, loss_scale=4, train_wall=179, wall=193112
2021-03-16 15:15:38 | INFO | train_inner | epoch 006:   3495 / 20258 loss=3.545, nll_loss=1.858, ppl=3.63, wps=27890.8, ups=0.55, wpb=50842.6, bsz=2998, num_updates=104700, lr=0.000175913, gnorm=0.269, loss_scale=4, train_wall=179, wall=193294
2021-03-16 15:18:41 | INFO | train_inner | epoch 006:   3595 / 20258 loss=3.54, nll_loss=1.853, ppl=3.61, wps=27878.8, ups=0.55, wpb=50841.3, bsz=2960.4, num_updates=104800, lr=0.00017583, gnorm=0.27, loss_scale=4, train_wall=179, wall=193476
2021-03-16 15:21:43 | INFO | train_inner | epoch 006:   3695 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27875.6, ups=0.55, wpb=50936.2, bsz=3101.4, num_updates=104900, lr=0.000175746, gnorm=0.267, loss_scale=4, train_wall=180, wall=193659
2021-03-16 15:24:46 | INFO | train_inner | epoch 006:   3795 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=27892.3, ups=0.55, wpb=50794.9, bsz=3082.6, num_updates=105000, lr=0.000175662, gnorm=0.27, loss_scale=4, train_wall=179, wall=193841
2021-03-16 15:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 15:24:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:24:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:24:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:24:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:24:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:24:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:24:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:24:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:24:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:24:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:24:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:24:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:24:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:24:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:24:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:24:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:24:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:24:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:24:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:24:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:24:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:04 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.949 | nll_loss 2.234 | ppl 4.7 | bleu 29.36 | wps 4383 | wpb 2432 | bsz 90.4 | num_updates 105000 | best_loss 3.949
2021-03-16 15:25:04 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 15:25:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 15:25:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 15:25:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 15:25:57 | INFO | valid1 | epoch 006 | valid on 'valid1' subset | loss 3.943 | nll_loss 2.251 | ppl 4.76 | bleu 27.22 | wps 4189.7 | wpb 2359.4 | bsz 106.4 | num_updates 105000 | best_loss 3.943
2021-03-16 15:25:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 15:26:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_6_105000.pt (epoch 6 @ 105000 updates, score 3.949) (writing took 6.603447085013613 seconds)
2021-03-16 15:29:06 | INFO | train_inner | epoch 006:   3895 / 20258 loss=3.539, nll_loss=1.851, ppl=3.61, wps=19521.5, ups=0.38, wpb=50845.2, bsz=2993.4, num_updates=105100, lr=0.000175578, gnorm=0.264, loss_scale=4, train_wall=179, wall=194102
2021-03-16 15:32:09 | INFO | train_inner | epoch 006:   3995 / 20258 loss=3.548, nll_loss=1.861, ppl=3.63, wps=27917.8, ups=0.55, wpb=50992.8, bsz=3001.7, num_updates=105200, lr=0.000175495, gnorm=0.269, loss_scale=4, train_wall=180, wall=194284
2021-03-16 15:35:13 | INFO | train_inner | epoch 006:   4095 / 20258 loss=3.526, nll_loss=1.837, ppl=3.57, wps=27724.5, ups=0.54, wpb=51044.7, bsz=3179, num_updates=105300, lr=0.000175412, gnorm=0.266, loss_scale=8, train_wall=181, wall=194468
2021-03-16 15:38:18 | INFO | train_inner | epoch 006:   4195 / 20258 loss=3.531, nll_loss=1.843, ppl=3.59, wps=27513.6, ups=0.54, wpb=50895.2, bsz=3012.1, num_updates=105400, lr=0.000175328, gnorm=0.275, loss_scale=8, train_wall=182, wall=194653
2021-03-16 15:41:20 | INFO | train_inner | epoch 006:   4295 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=27874.8, ups=0.55, wpb=50860, bsz=3060.1, num_updates=105500, lr=0.000175245, gnorm=0.274, loss_scale=8, train_wall=180, wall=194836
2021-03-16 15:44:22 | INFO | train_inner | epoch 006:   4395 / 20258 loss=3.555, nll_loss=1.869, ppl=3.65, wps=27925.4, ups=0.55, wpb=50788.8, bsz=2912.4, num_updates=105600, lr=0.000175162, gnorm=0.27, loss_scale=8, train_wall=179, wall=195018
2021-03-16 15:47:25 | INFO | train_inner | epoch 006:   4495 / 20258 loss=3.527, nll_loss=1.838, ppl=3.57, wps=27963.1, ups=0.55, wpb=51252.8, bsz=3010.7, num_updates=105700, lr=0.000175079, gnorm=0.268, loss_scale=8, train_wall=180, wall=195201
2021-03-16 15:50:29 | INFO | train_inner | epoch 006:   4595 / 20258 loss=3.534, nll_loss=1.846, ppl=3.59, wps=27848.4, ups=0.55, wpb=51038.6, bsz=2922.8, num_updates=105800, lr=0.000174997, gnorm=0.279, loss_scale=8, train_wall=180, wall=195384
2021-03-16 15:53:32 | INFO | train_inner | epoch 006:   4695 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=27745.8, ups=0.55, wpb=50792.5, bsz=3094.5, num_updates=105900, lr=0.000174914, gnorm=0.276, loss_scale=8, train_wall=180, wall=195567
2021-03-16 15:56:35 | INFO | train_inner | epoch 006:   4795 / 20258 loss=3.542, nll_loss=1.855, ppl=3.62, wps=27876.3, ups=0.55, wpb=50967.5, bsz=3010, num_updates=106000, lr=0.000174831, gnorm=0.281, loss_scale=8, train_wall=179, wall=195750
2021-03-16 15:59:37 | INFO | train_inner | epoch 006:   4895 / 20258 loss=3.542, nll_loss=1.855, ppl=3.62, wps=27831.7, ups=0.55, wpb=50674, bsz=2981.9, num_updates=106100, lr=0.000174749, gnorm=0.274, loss_scale=8, train_wall=179, wall=195932
2021-03-16 16:02:39 | INFO | train_inner | epoch 006:   4995 / 20258 loss=3.544, nll_loss=1.858, ppl=3.63, wps=27846.6, ups=0.55, wpb=50892.3, bsz=3068, num_updates=106200, lr=0.000174667, gnorm=0.272, loss_scale=8, train_wall=180, wall=196115
2021-03-16 16:05:42 | INFO | train_inner | epoch 006:   5095 / 20258 loss=3.537, nll_loss=1.85, ppl=3.6, wps=27802.8, ups=0.55, wpb=50843.4, bsz=3122.8, num_updates=106300, lr=0.000174585, gnorm=0.272, loss_scale=8, train_wall=179, wall=196298
2021-03-16 16:08:45 | INFO | train_inner | epoch 006:   5195 / 20258 loss=3.539, nll_loss=1.852, ppl=3.61, wps=27898.5, ups=0.55, wpb=50935.2, bsz=2969.9, num_updates=106400, lr=0.000174503, gnorm=0.27, loss_scale=16, train_wall=180, wall=196480
2021-03-16 16:09:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 16:11:49 | INFO | train_inner | epoch 006:   5296 / 20258 loss=3.536, nll_loss=1.848, ppl=3.6, wps=27685.4, ups=0.54, wpb=50967.9, bsz=2932.1, num_updates=106500, lr=0.000174421, gnorm=0.274, loss_scale=8, train_wall=181, wall=196664
2021-03-16 16:14:51 | INFO | train_inner | epoch 006:   5396 / 20258 loss=3.537, nll_loss=1.849, ppl=3.6, wps=27884.5, ups=0.55, wpb=50746.8, bsz=2944.2, num_updates=106600, lr=0.000174339, gnorm=0.274, loss_scale=8, train_wall=179, wall=196846
2021-03-16 16:17:55 | INFO | train_inner | epoch 006:   5496 / 20258 loss=3.532, nll_loss=1.845, ppl=3.59, wps=27711.7, ups=0.54, wpb=50937.8, bsz=3123, num_updates=106700, lr=0.000174257, gnorm=0.272, loss_scale=8, train_wall=181, wall=197030
2021-03-16 16:21:00 | INFO | train_inner | epoch 006:   5596 / 20258 loss=3.532, nll_loss=1.844, ppl=3.59, wps=27473.2, ups=0.54, wpb=50867.1, bsz=3023.8, num_updates=106800, lr=0.000174175, gnorm=0.275, loss_scale=8, train_wall=182, wall=197215
2021-03-16 16:24:05 | INFO | train_inner | epoch 006:   5696 / 20258 loss=3.524, nll_loss=1.835, ppl=3.57, wps=27584.1, ups=0.54, wpb=51022.3, bsz=2846.6, num_updates=106900, lr=0.000174094, gnorm=0.267, loss_scale=8, train_wall=182, wall=197400
2021-03-16 16:27:09 | INFO | train_inner | epoch 006:   5796 / 20258 loss=3.545, nll_loss=1.859, ppl=3.63, wps=27758.2, ups=0.54, wpb=51212.1, bsz=2887.8, num_updates=107000, lr=0.000174013, gnorm=0.274, loss_scale=8, train_wall=182, wall=197585
2021-03-16 16:30:14 | INFO | train_inner | epoch 006:   5896 / 20258 loss=3.545, nll_loss=1.858, ppl=3.63, wps=27590.6, ups=0.54, wpb=50877.3, bsz=2957.8, num_updates=107100, lr=0.000173931, gnorm=0.272, loss_scale=8, train_wall=181, wall=197769
2021-03-16 16:33:18 | INFO | train_inner | epoch 006:   5996 / 20258 loss=3.529, nll_loss=1.841, ppl=3.58, wps=27749.5, ups=0.54, wpb=51112.5, bsz=2974.8, num_updates=107200, lr=0.00017385, gnorm=0.268, loss_scale=8, train_wall=181, wall=197953
2021-03-16 16:36:22 | INFO | train_inner | epoch 006:   6096 / 20258 loss=3.536, nll_loss=1.849, ppl=3.6, wps=27637.2, ups=0.54, wpb=50740.2, bsz=3007.6, num_updates=107300, lr=0.000173769, gnorm=0.27, loss_scale=8, train_wall=181, wall=198137
2021-03-16 16:39:24 | INFO | train_inner | epoch 006:   6196 / 20258 loss=3.521, nll_loss=1.832, ppl=3.56, wps=27759.8, ups=0.55, wpb=50609.1, bsz=3127.7, num_updates=107400, lr=0.000173688, gnorm=0.271, loss_scale=8, train_wall=179, wall=198319
2021-03-16 16:42:26 | INFO | train_inner | epoch 006:   6296 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=27890.1, ups=0.55, wpb=50875, bsz=2904.8, num_updates=107500, lr=0.000173607, gnorm=0.267, loss_scale=16, train_wall=179, wall=198502
2021-03-16 16:45:29 | INFO | train_inner | epoch 006:   6396 / 20258 loss=3.53, nll_loss=1.842, ppl=3.58, wps=27839.1, ups=0.55, wpb=50809.1, bsz=2987.7, num_updates=107600, lr=0.000173527, gnorm=0.269, loss_scale=16, train_wall=180, wall=198684
2021-03-16 16:46:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 16:48:33 | INFO | train_inner | epoch 006:   6497 / 20258 loss=3.554, nll_loss=1.869, ppl=3.65, wps=27674.5, ups=0.54, wpb=50860.4, bsz=2981.8, num_updates=107700, lr=0.000173446, gnorm=0.271, loss_scale=8, train_wall=181, wall=198868
2021-03-16 16:51:59 | INFO | train_inner | epoch 006:   6597 / 20258 loss=3.539, nll_loss=1.852, ppl=3.61, wps=24769.1, ups=0.49, wpb=51043.5, bsz=3011.3, num_updates=107800, lr=0.000173366, gnorm=0.271, loss_scale=8, train_wall=203, wall=199074
2021-03-16 16:56:18 | INFO | train_inner | epoch 006:   6697 / 20258 loss=3.549, nll_loss=1.863, ppl=3.64, wps=19661, ups=0.39, wpb=50908.2, bsz=3013.7, num_updates=107900, lr=0.000173285, gnorm=0.265, loss_scale=8, train_wall=256, wall=199333
2021-03-16 17:01:27 | INFO | train_inner | epoch 006:   6797 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=16529.5, ups=0.32, wpb=51067.5, bsz=3017, num_updates=108000, lr=0.000173205, gnorm=0.271, loss_scale=8, train_wall=305, wall=199642
2021-03-16 17:06:35 | INFO | train_inner | epoch 006:   6897 / 20258 loss=3.545, nll_loss=1.859, ppl=3.63, wps=16460.2, ups=0.32, wpb=50775.1, bsz=2991.4, num_updates=108100, lr=0.000173125, gnorm=0.273, loss_scale=8, train_wall=306, wall=199951
2021-03-16 17:11:43 | INFO | train_inner | epoch 006:   6997 / 20258 loss=3.54, nll_loss=1.854, ppl=3.61, wps=16527.5, ups=0.32, wpb=50946.2, bsz=3036.5, num_updates=108200, lr=0.000173045, gnorm=0.271, loss_scale=8, train_wall=305, wall=200259
2021-03-16 17:15:11 | INFO | train_inner | epoch 006:   7097 / 20258 loss=3.551, nll_loss=1.865, ppl=3.64, wps=24326.5, ups=0.48, wpb=50657.1, bsz=2927.5, num_updates=108300, lr=0.000172965, gnorm=0.272, loss_scale=8, train_wall=205, wall=200467
2021-03-16 17:18:16 | INFO | train_inner | epoch 006:   7197 / 20258 loss=3.549, nll_loss=1.863, ppl=3.64, wps=27650.9, ups=0.54, wpb=50923.9, bsz=2989.4, num_updates=108400, lr=0.000172885, gnorm=0.272, loss_scale=8, train_wall=181, wall=200651
2021-03-16 17:21:18 | INFO | train_inner | epoch 006:   7297 / 20258 loss=3.531, nll_loss=1.843, ppl=3.59, wps=27850, ups=0.55, wpb=50849.4, bsz=3088.6, num_updates=108500, lr=0.000172806, gnorm=0.27, loss_scale=8, train_wall=179, wall=200834
2021-03-16 17:24:21 | INFO | train_inner | epoch 006:   7397 / 20258 loss=3.554, nll_loss=1.869, ppl=3.65, wps=27916.5, ups=0.55, wpb=50925, bsz=3071.1, num_updates=108600, lr=0.000172726, gnorm=0.271, loss_scale=8, train_wall=179, wall=201016
2021-03-16 17:28:03 | INFO | train_inner | epoch 006:   7497 / 20258 loss=3.526, nll_loss=1.838, ppl=3.57, wps=22967.9, ups=0.45, wpb=51130, bsz=3056.2, num_updates=108700, lr=0.000172646, gnorm=0.266, loss_scale=16, train_wall=220, wall=201239
2021-03-16 17:33:12 | INFO | train_inner | epoch 006:   7597 / 20258 loss=3.549, nll_loss=1.864, ppl=3.64, wps=16496.2, ups=0.32, wpb=50915.2, bsz=2958.4, num_updates=108800, lr=0.000172567, gnorm=0.275, loss_scale=16, train_wall=305, wall=201547
2021-03-16 17:38:20 | INFO | train_inner | epoch 006:   7697 / 20258 loss=3.531, nll_loss=1.842, ppl=3.59, wps=16576.7, ups=0.33, wpb=50988.2, bsz=2908.6, num_updates=108900, lr=0.000172488, gnorm=0.27, loss_scale=16, train_wall=305, wall=201855
2021-03-16 17:43:27 | INFO | train_inner | epoch 006:   7797 / 20258 loss=3.544, nll_loss=1.858, ppl=3.62, wps=16505, ups=0.33, wpb=50774.3, bsz=3098.2, num_updates=109000, lr=0.000172409, gnorm=0.275, loss_scale=16, train_wall=304, wall=202163
2021-03-16 17:46:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 17:47:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 17:47:36 | INFO | train_inner | epoch 006:   7899 / 20258 loss=3.523, nll_loss=1.834, ppl=3.57, wps=20341.8, ups=0.4, wpb=50647.6, bsz=3164.3, num_updates=109100, lr=0.00017233, gnorm=0.273, loss_scale=4, train_wall=246, wall=202412
2021-03-16 17:50:39 | INFO | train_inner | epoch 006:   7999 / 20258 loss=3.54, nll_loss=1.853, ppl=3.61, wps=27742.8, ups=0.55, wpb=50795.4, bsz=2929.5, num_updates=109200, lr=0.000172251, gnorm=0.276, loss_scale=4, train_wall=180, wall=202595
2021-03-16 17:53:42 | INFO | train_inner | epoch 006:   8099 / 20258 loss=3.544, nll_loss=1.857, ppl=3.62, wps=27941.9, ups=0.55, wpb=51028.7, bsz=2968.5, num_updates=109300, lr=0.000172172, gnorm=0.288, loss_scale=4, train_wall=179, wall=202777
2021-03-16 17:56:46 | INFO | train_inner | epoch 006:   8199 / 20258 loss=3.53, nll_loss=1.842, ppl=3.58, wps=27673.5, ups=0.54, wpb=50893.1, bsz=3025.2, num_updates=109400, lr=0.000172093, gnorm=0.27, loss_scale=4, train_wall=181, wall=202961
2021-03-16 17:59:49 | INFO | train_inner | epoch 006:   8299 / 20258 loss=3.535, nll_loss=1.847, ppl=3.6, wps=27918.1, ups=0.55, wpb=51059.9, bsz=3047.4, num_updates=109500, lr=0.000172015, gnorm=0.271, loss_scale=4, train_wall=180, wall=203144
2021-03-16 18:02:51 | INFO | train_inner | epoch 006:   8399 / 20258 loss=3.537, nll_loss=1.85, ppl=3.61, wps=27834.3, ups=0.55, wpb=50813.3, bsz=2997.9, num_updates=109600, lr=0.000171936, gnorm=0.275, loss_scale=4, train_wall=179, wall=203327
2021-03-16 18:03:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-16 18:05:56 | INFO | train_inner | epoch 006:   8500 / 20258 loss=3.547, nll_loss=1.861, ppl=3.63, wps=27649.6, ups=0.54, wpb=50995.3, bsz=3010.7, num_updates=109700, lr=0.000171858, gnorm=0.267, loss_scale=2, train_wall=181, wall=203511
2021-03-16 18:08:58 | INFO | train_inner | epoch 006:   8600 / 20258 loss=3.533, nll_loss=1.846, ppl=3.59, wps=27791.7, ups=0.55, wpb=50658.7, bsz=3052, num_updates=109800, lr=0.00017178, gnorm=0.281, loss_scale=2, train_wall=179, wall=203693
2021-03-16 18:13:56 | INFO | train_inner | epoch 006:   8700 / 20258 loss=3.541, nll_loss=1.855, ppl=3.62, wps=17056.8, ups=0.34, wpb=50859.6, bsz=2947.2, num_updates=109900, lr=0.000171701, gnorm=0.277, loss_scale=2, train_wall=295, wall=203992
2021-03-16 18:19:05 | INFO | train_inner | epoch 006:   8800 / 20258 loss=3.533, nll_loss=1.845, ppl=3.59, wps=16505.6, ups=0.32, wpb=51066.3, bsz=3040.7, num_updates=110000, lr=0.000171623, gnorm=0.28, loss_scale=2, train_wall=307, wall=204301
2021-03-16 18:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 18:19:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:44 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.947 | nll_loss 2.229 | ppl 4.69 | bleu 29.35 | wps 2118.2 | wpb 2432 | bsz 90.4 | num_updates 110000 | best_loss 3.947
2021-03-16 18:19:44 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 18:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:19:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:19:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:19:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:20:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 18:20:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 18:20:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 18:21:32 | INFO | valid1 | epoch 006 | valid on 'valid1' subset | loss 3.943 | nll_loss 2.248 | ppl 4.75 | bleu 27.3 | wps 2043.2 | wpb 2359.4 | bsz 106.4 | num_updates 110000 | best_loss 3.943
2021-03-16 18:21:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 18:21:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_6_110000.pt (epoch 6 @ 110000 updates, score 3.947) (writing took 7.988127002958208 seconds)
2021-03-16 18:26:50 | INFO | train_inner | epoch 006:   8900 / 20258 loss=3.517, nll_loss=1.828, ppl=3.55, wps=10976.1, ups=0.22, wpb=51018.5, bsz=3102.8, num_updates=110100, lr=0.000171545, gnorm=0.266, loss_scale=2, train_wall=306, wall=204766
2021-03-16 18:30:56 | INFO | train_inner | epoch 006:   9000 / 20258 loss=3.535, nll_loss=1.848, ppl=3.6, wps=20632.9, ups=0.41, wpb=50640, bsz=3029.8, num_updates=110200, lr=0.000171467, gnorm=0.275, loss_scale=2, train_wall=242, wall=205011
2021-03-16 18:31:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-16 18:34:00 | INFO | train_inner | epoch 006:   9101 / 20258 loss=3.543, nll_loss=1.857, ppl=3.62, wps=27583.7, ups=0.54, wpb=50936.6, bsz=3107.6, num_updates=110300, lr=0.00017139, gnorm=0.269, loss_scale=1, train_wall=181, wall=205196
2021-03-16 18:38:26 | INFO | train_inner | epoch 006:   9201 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=19246.4, ups=0.38, wpb=51047.1, bsz=3004.4, num_updates=110400, lr=0.000171312, gnorm=0.267, loss_scale=1, train_wall=262, wall=205461
2021-03-16 18:43:34 | INFO | train_inner | epoch 006:   9301 / 20258 loss=3.519, nll_loss=1.829, ppl=3.55, wps=16481.8, ups=0.32, wpb=50816.7, bsz=3021.2, num_updates=110500, lr=0.000171235, gnorm=0.272, loss_scale=1, train_wall=305, wall=205769
2021-03-16 18:48:42 | INFO | train_inner | epoch 006:   9401 / 20258 loss=3.548, nll_loss=1.862, ppl=3.64, wps=16581.7, ups=0.32, wpb=51099, bsz=3003, num_updates=110600, lr=0.000171157, gnorm=0.269, loss_scale=1, train_wall=305, wall=206078
2021-03-16 18:53:50 | INFO | train_inner | epoch 006:   9501 / 20258 loss=3.523, nll_loss=1.835, ppl=3.57, wps=16519.3, ups=0.32, wpb=50866.8, bsz=3120.7, num_updates=110700, lr=0.00017108, gnorm=0.267, loss_scale=1, train_wall=305, wall=206386
2021-03-16 18:58:59 | INFO | train_inner | epoch 006:   9601 / 20258 loss=3.533, nll_loss=1.845, ppl=3.59, wps=16520.5, ups=0.32, wpb=50993.1, bsz=3004.6, num_updates=110800, lr=0.000171003, gnorm=0.269, loss_scale=1, train_wall=306, wall=206694
2021-03-16 19:04:07 | INFO | train_inner | epoch 006:   9701 / 20258 loss=3.547, nll_loss=1.862, ppl=3.63, wps=16509, ups=0.32, wpb=50919.1, bsz=3047, num_updates=110900, lr=0.000170925, gnorm=0.267, loss_scale=1, train_wall=305, wall=207003
2021-03-16 19:09:16 | INFO | train_inner | epoch 006:   9801 / 20258 loss=3.545, nll_loss=1.859, ppl=3.63, wps=16582.4, ups=0.32, wpb=51232.8, bsz=2960.2, num_updates=111000, lr=0.000170848, gnorm=0.266, loss_scale=1, train_wall=306, wall=207312
2021-03-16 19:14:25 | INFO | train_inner | epoch 006:   9901 / 20258 loss=3.531, nll_loss=1.843, ppl=3.59, wps=16534, ups=0.32, wpb=51009.8, bsz=3028.8, num_updates=111100, lr=0.000170772, gnorm=0.269, loss_scale=1, train_wall=305, wall=207620
2021-03-16 19:17:56 | INFO | train_inner | epoch 006:  10001 / 20258 loss=3.53, nll_loss=1.842, ppl=3.58, wps=24060.9, ups=0.47, wpb=50908, bsz=2980.2, num_updates=111200, lr=0.000170695, gnorm=0.267, loss_scale=1, train_wall=208, wall=207832
2021-03-16 19:20:59 | INFO | train_inner | epoch 006:  10101 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27773.1, ups=0.55, wpb=50761.8, bsz=3093.2, num_updates=111300, lr=0.000170618, gnorm=0.271, loss_scale=2, train_wall=179, wall=208015
2021-03-16 19:24:01 | INFO | train_inner | epoch 006:  10201 / 20258 loss=3.539, nll_loss=1.852, ppl=3.61, wps=27945.6, ups=0.55, wpb=50959.3, bsz=2950.6, num_updates=111400, lr=0.000170541, gnorm=0.266, loss_scale=2, train_wall=179, wall=208197
2021-03-16 19:27:04 | INFO | train_inner | epoch 006:  10301 / 20258 loss=3.543, nll_loss=1.857, ppl=3.62, wps=27933, ups=0.55, wpb=50981.4, bsz=3067.1, num_updates=111500, lr=0.000170465, gnorm=0.265, loss_scale=2, train_wall=179, wall=208379
2021-03-16 19:30:07 | INFO | train_inner | epoch 006:  10401 / 20258 loss=3.53, nll_loss=1.843, ppl=3.59, wps=27932.1, ups=0.55, wpb=51090.7, bsz=3128.8, num_updates=111600, lr=0.000170389, gnorm=0.268, loss_scale=2, train_wall=180, wall=208562
2021-03-16 19:33:10 | INFO | train_inner | epoch 006:  10501 / 20258 loss=3.538, nll_loss=1.851, ppl=3.61, wps=27872.4, ups=0.55, wpb=51093.3, bsz=3024.6, num_updates=111700, lr=0.000170312, gnorm=0.267, loss_scale=2, train_wall=180, wall=208746
2021-03-16 19:36:12 | INFO | train_inner | epoch 006:  10601 / 20258 loss=3.543, nll_loss=1.857, ppl=3.62, wps=27880.5, ups=0.55, wpb=50652, bsz=2946.2, num_updates=111800, lr=0.000170236, gnorm=0.266, loss_scale=2, train_wall=179, wall=208927
2021-03-16 19:39:15 | INFO | train_inner | epoch 006:  10701 / 20258 loss=3.514, nll_loss=1.825, ppl=3.54, wps=27851.2, ups=0.55, wpb=50941.7, bsz=3095.3, num_updates=111900, lr=0.00017016, gnorm=0.277, loss_scale=2, train_wall=180, wall=209110
2021-03-16 19:42:17 | INFO | train_inner | epoch 006:  10801 / 20258 loss=3.518, nll_loss=1.829, ppl=3.55, wps=27920.4, ups=0.55, wpb=50963.7, bsz=2979.5, num_updates=112000, lr=0.000170084, gnorm=0.268, loss_scale=2, train_wall=179, wall=209293
2021-03-16 19:45:19 | INFO | train_inner | epoch 006:  10901 / 20258 loss=3.538, nll_loss=1.852, ppl=3.61, wps=27831.8, ups=0.55, wpb=50683.3, bsz=3046.5, num_updates=112100, lr=0.000170008, gnorm=0.279, loss_scale=2, train_wall=179, wall=209475
2021-03-16 19:48:22 | INFO | train_inner | epoch 006:  11001 / 20258 loss=3.532, nll_loss=1.844, ppl=3.59, wps=27905.4, ups=0.55, wpb=50967.2, bsz=3019.3, num_updates=112200, lr=0.000169932, gnorm=0.276, loss_scale=2, train_wall=179, wall=209657
2021-03-16 19:51:24 | INFO | train_inner | epoch 006:  11101 / 20258 loss=3.546, nll_loss=1.86, ppl=3.63, wps=27927.8, ups=0.55, wpb=50702, bsz=2873.6, num_updates=112300, lr=0.000169857, gnorm=0.273, loss_scale=4, train_wall=179, wall=209839
2021-03-16 19:54:26 | INFO | train_inner | epoch 006:  11201 / 20258 loss=3.547, nll_loss=1.862, ppl=3.63, wps=27907.9, ups=0.55, wpb=50885.7, bsz=3049.6, num_updates=112400, lr=0.000169781, gnorm=0.273, loss_scale=4, train_wall=179, wall=210021
2021-03-16 19:57:28 | INFO | train_inner | epoch 006:  11301 / 20258 loss=3.528, nll_loss=1.839, ppl=3.58, wps=27920, ups=0.55, wpb=50951.4, bsz=2984.6, num_updates=112500, lr=0.000169706, gnorm=0.273, loss_scale=4, train_wall=180, wall=210204
2021-03-16 20:00:30 | INFO | train_inner | epoch 006:  11401 / 20258 loss=3.548, nll_loss=1.863, ppl=3.64, wps=27907.6, ups=0.55, wpb=50670.3, bsz=2920, num_updates=112600, lr=0.00016963, gnorm=0.278, loss_scale=4, train_wall=179, wall=210385
2021-03-16 20:03:32 | INFO | train_inner | epoch 006:  11501 / 20258 loss=3.539, nll_loss=1.852, ppl=3.61, wps=27853.1, ups=0.55, wpb=50699.5, bsz=3051, num_updates=112700, lr=0.000169555, gnorm=0.27, loss_scale=4, train_wall=179, wall=210567
2021-03-16 20:06:34 | INFO | train_inner | epoch 006:  11601 / 20258 loss=3.537, nll_loss=1.851, ppl=3.61, wps=27886.2, ups=0.55, wpb=50787.4, bsz=3080.8, num_updates=112800, lr=0.00016948, gnorm=0.268, loss_scale=4, train_wall=179, wall=210750
2021-03-16 20:09:37 | INFO | train_inner | epoch 006:  11701 / 20258 loss=3.539, nll_loss=1.852, ppl=3.61, wps=27960, ups=0.55, wpb=51077.9, bsz=3028.2, num_updates=112900, lr=0.000169405, gnorm=0.268, loss_scale=4, train_wall=180, wall=210932
2021-03-16 20:12:39 | INFO | train_inner | epoch 006:  11801 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=27913.3, ups=0.55, wpb=50862.8, bsz=3063.8, num_updates=113000, lr=0.00016933, gnorm=0.267, loss_scale=4, train_wall=179, wall=211114
2021-03-16 20:15:41 | INFO | train_inner | epoch 006:  11901 / 20258 loss=3.549, nll_loss=1.864, ppl=3.64, wps=27933.7, ups=0.55, wpb=50736, bsz=2934.6, num_updates=113100, lr=0.000169255, gnorm=0.271, loss_scale=4, train_wall=179, wall=211296
2021-03-16 20:18:43 | INFO | train_inner | epoch 006:  12001 / 20258 loss=3.54, nll_loss=1.853, ppl=3.61, wps=27886.3, ups=0.55, wpb=50931.4, bsz=3026.6, num_updates=113200, lr=0.00016918, gnorm=0.278, loss_scale=4, train_wall=179, wall=211479
2021-03-16 20:21:46 | INFO | train_inner | epoch 006:  12101 / 20258 loss=3.544, nll_loss=1.858, ppl=3.63, wps=27868.5, ups=0.55, wpb=50837.5, bsz=2986, num_updates=113300, lr=0.000169105, gnorm=0.271, loss_scale=8, train_wall=179, wall=211661
2021-03-16 20:24:48 | INFO | train_inner | epoch 006:  12201 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27941.8, ups=0.55, wpb=51027.9, bsz=3063.8, num_updates=113400, lr=0.000169031, gnorm=0.273, loss_scale=8, train_wall=180, wall=211844
2021-03-16 20:27:51 | INFO | train_inner | epoch 006:  12301 / 20258 loss=3.529, nll_loss=1.841, ppl=3.58, wps=27898.1, ups=0.55, wpb=50865.9, bsz=2999.1, num_updates=113500, lr=0.000168956, gnorm=0.28, loss_scale=8, train_wall=179, wall=212026
2021-03-16 20:30:54 | INFO | train_inner | epoch 006:  12401 / 20258 loss=3.542, nll_loss=1.856, ppl=3.62, wps=27990.1, ups=0.55, wpb=51202.2, bsz=3114.4, num_updates=113600, lr=0.000168882, gnorm=0.287, loss_scale=8, train_wall=180, wall=212209
2021-03-16 20:33:56 | INFO | train_inner | epoch 006:  12501 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=27716.8, ups=0.55, wpb=50666.7, bsz=3075.9, num_updates=113700, lr=0.000168808, gnorm=0.276, loss_scale=8, train_wall=179, wall=212392
2021-03-16 20:36:59 | INFO | train_inner | epoch 006:  12601 / 20258 loss=3.53, nll_loss=1.842, ppl=3.59, wps=27816.3, ups=0.55, wpb=50819.4, bsz=3060.2, num_updates=113800, lr=0.000168734, gnorm=0.272, loss_scale=8, train_wall=180, wall=212575
2021-03-16 20:40:01 | INFO | train_inner | epoch 006:  12701 / 20258 loss=3.551, nll_loss=1.866, ppl=3.64, wps=27966, ups=0.55, wpb=50861.1, bsz=2790.3, num_updates=113900, lr=0.000168659, gnorm=0.275, loss_scale=8, train_wall=179, wall=212756
2021-03-16 20:43:03 | INFO | train_inner | epoch 006:  12801 / 20258 loss=3.521, nll_loss=1.832, ppl=3.56, wps=27865.1, ups=0.55, wpb=50805.3, bsz=3035.8, num_updates=114000, lr=0.000168585, gnorm=0.274, loss_scale=8, train_wall=179, wall=212939
2021-03-16 20:46:06 | INFO | train_inner | epoch 006:  12901 / 20258 loss=3.53, nll_loss=1.842, ppl=3.59, wps=27956.4, ups=0.55, wpb=51057.3, bsz=3086.4, num_updates=114100, lr=0.000168512, gnorm=0.265, loss_scale=8, train_wall=180, wall=213121
2021-03-16 20:49:08 | INFO | train_inner | epoch 006:  13001 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27873.7, ups=0.55, wpb=50890.7, bsz=3081.9, num_updates=114200, lr=0.000168438, gnorm=0.267, loss_scale=8, train_wall=180, wall=213304
2021-03-16 20:52:11 | INFO | train_inner | epoch 006:  13101 / 20258 loss=3.549, nll_loss=1.864, ppl=3.64, wps=28069.4, ups=0.55, wpb=51167.7, bsz=3011.8, num_updates=114300, lr=0.000168364, gnorm=0.27, loss_scale=8, train_wall=179, wall=213486
2021-03-16 20:55:13 | INFO | train_inner | epoch 006:  13201 / 20258 loss=3.527, nll_loss=1.839, ppl=3.58, wps=27869.1, ups=0.55, wpb=50915.2, bsz=2903.4, num_updates=114400, lr=0.00016829, gnorm=0.269, loss_scale=16, train_wall=180, wall=213669
2021-03-16 20:55:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-16 20:58:18 | INFO | train_inner | epoch 006:  13302 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27728.6, ups=0.54, wpb=51164.1, bsz=2953.8, num_updates=114500, lr=0.000168217, gnorm=0.273, loss_scale=8, train_wall=181, wall=213853
2021-03-16 21:01:21 | INFO | train_inner | epoch 006:  13402 / 20258 loss=3.526, nll_loss=1.838, ppl=3.58, wps=27874.9, ups=0.55, wpb=50929.3, bsz=2999, num_updates=114600, lr=0.000168144, gnorm=0.268, loss_scale=8, train_wall=180, wall=214036
2021-03-16 21:04:23 | INFO | train_inner | epoch 006:  13502 / 20258 loss=3.547, nll_loss=1.861, ppl=3.63, wps=28021.9, ups=0.55, wpb=51060.4, bsz=2861.9, num_updates=114700, lr=0.00016807, gnorm=0.269, loss_scale=8, train_wall=179, wall=214218
2021-03-16 21:07:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 21:07:27 | INFO | train_inner | epoch 006:  13603 / 20258 loss=3.54, nll_loss=1.854, ppl=3.61, wps=27637.1, ups=0.54, wpb=50826.2, bsz=3070.5, num_updates=114800, lr=0.000167997, gnorm=0.269, loss_scale=4, train_wall=181, wall=214402
2021-03-16 21:10:29 | INFO | train_inner | epoch 006:  13703 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27811.4, ups=0.55, wpb=50667.3, bsz=3039.7, num_updates=114900, lr=0.000167924, gnorm=0.266, loss_scale=4, train_wall=179, wall=214584
2021-03-16 21:13:32 | INFO | train_inner | epoch 006:  13803 / 20258 loss=3.527, nll_loss=1.84, ppl=3.58, wps=27835, ups=0.55, wpb=50831.6, bsz=3118.3, num_updates=115000, lr=0.000167851, gnorm=0.27, loss_scale=4, train_wall=179, wall=214767
2021-03-16 21:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 21:13:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:50 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.939 | nll_loss 2.221 | ppl 4.66 | bleu 29.51 | wps 4361 | wpb 2432 | bsz 90.4 | num_updates 115000 | best_loss 3.939
2021-03-16 21:13:50 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 21:13:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:13:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:13:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:13:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 21:14:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 21:14:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 21:14:43 | INFO | valid1 | epoch 006 | valid on 'valid1' subset | loss 3.936 | nll_loss 2.239 | ppl 4.72 | bleu 27.68 | wps 4231.3 | wpb 2359.4 | bsz 106.4 | num_updates 115000 | best_loss 3.936
2021-03-16 21:14:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 21:14:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_6_115000.pt (epoch 6 @ 115000 updates, score 3.939) (writing took 6.754611695883796 seconds)
2021-03-16 21:17:52 | INFO | train_inner | epoch 006:  13903 / 20258 loss=3.515, nll_loss=1.826, ppl=3.54, wps=19500.4, ups=0.38, wpb=50870.8, bsz=3018.5, num_updates=115100, lr=0.000167778, gnorm=0.27, loss_scale=4, train_wall=180, wall=215028
2021-03-16 21:20:54 | INFO | train_inner | epoch 006:  14003 / 20258 loss=3.535, nll_loss=1.848, ppl=3.6, wps=27964.1, ups=0.55, wpb=50852.2, bsz=3059.2, num_updates=115200, lr=0.000167705, gnorm=0.27, loss_scale=4, train_wall=179, wall=215210
2021-03-16 21:23:56 | INFO | train_inner | epoch 006:  14103 / 20258 loss=3.54, nll_loss=1.853, ppl=3.61, wps=27915.9, ups=0.55, wpb=50714.4, bsz=2911.7, num_updates=115300, lr=0.000167632, gnorm=0.274, loss_scale=4, train_wall=179, wall=215391
2021-03-16 21:26:58 | INFO | train_inner | epoch 006:  14203 / 20258 loss=3.539, nll_loss=1.852, ppl=3.61, wps=27928.6, ups=0.55, wpb=50876.4, bsz=2968.8, num_updates=115400, lr=0.00016756, gnorm=0.268, loss_scale=4, train_wall=179, wall=215574
2021-03-16 21:29:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-16 21:30:03 | INFO | train_inner | epoch 006:  14304 / 20258 loss=3.543, nll_loss=1.857, ppl=3.62, wps=27692.6, ups=0.54, wpb=51071.8, bsz=3032.1, num_updates=115500, lr=0.000167487, gnorm=0.312, loss_scale=2, train_wall=181, wall=215758
2021-03-16 21:33:05 | INFO | train_inner | epoch 006:  14404 / 20258 loss=3.513, nll_loss=1.823, ppl=3.54, wps=27867.5, ups=0.55, wpb=50975.4, bsz=3028.2, num_updates=115600, lr=0.000167415, gnorm=0.267, loss_scale=2, train_wall=180, wall=215941
2021-03-16 21:36:08 | INFO | train_inner | epoch 006:  14504 / 20258 loss=3.527, nll_loss=1.839, ppl=3.58, wps=27953.1, ups=0.55, wpb=51081.7, bsz=3073, num_updates=115700, lr=0.000167342, gnorm=0.27, loss_scale=2, train_wall=179, wall=216124
2021-03-16 21:39:11 | INFO | train_inner | epoch 006:  14604 / 20258 loss=3.53, nll_loss=1.842, ppl=3.59, wps=27829, ups=0.55, wpb=50728.6, bsz=3012.1, num_updates=115800, lr=0.00016727, gnorm=0.277, loss_scale=2, train_wall=179, wall=216306
2021-03-16 21:42:13 | INFO | train_inner | epoch 006:  14704 / 20258 loss=3.533, nll_loss=1.846, ppl=3.59, wps=27796.3, ups=0.55, wpb=50817.2, bsz=2996.6, num_updates=115900, lr=0.000167198, gnorm=0.273, loss_scale=2, train_wall=179, wall=216489
2021-03-16 21:45:16 | INFO | train_inner | epoch 006:  14804 / 20258 loss=3.531, nll_loss=1.843, ppl=3.59, wps=27881.9, ups=0.55, wpb=50799.4, bsz=3048.5, num_updates=116000, lr=0.000167126, gnorm=0.279, loss_scale=2, train_wall=179, wall=216671
2021-03-16 21:48:18 | INFO | train_inner | epoch 006:  14904 / 20258 loss=3.531, nll_loss=1.844, ppl=3.59, wps=27915.9, ups=0.55, wpb=50942, bsz=2963.2, num_updates=116100, lr=0.000167054, gnorm=0.264, loss_scale=2, train_wall=179, wall=216854
2021-03-16 21:51:21 | INFO | train_inner | epoch 006:  15004 / 20258 loss=3.521, nll_loss=1.832, ppl=3.56, wps=27945.7, ups=0.55, wpb=51011.1, bsz=3063.2, num_updates=116200, lr=0.000166982, gnorm=0.3, loss_scale=2, train_wall=179, wall=217036
2021-03-16 21:54:22 | INFO | train_inner | epoch 006:  15104 / 20258 loss=3.524, nll_loss=1.836, ppl=3.57, wps=27936.3, ups=0.55, wpb=50791.5, bsz=2894.1, num_updates=116300, lr=0.00016691, gnorm=0.27, loss_scale=2, train_wall=179, wall=217218
2021-03-16 21:57:25 | INFO | train_inner | epoch 006:  15204 / 20258 loss=3.527, nll_loss=1.838, ppl=3.58, wps=27935.7, ups=0.55, wpb=50916.3, bsz=2919, num_updates=116400, lr=0.000166838, gnorm=0.274, loss_scale=2, train_wall=179, wall=217400
2021-03-16 22:00:26 | INFO | train_inner | epoch 006:  15304 / 20258 loss=3.537, nll_loss=1.85, ppl=3.61, wps=27904.3, ups=0.55, wpb=50660.6, bsz=2862.4, num_updates=116500, lr=0.000166767, gnorm=0.267, loss_scale=2, train_wall=179, wall=217582
2021-03-16 22:03:38 | INFO | train_inner | epoch 006:  15404 / 20258 loss=3.531, nll_loss=1.844, ppl=3.59, wps=26476.2, ups=0.52, wpb=50897.2, bsz=3123.7, num_updates=116600, lr=0.000166695, gnorm=0.27, loss_scale=4, train_wall=189, wall=217774
2021-03-16 22:06:42 | INFO | train_inner | epoch 006:  15504 / 20258 loss=3.518, nll_loss=1.829, ppl=3.55, wps=27653.7, ups=0.54, wpb=50859.4, bsz=3076.8, num_updates=116700, lr=0.000166624, gnorm=0.275, loss_scale=4, train_wall=180, wall=217958
2021-03-16 22:09:45 | INFO | train_inner | epoch 006:  15604 / 20258 loss=3.535, nll_loss=1.848, ppl=3.6, wps=27851.8, ups=0.55, wpb=50943.7, bsz=3057.5, num_updates=116800, lr=0.000166552, gnorm=0.272, loss_scale=4, train_wall=180, wall=218141
2021-03-16 22:12:48 | INFO | train_inner | epoch 006:  15704 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=27878.5, ups=0.55, wpb=50827.8, bsz=3010.1, num_updates=116900, lr=0.000166481, gnorm=0.27, loss_scale=4, train_wall=179, wall=218323
2021-03-16 22:15:51 | INFO | train_inner | epoch 006:  15804 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=27970.8, ups=0.55, wpb=51170.9, bsz=2863, num_updates=117000, lr=0.00016641, gnorm=0.269, loss_scale=4, train_wall=180, wall=218506
2021-03-16 22:18:53 | INFO | train_inner | epoch 006:  15904 / 20258 loss=3.539, nll_loss=1.853, ppl=3.61, wps=27940.9, ups=0.55, wpb=51102, bsz=2999.7, num_updates=117100, lr=0.000166339, gnorm=0.272, loss_scale=4, train_wall=180, wall=218689
2021-03-16 22:21:56 | INFO | train_inner | epoch 006:  16004 / 20258 loss=3.541, nll_loss=1.855, ppl=3.62, wps=27887.8, ups=0.55, wpb=50818.4, bsz=2988.3, num_updates=117200, lr=0.000166268, gnorm=0.276, loss_scale=4, train_wall=179, wall=218871
2021-03-16 22:24:57 | INFO | train_inner | epoch 006:  16104 / 20258 loss=3.541, nll_loss=1.855, ppl=3.62, wps=27921.3, ups=0.55, wpb=50770.3, bsz=3119.4, num_updates=117300, lr=0.000166197, gnorm=0.276, loss_scale=4, train_wall=179, wall=219053
2021-03-16 22:28:00 | INFO | train_inner | epoch 006:  16204 / 20258 loss=3.544, nll_loss=1.858, ppl=3.63, wps=27772.8, ups=0.55, wpb=50703, bsz=2994.2, num_updates=117400, lr=0.000166126, gnorm=0.281, loss_scale=4, train_wall=179, wall=219236
2021-03-16 22:31:02 | INFO | train_inner | epoch 006:  16304 / 20258 loss=3.543, nll_loss=1.857, ppl=3.62, wps=27915.6, ups=0.55, wpb=50890.7, bsz=3017, num_updates=117500, lr=0.000166056, gnorm=0.277, loss_scale=4, train_wall=179, wall=219418
2021-03-16 22:34:05 | INFO | train_inner | epoch 006:  16404 / 20258 loss=3.555, nll_loss=1.871, ppl=3.66, wps=27806.3, ups=0.55, wpb=50734.9, bsz=3000.8, num_updates=117600, lr=0.000165985, gnorm=0.272, loss_scale=8, train_wall=179, wall=219600
2021-03-16 22:37:08 | INFO | train_inner | epoch 006:  16504 / 20258 loss=3.514, nll_loss=1.825, ppl=3.54, wps=27871.1, ups=0.55, wpb=50984.5, bsz=3100.5, num_updates=117700, lr=0.000165914, gnorm=0.27, loss_scale=8, train_wall=180, wall=219783
2021-03-16 22:38:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-16 22:40:11 | INFO | train_inner | epoch 006:  16605 / 20258 loss=3.536, nll_loss=1.849, ppl=3.6, wps=27695.4, ups=0.54, wpb=50857.1, bsz=2972, num_updates=117800, lr=0.000165844, gnorm=0.284, loss_scale=4, train_wall=181, wall=219967
2021-03-16 22:43:14 | INFO | train_inner | epoch 006:  16705 / 20258 loss=3.544, nll_loss=1.858, ppl=3.63, wps=27912, ups=0.55, wpb=50899.1, bsz=2980.3, num_updates=117900, lr=0.000165774, gnorm=0.269, loss_scale=4, train_wall=179, wall=220149
2021-03-16 22:46:16 | INFO | train_inner | epoch 006:  16805 / 20258 loss=3.521, nll_loss=1.832, ppl=3.56, wps=27941.8, ups=0.55, wpb=51040.4, bsz=2931.8, num_updates=118000, lr=0.000165703, gnorm=0.266, loss_scale=4, train_wall=180, wall=220332
2021-03-16 22:47:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-16 22:47:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-16 22:49:22 | INFO | train_inner | epoch 006:  16907 / 20258 loss=3.536, nll_loss=1.849, ppl=3.6, wps=27243.8, ups=0.54, wpb=50667.7, bsz=3037.3, num_updates=118100, lr=0.000165633, gnorm=0.28, loss_scale=1, train_wall=182, wall=220518
2021-03-16 22:52:24 | INFO | train_inner | epoch 006:  17007 / 20258 loss=3.541, nll_loss=1.855, ppl=3.62, wps=27978.3, ups=0.55, wpb=50762.4, bsz=2994.5, num_updates=118200, lr=0.000165563, gnorm=0.281, loss_scale=1, train_wall=179, wall=220699
2021-03-16 22:55:26 | INFO | train_inner | epoch 006:  17107 / 20258 loss=3.546, nll_loss=1.861, ppl=3.63, wps=27944.6, ups=0.55, wpb=50802.4, bsz=3005, num_updates=118300, lr=0.000165493, gnorm=0.268, loss_scale=1, train_wall=179, wall=220881
2021-03-16 22:58:28 | INFO | train_inner | epoch 006:  17207 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27921, ups=0.55, wpb=50888.5, bsz=2935.4, num_updates=118400, lr=0.000165423, gnorm=0.272, loss_scale=1, train_wall=179, wall=221063
2021-03-16 23:01:31 | INFO | train_inner | epoch 006:  17307 / 20258 loss=3.522, nll_loss=1.833, ppl=3.56, wps=27919.5, ups=0.55, wpb=50997.2, bsz=3076.3, num_updates=118500, lr=0.000165353, gnorm=0.269, loss_scale=1, train_wall=179, wall=221246
2021-03-16 23:04:33 | INFO | train_inner | epoch 006:  17407 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27991.1, ups=0.55, wpb=50967.8, bsz=2999.3, num_updates=118600, lr=0.000165284, gnorm=0.272, loss_scale=1, train_wall=179, wall=221428
2021-03-16 23:07:34 | INFO | train_inner | epoch 006:  17507 / 20258 loss=3.54, nll_loss=1.854, ppl=3.61, wps=27917, ups=0.55, wpb=50729.2, bsz=2983.8, num_updates=118700, lr=0.000165214, gnorm=0.278, loss_scale=1, train_wall=179, wall=221610
2021-03-16 23:10:37 | INFO | train_inner | epoch 006:  17607 / 20258 loss=3.52, nll_loss=1.831, ppl=3.56, wps=27946.4, ups=0.55, wpb=51042.9, bsz=3085, num_updates=118800, lr=0.000165145, gnorm=0.274, loss_scale=1, train_wall=179, wall=221792
2021-03-16 23:13:40 | INFO | train_inner | epoch 006:  17707 / 20258 loss=3.533, nll_loss=1.846, ppl=3.59, wps=27894.8, ups=0.55, wpb=51057.9, bsz=2937.7, num_updates=118900, lr=0.000165075, gnorm=0.265, loss_scale=1, train_wall=179, wall=221976
2021-03-16 23:16:42 | INFO | train_inner | epoch 006:  17807 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=27839.8, ups=0.55, wpb=50735.9, bsz=3000.4, num_updates=119000, lr=0.000165006, gnorm=0.272, loss_scale=1, train_wall=179, wall=222158
2021-03-16 23:19:44 | INFO | train_inner | epoch 006:  17907 / 20258 loss=3.531, nll_loss=1.844, ppl=3.59, wps=27916.6, ups=0.55, wpb=50792.7, bsz=2961.5, num_updates=119100, lr=0.000164936, gnorm=0.263, loss_scale=2, train_wall=179, wall=222340
2021-03-16 23:22:47 | INFO | train_inner | epoch 006:  18007 / 20258 loss=3.529, nll_loss=1.842, ppl=3.58, wps=27981.7, ups=0.55, wpb=51057.5, bsz=3038.2, num_updates=119200, lr=0.000164867, gnorm=0.274, loss_scale=2, train_wall=179, wall=222522
2021-03-16 23:25:49 | INFO | train_inner | epoch 006:  18107 / 20258 loss=3.536, nll_loss=1.849, ppl=3.6, wps=27888.9, ups=0.55, wpb=50743.7, bsz=3023.2, num_updates=119300, lr=0.000164798, gnorm=0.269, loss_scale=2, train_wall=179, wall=222704
2021-03-16 23:28:51 | INFO | train_inner | epoch 006:  18207 / 20258 loss=3.527, nll_loss=1.84, ppl=3.58, wps=27873.7, ups=0.55, wpb=50751.4, bsz=3019.8, num_updates=119400, lr=0.000164729, gnorm=0.271, loss_scale=2, train_wall=179, wall=222886
2021-03-16 23:31:52 | INFO | train_inner | epoch 006:  18307 / 20258 loss=3.547, nll_loss=1.862, ppl=3.64, wps=28046.8, ups=0.55, wpb=50987.5, bsz=3043.8, num_updates=119500, lr=0.00016466, gnorm=0.269, loss_scale=2, train_wall=179, wall=223068
2021-03-16 23:34:54 | INFO | train_inner | epoch 006:  18407 / 20258 loss=3.537, nll_loss=1.85, ppl=3.61, wps=28066.2, ups=0.55, wpb=51071.2, bsz=2871.5, num_updates=119600, lr=0.000164591, gnorm=0.269, loss_scale=2, train_wall=179, wall=223250
2021-03-16 23:37:56 | INFO | train_inner | epoch 006:  18507 / 20258 loss=3.539, nll_loss=1.853, ppl=3.61, wps=28013.8, ups=0.55, wpb=50838.2, bsz=2985.7, num_updates=119700, lr=0.000164523, gnorm=0.273, loss_scale=2, train_wall=178, wall=223431
2021-03-16 23:40:58 | INFO | train_inner | epoch 006:  18607 / 20258 loss=3.53, nll_loss=1.843, ppl=3.59, wps=27965.8, ups=0.55, wpb=50939.9, bsz=2974.6, num_updates=119800, lr=0.000164454, gnorm=0.269, loss_scale=2, train_wall=179, wall=223614
2021-03-16 23:44:00 | INFO | train_inner | epoch 006:  18707 / 20258 loss=3.539, nll_loss=1.853, ppl=3.61, wps=27930.2, ups=0.55, wpb=50921.4, bsz=2947, num_updates=119900, lr=0.000164385, gnorm=0.274, loss_scale=2, train_wall=179, wall=223796
2021-03-16 23:47:03 | INFO | train_inner | epoch 006:  18807 / 20258 loss=3.527, nll_loss=1.84, ppl=3.58, wps=27956.3, ups=0.55, wpb=50955.1, bsz=3002.5, num_updates=120000, lr=0.000164317, gnorm=0.271, loss_scale=2, train_wall=179, wall=223978
2021-03-16 23:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-16 23:47:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:21 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.932 | nll_loss 2.221 | ppl 4.66 | bleu 29.26 | wps 4381.8 | wpb 2432 | bsz 90.4 | num_updates 120000 | best_loss 3.932
2021-03-16 23:47:21 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-16 23:47:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:47:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-16 23:47:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-16 23:47:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-16 23:48:13 | INFO | valid1 | epoch 006 | valid on 'valid1' subset | loss 3.934 | nll_loss 2.246 | ppl 4.74 | bleu 27.08 | wps 4262.5 | wpb 2359.4 | bsz 106.4 | num_updates 120000 | best_loss 3.934
2021-03-16 23:48:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-16 23:48:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_6_120000.pt (epoch 6 @ 120000 updates, score 3.932) (writing took 8.055087432032451 seconds)
2021-03-16 23:51:24 | INFO | train_inner | epoch 006:  18907 / 20258 loss=3.523, nll_loss=1.835, ppl=3.57, wps=19477.5, ups=0.38, wpb=50923, bsz=3014.8, num_updates=120100, lr=0.000164248, gnorm=0.273, loss_scale=4, train_wall=179, wall=224240
2021-03-16 23:54:27 | INFO | train_inner | epoch 006:  19007 / 20258 loss=3.536, nll_loss=1.85, ppl=3.6, wps=28061.6, ups=0.55, wpb=51197.1, bsz=3023, num_updates=120200, lr=0.00016418, gnorm=0.271, loss_scale=4, train_wall=180, wall=224422
2021-03-16 23:57:29 | INFO | train_inner | epoch 006:  19107 / 20258 loss=3.527, nll_loss=1.84, ppl=3.58, wps=27851.3, ups=0.55, wpb=50750.8, bsz=3118.2, num_updates=120300, lr=0.000164112, gnorm=0.272, loss_scale=4, train_wall=179, wall=224604
2021-03-17 00:00:31 | INFO | train_inner | epoch 006:  19207 / 20258 loss=3.54, nll_loss=1.854, ppl=3.62, wps=27911.7, ups=0.55, wpb=50868.1, bsz=2930.2, num_updates=120400, lr=0.000164044, gnorm=0.277, loss_scale=4, train_wall=179, wall=224787
2021-03-17 00:03:33 | INFO | train_inner | epoch 006:  19307 / 20258 loss=3.529, nll_loss=1.842, ppl=3.58, wps=27901.9, ups=0.55, wpb=50910.2, bsz=3019.5, num_updates=120500, lr=0.000163976, gnorm=0.267, loss_scale=4, train_wall=179, wall=224969
2021-03-17 00:06:36 | INFO | train_inner | epoch 006:  19407 / 20258 loss=3.514, nll_loss=1.825, ppl=3.54, wps=27937.2, ups=0.55, wpb=51068.8, bsz=3027.4, num_updates=120600, lr=0.000163908, gnorm=0.272, loss_scale=4, train_wall=180, wall=225152
2021-03-17 00:09:39 | INFO | train_inner | epoch 006:  19507 / 20258 loss=3.528, nll_loss=1.841, ppl=3.58, wps=27798.4, ups=0.55, wpb=50889.3, bsz=3053, num_updates=120700, lr=0.00016384, gnorm=0.274, loss_scale=4, train_wall=179, wall=225335
2021-03-17 00:12:41 | INFO | train_inner | epoch 006:  19607 / 20258 loss=3.543, nll_loss=1.857, ppl=3.62, wps=27818.2, ups=0.55, wpb=50657.9, bsz=2929.4, num_updates=120800, lr=0.000163772, gnorm=0.272, loss_scale=4, train_wall=179, wall=225517
2021-03-17 00:15:44 | INFO | train_inner | epoch 006:  19707 / 20258 loss=3.523, nll_loss=1.834, ppl=3.57, wps=27917, ups=0.55, wpb=50913.5, bsz=2960.4, num_updates=120900, lr=0.000163704, gnorm=0.268, loss_scale=4, train_wall=179, wall=225699
2021-03-17 00:18:47 | INFO | train_inner | epoch 006:  19807 / 20258 loss=3.527, nll_loss=1.84, ppl=3.58, wps=27809.6, ups=0.55, wpb=50829.3, bsz=3030.2, num_updates=121000, lr=0.000163636, gnorm=0.274, loss_scale=4, train_wall=179, wall=225882
2021-03-17 00:21:49 | INFO | train_inner | epoch 006:  19907 / 20258 loss=3.537, nll_loss=1.85, ppl=3.61, wps=28062.3, ups=0.55, wpb=51216.8, bsz=3018.6, num_updates=121100, lr=0.000163569, gnorm=0.286, loss_scale=4, train_wall=180, wall=226065
2021-03-17 00:24:52 | INFO | train_inner | epoch 006:  20007 / 20258 loss=3.533, nll_loss=1.846, ppl=3.6, wps=27877.1, ups=0.55, wpb=50970.1, bsz=3097.4, num_updates=121200, lr=0.000163501, gnorm=0.27, loss_scale=8, train_wall=180, wall=226247
2021-03-17 00:27:54 | INFO | train_inner | epoch 006:  20107 / 20258 loss=3.525, nll_loss=1.838, ppl=3.57, wps=27910.3, ups=0.55, wpb=50875.4, bsz=3028.2, num_updates=121300, lr=0.000163434, gnorm=0.271, loss_scale=8, train_wall=179, wall=226430
2021-03-17 00:30:57 | INFO | train_inner | epoch 006:  20207 / 20258 loss=3.535, nll_loss=1.849, ppl=3.6, wps=27862.9, ups=0.55, wpb=50833.9, bsz=2958.1, num_updates=121400, lr=0.000163367, gnorm=0.274, loss_scale=8, train_wall=179, wall=226612
2021-03-17 00:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 00:32:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:48 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.939 | nll_loss 2.222 | ppl 4.67 | bleu 29.62 | wps 4363.7 | wpb 2432 | bsz 90.4 | num_updates 121451 | best_loss 3.932
2021-03-17 00:32:48 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 00:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:32:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:32:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:32:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 00:33:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 00:33:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 00:33:41 | INFO | valid1 | epoch 006 | valid on 'valid1' subset | loss 3.933 | nll_loss 2.238 | ppl 4.72 | bleu 27.51 | wps 4219.8 | wpb 2359.4 | bsz 106.4 | num_updates 121451 | best_loss 3.932
2021-03-17 00:33:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 00:33:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint6.pt (epoch 6 @ 121451 updates, score 3.939) (writing took 4.6740123918280005 seconds)
2021-03-17 00:33:46 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-03-17 00:33:46 | INFO | train | epoch 006 | loss 3.535 | nll_loss 1.848 | ppl 3.6 | wps 25842.1 | ups 0.51 | wpb 50905.7 | bsz 3010.1 | num_updates 121451 | lr 0.000163332 | gnorm 0.272 | loss_scale 8 | train_wall 38787 | wall 226781
2021-03-17 00:33:46 | INFO | fairseq.trainer | begin training epoch 7
2021-03-17 00:35:15 | INFO | train_inner | epoch 007:     49 / 20258 loss=3.535, nll_loss=1.848, ppl=3.6, wps=19699.9, ups=0.39, wpb=50982.4, bsz=3106, num_updates=121500, lr=0.000163299, gnorm=0.275, loss_scale=8, train_wall=180, wall=226871
2021-03-17 00:38:18 | INFO | train_inner | epoch 007:    149 / 20258 loss=3.499, nll_loss=1.807, ppl=3.5, wps=27841.2, ups=0.55, wpb=50826.5, bsz=3035, num_updates=121600, lr=0.000163232, gnorm=0.273, loss_scale=8, train_wall=179, wall=227054
2021-03-17 00:41:21 | INFO | train_inner | epoch 007:    249 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27819.1, ups=0.55, wpb=50864.8, bsz=3064.2, num_updates=121700, lr=0.000163165, gnorm=0.264, loss_scale=8, train_wall=179, wall=227236
2021-03-17 00:44:23 | INFO | train_inner | epoch 007:    349 / 20258 loss=3.518, nll_loss=1.828, ppl=3.55, wps=27911.2, ups=0.55, wpb=50910.7, bsz=2950.2, num_updates=121800, lr=0.000163098, gnorm=0.27, loss_scale=8, train_wall=179, wall=227419
2021-03-17 00:47:26 | INFO | train_inner | epoch 007:    449 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27941.2, ups=0.55, wpb=50914.2, bsz=3108.5, num_updates=121900, lr=0.000163031, gnorm=0.266, loss_scale=8, train_wall=179, wall=227601
2021-03-17 00:50:28 | INFO | train_inner | epoch 007:    549 / 20258 loss=3.515, nll_loss=1.825, ppl=3.54, wps=27921.6, ups=0.55, wpb=50868.5, bsz=2950.2, num_updates=122000, lr=0.000162964, gnorm=0.269, loss_scale=8, train_wall=179, wall=227783
2021-03-17 00:53:30 | INFO | train_inner | epoch 007:    649 / 20258 loss=3.502, nll_loss=1.811, ppl=3.51, wps=27941.9, ups=0.55, wpb=51002.8, bsz=3019.3, num_updates=122100, lr=0.000162898, gnorm=0.266, loss_scale=8, train_wall=179, wall=227966
2021-03-17 00:56:33 | INFO | train_inner | epoch 007:    749 / 20258 loss=3.524, nll_loss=1.835, ppl=3.57, wps=27882.1, ups=0.55, wpb=50850.9, bsz=2907.5, num_updates=122200, lr=0.000162831, gnorm=0.271, loss_scale=16, train_wall=179, wall=228148
2021-03-17 00:59:34 | INFO | train_inner | epoch 007:    849 / 20258 loss=3.521, nll_loss=1.833, ppl=3.56, wps=27821.7, ups=0.55, wpb=50581, bsz=2952.6, num_updates=122300, lr=0.000162764, gnorm=0.278, loss_scale=16, train_wall=179, wall=228330
2021-03-17 01:02:37 | INFO | train_inner | epoch 007:    949 / 20258 loss=3.516, nll_loss=1.827, ppl=3.55, wps=27824.5, ups=0.55, wpb=50742.2, bsz=2941.4, num_updates=122400, lr=0.000162698, gnorm=0.277, loss_scale=16, train_wall=179, wall=228512
2021-03-17 01:03:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 01:05:41 | INFO | train_inner | epoch 007:   1050 / 20258 loss=3.517, nll_loss=1.827, ppl=3.55, wps=27747.5, ups=0.54, wpb=51176.4, bsz=3030.6, num_updates=122500, lr=0.000162631, gnorm=0.269, loss_scale=8, train_wall=181, wall=228697
2021-03-17 01:08:44 | INFO | train_inner | epoch 007:   1150 / 20258 loss=3.51, nll_loss=1.82, ppl=3.53, wps=27969.2, ups=0.55, wpb=51077.9, bsz=3038.3, num_updates=122600, lr=0.000162565, gnorm=0.269, loss_scale=8, train_wall=179, wall=228879
2021-03-17 01:11:46 | INFO | train_inner | epoch 007:   1250 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27886.3, ups=0.55, wpb=50827.3, bsz=2945.3, num_updates=122700, lr=0.000162499, gnorm=0.269, loss_scale=8, train_wall=179, wall=229062
2021-03-17 01:14:49 | INFO | train_inner | epoch 007:   1350 / 20258 loss=3.519, nll_loss=1.83, ppl=3.56, wps=27883.4, ups=0.55, wpb=50979.3, bsz=3084, num_updates=122800, lr=0.000162433, gnorm=0.272, loss_scale=8, train_wall=179, wall=229244
2021-03-17 01:17:51 | INFO | train_inner | epoch 007:   1450 / 20258 loss=3.518, nll_loss=1.828, ppl=3.55, wps=27807.1, ups=0.55, wpb=50646.7, bsz=2856.2, num_updates=122900, lr=0.000162367, gnorm=0.272, loss_scale=8, train_wall=179, wall=229427
2021-03-17 01:20:54 | INFO | train_inner | epoch 007:   1550 / 20258 loss=3.51, nll_loss=1.82, ppl=3.53, wps=27909.7, ups=0.55, wpb=51103.6, bsz=3046.1, num_updates=123000, lr=0.000162301, gnorm=0.27, loss_scale=8, train_wall=180, wall=229610
2021-03-17 01:23:57 | INFO | train_inner | epoch 007:   1650 / 20258 loss=3.52, nll_loss=1.831, ppl=3.56, wps=27870.9, ups=0.55, wpb=50866.6, bsz=3145.8, num_updates=123100, lr=0.000162235, gnorm=0.272, loss_scale=8, train_wall=179, wall=229792
2021-03-17 01:27:00 | INFO | train_inner | epoch 007:   1750 / 20258 loss=3.511, nll_loss=1.821, ppl=3.53, wps=27915.5, ups=0.55, wpb=51044.4, bsz=3085.4, num_updates=123200, lr=0.000162169, gnorm=0.263, loss_scale=8, train_wall=180, wall=229975
2021-03-17 01:30:02 | INFO | train_inner | epoch 007:   1850 / 20258 loss=3.508, nll_loss=1.818, ppl=3.53, wps=27939.2, ups=0.55, wpb=51015.9, bsz=2939.8, num_updates=123300, lr=0.000162103, gnorm=0.273, loss_scale=8, train_wall=179, wall=230158
2021-03-17 01:33:04 | INFO | train_inner | epoch 007:   1950 / 20258 loss=3.518, nll_loss=1.829, ppl=3.55, wps=27847.8, ups=0.55, wpb=50760, bsz=3003, num_updates=123400, lr=0.000162037, gnorm=0.274, loss_scale=8, train_wall=179, wall=230340
2021-03-17 01:36:08 | INFO | train_inner | epoch 007:   2050 / 20258 loss=3.511, nll_loss=1.821, ppl=3.53, wps=27885.7, ups=0.55, wpb=51164, bsz=3023.8, num_updates=123500, lr=0.000161972, gnorm=0.266, loss_scale=16, train_wall=180, wall=230523
2021-03-17 01:39:10 | INFO | train_inner | epoch 007:   2150 / 20258 loss=3.529, nll_loss=1.842, ppl=3.58, wps=27896.6, ups=0.55, wpb=50907.1, bsz=3118.4, num_updates=123600, lr=0.000161906, gnorm=0.27, loss_scale=16, train_wall=179, wall=230706
2021-03-17 01:41:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 01:42:15 | INFO | train_inner | epoch 007:   2251 / 20258 loss=3.511, nll_loss=1.821, ppl=3.53, wps=27559, ups=0.54, wpb=50799.6, bsz=2956.2, num_updates=123700, lr=0.000161841, gnorm=0.268, loss_scale=8, train_wall=181, wall=230890
2021-03-17 01:45:18 | INFO | train_inner | epoch 007:   2351 / 20258 loss=3.52, nll_loss=1.831, ppl=3.56, wps=27870.8, ups=0.55, wpb=51049.6, bsz=3118.3, num_updates=123800, lr=0.000161775, gnorm=0.265, loss_scale=8, train_wall=180, wall=231073
2021-03-17 01:48:20 | INFO | train_inner | epoch 007:   2451 / 20258 loss=3.526, nll_loss=1.838, ppl=3.57, wps=27982.7, ups=0.55, wpb=50960.3, bsz=2970.2, num_updates=123900, lr=0.00016171, gnorm=0.269, loss_scale=8, train_wall=179, wall=231256
2021-03-17 01:51:23 | INFO | train_inner | epoch 007:   2551 / 20258 loss=3.515, nll_loss=1.826, ppl=3.55, wps=27904.7, ups=0.55, wpb=50942.8, bsz=3027.8, num_updates=124000, lr=0.000161645, gnorm=0.268, loss_scale=8, train_wall=179, wall=231438
2021-03-17 01:54:25 | INFO | train_inner | epoch 007:   2651 / 20258 loss=3.517, nll_loss=1.827, ppl=3.55, wps=27935.1, ups=0.55, wpb=50968.5, bsz=3027.9, num_updates=124100, lr=0.00016158, gnorm=0.272, loss_scale=8, train_wall=179, wall=231621
2021-03-17 01:57:28 | INFO | train_inner | epoch 007:   2751 / 20258 loss=3.518, nll_loss=1.83, ppl=3.55, wps=27910, ups=0.55, wpb=50931.2, bsz=3012.8, num_updates=124200, lr=0.000161515, gnorm=0.268, loss_scale=8, train_wall=180, wall=231803
2021-03-17 02:00:30 | INFO | train_inner | epoch 007:   2851 / 20258 loss=3.518, nll_loss=1.829, ppl=3.55, wps=27994.1, ups=0.55, wpb=51077.2, bsz=3030.1, num_updates=124300, lr=0.00016145, gnorm=0.268, loss_scale=8, train_wall=180, wall=231985
2021-03-17 02:03:32 | INFO | train_inner | epoch 007:   2951 / 20258 loss=3.504, nll_loss=1.813, ppl=3.51, wps=27816.4, ups=0.55, wpb=50693.6, bsz=2968.8, num_updates=124400, lr=0.000161385, gnorm=0.275, loss_scale=8, train_wall=179, wall=232168
2021-03-17 02:06:35 | INFO | train_inner | epoch 007:   3051 / 20258 loss=3.506, nll_loss=1.816, ppl=3.52, wps=27923.3, ups=0.55, wpb=51070.6, bsz=3180.2, num_updates=124500, lr=0.00016132, gnorm=0.265, loss_scale=8, train_wall=180, wall=232351
2021-03-17 02:09:38 | INFO | train_inner | epoch 007:   3151 / 20258 loss=3.52, nll_loss=1.831, ppl=3.56, wps=27889.1, ups=0.55, wpb=50877.4, bsz=2906, num_updates=124600, lr=0.000161255, gnorm=0.27, loss_scale=8, train_wall=179, wall=232533
2021-03-17 02:12:40 | INFO | train_inner | epoch 007:   3251 / 20258 loss=3.511, nll_loss=1.822, ppl=3.53, wps=27854.8, ups=0.55, wpb=50894.3, bsz=3066.2, num_updates=124700, lr=0.00016119, gnorm=0.27, loss_scale=8, train_wall=180, wall=232716
2021-03-17 02:15:43 | INFO | train_inner | epoch 007:   3351 / 20258 loss=3.503, nll_loss=1.812, ppl=3.51, wps=27969.4, ups=0.55, wpb=51116.6, bsz=2944.8, num_updates=124800, lr=0.000161126, gnorm=0.27, loss_scale=16, train_wall=180, wall=232899
2021-03-17 02:18:45 | INFO | train_inner | epoch 007:   3451 / 20258 loss=3.515, nll_loss=1.826, ppl=3.55, wps=27781.6, ups=0.55, wpb=50651.6, bsz=3040.7, num_updates=124900, lr=0.000161061, gnorm=0.269, loss_scale=16, train_wall=179, wall=233081
2021-03-17 02:19:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 02:21:50 | INFO | train_inner | epoch 007:   3552 / 20258 loss=3.513, nll_loss=1.824, ppl=3.54, wps=27743.3, ups=0.54, wpb=51197, bsz=3012.9, num_updates=125000, lr=0.000160997, gnorm=0.269, loss_scale=8, train_wall=181, wall=233265
2021-03-17 02:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 02:21:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:21:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:21:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:21:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:21:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:21:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:21:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:21:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:21:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:21:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:21:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:21:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:21:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:21:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:21:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:21:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:21:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:21:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:21:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:21:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:21:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:08 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.938 | nll_loss 2.22 | ppl 4.66 | bleu 29.68 | wps 4394.4 | wpb 2432 | bsz 90.4 | num_updates 125000 | best_loss 3.932
2021-03-17 02:22:08 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 02:22:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:22:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 02:22:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 02:22:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 02:23:00 | INFO | valid1 | epoch 007 | valid on 'valid1' subset | loss 3.933 | nll_loss 2.24 | ppl 4.72 | bleu 27.43 | wps 4267.5 | wpb 2359.4 | bsz 106.4 | num_updates 125000 | best_loss 3.932
2021-03-17 02:23:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 02:23:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_7_125000.pt (epoch 7 @ 125000 updates, score 3.938) (writing took 4.531023014103994 seconds)
2021-03-17 02:26:07 | INFO | train_inner | epoch 007:   3652 / 20258 loss=3.512, nll_loss=1.823, ppl=3.54, wps=19710.7, ups=0.39, wpb=50705.2, bsz=3003, num_updates=125100, lr=0.000160933, gnorm=0.277, loss_scale=8, train_wall=179, wall=233523
2021-03-17 02:29:09 | INFO | train_inner | epoch 007:   3752 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27892.7, ups=0.55, wpb=50843.8, bsz=2791.8, num_updates=125200, lr=0.000160868, gnorm=0.272, loss_scale=8, train_wall=179, wall=233705
2021-03-17 02:32:12 | INFO | train_inner | epoch 007:   3852 / 20258 loss=3.518, nll_loss=1.829, ppl=3.55, wps=27956.3, ups=0.55, wpb=51107, bsz=2974.9, num_updates=125300, lr=0.000160804, gnorm=0.27, loss_scale=8, train_wall=180, wall=233888
2021-03-17 02:35:15 | INFO | train_inner | epoch 007:   3952 / 20258 loss=3.511, nll_loss=1.821, ppl=3.53, wps=27963.1, ups=0.55, wpb=51052.2, bsz=2956.3, num_updates=125400, lr=0.00016074, gnorm=0.266, loss_scale=8, train_wall=180, wall=234070
2021-03-17 02:38:17 | INFO | train_inner | epoch 007:   4052 / 20258 loss=3.518, nll_loss=1.828, ppl=3.55, wps=27675.9, ups=0.55, wpb=50339.2, bsz=2941.1, num_updates=125500, lr=0.000160676, gnorm=0.274, loss_scale=8, train_wall=179, wall=234252
2021-03-17 02:40:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-17 02:41:22 | INFO | train_inner | epoch 007:   4153 / 20258 loss=3.509, nll_loss=1.819, ppl=3.53, wps=27646.3, ups=0.54, wpb=51187.7, bsz=3074.6, num_updates=125600, lr=0.000160612, gnorm=0.269, loss_scale=4, train_wall=182, wall=234437
2021-03-17 02:44:24 | INFO | train_inner | epoch 007:   4253 / 20258 loss=3.523, nll_loss=1.835, ppl=3.57, wps=27908.6, ups=0.55, wpb=50881.1, bsz=3062.6, num_updates=125700, lr=0.000160548, gnorm=0.274, loss_scale=4, train_wall=179, wall=234620
2021-03-17 02:47:27 | INFO | train_inner | epoch 007:   4353 / 20258 loss=3.509, nll_loss=1.819, ppl=3.53, wps=28025.5, ups=0.55, wpb=51351.9, bsz=3090.2, num_updates=125800, lr=0.000160484, gnorm=0.272, loss_scale=4, train_wall=180, wall=234803
2021-03-17 02:50:29 | INFO | train_inner | epoch 007:   4453 / 20258 loss=3.512, nll_loss=1.822, ppl=3.54, wps=27696, ups=0.55, wpb=50403.4, bsz=2840.8, num_updates=125900, lr=0.00016042, gnorm=0.275, loss_scale=4, train_wall=179, wall=234985
2021-03-17 02:53:32 | INFO | train_inner | epoch 007:   4553 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27780.5, ups=0.55, wpb=50704.2, bsz=2916, num_updates=126000, lr=0.000160357, gnorm=0.273, loss_scale=4, train_wall=179, wall=235167
2021-03-17 02:56:35 | INFO | train_inner | epoch 007:   4653 / 20258 loss=3.505, nll_loss=1.815, ppl=3.52, wps=27800.3, ups=0.55, wpb=50826.2, bsz=3187.2, num_updates=126100, lr=0.000160293, gnorm=0.271, loss_scale=4, train_wall=180, wall=235350
2021-03-17 02:59:38 | INFO | train_inner | epoch 007:   4753 / 20258 loss=3.513, nll_loss=1.823, ppl=3.54, wps=27901.8, ups=0.54, wpb=51202.9, bsz=2957.8, num_updates=126200, lr=0.00016023, gnorm=0.266, loss_scale=4, train_wall=180, wall=235534
2021-03-17 03:02:41 | INFO | train_inner | epoch 007:   4853 / 20258 loss=3.506, nll_loss=1.815, ppl=3.52, wps=27988.8, ups=0.55, wpb=51248.3, bsz=3026.2, num_updates=126300, lr=0.000160166, gnorm=0.267, loss_scale=4, train_wall=180, wall=235717
2021-03-17 03:05:43 | INFO | train_inner | epoch 007:   4953 / 20258 loss=3.511, nll_loss=1.821, ppl=3.53, wps=27873.2, ups=0.55, wpb=50762.7, bsz=2959.4, num_updates=126400, lr=0.000160103, gnorm=0.27, loss_scale=4, train_wall=179, wall=235899
2021-03-17 03:08:47 | INFO | train_inner | epoch 007:   5053 / 20258 loss=3.52, nll_loss=1.831, ppl=3.56, wps=27937, ups=0.55, wpb=51177, bsz=3016.3, num_updates=126500, lr=0.00016004, gnorm=0.272, loss_scale=4, train_wall=180, wall=236082
2021-03-17 03:11:50 | INFO | train_inner | epoch 007:   5153 / 20258 loss=3.504, nll_loss=1.813, ppl=3.51, wps=27905.7, ups=0.55, wpb=51058.3, bsz=2986.2, num_updates=126600, lr=0.000159976, gnorm=0.274, loss_scale=8, train_wall=180, wall=236265
2021-03-17 03:14:52 | INFO | train_inner | epoch 007:   5253 / 20258 loss=3.507, nll_loss=1.818, ppl=3.53, wps=27904.3, ups=0.55, wpb=50949.1, bsz=3100.7, num_updates=126700, lr=0.000159913, gnorm=0.268, loss_scale=8, train_wall=180, wall=236448
2021-03-17 03:15:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-17 03:17:57 | INFO | train_inner | epoch 007:   5354 / 20258 loss=3.515, nll_loss=1.826, ppl=3.54, wps=27513, ups=0.54, wpb=50735.4, bsz=2971.4, num_updates=126800, lr=0.00015985, gnorm=0.273, loss_scale=4, train_wall=181, wall=236632
2021-03-17 03:21:00 | INFO | train_inner | epoch 007:   5454 / 20258 loss=3.509, nll_loss=1.819, ppl=3.53, wps=27809.1, ups=0.55, wpb=50873.8, bsz=2987.8, num_updates=126900, lr=0.000159787, gnorm=0.268, loss_scale=4, train_wall=180, wall=236815
2021-03-17 03:24:01 | INFO | train_inner | epoch 007:   5554 / 20258 loss=3.537, nll_loss=1.851, ppl=3.61, wps=27925.1, ups=0.55, wpb=50779.1, bsz=2983.2, num_updates=127000, lr=0.000159724, gnorm=0.276, loss_scale=4, train_wall=179, wall=236997
2021-03-17 03:27:04 | INFO | train_inner | epoch 007:   5654 / 20258 loss=3.528, nll_loss=1.841, ppl=3.58, wps=27864.9, ups=0.55, wpb=50750.3, bsz=3094.6, num_updates=127100, lr=0.000159661, gnorm=0.271, loss_scale=4, train_wall=179, wall=237179
2021-03-17 03:30:06 | INFO | train_inner | epoch 007:   5754 / 20258 loss=3.514, nll_loss=1.825, ppl=3.54, wps=27847.9, ups=0.55, wpb=50813.5, bsz=3071.6, num_updates=127200, lr=0.000159599, gnorm=0.267, loss_scale=4, train_wall=179, wall=237362
2021-03-17 03:33:08 | INFO | train_inner | epoch 007:   5854 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27827.9, ups=0.55, wpb=50720.8, bsz=3089.4, num_updates=127300, lr=0.000159536, gnorm=0.269, loss_scale=4, train_wall=179, wall=237544
2021-03-17 03:36:12 | INFO | train_inner | epoch 007:   5954 / 20258 loss=3.509, nll_loss=1.819, ppl=3.53, wps=27894.1, ups=0.55, wpb=51127.1, bsz=3180.5, num_updates=127400, lr=0.000159473, gnorm=0.267, loss_scale=4, train_wall=180, wall=237727
2021-03-17 03:39:15 | INFO | train_inner | epoch 007:   6054 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27875.6, ups=0.55, wpb=51097.5, bsz=3015.8, num_updates=127500, lr=0.000159411, gnorm=0.266, loss_scale=4, train_wall=180, wall=237910
2021-03-17 03:42:17 | INFO | train_inner | epoch 007:   6154 / 20258 loss=3.519, nll_loss=1.831, ppl=3.56, wps=27846.1, ups=0.55, wpb=50729, bsz=2997.5, num_updates=127600, lr=0.000159348, gnorm=0.266, loss_scale=4, train_wall=179, wall=238093
2021-03-17 03:45:19 | INFO | train_inner | epoch 007:   6254 / 20258 loss=3.519, nll_loss=1.83, ppl=3.56, wps=27928.7, ups=0.55, wpb=50875, bsz=3075.8, num_updates=127700, lr=0.000159286, gnorm=0.274, loss_scale=4, train_wall=179, wall=238275
2021-03-17 03:48:22 | INFO | train_inner | epoch 007:   6354 / 20258 loss=3.523, nll_loss=1.834, ppl=3.57, wps=27968.9, ups=0.55, wpb=50993.3, bsz=3008, num_updates=127800, lr=0.000159223, gnorm=0.272, loss_scale=8, train_wall=179, wall=238457
2021-03-17 03:51:25 | INFO | train_inner | epoch 007:   6454 / 20258 loss=3.51, nll_loss=1.821, ppl=3.53, wps=27796.4, ups=0.55, wpb=50911, bsz=3027, num_updates=127900, lr=0.000159161, gnorm=0.272, loss_scale=8, train_wall=180, wall=238640
2021-03-17 03:54:28 | INFO | train_inner | epoch 007:   6554 / 20258 loss=3.506, nll_loss=1.816, ppl=3.52, wps=27781, ups=0.55, wpb=50795.3, bsz=3053.4, num_updates=128000, lr=0.000159099, gnorm=0.269, loss_scale=8, train_wall=179, wall=238823
2021-03-17 03:57:30 | INFO | train_inner | epoch 007:   6654 / 20258 loss=3.534, nll_loss=1.847, ppl=3.6, wps=28050.2, ups=0.55, wpb=51166, bsz=2949.3, num_updates=128100, lr=0.000159037, gnorm=0.27, loss_scale=8, train_wall=180, wall=239005
2021-03-17 04:00:33 | INFO | train_inner | epoch 007:   6754 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27924.7, ups=0.55, wpb=50999.3, bsz=2991.5, num_updates=128200, lr=0.000158975, gnorm=0.274, loss_scale=8, train_wall=179, wall=239188
2021-03-17 04:03:35 | INFO | train_inner | epoch 007:   6854 / 20258 loss=3.512, nll_loss=1.823, ppl=3.54, wps=27880.3, ups=0.55, wpb=50909.8, bsz=3103, num_updates=128300, lr=0.000158913, gnorm=0.268, loss_scale=8, train_wall=179, wall=239371
2021-03-17 04:06:38 | INFO | train_inner | epoch 007:   6954 / 20258 loss=3.513, nll_loss=1.823, ppl=3.54, wps=27925.8, ups=0.55, wpb=51000.4, bsz=2924.2, num_updates=128400, lr=0.000158851, gnorm=0.271, loss_scale=8, train_wall=179, wall=239553
2021-03-17 04:09:39 | INFO | train_inner | epoch 007:   7054 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27910.5, ups=0.55, wpb=50702.6, bsz=2877.8, num_updates=128500, lr=0.000158789, gnorm=0.281, loss_scale=8, train_wall=179, wall=239735
2021-03-17 04:12:42 | INFO | train_inner | epoch 007:   7154 / 20258 loss=3.517, nll_loss=1.828, ppl=3.55, wps=27950.6, ups=0.55, wpb=51111.7, bsz=3027, num_updates=128600, lr=0.000158727, gnorm=0.267, loss_scale=8, train_wall=180, wall=239918
2021-03-17 04:15:45 | INFO | train_inner | epoch 007:   7254 / 20258 loss=3.513, nll_loss=1.824, ppl=3.54, wps=27808.2, ups=0.55, wpb=50773.1, bsz=2906, num_updates=128700, lr=0.000158666, gnorm=0.271, loss_scale=8, train_wall=179, wall=240100
2021-03-17 04:18:47 | INFO | train_inner | epoch 007:   7354 / 20258 loss=3.531, nll_loss=1.844, ppl=3.59, wps=27942.1, ups=0.55, wpb=50991.9, bsz=2893.8, num_updates=128800, lr=0.000158604, gnorm=0.273, loss_scale=16, train_wall=179, wall=240283
2021-03-17 04:19:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 04:21:52 | INFO | train_inner | epoch 007:   7455 / 20258 loss=3.524, nll_loss=1.837, ppl=3.57, wps=27583.7, ups=0.54, wpb=50815.4, bsz=3023.5, num_updates=128900, lr=0.000158543, gnorm=0.289, loss_scale=8, train_wall=181, wall=240467
2021-03-17 04:24:54 | INFO | train_inner | epoch 007:   7555 / 20258 loss=3.529, nll_loss=1.841, ppl=3.58, wps=27880.6, ups=0.55, wpb=50980.3, bsz=3086.7, num_updates=129000, lr=0.000158481, gnorm=0.277, loss_scale=8, train_wall=179, wall=240650
2021-03-17 04:27:57 | INFO | train_inner | epoch 007:   7655 / 20258 loss=3.526, nll_loss=1.839, ppl=3.58, wps=27941.5, ups=0.55, wpb=51140.9, bsz=2988.9, num_updates=129100, lr=0.00015842, gnorm=0.272, loss_scale=8, train_wall=180, wall=240833
2021-03-17 04:31:00 | INFO | train_inner | epoch 007:   7755 / 20258 loss=3.516, nll_loss=1.827, ppl=3.55, wps=27826.8, ups=0.55, wpb=50768, bsz=3006.6, num_updates=129200, lr=0.000158358, gnorm=0.271, loss_scale=8, train_wall=179, wall=241015
2021-03-17 04:34:03 | INFO | train_inner | epoch 007:   7855 / 20258 loss=3.506, nll_loss=1.816, ppl=3.52, wps=27863.9, ups=0.55, wpb=50920.4, bsz=3120.4, num_updates=129300, lr=0.000158297, gnorm=0.268, loss_scale=8, train_wall=179, wall=241198
2021-03-17 04:37:05 | INFO | train_inner | epoch 007:   7955 / 20258 loss=3.545, nll_loss=1.859, ppl=3.63, wps=28099.9, ups=0.55, wpb=51222.5, bsz=2966.4, num_updates=129400, lr=0.000158236, gnorm=0.278, loss_scale=8, train_wall=179, wall=241381
2021-03-17 04:40:08 | INFO | train_inner | epoch 007:   8055 / 20258 loss=3.505, nll_loss=1.814, ppl=3.52, wps=27933.8, ups=0.55, wpb=51005.4, bsz=3024.8, num_updates=129500, lr=0.000158175, gnorm=0.267, loss_scale=8, train_wall=180, wall=241563
2021-03-17 04:43:10 | INFO | train_inner | epoch 007:   8155 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27809.3, ups=0.55, wpb=50620.2, bsz=3067.8, num_updates=129600, lr=0.000158114, gnorm=0.279, loss_scale=8, train_wall=179, wall=241745
2021-03-17 04:46:12 | INFO | train_inner | epoch 007:   8255 / 20258 loss=3.523, nll_loss=1.835, ppl=3.57, wps=27818.2, ups=0.55, wpb=50622.1, bsz=3016.8, num_updates=129700, lr=0.000158053, gnorm=0.269, loss_scale=8, train_wall=179, wall=241927
2021-03-17 04:49:13 | INFO | train_inner | epoch 007:   8355 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27827.8, ups=0.55, wpb=50612.2, bsz=3112.3, num_updates=129800, lr=0.000157992, gnorm=0.272, loss_scale=8, train_wall=179, wall=242109
2021-03-17 04:52:16 | INFO | train_inner | epoch 007:   8455 / 20258 loss=3.508, nll_loss=1.818, ppl=3.53, wps=27724.9, ups=0.55, wpb=50501, bsz=3016.9, num_updates=129900, lr=0.000157931, gnorm=0.27, loss_scale=16, train_wall=179, wall=242291
2021-03-17 04:55:19 | INFO | train_inner | epoch 007:   8555 / 20258 loss=3.513, nll_loss=1.824, ppl=3.54, wps=27902.2, ups=0.55, wpb=51104.6, bsz=3086.8, num_updates=130000, lr=0.00015787, gnorm=0.269, loss_scale=16, train_wall=179, wall=242474
2021-03-17 04:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 04:55:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:37 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.93 | nll_loss 2.214 | ppl 4.64 | bleu 29.57 | wps 4394.8 | wpb 2432 | bsz 90.4 | num_updates 130000 | best_loss 3.93
2021-03-17 04:55:37 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 04:55:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:55:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:55:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:55:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:56:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:56:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:56:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:56:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 04:56:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 04:56:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 04:56:30 | INFO | valid1 | epoch 007 | valid on 'valid1' subset | loss 3.923 | nll_loss 2.232 | ppl 4.7 | bleu 27.89 | wps 4258.7 | wpb 2359.4 | bsz 106.4 | num_updates 130000 | best_loss 3.923
2021-03-17 04:56:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 04:56:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_7_130000.pt (epoch 7 @ 130000 updates, score 3.93) (writing took 6.406002748059109 seconds)
2021-03-17 04:59:39 | INFO | train_inner | epoch 007:   8655 / 20258 loss=3.523, nll_loss=1.835, ppl=3.57, wps=19596.6, ups=0.38, wpb=50901.6, bsz=2978.9, num_updates=130100, lr=0.00015781, gnorm=0.27, loss_scale=16, train_wall=179, wall=242734
2021-03-17 05:02:42 | INFO | train_inner | epoch 007:   8755 / 20258 loss=3.508, nll_loss=1.818, ppl=3.53, wps=27799.8, ups=0.55, wpb=50898.2, bsz=2929.3, num_updates=130200, lr=0.000157749, gnorm=0.269, loss_scale=16, train_wall=180, wall=242917
2021-03-17 05:05:44 | INFO | train_inner | epoch 007:   8855 / 20258 loss=3.525, nll_loss=1.838, ppl=3.57, wps=27916.5, ups=0.55, wpb=50917.2, bsz=2961.8, num_updates=130300, lr=0.000157689, gnorm=0.266, loss_scale=16, train_wall=179, wall=243100
2021-03-17 05:08:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 05:08:49 | INFO | train_inner | epoch 007:   8956 / 20258 loss=3.5, nll_loss=1.809, ppl=3.5, wps=27516.5, ups=0.54, wpb=50833.3, bsz=3041.2, num_updates=130400, lr=0.000157628, gnorm=0.266, loss_scale=8, train_wall=182, wall=243284
2021-03-17 05:11:51 | INFO | train_inner | epoch 007:   9056 / 20258 loss=3.524, nll_loss=1.836, ppl=3.57, wps=27805.2, ups=0.55, wpb=50648.8, bsz=3112.9, num_updates=130500, lr=0.000157568, gnorm=0.273, loss_scale=8, train_wall=179, wall=243466
2021-03-17 05:14:54 | INFO | train_inner | epoch 007:   9156 / 20258 loss=3.506, nll_loss=1.816, ppl=3.52, wps=27900.9, ups=0.55, wpb=51132, bsz=3096.5, num_updates=130600, lr=0.000157507, gnorm=0.27, loss_scale=8, train_wall=180, wall=243650
2021-03-17 05:17:57 | INFO | train_inner | epoch 007:   9256 / 20258 loss=3.51, nll_loss=1.82, ppl=3.53, wps=27940.5, ups=0.55, wpb=50994.6, bsz=2942.8, num_updates=130700, lr=0.000157447, gnorm=0.272, loss_scale=8, train_wall=180, wall=243832
2021-03-17 05:20:59 | INFO | train_inner | epoch 007:   9356 / 20258 loss=3.504, nll_loss=1.815, ppl=3.52, wps=27859.3, ups=0.55, wpb=50916.3, bsz=3230.9, num_updates=130800, lr=0.000157387, gnorm=0.277, loss_scale=8, train_wall=179, wall=244015
2021-03-17 05:24:01 | INFO | train_inner | epoch 007:   9456 / 20258 loss=3.52, nll_loss=1.831, ppl=3.56, wps=27999.8, ups=0.55, wpb=50832.5, bsz=2939.3, num_updates=130900, lr=0.000157327, gnorm=0.273, loss_scale=8, train_wall=178, wall=244197
2021-03-17 05:27:03 | INFO | train_inner | epoch 007:   9556 / 20258 loss=3.526, nll_loss=1.838, ppl=3.58, wps=27964.9, ups=0.55, wpb=50996.9, bsz=2948.1, num_updates=131000, lr=0.000157267, gnorm=0.277, loss_scale=8, train_wall=179, wall=244379
2021-03-17 05:30:05 | INFO | train_inner | epoch 007:   9656 / 20258 loss=3.526, nll_loss=1.838, ppl=3.58, wps=27929.5, ups=0.55, wpb=50820, bsz=3014.5, num_updates=131100, lr=0.000157207, gnorm=0.276, loss_scale=8, train_wall=179, wall=244561
2021-03-17 05:33:07 | INFO | train_inner | epoch 007:   9756 / 20258 loss=3.518, nll_loss=1.829, ppl=3.55, wps=27757.6, ups=0.55, wpb=50467, bsz=2913.1, num_updates=131200, lr=0.000157147, gnorm=0.275, loss_scale=8, train_wall=178, wall=244743
2021-03-17 05:36:10 | INFO | train_inner | epoch 007:   9856 / 20258 loss=3.54, nll_loss=1.854, ppl=3.62, wps=28098.9, ups=0.55, wpb=51356.7, bsz=2901.1, num_updates=131300, lr=0.000157087, gnorm=0.272, loss_scale=8, train_wall=180, wall=244925
2021-03-17 05:39:12 | INFO | train_inner | epoch 007:   9956 / 20258 loss=3.521, nll_loss=1.833, ppl=3.56, wps=27882.8, ups=0.55, wpb=50842.8, bsz=3035.4, num_updates=131400, lr=0.000157027, gnorm=0.273, loss_scale=8, train_wall=179, wall=245108
2021-03-17 05:40:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 05:42:17 | INFO | train_inner | epoch 007:  10057 / 20258 loss=3.519, nll_loss=1.831, ppl=3.56, wps=27712.8, ups=0.54, wpb=51130, bsz=3092.7, num_updates=131500, lr=0.000156967, gnorm=0.272, loss_scale=8, train_wall=181, wall=245292
2021-03-17 05:45:19 | INFO | train_inner | epoch 007:  10157 / 20258 loss=3.521, nll_loss=1.832, ppl=3.56, wps=27917.2, ups=0.55, wpb=50925.7, bsz=2867.2, num_updates=131600, lr=0.000156908, gnorm=0.276, loss_scale=8, train_wall=179, wall=245475
2021-03-17 05:48:22 | INFO | train_inner | epoch 007:  10257 / 20258 loss=3.527, nll_loss=1.839, ppl=3.58, wps=28010.4, ups=0.55, wpb=51125.7, bsz=2952.6, num_updates=131700, lr=0.000156848, gnorm=0.271, loss_scale=8, train_wall=179, wall=245657
2021-03-17 05:51:24 | INFO | train_inner | epoch 007:  10357 / 20258 loss=3.52, nll_loss=1.831, ppl=3.56, wps=27930.7, ups=0.55, wpb=51020.6, bsz=2993.7, num_updates=131800, lr=0.000156789, gnorm=0.271, loss_scale=8, train_wall=179, wall=245840
2021-03-17 05:54:27 | INFO | train_inner | epoch 007:  10457 / 20258 loss=3.53, nll_loss=1.843, ppl=3.59, wps=27905.5, ups=0.55, wpb=50930.4, bsz=3047, num_updates=131900, lr=0.000156729, gnorm=0.273, loss_scale=8, train_wall=179, wall=246022
2021-03-17 05:57:29 | INFO | train_inner | epoch 007:  10557 / 20258 loss=3.514, nll_loss=1.825, ppl=3.54, wps=27893.6, ups=0.55, wpb=50887.5, bsz=2962.4, num_updates=132000, lr=0.00015667, gnorm=0.271, loss_scale=8, train_wall=179, wall=246205
2021-03-17 06:00:32 | INFO | train_inner | epoch 007:  10657 / 20258 loss=3.518, nll_loss=1.829, ppl=3.55, wps=28002.8, ups=0.55, wpb=51133.2, bsz=2955.6, num_updates=132100, lr=0.000156611, gnorm=0.265, loss_scale=8, train_wall=180, wall=246387
2021-03-17 06:03:34 | INFO | train_inner | epoch 007:  10757 / 20258 loss=3.525, nll_loss=1.837, ppl=3.57, wps=27949, ups=0.55, wpb=50875.9, bsz=2965.2, num_updates=132200, lr=0.000156551, gnorm=0.275, loss_scale=8, train_wall=179, wall=246569
2021-03-17 06:06:37 | INFO | train_inner | epoch 007:  10857 / 20258 loss=3.509, nll_loss=1.819, ppl=3.53, wps=27738.7, ups=0.55, wpb=50701.3, bsz=2965.8, num_updates=132300, lr=0.000156492, gnorm=0.266, loss_scale=8, train_wall=179, wall=246752
2021-03-17 06:09:39 | INFO | train_inner | epoch 007:  10957 / 20258 loss=3.527, nll_loss=1.84, ppl=3.58, wps=27783.3, ups=0.55, wpb=50666.2, bsz=3048.7, num_updates=132400, lr=0.000156433, gnorm=0.269, loss_scale=8, train_wall=179, wall=246935
2021-03-17 06:12:42 | INFO | train_inner | epoch 007:  11057 / 20258 loss=3.518, nll_loss=1.83, ppl=3.55, wps=27973.7, ups=0.55, wpb=51082.9, bsz=2960.1, num_updates=132500, lr=0.000156374, gnorm=0.269, loss_scale=16, train_wall=180, wall=247117
2021-03-17 06:15:44 | INFO | train_inner | epoch 007:  11157 / 20258 loss=3.517, nll_loss=1.829, ppl=3.55, wps=27861.5, ups=0.55, wpb=50772.7, bsz=2913.5, num_updates=132600, lr=0.000156315, gnorm=0.273, loss_scale=16, train_wall=179, wall=247299
2021-03-17 06:18:47 | INFO | train_inner | epoch 007:  11257 / 20258 loss=3.512, nll_loss=1.823, ppl=3.54, wps=27967.9, ups=0.55, wpb=51110.8, bsz=3035.2, num_updates=132700, lr=0.000156256, gnorm=0.273, loss_scale=16, train_wall=180, wall=247482
2021-03-17 06:19:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 06:21:51 | INFO | train_inner | epoch 007:  11358 / 20258 loss=3.513, nll_loss=1.825, ppl=3.54, wps=27621.6, ups=0.54, wpb=51036.1, bsz=3035, num_updates=132800, lr=0.000156197, gnorm=0.267, loss_scale=8, train_wall=181, wall=247667
2021-03-17 06:24:55 | INFO | train_inner | epoch 007:  11458 / 20258 loss=3.51, nll_loss=1.82, ppl=3.53, wps=27824.2, ups=0.55, wpb=50965.6, bsz=2976.8, num_updates=132900, lr=0.000156139, gnorm=0.267, loss_scale=8, train_wall=180, wall=247850
2021-03-17 06:27:57 | INFO | train_inner | epoch 007:  11558 / 20258 loss=3.521, nll_loss=1.833, ppl=3.56, wps=28007.1, ups=0.55, wpb=51187.9, bsz=3011.5, num_updates=133000, lr=0.00015608, gnorm=0.269, loss_scale=8, train_wall=180, wall=248033
2021-03-17 06:31:00 | INFO | train_inner | epoch 007:  11658 / 20258 loss=3.519, nll_loss=1.831, ppl=3.56, wps=27830.3, ups=0.55, wpb=50689.3, bsz=3078.6, num_updates=133100, lr=0.000156021, gnorm=0.268, loss_scale=8, train_wall=179, wall=248215
2021-03-17 06:34:02 | INFO | train_inner | epoch 007:  11758 / 20258 loss=3.528, nll_loss=1.84, ppl=3.58, wps=27917.7, ups=0.55, wpb=50829.3, bsz=2836.8, num_updates=133200, lr=0.000155963, gnorm=0.272, loss_scale=8, train_wall=179, wall=248397
2021-03-17 06:37:04 | INFO | train_inner | epoch 007:  11858 / 20258 loss=3.522, nll_loss=1.834, ppl=3.57, wps=28025.8, ups=0.55, wpb=51195.1, bsz=3027.6, num_updates=133300, lr=0.000155904, gnorm=0.27, loss_scale=8, train_wall=179, wall=248580
2021-03-17 06:40:07 | INFO | train_inner | epoch 007:  11958 / 20258 loss=3.518, nll_loss=1.83, ppl=3.56, wps=27750.6, ups=0.55, wpb=50681.8, bsz=3024.5, num_updates=133400, lr=0.000155846, gnorm=0.276, loss_scale=8, train_wall=179, wall=248762
2021-03-17 06:43:09 | INFO | train_inner | epoch 007:  12058 / 20258 loss=3.522, nll_loss=1.834, ppl=3.56, wps=27904.7, ups=0.55, wpb=50882.4, bsz=2969.5, num_updates=133500, lr=0.000155787, gnorm=0.278, loss_scale=8, train_wall=179, wall=248945
2021-03-17 06:46:12 | INFO | train_inner | epoch 007:  12158 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27823.2, ups=0.55, wpb=50930.7, bsz=3004.6, num_updates=133600, lr=0.000155729, gnorm=0.27, loss_scale=8, train_wall=180, wall=249128
2021-03-17 06:49:15 | INFO | train_inner | epoch 007:  12258 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27803.1, ups=0.55, wpb=50854.9, bsz=3091.5, num_updates=133700, lr=0.000155671, gnorm=0.268, loss_scale=8, train_wall=180, wall=249311
2021-03-17 06:52:18 | INFO | train_inner | epoch 007:  12358 / 20258 loss=3.52, nll_loss=1.833, ppl=3.56, wps=27833.1, ups=0.55, wpb=50893.1, bsz=3088.5, num_updates=133800, lr=0.000155612, gnorm=0.263, loss_scale=16, train_wall=179, wall=249494
2021-03-17 06:55:21 | INFO | train_inner | epoch 007:  12458 / 20258 loss=3.509, nll_loss=1.819, ppl=3.53, wps=27831.3, ups=0.55, wpb=51020.9, bsz=3073.6, num_updates=133900, lr=0.000155554, gnorm=0.269, loss_scale=16, train_wall=180, wall=249677
2021-03-17 06:58:24 | INFO | train_inner | epoch 007:  12558 / 20258 loss=3.513, nll_loss=1.824, ppl=3.54, wps=27731.2, ups=0.55, wpb=50668.4, bsz=2993.4, num_updates=134000, lr=0.000155496, gnorm=0.271, loss_scale=16, train_wall=179, wall=249860
2021-03-17 07:01:27 | INFO | train_inner | epoch 007:  12658 / 20258 loss=3.516, nll_loss=1.828, ppl=3.55, wps=27906.4, ups=0.55, wpb=51001.5, bsz=3001.2, num_updates=134100, lr=0.000155438, gnorm=0.269, loss_scale=16, train_wall=179, wall=250042
2021-03-17 07:04:30 | INFO | train_inner | epoch 007:  12758 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27941, ups=0.55, wpb=51118.2, bsz=3115.8, num_updates=134200, lr=0.00015538, gnorm=0.272, loss_scale=16, train_wall=180, wall=250225
2021-03-17 07:06:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 07:07:35 | INFO | train_inner | epoch 007:  12859 / 20258 loss=3.514, nll_loss=1.825, ppl=3.54, wps=27580.4, ups=0.54, wpb=50963, bsz=3081.4, num_updates=134300, lr=0.000155323, gnorm=0.264, loss_scale=8, train_wall=181, wall=250410
2021-03-17 07:10:37 | INFO | train_inner | epoch 007:  12959 / 20258 loss=3.521, nll_loss=1.834, ppl=3.57, wps=27774.7, ups=0.55, wpb=50702.7, bsz=3193.1, num_updates=134400, lr=0.000155265, gnorm=0.275, loss_scale=8, train_wall=179, wall=250593
2021-03-17 07:13:40 | INFO | train_inner | epoch 007:  13059 / 20258 loss=3.519, nll_loss=1.831, ppl=3.56, wps=27829.7, ups=0.55, wpb=50818, bsz=3123.2, num_updates=134500, lr=0.000155207, gnorm=0.272, loss_scale=8, train_wall=179, wall=250775
2021-03-17 07:16:42 | INFO | train_inner | epoch 007:  13159 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27842.8, ups=0.55, wpb=50688, bsz=2922.8, num_updates=134600, lr=0.000155149, gnorm=0.271, loss_scale=8, train_wall=179, wall=250957
2021-03-17 07:19:45 | INFO | train_inner | epoch 007:  13259 / 20258 loss=3.504, nll_loss=1.814, ppl=3.52, wps=27884.7, ups=0.55, wpb=50984.3, bsz=3031.5, num_updates=134700, lr=0.000155092, gnorm=0.267, loss_scale=8, train_wall=180, wall=251140
2021-03-17 07:22:47 | INFO | train_inner | epoch 007:  13359 / 20258 loss=3.511, nll_loss=1.822, ppl=3.54, wps=27854.8, ups=0.55, wpb=50874.8, bsz=2957.2, num_updates=134800, lr=0.000155034, gnorm=0.267, loss_scale=8, train_wall=179, wall=251323
2021-03-17 07:25:50 | INFO | train_inner | epoch 007:  13459 / 20258 loss=3.515, nll_loss=1.826, ppl=3.55, wps=27928.8, ups=0.55, wpb=50979.7, bsz=3098.9, num_updates=134900, lr=0.000154977, gnorm=0.28, loss_scale=8, train_wall=179, wall=251505
2021-03-17 07:28:52 | INFO | train_inner | epoch 007:  13559 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27967.8, ups=0.55, wpb=50855.1, bsz=3015.6, num_updates=135000, lr=0.000154919, gnorm=0.274, loss_scale=8, train_wall=179, wall=251687
2021-03-17 07:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 07:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:28:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:28:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:28:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:28:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:28:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:28:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:28:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:28:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:28:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:28:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:28:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:28:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:28:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:28:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:28:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:28:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:28:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:28:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:10 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.926 | nll_loss 2.21 | ppl 4.63 | bleu 29.51 | wps 4362.8 | wpb 2432 | bsz 90.4 | num_updates 135000 | best_loss 3.926
2021-03-17 07:29:10 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 07:29:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:29:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 07:29:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 07:29:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 07:30:03 | INFO | valid1 | epoch 007 | valid on 'valid1' subset | loss 3.923 | nll_loss 2.231 | ppl 4.69 | bleu 27.33 | wps 4208.1 | wpb 2359.4 | bsz 106.4 | num_updates 135000 | best_loss 3.923
2021-03-17 07:30:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 07:30:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_7_135000.pt (epoch 7 @ 135000 updates, score 3.926) (writing took 6.519675350049511 seconds)
2021-03-17 07:33:12 | INFO | train_inner | epoch 007:  13659 / 20258 loss=3.513, nll_loss=1.825, ppl=3.54, wps=19542.3, ups=0.38, wpb=50851.3, bsz=3031.2, num_updates=135100, lr=0.000154862, gnorm=0.271, loss_scale=8, train_wall=179, wall=251947
2021-03-17 07:36:14 | INFO | train_inner | epoch 007:  13759 / 20258 loss=3.516, nll_loss=1.827, ppl=3.55, wps=27898.8, ups=0.55, wpb=50863.6, bsz=3083.4, num_updates=135200, lr=0.000154805, gnorm=0.272, loss_scale=8, train_wall=179, wall=252130
2021-03-17 07:39:16 | INFO | train_inner | epoch 007:  13859 / 20258 loss=3.515, nll_loss=1.826, ppl=3.55, wps=27973, ups=0.55, wpb=50821.9, bsz=2948.8, num_updates=135300, lr=0.000154747, gnorm=0.278, loss_scale=16, train_wall=179, wall=252311
2021-03-17 07:42:19 | INFO | train_inner | epoch 007:  13959 / 20258 loss=3.506, nll_loss=1.817, ppl=3.52, wps=27926.9, ups=0.55, wpb=51069.1, bsz=3050.7, num_updates=135400, lr=0.00015469, gnorm=0.268, loss_scale=16, train_wall=180, wall=252494
2021-03-17 07:44:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 07:45:23 | INFO | train_inner | epoch 007:  14060 / 20258 loss=3.522, nll_loss=1.834, ppl=3.57, wps=27639.9, ups=0.54, wpb=50997.6, bsz=2966.5, num_updates=135500, lr=0.000154633, gnorm=0.277, loss_scale=8, train_wall=181, wall=252679
2021-03-17 07:48:26 | INFO | train_inner | epoch 007:  14160 / 20258 loss=3.529, nll_loss=1.842, ppl=3.59, wps=28029.9, ups=0.55, wpb=51133.5, bsz=3063, num_updates=135600, lr=0.000154576, gnorm=0.277, loss_scale=8, train_wall=180, wall=252861
2021-03-17 07:51:28 | INFO | train_inner | epoch 007:  14260 / 20258 loss=3.52, nll_loss=1.833, ppl=3.56, wps=27960.1, ups=0.55, wpb=51120.7, bsz=3055.8, num_updates=135700, lr=0.000154519, gnorm=0.271, loss_scale=8, train_wall=180, wall=253044
2021-03-17 07:54:31 | INFO | train_inner | epoch 007:  14360 / 20258 loss=3.511, nll_loss=1.821, ppl=3.53, wps=27798.8, ups=0.55, wpb=50820.1, bsz=2893.4, num_updates=135800, lr=0.000154462, gnorm=0.27, loss_scale=8, train_wall=179, wall=253227
2021-03-17 07:57:34 | INFO | train_inner | epoch 007:  14460 / 20258 loss=3.509, nll_loss=1.82, ppl=3.53, wps=27893.9, ups=0.55, wpb=50909.7, bsz=3083.6, num_updates=135900, lr=0.000154406, gnorm=0.269, loss_scale=8, train_wall=179, wall=253409
2021-03-17 08:00:36 | INFO | train_inner | epoch 007:  14560 / 20258 loss=3.504, nll_loss=1.814, ppl=3.52, wps=27840.9, ups=0.55, wpb=50802, bsz=3010.5, num_updates=136000, lr=0.000154349, gnorm=0.267, loss_scale=8, train_wall=179, wall=253592
2021-03-17 08:03:39 | INFO | train_inner | epoch 007:  14660 / 20258 loss=3.518, nll_loss=1.83, ppl=3.55, wps=27931.7, ups=0.55, wpb=51127.2, bsz=2996.5, num_updates=136100, lr=0.000154292, gnorm=0.276, loss_scale=8, train_wall=180, wall=253775
2021-03-17 08:06:41 | INFO | train_inner | epoch 007:  14760 / 20258 loss=3.524, nll_loss=1.837, ppl=3.57, wps=27928.3, ups=0.55, wpb=50846.4, bsz=2927.5, num_updates=136200, lr=0.000154235, gnorm=0.275, loss_scale=8, train_wall=179, wall=253957
2021-03-17 08:09:44 | INFO | train_inner | epoch 007:  14860 / 20258 loss=3.514, nll_loss=1.826, ppl=3.54, wps=27957.6, ups=0.55, wpb=50940.2, bsz=3047.8, num_updates=136300, lr=0.000154179, gnorm=0.273, loss_scale=8, train_wall=179, wall=254139
2021-03-17 08:12:46 | INFO | train_inner | epoch 007:  14960 / 20258 loss=3.52, nll_loss=1.833, ppl=3.56, wps=27890.7, ups=0.55, wpb=50740.5, bsz=2987.7, num_updates=136400, lr=0.000154122, gnorm=0.272, loss_scale=8, train_wall=179, wall=254321
2021-03-17 08:15:48 | INFO | train_inner | epoch 007:  15060 / 20258 loss=3.516, nll_loss=1.828, ppl=3.55, wps=27956.1, ups=0.55, wpb=51017.6, bsz=3059.8, num_updates=136500, lr=0.000154066, gnorm=0.27, loss_scale=16, train_wall=179, wall=254504
2021-03-17 08:18:51 | INFO | train_inner | epoch 007:  15160 / 20258 loss=3.522, nll_loss=1.834, ppl=3.57, wps=27886.4, ups=0.55, wpb=50946.7, bsz=3014.4, num_updates=136600, lr=0.000154009, gnorm=0.27, loss_scale=16, train_wall=179, wall=254686
2021-03-17 08:21:53 | INFO | train_inner | epoch 007:  15260 / 20258 loss=3.52, nll_loss=1.833, ppl=3.56, wps=27993.2, ups=0.55, wpb=51073.2, bsz=2999, num_updates=136700, lr=0.000153953, gnorm=0.269, loss_scale=16, train_wall=179, wall=254869
2021-03-17 08:24:56 | INFO | train_inner | epoch 007:  15360 / 20258 loss=3.529, nll_loss=1.842, ppl=3.58, wps=27884.5, ups=0.55, wpb=50913.5, bsz=2993.6, num_updates=136800, lr=0.000153897, gnorm=0.27, loss_scale=16, train_wall=179, wall=255051
2021-03-17 08:27:59 | INFO | train_inner | epoch 007:  15460 / 20258 loss=3.496, nll_loss=1.804, ppl=3.49, wps=27829.9, ups=0.55, wpb=50992.4, bsz=2980.1, num_updates=136900, lr=0.000153841, gnorm=0.271, loss_scale=16, train_wall=180, wall=255235
2021-03-17 08:28:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 08:31:03 | INFO | train_inner | epoch 007:  15561 / 20258 loss=3.525, nll_loss=1.838, ppl=3.57, wps=27648, ups=0.54, wpb=50809.8, bsz=3060.1, num_updates=137000, lr=0.000153784, gnorm=0.274, loss_scale=8, train_wall=181, wall=255418
2021-03-17 08:34:05 | INFO | train_inner | epoch 007:  15661 / 20258 loss=3.518, nll_loss=1.83, ppl=3.56, wps=27892.6, ups=0.55, wpb=50866.6, bsz=2986.8, num_updates=137100, lr=0.000153728, gnorm=0.267, loss_scale=8, train_wall=179, wall=255601
2021-03-17 08:37:07 | INFO | train_inner | epoch 007:  15761 / 20258 loss=3.529, nll_loss=1.843, ppl=3.59, wps=27899.6, ups=0.55, wpb=50814.5, bsz=3052.4, num_updates=137200, lr=0.000153672, gnorm=0.275, loss_scale=8, train_wall=179, wall=255783
2021-03-17 08:40:10 | INFO | train_inner | epoch 007:  15861 / 20258 loss=3.512, nll_loss=1.823, ppl=3.54, wps=27740.7, ups=0.55, wpb=50621.4, bsz=2944.6, num_updates=137300, lr=0.000153616, gnorm=0.271, loss_scale=8, train_wall=179, wall=255965
2021-03-17 08:43:13 | INFO | train_inner | epoch 007:  15961 / 20258 loss=3.501, nll_loss=1.811, ppl=3.51, wps=27854.8, ups=0.55, wpb=50956.3, bsz=3022.2, num_updates=137400, lr=0.00015356, gnorm=0.271, loss_scale=8, train_wall=180, wall=256148
2021-03-17 08:46:15 | INFO | train_inner | epoch 007:  16061 / 20258 loss=3.499, nll_loss=1.809, ppl=3.5, wps=27734.9, ups=0.55, wpb=50645.8, bsz=2981.9, num_updates=137500, lr=0.000153505, gnorm=0.273, loss_scale=8, train_wall=179, wall=256331
2021-03-17 08:49:18 | INFO | train_inner | epoch 007:  16161 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27806.3, ups=0.55, wpb=50801.2, bsz=3119.4, num_updates=137600, lr=0.000153449, gnorm=0.275, loss_scale=8, train_wall=179, wall=256514
2021-03-17 08:52:21 | INFO | train_inner | epoch 007:  16261 / 20258 loss=3.524, nll_loss=1.837, ppl=3.57, wps=27718.7, ups=0.55, wpb=50806.3, bsz=3016.9, num_updates=137700, lr=0.000153393, gnorm=0.273, loss_scale=8, train_wall=179, wall=256697
2021-03-17 08:55:24 | INFO | train_inner | epoch 007:  16361 / 20258 loss=3.511, nll_loss=1.822, ppl=3.54, wps=27847, ups=0.55, wpb=50801.8, bsz=3011.3, num_updates=137800, lr=0.000153337, gnorm=0.274, loss_scale=8, train_wall=179, wall=256879
2021-03-17 08:58:26 | INFO | train_inner | epoch 007:  16461 / 20258 loss=3.521, nll_loss=1.833, ppl=3.56, wps=27992.8, ups=0.55, wpb=50979.6, bsz=3104.2, num_updates=137900, lr=0.000153282, gnorm=0.273, loss_scale=8, train_wall=179, wall=257061
2021-03-17 09:00:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 09:01:30 | INFO | train_inner | epoch 007:  16562 / 20258 loss=3.524, nll_loss=1.838, ppl=3.57, wps=27604, ups=0.54, wpb=50699.8, bsz=3099.5, num_updates=138000, lr=0.000153226, gnorm=0.271, loss_scale=8, train_wall=181, wall=257245
2021-03-17 09:04:32 | INFO | train_inner | epoch 007:  16662 / 20258 loss=3.515, nll_loss=1.826, ppl=3.55, wps=27755.5, ups=0.55, wpb=50758.4, bsz=3023.9, num_updates=138100, lr=0.000153171, gnorm=0.27, loss_scale=8, train_wall=179, wall=257428
2021-03-17 09:07:35 | INFO | train_inner | epoch 007:  16762 / 20258 loss=3.512, nll_loss=1.823, ppl=3.54, wps=27872.5, ups=0.55, wpb=50818.6, bsz=2939.6, num_updates=138200, lr=0.000153115, gnorm=0.273, loss_scale=8, train_wall=179, wall=257610
2021-03-17 09:10:37 | INFO | train_inner | epoch 007:  16862 / 20258 loss=3.507, nll_loss=1.818, ppl=3.53, wps=27867.4, ups=0.55, wpb=50883.7, bsz=2968.5, num_updates=138300, lr=0.00015306, gnorm=0.267, loss_scale=8, train_wall=180, wall=257793
2021-03-17 09:13:40 | INFO | train_inner | epoch 007:  16962 / 20258 loss=3.514, nll_loss=1.825, ppl=3.54, wps=27872.4, ups=0.55, wpb=50878.6, bsz=3012.6, num_updates=138400, lr=0.000153005, gnorm=0.27, loss_scale=8, train_wall=179, wall=257975
2021-03-17 09:16:42 | INFO | train_inner | epoch 007:  17062 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27894, ups=0.55, wpb=50806.4, bsz=2998.7, num_updates=138500, lr=0.000152949, gnorm=0.268, loss_scale=8, train_wall=179, wall=258158
2021-03-17 09:19:45 | INFO | train_inner | epoch 007:  17162 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27942.7, ups=0.55, wpb=51023.9, bsz=3053, num_updates=138600, lr=0.000152894, gnorm=0.273, loss_scale=8, train_wall=180, wall=258340
2021-03-17 09:22:47 | INFO | train_inner | epoch 007:  17262 / 20258 loss=3.504, nll_loss=1.814, ppl=3.52, wps=27969.6, ups=0.55, wpb=51068.2, bsz=2867.1, num_updates=138700, lr=0.000152839, gnorm=0.267, loss_scale=8, train_wall=180, wall=258523
2021-03-17 09:25:50 | INFO | train_inner | epoch 007:  17362 / 20258 loss=3.516, nll_loss=1.828, ppl=3.55, wps=27836.6, ups=0.55, wpb=50820.9, bsz=3221.8, num_updates=138800, lr=0.000152784, gnorm=0.274, loss_scale=8, train_wall=179, wall=258705
2021-03-17 09:28:52 | INFO | train_inner | epoch 007:  17462 / 20258 loss=3.525, nll_loss=1.838, ppl=3.57, wps=27934, ups=0.55, wpb=50786.7, bsz=2980.6, num_updates=138900, lr=0.000152729, gnorm=0.276, loss_scale=8, train_wall=179, wall=258887
2021-03-17 09:31:54 | INFO | train_inner | epoch 007:  17562 / 20258 loss=3.504, nll_loss=1.815, ppl=3.52, wps=27822.1, ups=0.55, wpb=50829.9, bsz=3027.8, num_updates=139000, lr=0.000152674, gnorm=0.267, loss_scale=8, train_wall=179, wall=259070
2021-03-17 09:34:56 | INFO | train_inner | epoch 007:  17662 / 20258 loss=3.505, nll_loss=1.815, ppl=3.52, wps=27954.1, ups=0.55, wpb=50888.2, bsz=2856.9, num_updates=139100, lr=0.000152619, gnorm=0.271, loss_scale=16, train_wall=179, wall=259252
2021-03-17 09:37:58 | INFO | train_inner | epoch 007:  17762 / 20258 loss=3.518, nll_loss=1.83, ppl=3.56, wps=28024.4, ups=0.55, wpb=50948.7, bsz=2968.6, num_updates=139200, lr=0.000152564, gnorm=0.273, loss_scale=16, train_wall=179, wall=259434
2021-03-17 09:41:00 | INFO | train_inner | epoch 007:  17862 / 20258 loss=3.529, nll_loss=1.842, ppl=3.59, wps=27929.8, ups=0.55, wpb=50934, bsz=3002.4, num_updates=139300, lr=0.00015251, gnorm=0.269, loss_scale=16, train_wall=179, wall=259616
2021-03-17 09:41:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 09:44:05 | INFO | train_inner | epoch 007:  17963 / 20258 loss=3.5, nll_loss=1.809, ppl=3.5, wps=27540.2, ups=0.54, wpb=50895.6, bsz=2938.2, num_updates=139400, lr=0.000152455, gnorm=0.274, loss_scale=8, train_wall=181, wall=259801
2021-03-17 09:44:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-17 09:47:10 | INFO | train_inner | epoch 007:  18064 / 20258 loss=3.53, nll_loss=1.843, ppl=3.59, wps=27682.9, ups=0.54, wpb=51008.2, bsz=2939.1, num_updates=139500, lr=0.0001524, gnorm=0.274, loss_scale=4, train_wall=181, wall=259985
2021-03-17 09:50:12 | INFO | train_inner | epoch 007:  18164 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27936.9, ups=0.55, wpb=50950.5, bsz=3043.7, num_updates=139600, lr=0.000152346, gnorm=0.269, loss_scale=4, train_wall=180, wall=260167
2021-03-17 09:53:15 | INFO | train_inner | epoch 007:  18264 / 20258 loss=3.517, nll_loss=1.828, ppl=3.55, wps=27827.5, ups=0.55, wpb=50913.8, bsz=2899.1, num_updates=139700, lr=0.000152291, gnorm=0.272, loss_scale=4, train_wall=179, wall=260350
2021-03-17 09:56:17 | INFO | train_inner | epoch 007:  18364 / 20258 loss=3.51, nll_loss=1.821, ppl=3.53, wps=27783.2, ups=0.55, wpb=50726.9, bsz=3007.3, num_updates=139800, lr=0.000152237, gnorm=0.274, loss_scale=4, train_wall=179, wall=260533
2021-03-17 09:59:20 | INFO | train_inner | epoch 007:  18464 / 20258 loss=3.516, nll_loss=1.828, ppl=3.55, wps=27718.6, ups=0.55, wpb=50604.3, bsz=3036.2, num_updates=139900, lr=0.000152182, gnorm=0.267, loss_scale=4, train_wall=179, wall=260716
2021-03-17 10:02:22 | INFO | train_inner | epoch 007:  18564 / 20258 loss=3.514, nll_loss=1.826, ppl=3.55, wps=27960, ups=0.55, wpb=51002.9, bsz=3051.3, num_updates=140000, lr=0.000152128, gnorm=0.275, loss_scale=4, train_wall=179, wall=260898
2021-03-17 10:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 10:02:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:41 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.924 | nll_loss 2.213 | ppl 4.64 | bleu 29.54 | wps 4390.5 | wpb 2432 | bsz 90.4 | num_updates 140000 | best_loss 3.924
2021-03-17 10:02:41 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 10:02:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:02:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:02:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:02:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:03:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:03:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:03:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:03:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:03:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:03:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:03:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:03:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:03:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:03:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:03:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:03:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:03:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:03:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:03:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:03:33 | INFO | valid1 | epoch 007 | valid on 'valid1' subset | loss 3.92 | nll_loss 2.232 | ppl 4.7 | bleu 27.53 | wps 4256.3 | wpb 2359.4 | bsz 106.4 | num_updates 140000 | best_loss 3.92
2021-03-17 10:03:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 10:03:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_7_140000.pt (epoch 7 @ 140000 updates, score 3.924) (writing took 8.200033660046756 seconds)
2021-03-17 10:06:44 | INFO | train_inner | epoch 007:  18664 / 20258 loss=3.513, nll_loss=1.825, ppl=3.54, wps=19536.1, ups=0.38, wpb=51192.5, bsz=3035, num_updates=140100, lr=0.000152073, gnorm=0.266, loss_scale=4, train_wall=179, wall=261160
2021-03-17 10:09:47 | INFO | train_inner | epoch 007:  18764 / 20258 loss=3.507, nll_loss=1.819, ppl=3.53, wps=27814.4, ups=0.55, wpb=50826.3, bsz=3076.9, num_updates=140200, lr=0.000152019, gnorm=0.269, loss_scale=4, train_wall=179, wall=261343
2021-03-17 10:12:50 | INFO | train_inner | epoch 007:  18864 / 20258 loss=3.522, nll_loss=1.835, ppl=3.57, wps=27911.5, ups=0.55, wpb=51076.6, bsz=3012.6, num_updates=140300, lr=0.000151965, gnorm=0.274, loss_scale=4, train_wall=179, wall=261526
2021-03-17 10:15:53 | INFO | train_inner | epoch 007:  18964 / 20258 loss=3.521, nll_loss=1.833, ppl=3.56, wps=27790.9, ups=0.55, wpb=50787.4, bsz=2973.5, num_updates=140400, lr=0.000151911, gnorm=0.276, loss_scale=4, train_wall=179, wall=261708
2021-03-17 10:18:55 | INFO | train_inner | epoch 007:  19064 / 20258 loss=3.514, nll_loss=1.826, ppl=3.54, wps=27884.8, ups=0.55, wpb=50662.1, bsz=2922.6, num_updates=140500, lr=0.000151857, gnorm=0.276, loss_scale=8, train_wall=179, wall=261890
2021-03-17 10:21:57 | INFO | train_inner | epoch 007:  19164 / 20258 loss=3.51, nll_loss=1.821, ppl=3.53, wps=27895.4, ups=0.55, wpb=50901.2, bsz=3029, num_updates=140600, lr=0.000151803, gnorm=0.274, loss_scale=8, train_wall=179, wall=262073
2021-03-17 10:25:00 | INFO | train_inner | epoch 007:  19264 / 20258 loss=3.508, nll_loss=1.819, ppl=3.53, wps=27846.2, ups=0.55, wpb=50960.9, bsz=2972.9, num_updates=140700, lr=0.000151749, gnorm=0.268, loss_scale=8, train_wall=179, wall=262256
2021-03-17 10:28:02 | INFO | train_inner | epoch 007:  19364 / 20258 loss=3.516, nll_loss=1.828, ppl=3.55, wps=27909.7, ups=0.55, wpb=50789.3, bsz=2883.1, num_updates=140800, lr=0.000151695, gnorm=0.274, loss_scale=8, train_wall=179, wall=262438
2021-03-17 10:31:04 | INFO | train_inner | epoch 007:  19464 / 20258 loss=3.52, nll_loss=1.832, ppl=3.56, wps=27901.2, ups=0.55, wpb=50794.1, bsz=2958.2, num_updates=140900, lr=0.000151641, gnorm=0.274, loss_scale=8, train_wall=179, wall=262620
2021-03-17 10:34:07 | INFO | train_inner | epoch 007:  19564 / 20258 loss=3.512, nll_loss=1.823, ppl=3.54, wps=27951.3, ups=0.55, wpb=51034.1, bsz=3011.6, num_updates=141000, lr=0.000151587, gnorm=0.269, loss_scale=8, train_wall=179, wall=262802
2021-03-17 10:37:09 | INFO | train_inner | epoch 007:  19664 / 20258 loss=3.505, nll_loss=1.815, ppl=3.52, wps=27856.5, ups=0.55, wpb=50802.9, bsz=2884.6, num_updates=141100, lr=0.000151534, gnorm=0.27, loss_scale=8, train_wall=179, wall=262985
2021-03-17 10:40:12 | INFO | train_inner | epoch 007:  19764 / 20258 loss=3.522, nll_loss=1.835, ppl=3.57, wps=27914.6, ups=0.55, wpb=50943.5, bsz=3081, num_updates=141200, lr=0.00015148, gnorm=0.271, loss_scale=8, train_wall=179, wall=263167
2021-03-17 10:43:14 | INFO | train_inner | epoch 007:  19864 / 20258 loss=3.518, nll_loss=1.83, ppl=3.55, wps=27984.6, ups=0.55, wpb=51056.7, bsz=3034.9, num_updates=141300, lr=0.000151426, gnorm=0.272, loss_scale=8, train_wall=179, wall=263350
2021-03-17 10:46:17 | INFO | train_inner | epoch 007:  19964 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27970.8, ups=0.55, wpb=51156, bsz=2935.5, num_updates=141400, lr=0.000151373, gnorm=0.273, loss_scale=8, train_wall=180, wall=263532
2021-03-17 10:49:20 | INFO | train_inner | epoch 007:  20064 / 20258 loss=3.516, nll_loss=1.828, ppl=3.55, wps=27799, ups=0.54, wpb=51012.4, bsz=3002.6, num_updates=141500, lr=0.000151319, gnorm=0.27, loss_scale=16, train_wall=179, wall=263716
2021-03-17 10:52:23 | INFO | train_inner | epoch 007:  20164 / 20258 loss=3.531, nll_loss=1.844, ppl=3.59, wps=27896.6, ups=0.55, wpb=50805.2, bsz=2975.7, num_updates=141600, lr=0.000151266, gnorm=0.274, loss_scale=16, train_wall=179, wall=263898
2021-03-17 10:53:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 10:55:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 10:55:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:32 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.915 | nll_loss 2.202 | ppl 4.6 | bleu 29.82 | wps 4377.9 | wpb 2432 | bsz 90.4 | num_updates 141693 | best_loss 3.915
2021-03-17 10:55:32 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 10:55:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:55:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 10:55:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 10:55:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 10:56:25 | INFO | valid1 | epoch 007 | valid on 'valid1' subset | loss 3.914 | nll_loss 2.222 | ppl 4.67 | bleu 27.68 | wps 4262.8 | wpb 2359.4 | bsz 106.4 | num_updates 141693 | best_loss 3.914
2021-03-17 10:56:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 10:56:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint7.pt (epoch 7 @ 141693 updates, score 3.915) (writing took 6.464681959943846 seconds)
2021-03-17 10:56:31 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-03-17 10:56:31 | INFO | train | epoch 007 | loss 3.516 | nll_loss 1.827 | ppl 3.55 | wps 27577.3 | ups 0.54 | wpb 50905.7 | bsz 3010.3 | num_updates 141693 | lr 0.000151216 | gnorm 0.271 | loss_scale 8 | train_wall 36324 | wall 264147
2021-03-17 10:56:31 | INFO | fairseq.trainer | begin training epoch 8
2021-03-17 10:56:44 | INFO | train_inner | epoch 008:      7 / 20258 loss=3.506, nll_loss=1.817, ppl=3.52, wps=19427.3, ups=0.38, wpb=50812.8, bsz=3056.6, num_updates=141700, lr=0.000151212, gnorm=0.275, loss_scale=8, train_wall=181, wall=264160
2021-03-17 10:59:46 | INFO | train_inner | epoch 008:    107 / 20258 loss=3.498, nll_loss=1.807, ppl=3.5, wps=27842.9, ups=0.55, wpb=50672.3, bsz=2944.3, num_updates=141800, lr=0.000151159, gnorm=0.271, loss_scale=8, train_wall=179, wall=264342
2021-03-17 11:02:49 | INFO | train_inner | epoch 008:    207 / 20258 loss=3.505, nll_loss=1.815, ppl=3.52, wps=27782.8, ups=0.55, wpb=50756, bsz=3020.1, num_updates=141900, lr=0.000151106, gnorm=0.275, loss_scale=8, train_wall=179, wall=264524
2021-03-17 11:05:51 | INFO | train_inner | epoch 008:    307 / 20258 loss=3.492, nll_loss=1.8, ppl=3.48, wps=27927.1, ups=0.55, wpb=50899.8, bsz=2968.2, num_updates=142000, lr=0.000151053, gnorm=0.268, loss_scale=8, train_wall=179, wall=264707
2021-03-17 11:08:54 | INFO | train_inner | epoch 008:    407 / 20258 loss=3.487, nll_loss=1.795, ppl=3.47, wps=28045.6, ups=0.55, wpb=51224.8, bsz=2955.1, num_updates=142100, lr=0.000150999, gnorm=0.271, loss_scale=8, train_wall=179, wall=264889
2021-03-17 11:11:56 | INFO | train_inner | epoch 008:    507 / 20258 loss=3.494, nll_loss=1.803, ppl=3.49, wps=27776.1, ups=0.55, wpb=50675.5, bsz=2987.3, num_updates=142200, lr=0.000150946, gnorm=0.267, loss_scale=8, train_wall=179, wall=265072
2021-03-17 11:14:58 | INFO | train_inner | epoch 008:    607 / 20258 loss=3.51, nll_loss=1.821, ppl=3.53, wps=27873.9, ups=0.55, wpb=50706.3, bsz=3111.5, num_updates=142300, lr=0.000150893, gnorm=0.269, loss_scale=8, train_wall=179, wall=265254
2021-03-17 11:18:00 | INFO | train_inner | epoch 008:    707 / 20258 loss=3.494, nll_loss=1.802, ppl=3.49, wps=28029.3, ups=0.55, wpb=51114.8, bsz=2923, num_updates=142400, lr=0.00015084, gnorm=0.276, loss_scale=8, train_wall=180, wall=265436
2021-03-17 11:21:03 | INFO | train_inner | epoch 008:    807 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27933.6, ups=0.55, wpb=50917.2, bsz=3085.3, num_updates=142500, lr=0.000150787, gnorm=0.269, loss_scale=8, train_wall=179, wall=265618
2021-03-17 11:24:05 | INFO | train_inner | epoch 008:    907 / 20258 loss=3.51, nll_loss=1.82, ppl=3.53, wps=27879.3, ups=0.55, wpb=50778.3, bsz=2937.1, num_updates=142600, lr=0.000150735, gnorm=0.275, loss_scale=8, train_wall=179, wall=265800
2021-03-17 11:27:07 | INFO | train_inner | epoch 008:   1007 / 20258 loss=3.492, nll_loss=1.801, ppl=3.48, wps=27930.7, ups=0.55, wpb=50956.4, bsz=3029.8, num_updates=142700, lr=0.000150682, gnorm=0.274, loss_scale=16, train_wall=179, wall=265983
2021-03-17 11:30:09 | INFO | train_inner | epoch 008:   1107 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=27864.1, ups=0.55, wpb=50665.2, bsz=2913, num_updates=142800, lr=0.000150629, gnorm=0.274, loss_scale=16, train_wall=179, wall=266165
2021-03-17 11:33:12 | INFO | train_inner | epoch 008:   1207 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=27975.5, ups=0.55, wpb=51153.2, bsz=3068.1, num_updates=142900, lr=0.000150576, gnorm=0.27, loss_scale=16, train_wall=180, wall=266348
2021-03-17 11:34:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 11:36:16 | INFO | train_inner | epoch 008:   1308 / 20258 loss=3.486, nll_loss=1.794, ppl=3.47, wps=27672.9, ups=0.54, wpb=51053.3, bsz=2951.5, num_updates=143000, lr=0.000150524, gnorm=0.268, loss_scale=8, train_wall=181, wall=266532
2021-03-17 11:39:19 | INFO | train_inner | epoch 008:   1408 / 20258 loss=3.5, nll_loss=1.809, ppl=3.5, wps=27848, ups=0.55, wpb=50766.1, bsz=2985, num_updates=143100, lr=0.000150471, gnorm=0.271, loss_scale=8, train_wall=179, wall=266714
2021-03-17 11:42:21 | INFO | train_inner | epoch 008:   1508 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=27906.8, ups=0.55, wpb=50825.2, bsz=2929.4, num_updates=143200, lr=0.000150418, gnorm=0.266, loss_scale=8, train_wall=179, wall=266896
2021-03-17 11:45:23 | INFO | train_inner | epoch 008:   1608 / 20258 loss=3.513, nll_loss=1.824, ppl=3.54, wps=27884, ups=0.55, wpb=50811.9, bsz=2991.2, num_updates=143300, lr=0.000150366, gnorm=0.27, loss_scale=8, train_wall=179, wall=267079
2021-03-17 11:48:26 | INFO | train_inner | epoch 008:   1708 / 20258 loss=3.517, nll_loss=1.829, ppl=3.55, wps=28005.2, ups=0.55, wpb=51088.4, bsz=3045, num_updates=143400, lr=0.000150313, gnorm=0.273, loss_scale=8, train_wall=179, wall=267261
2021-03-17 11:51:28 | INFO | train_inner | epoch 008:   1808 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27789.8, ups=0.55, wpb=50713.5, bsz=2986.2, num_updates=143500, lr=0.000150261, gnorm=0.268, loss_scale=8, train_wall=179, wall=267444
2021-03-17 11:54:30 | INFO | train_inner | epoch 008:   1908 / 20258 loss=3.499, nll_loss=1.808, ppl=3.5, wps=27782.9, ups=0.55, wpb=50633.5, bsz=3006.6, num_updates=143600, lr=0.000150209, gnorm=0.277, loss_scale=8, train_wall=179, wall=267626
2021-03-17 11:57:34 | INFO | train_inner | epoch 008:   2008 / 20258 loss=3.491, nll_loss=1.799, ppl=3.48, wps=27972.6, ups=0.55, wpb=51269.4, bsz=3080.6, num_updates=143700, lr=0.000150156, gnorm=0.268, loss_scale=8, train_wall=180, wall=267809
2021-03-17 12:00:35 | INFO | train_inner | epoch 008:   2108 / 20258 loss=3.519, nll_loss=1.831, ppl=3.56, wps=27859.7, ups=0.55, wpb=50481.8, bsz=2924.8, num_updates=143800, lr=0.000150104, gnorm=0.281, loss_scale=8, train_wall=178, wall=267990
2021-03-17 12:03:38 | INFO | train_inner | epoch 008:   2208 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27792.3, ups=0.55, wpb=50824.3, bsz=3057.3, num_updates=143900, lr=0.000150052, gnorm=0.272, loss_scale=8, train_wall=179, wall=268173
2021-03-17 12:06:39 | INFO | train_inner | epoch 008:   2308 / 20258 loss=3.509, nll_loss=1.82, ppl=3.53, wps=27818.4, ups=0.55, wpb=50509.6, bsz=3141.5, num_updates=144000, lr=0.00015, gnorm=0.27, loss_scale=16, train_wall=178, wall=268355
2021-03-17 12:06:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 12:09:44 | INFO | train_inner | epoch 008:   2409 / 20258 loss=3.497, nll_loss=1.806, ppl=3.5, wps=27580.3, ups=0.54, wpb=50940.1, bsz=2992.5, num_updates=144100, lr=0.000149948, gnorm=0.271, loss_scale=8, train_wall=181, wall=268539
2021-03-17 12:12:47 | INFO | train_inner | epoch 008:   2509 / 20258 loss=3.495, nll_loss=1.803, ppl=3.49, wps=27861.6, ups=0.55, wpb=50912.2, bsz=2929.4, num_updates=144200, lr=0.000149896, gnorm=0.268, loss_scale=8, train_wall=180, wall=268722
2021-03-17 12:15:49 | INFO | train_inner | epoch 008:   2609 / 20258 loss=3.496, nll_loss=1.805, ppl=3.5, wps=27918.8, ups=0.55, wpb=50817.7, bsz=3013, num_updates=144300, lr=0.000149844, gnorm=0.272, loss_scale=8, train_wall=179, wall=268904
2021-03-17 12:18:51 | INFO | train_inner | epoch 008:   2709 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27858.1, ups=0.55, wpb=50825.2, bsz=3065.7, num_updates=144400, lr=0.000149792, gnorm=0.273, loss_scale=8, train_wall=179, wall=269087
2021-03-17 12:21:53 | INFO | train_inner | epoch 008:   2809 / 20258 loss=3.501, nll_loss=1.811, ppl=3.51, wps=27874.5, ups=0.55, wpb=50578.5, bsz=2954.4, num_updates=144500, lr=0.00014974, gnorm=0.276, loss_scale=8, train_wall=179, wall=269268
2021-03-17 12:24:55 | INFO | train_inner | epoch 008:   2909 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27937, ups=0.55, wpb=51055.9, bsz=3060.5, num_updates=144600, lr=0.000149688, gnorm=0.271, loss_scale=8, train_wall=180, wall=269451
2021-03-17 12:27:59 | INFO | train_inner | epoch 008:   3009 / 20258 loss=3.493, nll_loss=1.802, ppl=3.49, wps=27873.3, ups=0.54, wpb=51161.5, bsz=2969.4, num_updates=144700, lr=0.000149637, gnorm=0.276, loss_scale=8, train_wall=180, wall=269634
2021-03-17 12:31:02 | INFO | train_inner | epoch 008:   3109 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=27827.4, ups=0.55, wpb=50918.7, bsz=2977.1, num_updates=144800, lr=0.000149585, gnorm=0.268, loss_scale=8, train_wall=180, wall=269817
2021-03-17 12:34:04 | INFO | train_inner | epoch 008:   3209 / 20258 loss=3.512, nll_loss=1.823, ppl=3.54, wps=27940.7, ups=0.55, wpb=50934.2, bsz=3077.4, num_updates=144900, lr=0.000149533, gnorm=0.271, loss_scale=8, train_wall=179, wall=270000
2021-03-17 12:37:07 | INFO | train_inner | epoch 008:   3309 / 20258 loss=3.498, nll_loss=1.807, ppl=3.5, wps=27808.6, ups=0.55, wpb=50774.4, bsz=2996.3, num_updates=145000, lr=0.000149482, gnorm=0.269, loss_scale=8, train_wall=179, wall=270182
2021-03-17 12:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 12:37:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:25 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.925 | nll_loss 2.209 | ppl 4.62 | bleu 29.66 | wps 4396.5 | wpb 2432 | bsz 90.4 | num_updates 145000 | best_loss 3.915
2021-03-17 12:37:25 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 12:37:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:37:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 12:37:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 12:37:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 12:38:18 | INFO | valid1 | epoch 008 | valid on 'valid1' subset | loss 3.922 | nll_loss 2.23 | ppl 4.69 | bleu 27.36 | wps 4237.1 | wpb 2359.4 | bsz 106.4 | num_updates 145000 | best_loss 3.915
2021-03-17 12:38:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 12:38:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_8_145000.pt (epoch 8 @ 145000 updates, score 3.925) (writing took 4.6129813368897885 seconds)
2021-03-17 12:41:25 | INFO | train_inner | epoch 008:   3409 / 20258 loss=3.505, nll_loss=1.814, ppl=3.52, wps=19774.9, ups=0.39, wpb=51055.1, bsz=2873.9, num_updates=145100, lr=0.00014943, gnorm=0.278, loss_scale=16, train_wall=180, wall=270440
2021-03-17 12:44:27 | INFO | train_inner | epoch 008:   3509 / 20258 loss=3.522, nll_loss=1.835, ppl=3.57, wps=27923.3, ups=0.55, wpb=50738.3, bsz=2971.1, num_updates=145200, lr=0.000149379, gnorm=0.281, loss_scale=16, train_wall=179, wall=270622
2021-03-17 12:47:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 12:47:31 | INFO | train_inner | epoch 008:   3610 / 20258 loss=3.51, nll_loss=1.821, ppl=3.53, wps=27466.6, ups=0.54, wpb=50601.7, bsz=3068.7, num_updates=145300, lr=0.000149327, gnorm=0.273, loss_scale=8, train_wall=181, wall=270806
2021-03-17 12:50:34 | INFO | train_inner | epoch 008:   3710 / 20258 loss=3.498, nll_loss=1.807, ppl=3.5, wps=27803.6, ups=0.55, wpb=50924.5, bsz=3034.2, num_updates=145400, lr=0.000149276, gnorm=0.265, loss_scale=8, train_wall=180, wall=270990
2021-03-17 12:53:37 | INFO | train_inner | epoch 008:   3810 / 20258 loss=3.498, nll_loss=1.808, ppl=3.5, wps=27926.3, ups=0.55, wpb=51134.4, bsz=3101.8, num_updates=145500, lr=0.000149225, gnorm=0.265, loss_scale=8, train_wall=180, wall=271173
2021-03-17 12:56:40 | INFO | train_inner | epoch 008:   3910 / 20258 loss=3.492, nll_loss=1.801, ppl=3.49, wps=27859.6, ups=0.55, wpb=50862.9, bsz=3065.2, num_updates=145600, lr=0.000149174, gnorm=0.272, loss_scale=8, train_wall=179, wall=271355
2021-03-17 12:59:42 | INFO | train_inner | epoch 008:   4010 / 20258 loss=3.483, nll_loss=1.79, ppl=3.46, wps=27860.1, ups=0.55, wpb=50911.5, bsz=3007, num_updates=145700, lr=0.000149122, gnorm=0.275, loss_scale=8, train_wall=180, wall=271538
2021-03-17 13:02:45 | INFO | train_inner | epoch 008:   4110 / 20258 loss=3.522, nll_loss=1.835, ppl=3.57, wps=27959.2, ups=0.55, wpb=50927.6, bsz=3116.5, num_updates=145800, lr=0.000149071, gnorm=0.279, loss_scale=8, train_wall=179, wall=271720
2021-03-17 13:05:47 | INFO | train_inner | epoch 008:   4210 / 20258 loss=3.498, nll_loss=1.808, ppl=3.5, wps=27865, ups=0.55, wpb=50887.3, bsz=3013.4, num_updates=145900, lr=0.00014902, gnorm=0.275, loss_scale=8, train_wall=179, wall=271903
2021-03-17 13:06:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-17 13:08:52 | INFO | train_inner | epoch 008:   4311 / 20258 loss=3.498, nll_loss=1.807, ppl=3.5, wps=27598.4, ups=0.54, wpb=51022.3, bsz=3122.8, num_updates=146000, lr=0.000148969, gnorm=0.273, loss_scale=4, train_wall=181, wall=272088
2021-03-17 13:11:54 | INFO | train_inner | epoch 008:   4411 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27812.2, ups=0.55, wpb=50710.6, bsz=3093, num_updates=146100, lr=0.000148918, gnorm=0.272, loss_scale=4, train_wall=179, wall=272270
2021-03-17 13:14:58 | INFO | train_inner | epoch 008:   4511 / 20258 loss=3.488, nll_loss=1.796, ppl=3.47, wps=27984, ups=0.55, wpb=51305.8, bsz=3049.3, num_updates=146200, lr=0.000148867, gnorm=0.267, loss_scale=4, train_wall=180, wall=272453
2021-03-17 13:18:01 | INFO | train_inner | epoch 008:   4611 / 20258 loss=3.51, nll_loss=1.821, ppl=3.53, wps=27886.1, ups=0.55, wpb=50961.3, bsz=2997, num_updates=146300, lr=0.000148816, gnorm=0.279, loss_scale=4, train_wall=180, wall=272636
2021-03-17 13:21:03 | INFO | train_inner | epoch 008:   4711 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27813.3, ups=0.55, wpb=50808.4, bsz=3145, num_updates=146400, lr=0.000148765, gnorm=0.273, loss_scale=4, train_wall=179, wall=272819
2021-03-17 13:24:05 | INFO | train_inner | epoch 008:   4811 / 20258 loss=3.509, nll_loss=1.82, ppl=3.53, wps=27811.5, ups=0.55, wpb=50638.1, bsz=2909.5, num_updates=146500, lr=0.000148715, gnorm=0.267, loss_scale=4, train_wall=179, wall=273001
2021-03-17 13:27:08 | INFO | train_inner | epoch 008:   4911 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=27836, ups=0.55, wpb=50838.9, bsz=3018.9, num_updates=146600, lr=0.000148664, gnorm=0.273, loss_scale=4, train_wall=179, wall=273183
2021-03-17 13:30:11 | INFO | train_inner | epoch 008:   5011 / 20258 loss=3.499, nll_loss=1.809, ppl=3.51, wps=27939.4, ups=0.55, wpb=51097.5, bsz=3216.8, num_updates=146700, lr=0.000148613, gnorm=0.28, loss_scale=4, train_wall=180, wall=273366
2021-03-17 13:33:13 | INFO | train_inner | epoch 008:   5111 / 20258 loss=3.521, nll_loss=1.834, ppl=3.56, wps=27937.8, ups=0.55, wpb=50918.1, bsz=2963, num_updates=146800, lr=0.000148563, gnorm=0.272, loss_scale=4, train_wall=179, wall=273549
2021-03-17 13:36:16 | INFO | train_inner | epoch 008:   5211 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27917.4, ups=0.55, wpb=51053.7, bsz=3035.8, num_updates=146900, lr=0.000148512, gnorm=0.266, loss_scale=4, train_wall=180, wall=273731
2021-03-17 13:39:19 | INFO | train_inner | epoch 008:   5311 / 20258 loss=3.499, nll_loss=1.809, ppl=3.5, wps=27868, ups=0.55, wpb=50935.8, bsz=2875.4, num_updates=147000, lr=0.000148461, gnorm=0.272, loss_scale=8, train_wall=179, wall=273914
2021-03-17 13:42:22 | INFO | train_inner | epoch 008:   5411 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27919.2, ups=0.55, wpb=51129.8, bsz=3028.9, num_updates=147100, lr=0.000148411, gnorm=0.272, loss_scale=8, train_wall=180, wall=274097
2021-03-17 13:45:25 | INFO | train_inner | epoch 008:   5511 / 20258 loss=3.499, nll_loss=1.809, ppl=3.5, wps=27874.9, ups=0.55, wpb=50967.8, bsz=3047.7, num_updates=147200, lr=0.000148361, gnorm=0.274, loss_scale=8, train_wall=180, wall=274280
2021-03-17 13:48:27 | INFO | train_inner | epoch 008:   5611 / 20258 loss=3.517, nll_loss=1.828, ppl=3.55, wps=27954.1, ups=0.55, wpb=50923.3, bsz=2984.8, num_updates=147300, lr=0.00014831, gnorm=0.278, loss_scale=8, train_wall=179, wall=274462
2021-03-17 13:51:30 | INFO | train_inner | epoch 008:   5711 / 20258 loss=3.495, nll_loss=1.803, ppl=3.49, wps=27878.4, ups=0.55, wpb=50974.7, bsz=2997.7, num_updates=147400, lr=0.00014826, gnorm=0.269, loss_scale=8, train_wall=180, wall=274645
2021-03-17 13:54:32 | INFO | train_inner | epoch 008:   5811 / 20258 loss=3.519, nll_loss=1.831, ppl=3.56, wps=27832.8, ups=0.55, wpb=50725.6, bsz=2973.8, num_updates=147500, lr=0.00014821, gnorm=0.273, loss_scale=8, train_wall=179, wall=274827
2021-03-17 13:57:35 | INFO | train_inner | epoch 008:   5911 / 20258 loss=3.526, nll_loss=1.839, ppl=3.58, wps=27843.6, ups=0.55, wpb=50913, bsz=3019.9, num_updates=147600, lr=0.000148159, gnorm=0.275, loss_scale=8, train_wall=179, wall=275010
2021-03-17 14:00:38 | INFO | train_inner | epoch 008:   6011 / 20258 loss=3.508, nll_loss=1.819, ppl=3.53, wps=27964.1, ups=0.55, wpb=51115.8, bsz=2991.3, num_updates=147700, lr=0.000148109, gnorm=0.27, loss_scale=8, train_wall=179, wall=275193
2021-03-17 14:03:40 | INFO | train_inner | epoch 008:   6111 / 20258 loss=3.489, nll_loss=1.797, ppl=3.48, wps=27800.8, ups=0.55, wpb=50829.7, bsz=3039, num_updates=147800, lr=0.000148059, gnorm=0.275, loss_scale=8, train_wall=179, wall=275376
2021-03-17 14:06:43 | INFO | train_inner | epoch 008:   6211 / 20258 loss=3.526, nll_loss=1.84, ppl=3.58, wps=27866.9, ups=0.55, wpb=50809.2, bsz=3061.3, num_updates=147900, lr=0.000148009, gnorm=0.274, loss_scale=8, train_wall=179, wall=275558
2021-03-17 14:09:46 | INFO | train_inner | epoch 008:   6311 / 20258 loss=3.513, nll_loss=1.824, ppl=3.54, wps=27993.3, ups=0.55, wpb=51288.2, bsz=3060.4, num_updates=148000, lr=0.000147959, gnorm=0.274, loss_scale=16, train_wall=180, wall=275742
2021-03-17 14:09:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 14:12:50 | INFO | train_inner | epoch 008:   6412 / 20258 loss=3.488, nll_loss=1.796, ppl=3.47, wps=27586.4, ups=0.54, wpb=50892.6, bsz=2921.8, num_updates=148100, lr=0.000147909, gnorm=0.273, loss_scale=8, train_wall=181, wall=275926
2021-03-17 14:15:53 | INFO | train_inner | epoch 008:   6512 / 20258 loss=3.506, nll_loss=1.816, ppl=3.52, wps=28012.4, ups=0.55, wpb=51005.8, bsz=3024.6, num_updates=148200, lr=0.000147859, gnorm=0.271, loss_scale=8, train_wall=179, wall=276108
2021-03-17 14:18:56 | INFO | train_inner | epoch 008:   6612 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27931.1, ups=0.55, wpb=51189.7, bsz=3067.8, num_updates=148300, lr=0.000147809, gnorm=0.269, loss_scale=8, train_wall=180, wall=276291
2021-03-17 14:21:59 | INFO | train_inner | epoch 008:   6712 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27780.1, ups=0.55, wpb=50953.4, bsz=3046.2, num_updates=148400, lr=0.00014776, gnorm=0.275, loss_scale=8, train_wall=180, wall=276475
2021-03-17 14:25:02 | INFO | train_inner | epoch 008:   6812 / 20258 loss=3.51, nll_loss=1.82, ppl=3.53, wps=27889, ups=0.55, wpb=50887.9, bsz=2882.6, num_updates=148500, lr=0.00014771, gnorm=0.272, loss_scale=8, train_wall=179, wall=276657
2021-03-17 14:28:04 | INFO | train_inner | epoch 008:   6912 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27866.8, ups=0.55, wpb=50708, bsz=3035.2, num_updates=148600, lr=0.00014766, gnorm=0.274, loss_scale=8, train_wall=179, wall=276839
2021-03-17 14:31:06 | INFO | train_inner | epoch 008:   7012 / 20258 loss=3.511, nll_loss=1.823, ppl=3.54, wps=27850.4, ups=0.55, wpb=50873.9, bsz=3044.9, num_updates=148700, lr=0.00014761, gnorm=0.268, loss_scale=8, train_wall=179, wall=277022
2021-03-17 14:34:08 | INFO | train_inner | epoch 008:   7112 / 20258 loss=3.503, nll_loss=1.812, ppl=3.51, wps=27837.4, ups=0.55, wpb=50704.9, bsz=2896.3, num_updates=148800, lr=0.000147561, gnorm=0.28, loss_scale=8, train_wall=179, wall=277204
2021-03-17 14:37:11 | INFO | train_inner | epoch 008:   7212 / 20258 loss=3.513, nll_loss=1.824, ppl=3.54, wps=28054.5, ups=0.55, wpb=51166.1, bsz=2986, num_updates=148900, lr=0.000147511, gnorm=0.27, loss_scale=8, train_wall=179, wall=277386
2021-03-17 14:37:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-17 14:40:15 | INFO | train_inner | epoch 008:   7313 / 20258 loss=3.518, nll_loss=1.831, ppl=3.56, wps=27650.4, ups=0.54, wpb=51036.3, bsz=3162.9, num_updates=149000, lr=0.000147462, gnorm=0.277, loss_scale=4, train_wall=181, wall=277571
2021-03-17 14:43:18 | INFO | train_inner | epoch 008:   7413 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27945.9, ups=0.55, wpb=50925.1, bsz=3031.8, num_updates=149100, lr=0.000147412, gnorm=0.266, loss_scale=4, train_wall=179, wall=277753
2021-03-17 14:46:20 | INFO | train_inner | epoch 008:   7513 / 20258 loss=3.496, nll_loss=1.805, ppl=3.5, wps=27951.6, ups=0.55, wpb=51066.1, bsz=3056.5, num_updates=149200, lr=0.000147363, gnorm=0.271, loss_scale=4, train_wall=179, wall=277936
2021-03-17 14:49:23 | INFO | train_inner | epoch 008:   7613 / 20258 loss=3.48, nll_loss=1.787, ppl=3.45, wps=27811.5, ups=0.55, wpb=50812.2, bsz=2992.1, num_updates=149300, lr=0.000147314, gnorm=0.278, loss_scale=4, train_wall=180, wall=278119
2021-03-17 14:52:25 | INFO | train_inner | epoch 008:   7713 / 20258 loss=3.501, nll_loss=1.811, ppl=3.51, wps=27841.6, ups=0.55, wpb=50739.1, bsz=2965.9, num_updates=149400, lr=0.000147264, gnorm=0.273, loss_scale=4, train_wall=179, wall=278301
2021-03-17 14:52:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-17 14:55:30 | INFO | train_inner | epoch 008:   7814 / 20258 loss=3.505, nll_loss=1.816, ppl=3.52, wps=27608.6, ups=0.54, wpb=50924.6, bsz=2957.1, num_updates=149500, lr=0.000147215, gnorm=0.272, loss_scale=2, train_wall=181, wall=278485
2021-03-17 14:58:32 | INFO | train_inner | epoch 008:   7914 / 20258 loss=3.505, nll_loss=1.815, ppl=3.52, wps=27883.9, ups=0.55, wpb=50891.9, bsz=2937.8, num_updates=149600, lr=0.000147166, gnorm=0.274, loss_scale=2, train_wall=179, wall=278668
2021-03-17 15:01:34 | INFO | train_inner | epoch 008:   8014 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27983.2, ups=0.55, wpb=50957.8, bsz=2996.9, num_updates=149700, lr=0.000147117, gnorm=0.271, loss_scale=2, train_wall=179, wall=278850
2021-03-17 15:04:37 | INFO | train_inner | epoch 008:   8114 / 20258 loss=3.506, nll_loss=1.817, ppl=3.52, wps=27840.8, ups=0.55, wpb=50900.4, bsz=3120.1, num_updates=149800, lr=0.000147067, gnorm=0.272, loss_scale=2, train_wall=180, wall=279033
2021-03-17 15:07:40 | INFO | train_inner | epoch 008:   8214 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27749.2, ups=0.55, wpb=50777.6, bsz=2985.8, num_updates=149900, lr=0.000147018, gnorm=0.274, loss_scale=2, train_wall=180, wall=279216
2021-03-17 15:10:43 | INFO | train_inner | epoch 008:   8314 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27966.4, ups=0.55, wpb=51122.4, bsz=2987, num_updates=150000, lr=0.000146969, gnorm=0.272, loss_scale=2, train_wall=179, wall=279399
2021-03-17 15:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 15:10:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:10:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:10:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:10:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:10:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:10:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:10:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:10:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:10:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:10:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:10:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:10:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:10:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:10:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:10:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:10:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:10:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:10:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:10:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:10:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:10:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:01 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.922 | nll_loss 2.206 | ppl 4.62 | bleu 29.75 | wps 4378.5 | wpb 2432 | bsz 90.4 | num_updates 150000 | best_loss 3.915
2021-03-17 15:11:01 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 15:11:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 15:11:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 15:11:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 15:11:54 | INFO | valid1 | epoch 008 | valid on 'valid1' subset | loss 3.923 | nll_loss 2.231 | ppl 4.7 | bleu 27.1 | wps 4244.6 | wpb 2359.4 | bsz 106.4 | num_updates 150000 | best_loss 3.915
2021-03-17 15:11:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 15:11:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_8_150000.pt (epoch 8 @ 150000 updates, score 3.922) (writing took 4.568112124921754 seconds)
2021-03-17 15:15:01 | INFO | train_inner | epoch 008:   8414 / 20258 loss=3.494, nll_loss=1.803, ppl=3.49, wps=19705.3, ups=0.39, wpb=50882.5, bsz=2987.1, num_updates=150100, lr=0.00014692, gnorm=0.27, loss_scale=2, train_wall=180, wall=279657
2021-03-17 15:18:04 | INFO | train_inner | epoch 008:   8514 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27849, ups=0.55, wpb=50906.2, bsz=3075.5, num_updates=150200, lr=0.000146872, gnorm=0.273, loss_scale=2, train_wall=180, wall=279840
2021-03-17 15:21:07 | INFO | train_inner | epoch 008:   8614 / 20258 loss=3.511, nll_loss=1.822, ppl=3.54, wps=27975.4, ups=0.55, wpb=51139, bsz=3136.6, num_updates=150300, lr=0.000146823, gnorm=0.272, loss_scale=2, train_wall=179, wall=280022
2021-03-17 15:24:10 | INFO | train_inner | epoch 008:   8714 / 20258 loss=3.499, nll_loss=1.808, ppl=3.5, wps=27787.1, ups=0.55, wpb=50935.8, bsz=3046.1, num_updates=150400, lr=0.000146774, gnorm=0.278, loss_scale=2, train_wall=180, wall=280206
2021-03-17 15:27:13 | INFO | train_inner | epoch 008:   8814 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27899, ups=0.55, wpb=51116.5, bsz=3012.8, num_updates=150500, lr=0.000146725, gnorm=0.278, loss_scale=4, train_wall=180, wall=280389
2021-03-17 15:30:16 | INFO | train_inner | epoch 008:   8914 / 20258 loss=3.505, nll_loss=1.816, ppl=3.52, wps=27852.8, ups=0.55, wpb=50971.9, bsz=3016, num_updates=150600, lr=0.000146676, gnorm=0.274, loss_scale=4, train_wall=179, wall=280572
2021-03-17 15:33:19 | INFO | train_inner | epoch 008:   9014 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27943.7, ups=0.55, wpb=51156.1, bsz=2989.4, num_updates=150700, lr=0.000146628, gnorm=0.28, loss_scale=4, train_wall=180, wall=280755
2021-03-17 15:36:22 | INFO | train_inner | epoch 008:   9114 / 20258 loss=3.512, nll_loss=1.824, ppl=3.54, wps=27949.8, ups=0.55, wpb=51014.6, bsz=2888.9, num_updates=150800, lr=0.000146579, gnorm=0.277, loss_scale=4, train_wall=179, wall=280937
2021-03-17 15:39:24 | INFO | train_inner | epoch 008:   9214 / 20258 loss=3.505, nll_loss=1.815, ppl=3.52, wps=27849.4, ups=0.55, wpb=50753.9, bsz=2990, num_updates=150900, lr=0.00014653, gnorm=0.273, loss_scale=4, train_wall=179, wall=281120
2021-03-17 15:42:27 | INFO | train_inner | epoch 008:   9314 / 20258 loss=3.499, nll_loss=1.81, ppl=3.51, wps=27913.4, ups=0.55, wpb=50967.2, bsz=3075.1, num_updates=151000, lr=0.000146482, gnorm=0.269, loss_scale=4, train_wall=179, wall=281302
2021-03-17 15:45:29 | INFO | train_inner | epoch 008:   9414 / 20258 loss=3.502, nll_loss=1.811, ppl=3.51, wps=27773.8, ups=0.55, wpb=50629.3, bsz=2866.2, num_updates=151100, lr=0.000146433, gnorm=0.282, loss_scale=4, train_wall=179, wall=281485
2021-03-17 15:48:31 | INFO | train_inner | epoch 008:   9514 / 20258 loss=3.511, nll_loss=1.823, ppl=3.54, wps=27871.3, ups=0.55, wpb=50819.1, bsz=2968.7, num_updates=151200, lr=0.000146385, gnorm=0.274, loss_scale=4, train_wall=179, wall=281667
2021-03-17 15:51:34 | INFO | train_inner | epoch 008:   9614 / 20258 loss=3.498, nll_loss=1.808, ppl=3.5, wps=27793.6, ups=0.55, wpb=50862.3, bsz=3067, num_updates=151300, lr=0.000146337, gnorm=0.274, loss_scale=4, train_wall=180, wall=281850
2021-03-17 15:54:37 | INFO | train_inner | epoch 008:   9714 / 20258 loss=3.493, nll_loss=1.802, ppl=3.49, wps=27788.5, ups=0.55, wpb=50643.2, bsz=2911.5, num_updates=151400, lr=0.000146288, gnorm=0.278, loss_scale=4, train_wall=179, wall=282032
2021-03-17 15:57:39 | INFO | train_inner | epoch 008:   9814 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27803.6, ups=0.55, wpb=50686.5, bsz=2870.2, num_updates=151500, lr=0.00014624, gnorm=0.273, loss_scale=8, train_wall=179, wall=282215
2021-03-17 16:00:42 | INFO | train_inner | epoch 008:   9914 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27821.2, ups=0.55, wpb=50784.1, bsz=3108.1, num_updates=151600, lr=0.000146192, gnorm=0.276, loss_scale=8, train_wall=179, wall=282397
2021-03-17 16:03:44 | INFO | train_inner | epoch 008:  10014 / 20258 loss=3.517, nll_loss=1.829, ppl=3.55, wps=27939.7, ups=0.55, wpb=50953.8, bsz=3078.6, num_updates=151700, lr=0.000146144, gnorm=0.272, loss_scale=8, train_wall=179, wall=282579
2021-03-17 16:06:46 | INFO | train_inner | epoch 008:  10114 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27826.4, ups=0.55, wpb=50738.6, bsz=2927.3, num_updates=151800, lr=0.000146095, gnorm=0.273, loss_scale=8, train_wall=179, wall=282762
2021-03-17 16:09:49 | INFO | train_inner | epoch 008:  10214 / 20258 loss=3.503, nll_loss=1.814, ppl=3.52, wps=27972.3, ups=0.55, wpb=51073.3, bsz=2967.8, num_updates=151900, lr=0.000146047, gnorm=0.271, loss_scale=8, train_wall=180, wall=282944
2021-03-17 16:12:51 | INFO | train_inner | epoch 008:  10314 / 20258 loss=3.5, nll_loss=1.809, ppl=3.5, wps=27918.9, ups=0.55, wpb=50930, bsz=2957.3, num_updates=152000, lr=0.000145999, gnorm=0.275, loss_scale=8, train_wall=179, wall=283127
2021-03-17 16:15:53 | INFO | train_inner | epoch 008:  10414 / 20258 loss=3.527, nll_loss=1.84, ppl=3.58, wps=27873.8, ups=0.55, wpb=50559.9, bsz=2848.8, num_updates=152100, lr=0.000145951, gnorm=0.278, loss_scale=8, train_wall=178, wall=283308
2021-03-17 16:18:56 | INFO | train_inner | epoch 008:  10514 / 20258 loss=3.48, nll_loss=1.787, ppl=3.45, wps=27761.7, ups=0.55, wpb=50828.7, bsz=3043.4, num_updates=152200, lr=0.000145903, gnorm=0.269, loss_scale=8, train_wall=180, wall=283491
2021-03-17 16:21:58 | INFO | train_inner | epoch 008:  10614 / 20258 loss=3.512, nll_loss=1.824, ppl=3.54, wps=27873.7, ups=0.55, wpb=50935.8, bsz=3090.8, num_updates=152300, lr=0.000145855, gnorm=0.273, loss_scale=8, train_wall=179, wall=283674
2021-03-17 16:25:01 | INFO | train_inner | epoch 008:  10714 / 20258 loss=3.509, nll_loss=1.82, ppl=3.53, wps=27878.9, ups=0.55, wpb=50923.8, bsz=3065.1, num_updates=152400, lr=0.000145808, gnorm=0.273, loss_scale=8, train_wall=180, wall=283857
2021-03-17 16:28:05 | INFO | train_inner | epoch 008:  10814 / 20258 loss=3.48, nll_loss=1.788, ppl=3.45, wps=27810.5, ups=0.55, wpb=51018.9, bsz=3068.8, num_updates=152500, lr=0.00014576, gnorm=0.272, loss_scale=16, train_wall=180, wall=284040
2021-03-17 16:31:07 | INFO | train_inner | epoch 008:  10914 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27697.5, ups=0.55, wpb=50647.5, bsz=2998.9, num_updates=152600, lr=0.000145712, gnorm=0.271, loss_scale=16, train_wall=179, wall=284223
2021-03-17 16:31:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 16:34:12 | INFO | train_inner | epoch 008:  11015 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27557.3, ups=0.54, wpb=50867, bsz=2982.7, num_updates=152700, lr=0.000145664, gnorm=0.271, loss_scale=8, train_wall=182, wall=284408
2021-03-17 16:37:15 | INFO | train_inner | epoch 008:  11115 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27803.4, ups=0.55, wpb=50767.4, bsz=2946.2, num_updates=152800, lr=0.000145617, gnorm=0.275, loss_scale=8, train_wall=179, wall=284590
2021-03-17 16:40:19 | INFO | train_inner | epoch 008:  11215 / 20258 loss=3.492, nll_loss=1.8, ppl=3.48, wps=27895.2, ups=0.54, wpb=51299.4, bsz=2907.4, num_updates=152900, lr=0.000145569, gnorm=0.272, loss_scale=8, train_wall=180, wall=284774
2021-03-17 16:43:21 | INFO | train_inner | epoch 008:  11315 / 20258 loss=3.523, nll_loss=1.835, ppl=3.57, wps=27973.8, ups=0.55, wpb=51087.3, bsz=2968.2, num_updates=153000, lr=0.000145521, gnorm=0.274, loss_scale=8, train_wall=179, wall=284957
2021-03-17 16:46:24 | INFO | train_inner | epoch 008:  11415 / 20258 loss=3.521, nll_loss=1.834, ppl=3.56, wps=27916, ups=0.55, wpb=50928.8, bsz=2967, num_updates=153100, lr=0.000145474, gnorm=0.279, loss_scale=8, train_wall=179, wall=285139
2021-03-17 16:49:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-17 16:49:28 | INFO | train_inner | epoch 008:  11516 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27551.1, ups=0.54, wpb=50707.2, bsz=3015.2, num_updates=153200, lr=0.000145426, gnorm=0.272, loss_scale=4, train_wall=181, wall=285323
2021-03-17 16:52:31 | INFO | train_inner | epoch 008:  11616 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=27866.5, ups=0.55, wpb=51059, bsz=3113.9, num_updates=153300, lr=0.000145379, gnorm=0.269, loss_scale=4, train_wall=180, wall=285506
2021-03-17 16:55:33 | INFO | train_inner | epoch 008:  11716 / 20258 loss=3.497, nll_loss=1.807, ppl=3.5, wps=27705.1, ups=0.55, wpb=50543, bsz=2897.2, num_updates=153400, lr=0.000145332, gnorm=0.276, loss_scale=4, train_wall=179, wall=285689
2021-03-17 16:58:36 | INFO | train_inner | epoch 008:  11816 / 20258 loss=3.501, nll_loss=1.811, ppl=3.51, wps=27837.3, ups=0.55, wpb=50809.8, bsz=3022.7, num_updates=153500, lr=0.000145284, gnorm=0.271, loss_scale=4, train_wall=179, wall=285871
2021-03-17 17:01:38 | INFO | train_inner | epoch 008:  11916 / 20258 loss=3.506, nll_loss=1.816, ppl=3.52, wps=27915.6, ups=0.55, wpb=50939.1, bsz=2900, num_updates=153600, lr=0.000145237, gnorm=0.272, loss_scale=4, train_wall=179, wall=286054
2021-03-17 17:04:40 | INFO | train_inner | epoch 008:  12016 / 20258 loss=3.489, nll_loss=1.797, ppl=3.48, wps=27861.2, ups=0.55, wpb=50737.5, bsz=2880, num_updates=153700, lr=0.00014519, gnorm=0.271, loss_scale=4, train_wall=179, wall=286236
2021-03-17 17:07:43 | INFO | train_inner | epoch 008:  12116 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27817.8, ups=0.55, wpb=50838.2, bsz=3090.6, num_updates=153800, lr=0.000145142, gnorm=0.275, loss_scale=4, train_wall=180, wall=286419
2021-03-17 17:10:46 | INFO | train_inner | epoch 008:  12216 / 20258 loss=3.509, nll_loss=1.82, ppl=3.53, wps=27822.5, ups=0.55, wpb=50836.8, bsz=3048.6, num_updates=153900, lr=0.000145095, gnorm=0.278, loss_scale=4, train_wall=179, wall=286601
2021-03-17 17:13:49 | INFO | train_inner | epoch 008:  12316 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27933.5, ups=0.55, wpb=51111.2, bsz=3018.6, num_updates=154000, lr=0.000145048, gnorm=0.272, loss_scale=4, train_wall=180, wall=286784
2021-03-17 17:16:52 | INFO | train_inner | epoch 008:  12416 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=28023.3, ups=0.55, wpb=51228.9, bsz=3066, num_updates=154100, lr=0.000145001, gnorm=0.274, loss_scale=4, train_wall=180, wall=286967
2021-03-17 17:19:54 | INFO | train_inner | epoch 008:  12516 / 20258 loss=3.489, nll_loss=1.797, ppl=3.48, wps=27838.6, ups=0.55, wpb=50891.5, bsz=2860.2, num_updates=154200, lr=0.000144954, gnorm=0.27, loss_scale=4, train_wall=179, wall=287150
2021-03-17 17:22:57 | INFO | train_inner | epoch 008:  12616 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27934.2, ups=0.55, wpb=51029.8, bsz=3020.6, num_updates=154300, lr=0.000144907, gnorm=0.281, loss_scale=8, train_wall=179, wall=287333
2021-03-17 17:26:01 | INFO | train_inner | epoch 008:  12716 / 20258 loss=3.508, nll_loss=1.82, ppl=3.53, wps=28079.1, ups=0.55, wpb=51487.5, bsz=3096.4, num_updates=154400, lr=0.00014486, gnorm=0.273, loss_scale=8, train_wall=180, wall=287516
2021-03-17 17:29:03 | INFO | train_inner | epoch 008:  12816 / 20258 loss=3.503, nll_loss=1.814, ppl=3.52, wps=27836.2, ups=0.55, wpb=50707.8, bsz=3043.7, num_updates=154500, lr=0.000144813, gnorm=0.28, loss_scale=8, train_wall=179, wall=287698
2021-03-17 17:32:06 | INFO | train_inner | epoch 008:  12916 / 20258 loss=3.495, nll_loss=1.805, ppl=3.49, wps=27895.9, ups=0.55, wpb=51095.4, bsz=3070.9, num_updates=154600, lr=0.000144766, gnorm=0.27, loss_scale=8, train_wall=180, wall=287881
2021-03-17 17:35:09 | INFO | train_inner | epoch 008:  13016 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27805.9, ups=0.55, wpb=50849.2, bsz=3125, num_updates=154700, lr=0.00014472, gnorm=0.272, loss_scale=8, train_wall=180, wall=288064
2021-03-17 17:38:11 | INFO | train_inner | epoch 008:  13116 / 20258 loss=3.515, nll_loss=1.828, ppl=3.55, wps=27860.7, ups=0.55, wpb=50851.2, bsz=3095.1, num_updates=154800, lr=0.000144673, gnorm=0.277, loss_scale=8, train_wall=179, wall=288247
2021-03-17 17:41:15 | INFO | train_inner | epoch 008:  13216 / 20258 loss=3.501, nll_loss=1.812, ppl=3.51, wps=27801.5, ups=0.54, wpb=51063.2, bsz=3139.8, num_updates=154900, lr=0.000144626, gnorm=0.275, loss_scale=8, train_wall=180, wall=288430
2021-03-17 17:44:17 | INFO | train_inner | epoch 008:  13316 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27859.2, ups=0.55, wpb=50843.9, bsz=3002.5, num_updates=155000, lr=0.000144579, gnorm=0.272, loss_scale=8, train_wall=179, wall=288613
2021-03-17 17:44:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 17:44:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:36 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.906 | nll_loss 2.192 | ppl 4.57 | bleu 29.76 | wps 4303 | wpb 2432 | bsz 90.4 | num_updates 155000 | best_loss 3.906
2021-03-17 17:44:36 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 17:44:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:44:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:44:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:44:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:45:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 17:45:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 17:45:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 17:45:28 | INFO | valid1 | epoch 008 | valid on 'valid1' subset | loss 3.909 | nll_loss 2.217 | ppl 4.65 | bleu 27.38 | wps 4278.4 | wpb 2359.4 | bsz 106.4 | num_updates 155000 | best_loss 3.909
2021-03-17 17:45:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 17:45:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_8_155000.pt (epoch 8 @ 155000 updates, score 3.906) (writing took 6.382680405862629 seconds)
2021-03-17 17:48:37 | INFO | train_inner | epoch 008:  13416 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=19536.7, ups=0.39, wpb=50660.2, bsz=2967.3, num_updates=155100, lr=0.000144533, gnorm=0.273, loss_scale=8, train_wall=179, wall=288872
2021-03-17 17:51:40 | INFO | train_inner | epoch 008:  13516 / 20258 loss=3.499, nll_loss=1.809, ppl=3.5, wps=27873.1, ups=0.55, wpb=50967.4, bsz=3014.5, num_updates=155200, lr=0.000144486, gnorm=0.268, loss_scale=8, train_wall=180, wall=289055
2021-03-17 17:54:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 17:54:44 | INFO | train_inner | epoch 008:  13617 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27550.6, ups=0.54, wpb=50869.8, bsz=3081, num_updates=155300, lr=0.00014444, gnorm=0.276, loss_scale=8, train_wall=181, wall=289240
2021-03-17 17:57:46 | INFO | train_inner | epoch 008:  13717 / 20258 loss=3.488, nll_loss=1.797, ppl=3.47, wps=27900, ups=0.55, wpb=50774.9, bsz=2977, num_updates=155400, lr=0.000144393, gnorm=0.272, loss_scale=8, train_wall=179, wall=289422
2021-03-17 18:00:49 | INFO | train_inner | epoch 008:  13817 / 20258 loss=3.506, nll_loss=1.817, ppl=3.52, wps=27830.9, ups=0.55, wpb=50882, bsz=2956.2, num_updates=155500, lr=0.000144347, gnorm=0.277, loss_scale=8, train_wall=179, wall=289605
2021-03-17 18:03:52 | INFO | train_inner | epoch 008:  13917 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=27875.3, ups=0.55, wpb=50933.7, bsz=3006.9, num_updates=155600, lr=0.0001443, gnorm=0.268, loss_scale=8, train_wall=180, wall=289787
2021-03-17 18:06:55 | INFO | train_inner | epoch 008:  14017 / 20258 loss=3.49, nll_loss=1.799, ppl=3.48, wps=27911.6, ups=0.55, wpb=51054.4, bsz=3098.2, num_updates=155700, lr=0.000144254, gnorm=0.266, loss_scale=8, train_wall=180, wall=289970
2021-03-17 18:09:58 | INFO | train_inner | epoch 008:  14117 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27817.3, ups=0.55, wpb=50916, bsz=3016.8, num_updates=155800, lr=0.000144208, gnorm=0.272, loss_scale=8, train_wall=180, wall=290153
2021-03-17 18:13:00 | INFO | train_inner | epoch 008:  14217 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27935, ups=0.55, wpb=50954.7, bsz=2927.1, num_updates=155900, lr=0.000144162, gnorm=0.272, loss_scale=8, train_wall=179, wall=290336
2021-03-17 18:16:03 | INFO | train_inner | epoch 008:  14317 / 20258 loss=3.509, nll_loss=1.821, ppl=3.53, wps=27867.8, ups=0.55, wpb=50986, bsz=2944.8, num_updates=156000, lr=0.000144115, gnorm=0.274, loss_scale=8, train_wall=179, wall=290519
2021-03-17 18:19:06 | INFO | train_inner | epoch 008:  14417 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=27859.7, ups=0.55, wpb=50851.7, bsz=2969.9, num_updates=156100, lr=0.000144069, gnorm=0.28, loss_scale=8, train_wall=179, wall=290701
2021-03-17 18:22:09 | INFO | train_inner | epoch 008:  14517 / 20258 loss=3.509, nll_loss=1.821, ppl=3.53, wps=27871.3, ups=0.55, wpb=50987, bsz=3015.8, num_updates=156200, lr=0.000144023, gnorm=0.272, loss_scale=8, train_wall=180, wall=290884
2021-03-17 18:25:11 | INFO | train_inner | epoch 008:  14617 / 20258 loss=3.508, nll_loss=1.819, ppl=3.53, wps=27960.3, ups=0.55, wpb=51136.3, bsz=2914, num_updates=156300, lr=0.000143977, gnorm=0.269, loss_scale=8, train_wall=180, wall=291067
2021-03-17 18:28:14 | INFO | train_inner | epoch 008:  14717 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27821.6, ups=0.55, wpb=50709.5, bsz=3038, num_updates=156400, lr=0.000143931, gnorm=0.276, loss_scale=16, train_wall=179, wall=291249
2021-03-17 18:30:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 18:31:18 | INFO | train_inner | epoch 008:  14818 / 20258 loss=3.512, nll_loss=1.824, ppl=3.54, wps=27602.2, ups=0.54, wpb=50844, bsz=3074.1, num_updates=156500, lr=0.000143885, gnorm=0.278, loss_scale=8, train_wall=181, wall=291433
2021-03-17 18:34:20 | INFO | train_inner | epoch 008:  14918 / 20258 loss=3.497, nll_loss=1.807, ppl=3.5, wps=27926.6, ups=0.55, wpb=50883.8, bsz=2913, num_updates=156600, lr=0.000143839, gnorm=0.276, loss_scale=8, train_wall=179, wall=291616
2021-03-17 18:37:23 | INFO | train_inner | epoch 008:  15018 / 20258 loss=3.501, nll_loss=1.812, ppl=3.51, wps=27819.2, ups=0.55, wpb=50999.7, bsz=3124.7, num_updates=156700, lr=0.000143793, gnorm=0.287, loss_scale=8, train_wall=180, wall=291799
2021-03-17 18:40:26 | INFO | train_inner | epoch 008:  15118 / 20258 loss=3.497, nll_loss=1.806, ppl=3.5, wps=27907, ups=0.55, wpb=51059.7, bsz=3022.3, num_updates=156800, lr=0.000143747, gnorm=0.283, loss_scale=8, train_wall=180, wall=291982
2021-03-17 18:43:29 | INFO | train_inner | epoch 008:  15218 / 20258 loss=3.508, nll_loss=1.82, ppl=3.53, wps=27947, ups=0.55, wpb=51015.2, bsz=3095.4, num_updates=156900, lr=0.000143701, gnorm=0.279, loss_scale=8, train_wall=180, wall=292164
2021-03-17 18:46:32 | INFO | train_inner | epoch 008:  15318 / 20258 loss=3.488, nll_loss=1.796, ppl=3.47, wps=27800.8, ups=0.54, wpb=51015.9, bsz=3037.2, num_updates=157000, lr=0.000143656, gnorm=0.267, loss_scale=8, train_wall=180, wall=292348
2021-03-17 18:49:34 | INFO | train_inner | epoch 008:  15418 / 20258 loss=3.516, nll_loss=1.828, ppl=3.55, wps=28018.8, ups=0.55, wpb=50998.6, bsz=2983.8, num_updates=157100, lr=0.00014361, gnorm=0.274, loss_scale=8, train_wall=179, wall=292530
2021-03-17 18:52:36 | INFO | train_inner | epoch 008:  15518 / 20258 loss=3.507, nll_loss=1.818, ppl=3.53, wps=27868.7, ups=0.55, wpb=50602.6, bsz=3118.5, num_updates=157200, lr=0.000143564, gnorm=0.278, loss_scale=8, train_wall=179, wall=292712
2021-03-17 18:55:38 | INFO | train_inner | epoch 008:  15618 / 20258 loss=3.497, nll_loss=1.807, ppl=3.5, wps=27908.9, ups=0.55, wpb=50802.6, bsz=3030.8, num_updates=157300, lr=0.000143519, gnorm=0.279, loss_scale=8, train_wall=179, wall=292894
2021-03-17 18:58:40 | INFO | train_inner | epoch 008:  15718 / 20258 loss=3.477, nll_loss=1.784, ppl=3.44, wps=27882.4, ups=0.55, wpb=50836.2, bsz=2884.3, num_updates=157400, lr=0.000143473, gnorm=0.269, loss_scale=8, train_wall=179, wall=293076
2021-03-17 19:01:42 | INFO | train_inner | epoch 008:  15818 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27854.9, ups=0.55, wpb=50666.1, bsz=3004.1, num_updates=157500, lr=0.000143427, gnorm=0.279, loss_scale=8, train_wall=179, wall=293258
2021-03-17 19:04:45 | INFO | train_inner | epoch 008:  15918 / 20258 loss=3.505, nll_loss=1.816, ppl=3.52, wps=27877.3, ups=0.55, wpb=50865, bsz=3062, num_updates=157600, lr=0.000143382, gnorm=0.272, loss_scale=16, train_wall=179, wall=293440
2021-03-17 19:07:48 | INFO | train_inner | epoch 008:  16018 / 20258 loss=3.488, nll_loss=1.796, ppl=3.47, wps=27979, ups=0.55, wpb=51248.2, bsz=3009.3, num_updates=157700, lr=0.000143336, gnorm=0.277, loss_scale=16, train_wall=180, wall=293623
2021-03-17 19:10:51 | INFO | train_inner | epoch 008:  16118 / 20258 loss=3.511, nll_loss=1.823, ppl=3.54, wps=27855.4, ups=0.55, wpb=51061.7, bsz=3011.2, num_updates=157800, lr=0.000143291, gnorm=0.275, loss_scale=16, train_wall=180, wall=293807
2021-03-17 19:13:54 | INFO | train_inner | epoch 008:  16218 / 20258 loss=3.513, nll_loss=1.826, ppl=3.54, wps=27972.6, ups=0.55, wpb=50984.4, bsz=3007.8, num_updates=157900, lr=0.000143246, gnorm=0.271, loss_scale=16, train_wall=179, wall=293989
2021-03-17 19:14:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 19:16:58 | INFO | train_inner | epoch 008:  16319 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27553.2, ups=0.54, wpb=50787.8, bsz=2861.9, num_updates=158000, lr=0.0001432, gnorm=0.274, loss_scale=8, train_wall=181, wall=294173
2021-03-17 19:20:00 | INFO | train_inner | epoch 008:  16419 / 20258 loss=3.505, nll_loss=1.816, ppl=3.52, wps=28037.2, ups=0.55, wpb=51135.5, bsz=2961.9, num_updates=158100, lr=0.000143155, gnorm=0.273, loss_scale=8, train_wall=179, wall=294356
2021-03-17 19:23:03 | INFO | train_inner | epoch 008:  16519 / 20258 loss=3.511, nll_loss=1.823, ppl=3.54, wps=27964.1, ups=0.55, wpb=51074.2, bsz=3005.8, num_updates=158200, lr=0.00014311, gnorm=0.278, loss_scale=8, train_wall=179, wall=294538
2021-03-17 19:26:05 | INFO | train_inner | epoch 008:  16619 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27869.2, ups=0.55, wpb=50821.4, bsz=3077, num_updates=158300, lr=0.000143065, gnorm=0.281, loss_scale=8, train_wall=179, wall=294721
2021-03-17 19:29:08 | INFO | train_inner | epoch 008:  16719 / 20258 loss=3.484, nll_loss=1.792, ppl=3.46, wps=27799.1, ups=0.55, wpb=50890.6, bsz=2973.4, num_updates=158400, lr=0.000143019, gnorm=0.271, loss_scale=8, train_wall=180, wall=294904
2021-03-17 19:32:11 | INFO | train_inner | epoch 008:  16819 / 20258 loss=3.498, nll_loss=1.809, ppl=3.5, wps=27887.7, ups=0.55, wpb=50833.8, bsz=3013.2, num_updates=158500, lr=0.000142974, gnorm=0.28, loss_scale=8, train_wall=179, wall=295086
2021-03-17 19:35:13 | INFO | train_inner | epoch 008:  16919 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27802.8, ups=0.55, wpb=50818.8, bsz=3046.2, num_updates=158600, lr=0.000142929, gnorm=0.274, loss_scale=8, train_wall=179, wall=295269
2021-03-17 19:38:16 | INFO | train_inner | epoch 008:  17019 / 20258 loss=3.514, nll_loss=1.826, ppl=3.55, wps=27976.2, ups=0.55, wpb=51038.8, bsz=3060.1, num_updates=158700, lr=0.000142884, gnorm=0.28, loss_scale=8, train_wall=179, wall=295451
2021-03-17 19:41:18 | INFO | train_inner | epoch 008:  17119 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=27922.7, ups=0.55, wpb=50984.2, bsz=2990.9, num_updates=158800, lr=0.000142839, gnorm=0.272, loss_scale=8, train_wall=179, wall=295634
2021-03-17 19:44:21 | INFO | train_inner | epoch 008:  17219 / 20258 loss=3.511, nll_loss=1.822, ppl=3.54, wps=27803, ups=0.55, wpb=50717.8, bsz=3019, num_updates=158900, lr=0.000142794, gnorm=0.276, loss_scale=8, train_wall=179, wall=295816
2021-03-17 19:47:23 | INFO | train_inner | epoch 008:  17319 / 20258 loss=3.487, nll_loss=1.795, ppl=3.47, wps=27826, ups=0.55, wpb=50584.3, bsz=2985.4, num_updates=159000, lr=0.000142749, gnorm=0.27, loss_scale=16, train_wall=179, wall=295998
2021-03-17 19:50:25 | INFO | train_inner | epoch 008:  17419 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27937.3, ups=0.55, wpb=50989.6, bsz=3087.4, num_updates=159100, lr=0.000142704, gnorm=0.272, loss_scale=16, train_wall=179, wall=296181
2021-03-17 19:53:28 | INFO | train_inner | epoch 008:  17519 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=28021.7, ups=0.55, wpb=51126.8, bsz=2939, num_updates=159200, lr=0.00014266, gnorm=0.278, loss_scale=16, train_wall=180, wall=296363
2021-03-17 19:54:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 19:56:32 | INFO | train_inner | epoch 008:  17620 / 20258 loss=3.504, nll_loss=1.815, ppl=3.52, wps=27633.1, ups=0.54, wpb=50914.4, bsz=2902.5, num_updates=159300, lr=0.000142615, gnorm=0.275, loss_scale=8, train_wall=181, wall=296547
2021-03-17 19:59:34 | INFO | train_inner | epoch 008:  17720 / 20258 loss=3.487, nll_loss=1.795, ppl=3.47, wps=27889.7, ups=0.55, wpb=50893.2, bsz=3015.8, num_updates=159400, lr=0.00014257, gnorm=0.272, loss_scale=8, train_wall=179, wall=296730
2021-03-17 20:02:36 | INFO | train_inner | epoch 008:  17820 / 20258 loss=3.507, nll_loss=1.818, ppl=3.53, wps=27852.7, ups=0.55, wpb=50697.4, bsz=2925.1, num_updates=159500, lr=0.000142525, gnorm=0.274, loss_scale=8, train_wall=179, wall=296912
2021-03-17 20:05:39 | INFO | train_inner | epoch 008:  17920 / 20258 loss=3.489, nll_loss=1.799, ppl=3.48, wps=27837.7, ups=0.55, wpb=50807.9, bsz=3016, num_updates=159600, lr=0.000142481, gnorm=0.277, loss_scale=8, train_wall=179, wall=297094
2021-03-17 20:08:41 | INFO | train_inner | epoch 008:  18020 / 20258 loss=3.522, nll_loss=1.835, ppl=3.57, wps=27953.6, ups=0.55, wpb=50897, bsz=2969.1, num_updates=159700, lr=0.000142436, gnorm=0.275, loss_scale=8, train_wall=179, wall=297276
2021-03-17 20:11:43 | INFO | train_inner | epoch 008:  18120 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27960.7, ups=0.55, wpb=50969.4, bsz=2941.6, num_updates=159800, lr=0.000142392, gnorm=0.27, loss_scale=8, train_wall=179, wall=297459
2021-03-17 20:14:46 | INFO | train_inner | epoch 008:  18220 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27947.4, ups=0.55, wpb=51117.4, bsz=3041, num_updates=159900, lr=0.000142347, gnorm=0.271, loss_scale=8, train_wall=180, wall=297642
2021-03-17 20:17:49 | INFO | train_inner | epoch 008:  18320 / 20258 loss=3.49, nll_loss=1.799, ppl=3.48, wps=27761.3, ups=0.55, wpb=50736.4, bsz=3046.1, num_updates=160000, lr=0.000142302, gnorm=0.277, loss_scale=8, train_wall=179, wall=297824
2021-03-17 20:17:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 20:17:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:17:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:17:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:17:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:17:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:17:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:17:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:17:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:17:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:17:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:17:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:17:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:17:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:17:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:17:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:17:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:17:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:17:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:17:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:17:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:17:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:07 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.903 | nll_loss 2.187 | ppl 4.55 | bleu 29.84 | wps 4381.3 | wpb 2432 | bsz 90.4 | num_updates 160000 | best_loss 3.903
2021-03-17 20:18:07 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 20:18:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:18:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 20:18:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 20:18:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 20:19:00 | INFO | valid1 | epoch 008 | valid on 'valid1' subset | loss 3.906 | nll_loss 2.213 | ppl 4.64 | bleu 27.57 | wps 4251.3 | wpb 2359.4 | bsz 106.4 | num_updates 160000 | best_loss 3.906
2021-03-17 20:19:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 20:19:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_8_160000.pt (epoch 8 @ 160000 updates, score 3.903) (writing took 6.432001744164154 seconds)
2021-03-17 20:22:09 | INFO | train_inner | epoch 008:  18420 / 20258 loss=3.502, nll_loss=1.814, ppl=3.52, wps=19527, ups=0.39, wpb=50704, bsz=3052, num_updates=160100, lr=0.000142258, gnorm=0.272, loss_scale=8, train_wall=179, wall=298084
2021-03-17 20:25:12 | INFO | train_inner | epoch 008:  18520 / 20258 loss=3.481, nll_loss=1.789, ppl=3.46, wps=27867.3, ups=0.55, wpb=51127.4, bsz=2985.9, num_updates=160200, lr=0.000142214, gnorm=0.276, loss_scale=8, train_wall=180, wall=298268
2021-03-17 20:28:15 | INFO | train_inner | epoch 008:  18620 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27825.4, ups=0.55, wpb=50778.4, bsz=3000.9, num_updates=160300, lr=0.000142169, gnorm=0.272, loss_scale=16, train_wall=179, wall=298450
2021-03-17 20:31:17 | INFO | train_inner | epoch 008:  18720 / 20258 loss=3.499, nll_loss=1.809, ppl=3.5, wps=27981.8, ups=0.55, wpb=51064.8, bsz=2987.3, num_updates=160400, lr=0.000142125, gnorm=0.269, loss_scale=16, train_wall=179, wall=298633
2021-03-17 20:34:19 | INFO | train_inner | epoch 008:  18820 / 20258 loss=3.506, nll_loss=1.817, ppl=3.52, wps=27788.2, ups=0.55, wpb=50677.8, bsz=3111.3, num_updates=160500, lr=0.000142081, gnorm=0.277, loss_scale=16, train_wall=179, wall=298815
2021-03-17 20:37:22 | INFO | train_inner | epoch 008:  18920 / 20258 loss=3.515, nll_loss=1.828, ppl=3.55, wps=28038.5, ups=0.55, wpb=51082.7, bsz=2971.4, num_updates=160600, lr=0.000142036, gnorm=0.271, loss_scale=16, train_wall=179, wall=298997
2021-03-17 20:40:24 | INFO | train_inner | epoch 008:  19020 / 20258 loss=3.503, nll_loss=1.814, ppl=3.52, wps=27902.5, ups=0.55, wpb=50822.6, bsz=3014.4, num_updates=160700, lr=0.000141992, gnorm=0.27, loss_scale=16, train_wall=179, wall=299179
2021-03-17 20:43:26 | INFO | train_inner | epoch 008:  19120 / 20258 loss=3.514, nll_loss=1.827, ppl=3.55, wps=27843.4, ups=0.55, wpb=50804.3, bsz=3011.4, num_updates=160800, lr=0.000141948, gnorm=0.278, loss_scale=16, train_wall=179, wall=299362
2021-03-17 20:46:29 | INFO | train_inner | epoch 008:  19220 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27924.9, ups=0.55, wpb=50985.4, bsz=3043.6, num_updates=160900, lr=0.000141904, gnorm=0.27, loss_scale=16, train_wall=180, wall=299544
2021-03-17 20:49:31 | INFO | train_inner | epoch 008:  19320 / 20258 loss=3.515, nll_loss=1.827, ppl=3.55, wps=28024.6, ups=0.55, wpb=51193.3, bsz=3040.2, num_updates=161000, lr=0.00014186, gnorm=0.276, loss_scale=16, train_wall=179, wall=299727
2021-03-17 20:52:34 | INFO | train_inner | epoch 008:  19420 / 20258 loss=3.492, nll_loss=1.801, ppl=3.49, wps=27902.4, ups=0.55, wpb=50846.5, bsz=3061.3, num_updates=161100, lr=0.000141816, gnorm=0.268, loss_scale=16, train_wall=179, wall=299909
2021-03-17 20:55:36 | INFO | train_inner | epoch 008:  19520 / 20258 loss=3.522, nll_loss=1.835, ppl=3.57, wps=27895.9, ups=0.55, wpb=50815.2, bsz=2946.2, num_updates=161200, lr=0.000141772, gnorm=0.278, loss_scale=16, train_wall=179, wall=300091
2021-03-17 20:58:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2021-03-17 20:58:40 | INFO | train_inner | epoch 008:  19621 / 20258 loss=3.497, nll_loss=1.806, ppl=3.5, wps=27588.8, ups=0.54, wpb=50923.4, bsz=2931.4, num_updates=161300, lr=0.000141728, gnorm=0.273, loss_scale=16, train_wall=181, wall=300276
2021-03-17 21:01:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 21:01:44 | INFO | train_inner | epoch 008:  19722 / 20258 loss=3.505, nll_loss=1.816, ppl=3.52, wps=27558.9, ups=0.54, wpb=50671.4, bsz=3140.8, num_updates=161400, lr=0.000141684, gnorm=0.274, loss_scale=8, train_wall=181, wall=300460
2021-03-17 21:04:47 | INFO | train_inner | epoch 008:  19822 / 20258 loss=3.504, nll_loss=1.815, ppl=3.52, wps=27842, ups=0.55, wpb=50865.5, bsz=3005.5, num_updates=161500, lr=0.00014164, gnorm=0.273, loss_scale=8, train_wall=179, wall=300643
2021-03-17 21:07:49 | INFO | train_inner | epoch 008:  19922 / 20258 loss=3.497, nll_loss=1.807, ppl=3.5, wps=27896.2, ups=0.55, wpb=50822.3, bsz=3121.9, num_updates=161600, lr=0.000141596, gnorm=0.276, loss_scale=8, train_wall=179, wall=300825
2021-03-17 21:10:52 | INFO | train_inner | epoch 008:  20022 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27931.1, ups=0.55, wpb=51018.5, bsz=3046.8, num_updates=161700, lr=0.000141552, gnorm=0.27, loss_scale=8, train_wall=179, wall=301007
2021-03-17 21:13:54 | INFO | train_inner | epoch 008:  20122 / 20258 loss=3.51, nll_loss=1.821, ppl=3.53, wps=27952.6, ups=0.55, wpb=50808, bsz=2878.4, num_updates=161800, lr=0.000141509, gnorm=0.276, loss_scale=8, train_wall=179, wall=301189
2021-03-17 21:16:57 | INFO | train_inner | epoch 008:  20222 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27934.8, ups=0.55, wpb=51112.9, bsz=3136.1, num_updates=161900, lr=0.000141465, gnorm=0.278, loss_scale=8, train_wall=180, wall=301372
2021-03-17 21:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 21:18:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:21 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.907 | nll_loss 2.194 | ppl 4.58 | bleu 29.69 | wps 4310 | wpb 2432 | bsz 90.4 | num_updates 161936 | best_loss 3.903
2021-03-17 21:18:21 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 21:18:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:18:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 21:18:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 21:18:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 21:19:13 | INFO | valid1 | epoch 008 | valid on 'valid1' subset | loss 3.907 | nll_loss 2.218 | ppl 4.65 | bleu 27.6 | wps 4218.3 | wpb 2359.4 | bsz 106.4 | num_updates 161936 | best_loss 3.903
2021-03-17 21:19:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 21:19:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint8.pt (epoch 8 @ 161936 updates, score 3.907) (writing took 4.603683151071891 seconds)
2021-03-17 21:19:18 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-03-17 21:19:18 | INFO | train | epoch 008 | loss 3.501 | nll_loss 1.811 | ppl 3.51 | wps 27577.4 | ups 0.54 | wpb 50905.8 | bsz 3010.3 | num_updates 161936 | lr 0.000141449 | gnorm 0.273 | loss_scale 8 | train_wall 36332 | wall 301514
2021-03-17 21:19:18 | INFO | fairseq.trainer | begin training epoch 9
2021-03-17 21:21:15 | INFO | train_inner | epoch 009:     64 / 20258 loss=3.489, nll_loss=1.799, ppl=3.48, wps=19621.3, ups=0.39, wpb=50749.9, bsz=3060.6, num_updates=162000, lr=0.000141421, gnorm=0.275, loss_scale=8, train_wall=179, wall=301631
2021-03-17 21:24:18 | INFO | train_inner | epoch 009:    164 / 20258 loss=3.503, nll_loss=1.813, ppl=3.51, wps=27893.8, ups=0.55, wpb=51092.7, bsz=2976.3, num_updates=162100, lr=0.000141378, gnorm=0.272, loss_scale=8, train_wall=179, wall=301814
2021-03-17 21:27:22 | INFO | train_inner | epoch 009:    264 / 20258 loss=3.482, nll_loss=1.79, ppl=3.46, wps=27820, ups=0.55, wpb=51030.5, bsz=3083.8, num_updates=162200, lr=0.000141334, gnorm=0.268, loss_scale=8, train_wall=180, wall=301997
2021-03-17 21:30:25 | INFO | train_inner | epoch 009:    364 / 20258 loss=3.479, nll_loss=1.786, ppl=3.45, wps=27934.6, ups=0.55, wpb=51142.7, bsz=2994.2, num_updates=162300, lr=0.000141291, gnorm=0.271, loss_scale=8, train_wall=180, wall=302180
2021-03-17 21:33:28 | INFO | train_inner | epoch 009:    464 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27934.5, ups=0.55, wpb=51082.4, bsz=3023.4, num_updates=162400, lr=0.000141247, gnorm=0.279, loss_scale=8, train_wall=180, wall=302363
2021-03-17 21:36:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 21:36:33 | INFO | train_inner | epoch 009:    565 / 20258 loss=3.479, nll_loss=1.786, ppl=3.45, wps=27665.4, ups=0.54, wpb=51169.1, bsz=3008.8, num_updates=162500, lr=0.000141204, gnorm=0.268, loss_scale=8, train_wall=182, wall=302548
2021-03-17 21:39:35 | INFO | train_inner | epoch 009:    665 / 20258 loss=3.498, nll_loss=1.807, ppl=3.5, wps=27983.7, ups=0.55, wpb=51025.2, bsz=3002.9, num_updates=162600, lr=0.00014116, gnorm=0.276, loss_scale=8, train_wall=179, wall=302731
2021-03-17 21:42:38 | INFO | train_inner | epoch 009:    765 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27911.7, ups=0.55, wpb=51020.9, bsz=3043.8, num_updates=162700, lr=0.000141117, gnorm=0.274, loss_scale=8, train_wall=180, wall=302913
2021-03-17 21:45:40 | INFO | train_inner | epoch 009:    865 / 20258 loss=3.484, nll_loss=1.792, ppl=3.46, wps=27971.6, ups=0.55, wpb=51001.4, bsz=3051.3, num_updates=162800, lr=0.000141073, gnorm=0.28, loss_scale=8, train_wall=179, wall=303096
2021-03-17 21:48:43 | INFO | train_inner | epoch 009:    965 / 20258 loss=3.468, nll_loss=1.774, ppl=3.42, wps=27667.9, ups=0.55, wpb=50595.2, bsz=3237, num_updates=162900, lr=0.00014103, gnorm=0.27, loss_scale=8, train_wall=179, wall=303279
2021-03-17 21:51:46 | INFO | train_inner | epoch 009:   1065 / 20258 loss=3.479, nll_loss=1.786, ppl=3.45, wps=27818.8, ups=0.55, wpb=50897, bsz=2963.7, num_updates=163000, lr=0.000140987, gnorm=0.277, loss_scale=8, train_wall=179, wall=303462
2021-03-17 21:54:49 | INFO | train_inner | epoch 009:   1165 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27900.8, ups=0.55, wpb=50971.3, bsz=3030, num_updates=163100, lr=0.000140944, gnorm=0.271, loss_scale=8, train_wall=179, wall=303644
2021-03-17 21:57:51 | INFO | train_inner | epoch 009:   1265 / 20258 loss=3.484, nll_loss=1.791, ppl=3.46, wps=27826.6, ups=0.55, wpb=50834.2, bsz=2954.7, num_updates=163200, lr=0.0001409, gnorm=0.274, loss_scale=8, train_wall=179, wall=303827
2021-03-17 22:00:55 | INFO | train_inner | epoch 009:   1365 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27820.2, ups=0.55, wpb=50975.3, bsz=3151.8, num_updates=163300, lr=0.000140857, gnorm=0.274, loss_scale=8, train_wall=180, wall=304010
2021-03-17 22:03:58 | INFO | train_inner | epoch 009:   1465 / 20258 loss=3.492, nll_loss=1.801, ppl=3.49, wps=27915.5, ups=0.55, wpb=51074.5, bsz=3114.7, num_updates=163400, lr=0.000140814, gnorm=0.275, loss_scale=8, train_wall=180, wall=304193
2021-03-17 22:07:00 | INFO | train_inner | epoch 009:   1565 / 20258 loss=3.475, nll_loss=1.781, ppl=3.44, wps=27914.1, ups=0.55, wpb=51051.8, bsz=2969, num_updates=163500, lr=0.000140771, gnorm=0.275, loss_scale=8, train_wall=180, wall=304376
2021-03-17 22:08:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 22:10:05 | INFO | train_inner | epoch 009:   1666 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27590.6, ups=0.54, wpb=50896.3, bsz=3023.8, num_updates=163600, lr=0.000140728, gnorm=0.274, loss_scale=8, train_wall=181, wall=304560
2021-03-17 22:13:08 | INFO | train_inner | epoch 009:   1766 / 20258 loss=3.477, nll_loss=1.784, ppl=3.44, wps=27943.7, ups=0.55, wpb=51115.9, bsz=2972.2, num_updates=163700, lr=0.000140685, gnorm=0.273, loss_scale=8, train_wall=180, wall=304743
2021-03-17 22:16:10 | INFO | train_inner | epoch 009:   1866 / 20258 loss=3.466, nll_loss=1.772, ppl=3.42, wps=27742, ups=0.55, wpb=50565.4, bsz=3009.2, num_updates=163800, lr=0.000140642, gnorm=0.273, loss_scale=8, train_wall=179, wall=304926
2021-03-17 22:19:13 | INFO | train_inner | epoch 009:   1966 / 20258 loss=3.497, nll_loss=1.806, ppl=3.5, wps=27973.4, ups=0.55, wpb=51129.6, bsz=3024.2, num_updates=163900, lr=0.000140599, gnorm=0.274, loss_scale=8, train_wall=179, wall=305108
2021-03-17 22:22:15 | INFO | train_inner | epoch 009:   2066 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27788.4, ups=0.55, wpb=50681.2, bsz=3117.5, num_updates=164000, lr=0.000140556, gnorm=0.271, loss_scale=8, train_wall=179, wall=305291
2021-03-17 22:25:18 | INFO | train_inner | epoch 009:   2166 / 20258 loss=3.501, nll_loss=1.812, ppl=3.51, wps=27882.7, ups=0.55, wpb=50806.1, bsz=3137.9, num_updates=164100, lr=0.000140514, gnorm=0.273, loss_scale=8, train_wall=179, wall=305473
2021-03-17 22:28:20 | INFO | train_inner | epoch 009:   2266 / 20258 loss=3.456, nll_loss=1.76, ppl=3.39, wps=27869.2, ups=0.55, wpb=50972.6, bsz=2975.9, num_updates=164200, lr=0.000140471, gnorm=0.267, loss_scale=8, train_wall=180, wall=305656
2021-03-17 22:31:23 | INFO | train_inner | epoch 009:   2366 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27853.7, ups=0.55, wpb=50848.4, bsz=2980.8, num_updates=164300, lr=0.000140428, gnorm=0.277, loss_scale=8, train_wall=179, wall=305839
2021-03-17 22:34:25 | INFO | train_inner | epoch 009:   2466 / 20258 loss=3.49, nll_loss=1.799, ppl=3.48, wps=27859.9, ups=0.55, wpb=50743.5, bsz=2954.9, num_updates=164400, lr=0.000140385, gnorm=0.277, loss_scale=8, train_wall=179, wall=306021
2021-03-17 22:37:29 | INFO | train_inner | epoch 009:   2566 / 20258 loss=3.47, nll_loss=1.776, ppl=3.43, wps=27817.5, ups=0.55, wpb=51019.4, bsz=3099.9, num_updates=164500, lr=0.000140343, gnorm=0.275, loss_scale=8, train_wall=180, wall=306204
2021-03-17 22:40:32 | INFO | train_inner | epoch 009:   2666 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=27880.1, ups=0.55, wpb=51062.7, bsz=2978.5, num_updates=164600, lr=0.0001403, gnorm=0.276, loss_scale=16, train_wall=180, wall=306387
2021-03-17 22:43:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 22:43:37 | INFO | train_inner | epoch 009:   2767 / 20258 loss=3.471, nll_loss=1.778, ppl=3.43, wps=27516.1, ups=0.54, wpb=51005.8, bsz=3030.4, num_updates=164700, lr=0.000140257, gnorm=0.27, loss_scale=8, train_wall=182, wall=306573
2021-03-17 22:46:39 | INFO | train_inner | epoch 009:   2867 / 20258 loss=3.488, nll_loss=1.797, ppl=3.47, wps=27943.5, ups=0.55, wpb=50970.5, bsz=2990.8, num_updates=164800, lr=0.000140215, gnorm=0.274, loss_scale=8, train_wall=179, wall=306755
2021-03-17 22:49:42 | INFO | train_inner | epoch 009:   2967 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27824.6, ups=0.55, wpb=50699.8, bsz=3093.9, num_updates=164900, lr=0.000140172, gnorm=0.273, loss_scale=8, train_wall=179, wall=306937
2021-03-17 22:52:44 | INFO | train_inner | epoch 009:   3067 / 20258 loss=3.484, nll_loss=1.792, ppl=3.46, wps=27915.5, ups=0.55, wpb=50822.4, bsz=2988, num_updates=165000, lr=0.00014013, gnorm=0.275, loss_scale=8, train_wall=179, wall=307119
2021-03-17 22:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-17 22:52:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:52:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:52:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:52:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:52:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:52:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:52:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:52:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:52:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:52:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:52:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:52:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:52:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:52:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:52:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:02 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.909 | nll_loss 2.19 | ppl 4.56 | bleu 30.14 | wps 4372.6 | wpb 2432 | bsz 90.4 | num_updates 165000 | best_loss 3.903
2021-03-17 22:53:02 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-17 22:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-17 22:53:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-17 22:53:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-17 22:53:55 | INFO | valid1 | epoch 009 | valid on 'valid1' subset | loss 3.907 | nll_loss 2.212 | ppl 4.63 | bleu 27.72 | wps 4209.9 | wpb 2359.4 | bsz 106.4 | num_updates 165000 | best_loss 3.903
2021-03-17 22:53:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-17 22:54:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_9_165000.pt (epoch 9 @ 165000 updates, score 3.909) (writing took 4.619191219098866 seconds)
2021-03-17 22:57:02 | INFO | train_inner | epoch 009:   3167 / 20258 loss=3.491, nll_loss=1.799, ppl=3.48, wps=19749.7, ups=0.39, wpb=50978, bsz=2939.4, num_updates=165100, lr=0.000140087, gnorm=0.276, loss_scale=8, train_wall=179, wall=307377
2021-03-17 23:00:04 | INFO | train_inner | epoch 009:   3267 / 20258 loss=3.488, nll_loss=1.796, ppl=3.47, wps=27840.6, ups=0.55, wpb=50832.1, bsz=3001.8, num_updates=165200, lr=0.000140045, gnorm=0.271, loss_scale=8, train_wall=180, wall=307560
2021-03-17 23:03:07 | INFO | train_inner | epoch 009:   3367 / 20258 loss=3.492, nll_loss=1.801, ppl=3.48, wps=27981.3, ups=0.55, wpb=51189.7, bsz=2953.3, num_updates=165300, lr=0.000140003, gnorm=0.272, loss_scale=8, train_wall=180, wall=307743
2021-03-17 23:06:10 | INFO | train_inner | epoch 009:   3467 / 20258 loss=3.5, nll_loss=1.811, ppl=3.51, wps=27872.7, ups=0.55, wpb=50893.7, bsz=3068.6, num_updates=165400, lr=0.00013996, gnorm=0.278, loss_scale=8, train_wall=179, wall=307925
2021-03-17 23:09:13 | INFO | train_inner | epoch 009:   3567 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27868.1, ups=0.55, wpb=51039.2, bsz=3104.7, num_updates=165500, lr=0.000139918, gnorm=0.274, loss_scale=8, train_wall=180, wall=308109
2021-03-17 23:12:15 | INFO | train_inner | epoch 009:   3667 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27864.8, ups=0.55, wpb=50672.5, bsz=3021, num_updates=165600, lr=0.000139876, gnorm=0.269, loss_scale=8, train_wall=179, wall=308290
2021-03-17 23:15:18 | INFO | train_inner | epoch 009:   3767 / 20258 loss=3.488, nll_loss=1.796, ppl=3.47, wps=27838.6, ups=0.55, wpb=50841.5, bsz=3048.8, num_updates=165700, lr=0.000139834, gnorm=0.272, loss_scale=8, train_wall=180, wall=308473
2021-03-17 23:18:20 | INFO | train_inner | epoch 009:   3867 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27997.8, ups=0.55, wpb=51151.6, bsz=2965.4, num_updates=165800, lr=0.000139791, gnorm=0.275, loss_scale=16, train_wall=180, wall=308656
2021-03-17 23:21:23 | INFO | train_inner | epoch 009:   3967 / 20258 loss=3.48, nll_loss=1.788, ppl=3.45, wps=27900.7, ups=0.55, wpb=50944.7, bsz=2932, num_updates=165900, lr=0.000139749, gnorm=0.271, loss_scale=16, train_wall=180, wall=308838
2021-03-17 23:24:26 | INFO | train_inner | epoch 009:   4067 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27911, ups=0.55, wpb=51050.4, bsz=3016.3, num_updates=166000, lr=0.000139707, gnorm=0.273, loss_scale=16, train_wall=180, wall=309021
2021-03-17 23:27:29 | INFO | train_inner | epoch 009:   4167 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27888.9, ups=0.55, wpb=50967, bsz=3059.4, num_updates=166100, lr=0.000139665, gnorm=0.271, loss_scale=16, train_wall=179, wall=309204
2021-03-17 23:30:31 | INFO | train_inner | epoch 009:   4267 / 20258 loss=3.488, nll_loss=1.797, ppl=3.48, wps=27809.4, ups=0.55, wpb=50607.2, bsz=3027.9, num_updates=166200, lr=0.000139623, gnorm=0.275, loss_scale=16, train_wall=179, wall=309386
2021-03-17 23:33:33 | INFO | train_inner | epoch 009:   4367 / 20258 loss=3.502, nll_loss=1.812, ppl=3.51, wps=28024.5, ups=0.55, wpb=51081.4, bsz=2992.9, num_updates=166300, lr=0.000139581, gnorm=0.273, loss_scale=16, train_wall=179, wall=309568
2021-03-17 23:36:35 | INFO | train_inner | epoch 009:   4467 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=27901.2, ups=0.55, wpb=50813.4, bsz=2955.4, num_updates=166400, lr=0.000139539, gnorm=0.272, loss_scale=16, train_wall=179, wall=309750
2021-03-17 23:39:37 | INFO | train_inner | epoch 009:   4567 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27958.4, ups=0.55, wpb=50865.3, bsz=3068.6, num_updates=166500, lr=0.000139497, gnorm=0.272, loss_scale=16, train_wall=179, wall=309932
2021-03-17 23:42:40 | INFO | train_inner | epoch 009:   4667 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=27805.4, ups=0.55, wpb=50839.8, bsz=3039.5, num_updates=166600, lr=0.000139455, gnorm=0.277, loss_scale=16, train_wall=180, wall=310115
2021-03-17 23:45:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-17 23:45:44 | INFO | train_inner | epoch 009:   4768 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27737.5, ups=0.54, wpb=51116.8, bsz=2982.5, num_updates=166700, lr=0.000139413, gnorm=0.279, loss_scale=8, train_wall=181, wall=310300
2021-03-17 23:48:47 | INFO | train_inner | epoch 009:   4868 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27703.6, ups=0.55, wpb=50721.9, bsz=3099, num_updates=166800, lr=0.000139372, gnorm=0.275, loss_scale=8, train_wall=179, wall=310483
2021-03-17 23:51:50 | INFO | train_inner | epoch 009:   4968 / 20258 loss=3.471, nll_loss=1.778, ppl=3.43, wps=27830.3, ups=0.55, wpb=50979.4, bsz=3075.1, num_updates=166900, lr=0.00013933, gnorm=0.273, loss_scale=8, train_wall=180, wall=310666
2021-03-17 23:54:53 | INFO | train_inner | epoch 009:   5068 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27907.9, ups=0.55, wpb=51060.9, bsz=3033.8, num_updates=167000, lr=0.000139288, gnorm=0.275, loss_scale=8, train_wall=180, wall=310849
2021-03-17 23:57:56 | INFO | train_inner | epoch 009:   5168 / 20258 loss=3.48, nll_loss=1.788, ppl=3.45, wps=27926.2, ups=0.55, wpb=51070.6, bsz=2943, num_updates=167100, lr=0.000139246, gnorm=0.273, loss_scale=8, train_wall=180, wall=311032
2021-03-18 00:00:59 | INFO | train_inner | epoch 009:   5268 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27900.1, ups=0.55, wpb=51039.3, bsz=3013.8, num_updates=167200, lr=0.000139205, gnorm=0.272, loss_scale=8, train_wall=180, wall=311215
2021-03-18 00:04:04 | INFO | train_inner | epoch 009:   5368 / 20258 loss=3.494, nll_loss=1.803, ppl=3.49, wps=27479.8, ups=0.54, wpb=50744.4, bsz=2966.9, num_updates=167300, lr=0.000139163, gnorm=0.281, loss_scale=8, train_wall=181, wall=311399
2021-03-18 00:07:06 | INFO | train_inner | epoch 009:   5468 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27889.5, ups=0.55, wpb=50811.6, bsz=3060.1, num_updates=167400, lr=0.000139122, gnorm=0.272, loss_scale=8, train_wall=179, wall=311581
2021-03-18 00:07:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 00:10:11 | INFO | train_inner | epoch 009:   5569 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27671.8, ups=0.54, wpb=51187.2, bsz=3035.7, num_updates=167500, lr=0.00013908, gnorm=0.275, loss_scale=4, train_wall=182, wall=311766
2021-03-18 00:13:13 | INFO | train_inner | epoch 009:   5669 / 20258 loss=3.482, nll_loss=1.79, ppl=3.46, wps=27815.9, ups=0.55, wpb=50693.6, bsz=3105.4, num_updates=167600, lr=0.000139039, gnorm=0.271, loss_scale=4, train_wall=179, wall=311949
2021-03-18 00:16:15 | INFO | train_inner | epoch 009:   5769 / 20258 loss=3.487, nll_loss=1.795, ppl=3.47, wps=27919, ups=0.55, wpb=50852.1, bsz=3072.4, num_updates=167700, lr=0.000138997, gnorm=0.275, loss_scale=4, train_wall=179, wall=312131
2021-03-18 00:19:18 | INFO | train_inner | epoch 009:   5869 / 20258 loss=3.48, nll_loss=1.788, ppl=3.45, wps=27847.3, ups=0.55, wpb=50884.9, bsz=3152.6, num_updates=167800, lr=0.000138956, gnorm=0.277, loss_scale=4, train_wall=180, wall=312314
2021-03-18 00:22:20 | INFO | train_inner | epoch 009:   5969 / 20258 loss=3.476, nll_loss=1.783, ppl=3.44, wps=27809.4, ups=0.55, wpb=50751.6, bsz=3041.2, num_updates=167900, lr=0.000138914, gnorm=0.278, loss_scale=4, train_wall=180, wall=312496
2021-03-18 00:25:23 | INFO | train_inner | epoch 009:   6069 / 20258 loss=3.495, nll_loss=1.805, ppl=3.49, wps=27884.5, ups=0.55, wpb=50820, bsz=2947.4, num_updates=168000, lr=0.000138873, gnorm=0.278, loss_scale=4, train_wall=179, wall=312678
2021-03-18 00:28:25 | INFO | train_inner | epoch 009:   6169 / 20258 loss=3.497, nll_loss=1.807, ppl=3.5, wps=27878.7, ups=0.55, wpb=50788.8, bsz=3101.3, num_updates=168100, lr=0.000138832, gnorm=0.273, loss_scale=4, train_wall=179, wall=312860
2021-03-18 00:31:27 | INFO | train_inner | epoch 009:   6269 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=28044.3, ups=0.55, wpb=51195.7, bsz=3031, num_updates=168200, lr=0.00013879, gnorm=0.273, loss_scale=4, train_wall=179, wall=313043
2021-03-18 00:34:29 | INFO | train_inner | epoch 009:   6369 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27931.4, ups=0.55, wpb=50805.6, bsz=3021.4, num_updates=168300, lr=0.000138749, gnorm=0.273, loss_scale=4, train_wall=179, wall=313225
2021-03-18 00:37:32 | INFO | train_inner | epoch 009:   6469 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27886.7, ups=0.55, wpb=50791, bsz=3069.3, num_updates=168400, lr=0.000138708, gnorm=0.274, loss_scale=4, train_wall=179, wall=313407
2021-03-18 00:40:35 | INFO | train_inner | epoch 009:   6569 / 20258 loss=3.495, nll_loss=1.805, ppl=3.5, wps=27781.5, ups=0.55, wpb=50855.3, bsz=3044.8, num_updates=168500, lr=0.000138667, gnorm=0.269, loss_scale=8, train_wall=179, wall=313590
2021-03-18 00:43:38 | INFO | train_inner | epoch 009:   6669 / 20258 loss=3.475, nll_loss=1.782, ppl=3.44, wps=27888.8, ups=0.54, wpb=51191.7, bsz=3016, num_updates=168600, lr=0.000138626, gnorm=0.276, loss_scale=8, train_wall=180, wall=313774
2021-03-18 00:46:41 | INFO | train_inner | epoch 009:   6769 / 20258 loss=3.49, nll_loss=1.799, ppl=3.48, wps=27825.1, ups=0.55, wpb=50782.8, bsz=2923.4, num_updates=168700, lr=0.000138585, gnorm=0.278, loss_scale=8, train_wall=179, wall=313956
2021-03-18 00:49:44 | INFO | train_inner | epoch 009:   6869 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=27818.8, ups=0.55, wpb=50906.3, bsz=3064.7, num_updates=168800, lr=0.000138544, gnorm=0.28, loss_scale=8, train_wall=179, wall=314139
2021-03-18 00:52:46 | INFO | train_inner | epoch 009:   6969 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=28010, ups=0.55, wpb=51008.3, bsz=2873.9, num_updates=168900, lr=0.000138503, gnorm=0.274, loss_scale=8, train_wall=179, wall=314321
2021-03-18 00:55:48 | INFO | train_inner | epoch 009:   7069 / 20258 loss=3.478, nll_loss=1.785, ppl=3.45, wps=27927.4, ups=0.55, wpb=50895.2, bsz=2988.5, num_updates=169000, lr=0.000138462, gnorm=0.278, loss_scale=8, train_wall=179, wall=314504
2021-03-18 00:58:50 | INFO | train_inner | epoch 009:   7169 / 20258 loss=3.488, nll_loss=1.797, ppl=3.47, wps=27844.6, ups=0.55, wpb=50740.4, bsz=2985, num_updates=169100, lr=0.000138421, gnorm=0.274, loss_scale=8, train_wall=179, wall=314686
2021-03-18 01:01:52 | INFO | train_inner | epoch 009:   7269 / 20258 loss=3.495, nll_loss=1.804, ppl=3.49, wps=28027.4, ups=0.55, wpb=50954.4, bsz=2802.3, num_updates=169200, lr=0.00013838, gnorm=0.278, loss_scale=8, train_wall=179, wall=314868
2021-03-18 01:04:54 | INFO | train_inner | epoch 009:   7369 / 20258 loss=3.487, nll_loss=1.796, ppl=3.47, wps=27905.9, ups=0.55, wpb=50805.9, bsz=2949.2, num_updates=169300, lr=0.000138339, gnorm=0.274, loss_scale=8, train_wall=179, wall=315050
2021-03-18 01:08:01 | INFO | train_inner | epoch 009:   7469 / 20258 loss=3.482, nll_loss=1.79, ppl=3.46, wps=27275.6, ups=0.53, wpb=50999.1, bsz=2982.3, num_updates=169400, lr=0.000138298, gnorm=0.275, loss_scale=8, train_wall=184, wall=315237
2021-03-18 01:11:05 | INFO | train_inner | epoch 009:   7569 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27727.1, ups=0.54, wpb=50879, bsz=3166.2, num_updates=169500, lr=0.000138257, gnorm=0.275, loss_scale=16, train_wall=180, wall=315420
2021-03-18 01:14:07 | INFO | train_inner | epoch 009:   7669 / 20258 loss=3.508, nll_loss=1.82, ppl=3.53, wps=27840.3, ups=0.55, wpb=50924.2, bsz=3073.1, num_updates=169600, lr=0.000138216, gnorm=0.275, loss_scale=16, train_wall=179, wall=315603
2021-03-18 01:15:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 01:17:11 | INFO | train_inner | epoch 009:   7770 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27695.1, ups=0.54, wpb=50952.2, bsz=2929.4, num_updates=169700, lr=0.000138176, gnorm=0.274, loss_scale=8, train_wall=181, wall=315787
2021-03-18 01:20:14 | INFO | train_inner | epoch 009:   7870 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27908.1, ups=0.55, wpb=50885.2, bsz=2942.7, num_updates=169800, lr=0.000138135, gnorm=0.27, loss_scale=8, train_wall=179, wall=315969
2021-03-18 01:23:17 | INFO | train_inner | epoch 009:   7970 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=27783.3, ups=0.54, wpb=50984.3, bsz=2918.3, num_updates=169900, lr=0.000138094, gnorm=0.27, loss_scale=8, train_wall=180, wall=316153
2021-03-18 01:26:20 | INFO | train_inner | epoch 009:   8070 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27949.6, ups=0.55, wpb=51139.7, bsz=3087.8, num_updates=170000, lr=0.000138054, gnorm=0.273, loss_scale=8, train_wall=179, wall=316336
2021-03-18 01:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 01:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:39 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.906 | nll_loss 2.191 | ppl 4.56 | bleu 29.81 | wps 4385.3 | wpb 2432 | bsz 90.4 | num_updates 170000 | best_loss 3.903
2021-03-18 01:26:39 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 01:26:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:26:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:26:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:26:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:27:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:27:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:27:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:27:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:27:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:27:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:27:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 01:27:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 01:27:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 01:27:31 | INFO | valid1 | epoch 009 | valid on 'valid1' subset | loss 3.908 | nll_loss 2.215 | ppl 4.64 | bleu 27.44 | wps 4258.4 | wpb 2359.4 | bsz 106.4 | num_updates 170000 | best_loss 3.903
2021-03-18 01:27:31 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 01:27:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_9_170000.pt (epoch 9 @ 170000 updates, score 3.906) (writing took 4.59121563914232 seconds)
2021-03-18 01:30:39 | INFO | train_inner | epoch 009:   8170 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=19798.6, ups=0.39, wpb=51162.6, bsz=3054.7, num_updates=170100, lr=0.000138013, gnorm=0.275, loss_scale=8, train_wall=180, wall=316594
2021-03-18 01:33:41 | INFO | train_inner | epoch 009:   8270 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27834.6, ups=0.55, wpb=50874.5, bsz=2916, num_updates=170200, lr=0.000137973, gnorm=0.271, loss_scale=8, train_wall=179, wall=316777
2021-03-18 01:36:44 | INFO | train_inner | epoch 009:   8370 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27885.8, ups=0.55, wpb=50851.6, bsz=3091.1, num_updates=170300, lr=0.000137932, gnorm=0.275, loss_scale=8, train_wall=179, wall=316959
2021-03-18 01:37:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 01:39:48 | INFO | train_inner | epoch 009:   8471 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27691.7, ups=0.54, wpb=50999.4, bsz=2987.7, num_updates=170400, lr=0.000137892, gnorm=0.272, loss_scale=4, train_wall=181, wall=317144
2021-03-18 01:42:50 | INFO | train_inner | epoch 009:   8571 / 20258 loss=3.49, nll_loss=1.799, ppl=3.48, wps=27939.4, ups=0.55, wpb=50942.1, bsz=3048.2, num_updates=170500, lr=0.000137851, gnorm=0.276, loss_scale=4, train_wall=179, wall=317326
2021-03-18 01:45:53 | INFO | train_inner | epoch 009:   8671 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27873.9, ups=0.55, wpb=50859.7, bsz=2992.5, num_updates=170600, lr=0.000137811, gnorm=0.275, loss_scale=4, train_wall=179, wall=317508
2021-03-18 01:48:55 | INFO | train_inner | epoch 009:   8771 / 20258 loss=3.47, nll_loss=1.777, ppl=3.43, wps=27877.9, ups=0.55, wpb=50776.6, bsz=2968.3, num_updates=170700, lr=0.00013777, gnorm=0.271, loss_scale=4, train_wall=179, wall=317690
2021-03-18 01:51:57 | INFO | train_inner | epoch 009:   8871 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27938.4, ups=0.55, wpb=50992, bsz=2947.3, num_updates=170800, lr=0.00013773, gnorm=0.27, loss_scale=4, train_wall=180, wall=317873
2021-03-18 01:55:01 | INFO | train_inner | epoch 009:   8971 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27925.8, ups=0.55, wpb=51174.8, bsz=2981.2, num_updates=170900, lr=0.00013769, gnorm=0.267, loss_scale=4, train_wall=180, wall=318056
2021-03-18 01:58:03 | INFO | train_inner | epoch 009:   9071 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27903.1, ups=0.55, wpb=50842.3, bsz=3095.4, num_updates=171000, lr=0.000137649, gnorm=0.272, loss_scale=4, train_wall=179, wall=318238
2021-03-18 02:01:05 | INFO | train_inner | epoch 009:   9171 / 20258 loss=3.5, nll_loss=1.811, ppl=3.51, wps=27988.1, ups=0.55, wpb=51016, bsz=2967.8, num_updates=171100, lr=0.000137609, gnorm=0.282, loss_scale=4, train_wall=179, wall=318421
2021-03-18 02:04:08 | INFO | train_inner | epoch 009:   9271 / 20258 loss=3.468, nll_loss=1.774, ppl=3.42, wps=27855.3, ups=0.55, wpb=51000.5, bsz=3016.5, num_updates=171200, lr=0.000137569, gnorm=0.275, loss_scale=4, train_wall=180, wall=318604
2021-03-18 02:07:11 | INFO | train_inner | epoch 009:   9371 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27988.7, ups=0.55, wpb=51108.4, bsz=3107.5, num_updates=171300, lr=0.000137529, gnorm=0.276, loss_scale=4, train_wall=180, wall=318786
2021-03-18 02:10:13 | INFO | train_inner | epoch 009:   9471 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27769.2, ups=0.55, wpb=50544.1, bsz=2954.8, num_updates=171400, lr=0.000137489, gnorm=0.275, loss_scale=8, train_wall=179, wall=318968
2021-03-18 02:13:16 | INFO | train_inner | epoch 009:   9571 / 20258 loss=3.488, nll_loss=1.797, ppl=3.47, wps=27925.3, ups=0.55, wpb=51019.1, bsz=2952.8, num_updates=171500, lr=0.000137449, gnorm=0.28, loss_scale=8, train_wall=179, wall=319151
2021-03-18 02:16:19 | INFO | train_inner | epoch 009:   9671 / 20258 loss=3.484, nll_loss=1.792, ppl=3.46, wps=27879.5, ups=0.55, wpb=51042.7, bsz=3014.5, num_updates=171600, lr=0.000137409, gnorm=0.277, loss_scale=8, train_wall=180, wall=319334
2021-03-18 02:19:21 | INFO | train_inner | epoch 009:   9771 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=27891, ups=0.55, wpb=50831.2, bsz=2954.7, num_updates=171700, lr=0.000137369, gnorm=0.277, loss_scale=8, train_wall=179, wall=319516
2021-03-18 02:22:23 | INFO | train_inner | epoch 009:   9871 / 20258 loss=3.498, nll_loss=1.808, ppl=3.5, wps=27917.1, ups=0.55, wpb=50856.1, bsz=3021, num_updates=171800, lr=0.000137329, gnorm=0.28, loss_scale=8, train_wall=179, wall=319699
2021-03-18 02:25:26 | INFO | train_inner | epoch 009:   9971 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27905.4, ups=0.55, wpb=51084.4, bsz=3049.8, num_updates=171900, lr=0.000137289, gnorm=0.282, loss_scale=8, train_wall=180, wall=319882
2021-03-18 02:28:28 | INFO | train_inner | epoch 009:  10071 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27903.4, ups=0.55, wpb=50735.6, bsz=2978.2, num_updates=172000, lr=0.000137249, gnorm=0.275, loss_scale=8, train_wall=179, wall=320064
2021-03-18 02:31:30 | INFO | train_inner | epoch 009:  10171 / 20258 loss=3.5, nll_loss=1.81, ppl=3.51, wps=27960.1, ups=0.55, wpb=50862.8, bsz=2935, num_updates=172100, lr=0.000137209, gnorm=0.273, loss_scale=8, train_wall=179, wall=320245
2021-03-18 02:34:32 | INFO | train_inner | epoch 009:  10271 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27899.1, ups=0.55, wpb=50844, bsz=3016.2, num_updates=172200, lr=0.000137169, gnorm=0.274, loss_scale=8, train_wall=179, wall=320428
2021-03-18 02:37:35 | INFO | train_inner | epoch 009:  10371 / 20258 loss=3.489, nll_loss=1.799, ppl=3.48, wps=27925.5, ups=0.55, wpb=50956.3, bsz=3078.6, num_updates=172300, lr=0.000137129, gnorm=0.276, loss_scale=8, train_wall=179, wall=320610
2021-03-18 02:40:37 | INFO | train_inner | epoch 009:  10471 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27916.9, ups=0.55, wpb=51051.1, bsz=2955.4, num_updates=172400, lr=0.000137089, gnorm=0.275, loss_scale=16, train_wall=180, wall=320793
2021-03-18 02:43:40 | INFO | train_inner | epoch 009:  10571 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27901.8, ups=0.55, wpb=50884.9, bsz=2825.3, num_updates=172500, lr=0.00013705, gnorm=0.276, loss_scale=16, train_wall=179, wall=320975
2021-03-18 02:43:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 02:46:44 | INFO | train_inner | epoch 009:  10672 / 20258 loss=3.481, nll_loss=1.79, ppl=3.46, wps=27491, ups=0.54, wpb=50668.5, bsz=2891.7, num_updates=172600, lr=0.00013701, gnorm=0.276, loss_scale=8, train_wall=181, wall=321160
2021-03-18 02:49:46 | INFO | train_inner | epoch 009:  10772 / 20258 loss=3.504, nll_loss=1.815, ppl=3.52, wps=27981.9, ups=0.55, wpb=50969.7, bsz=2926.2, num_updates=172700, lr=0.00013697, gnorm=0.273, loss_scale=8, train_wall=179, wall=321342
2021-03-18 02:52:49 | INFO | train_inner | epoch 009:  10872 / 20258 loss=3.496, nll_loss=1.807, ppl=3.5, wps=27874.7, ups=0.55, wpb=50803.5, bsz=3012.2, num_updates=172800, lr=0.000136931, gnorm=0.276, loss_scale=8, train_wall=179, wall=321524
2021-03-18 02:55:52 | INFO | train_inner | epoch 009:  10972 / 20258 loss=3.482, nll_loss=1.79, ppl=3.46, wps=27852.1, ups=0.55, wpb=50948, bsz=2943, num_updates=172900, lr=0.000136891, gnorm=0.27, loss_scale=8, train_wall=180, wall=321707
2021-03-18 02:58:54 | INFO | train_inner | epoch 009:  11072 / 20258 loss=3.484, nll_loss=1.793, ppl=3.46, wps=27916.6, ups=0.55, wpb=50909.5, bsz=3062.4, num_updates=173000, lr=0.000136851, gnorm=0.272, loss_scale=8, train_wall=179, wall=321889
2021-03-18 03:01:57 | INFO | train_inner | epoch 009:  11172 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27951.3, ups=0.55, wpb=51056.5, bsz=3017.3, num_updates=173100, lr=0.000136812, gnorm=0.276, loss_scale=8, train_wall=180, wall=322072
2021-03-18 03:04:59 | INFO | train_inner | epoch 009:  11272 / 20258 loss=3.482, nll_loss=1.791, ppl=3.46, wps=27899.8, ups=0.55, wpb=50922.7, bsz=3045.7, num_updates=173200, lr=0.000136772, gnorm=0.273, loss_scale=8, train_wall=179, wall=322255
2021-03-18 03:08:01 | INFO | train_inner | epoch 009:  11372 / 20258 loss=3.504, nll_loss=1.814, ppl=3.52, wps=27997.7, ups=0.55, wpb=51059.5, bsz=2945.3, num_updates=173300, lr=0.000136733, gnorm=0.274, loss_scale=8, train_wall=179, wall=322437
2021-03-18 03:11:03 | INFO | train_inner | epoch 009:  11472 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27837.3, ups=0.55, wpb=50506.2, bsz=2912.2, num_updates=173400, lr=0.000136694, gnorm=0.276, loss_scale=8, train_wall=179, wall=322618
2021-03-18 03:14:05 | INFO | train_inner | epoch 009:  11572 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27820.1, ups=0.55, wpb=50706.1, bsz=3061.8, num_updates=173500, lr=0.000136654, gnorm=0.284, loss_scale=8, train_wall=179, wall=322801
2021-03-18 03:15:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 03:17:09 | INFO | train_inner | epoch 009:  11673 / 20258 loss=3.489, nll_loss=1.799, ppl=3.48, wps=27619.1, ups=0.54, wpb=50875.6, bsz=3048.1, num_updates=173600, lr=0.000136615, gnorm=0.268, loss_scale=8, train_wall=181, wall=322985
2021-03-18 03:20:12 | INFO | train_inner | epoch 009:  11773 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27881.7, ups=0.55, wpb=50922.6, bsz=2981.2, num_updates=173700, lr=0.000136575, gnorm=0.274, loss_scale=8, train_wall=179, wall=323168
2021-03-18 03:23:14 | INFO | train_inner | epoch 009:  11873 / 20258 loss=3.488, nll_loss=1.798, ppl=3.48, wps=27847.6, ups=0.55, wpb=50709.9, bsz=2932.7, num_updates=173800, lr=0.000136536, gnorm=0.278, loss_scale=8, train_wall=179, wall=323350
2021-03-18 03:26:17 | INFO | train_inner | epoch 009:  11973 / 20258 loss=3.482, nll_loss=1.79, ppl=3.46, wps=27821.6, ups=0.55, wpb=50907.7, bsz=2939.6, num_updates=173900, lr=0.000136497, gnorm=0.271, loss_scale=8, train_wall=179, wall=323533
2021-03-18 03:29:19 | INFO | train_inner | epoch 009:  12073 / 20258 loss=3.504, nll_loss=1.815, ppl=3.52, wps=27912.5, ups=0.55, wpb=50885.8, bsz=2978.7, num_updates=174000, lr=0.000136458, gnorm=0.273, loss_scale=8, train_wall=179, wall=323715
2021-03-18 03:32:22 | INFO | train_inner | epoch 009:  12173 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27903.1, ups=0.55, wpb=50979, bsz=3083.1, num_updates=174100, lr=0.000136418, gnorm=0.279, loss_scale=8, train_wall=179, wall=323898
2021-03-18 03:35:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 03:35:26 | INFO | train_inner | epoch 009:  12274 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27526.4, ups=0.54, wpb=50660.4, bsz=3008.1, num_updates=174200, lr=0.000136379, gnorm=0.275, loss_scale=4, train_wall=180, wall=324082
2021-03-18 03:38:29 | INFO | train_inner | epoch 009:  12374 / 20258 loss=3.487, nll_loss=1.796, ppl=3.47, wps=27955.2, ups=0.55, wpb=51063.5, bsz=2938.4, num_updates=174300, lr=0.00013634, gnorm=0.274, loss_scale=4, train_wall=180, wall=324264
2021-03-18 03:41:31 | INFO | train_inner | epoch 009:  12474 / 20258 loss=3.493, nll_loss=1.804, ppl=3.49, wps=27805.1, ups=0.55, wpb=50777.1, bsz=3207.4, num_updates=174400, lr=0.000136301, gnorm=0.278, loss_scale=4, train_wall=179, wall=324447
2021-03-18 03:44:33 | INFO | train_inner | epoch 009:  12574 / 20258 loss=3.479, nll_loss=1.786, ppl=3.45, wps=27876.8, ups=0.55, wpb=50718.8, bsz=2914.3, num_updates=174500, lr=0.000136262, gnorm=0.275, loss_scale=4, train_wall=179, wall=324629
2021-03-18 03:47:36 | INFO | train_inner | epoch 009:  12674 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27880, ups=0.55, wpb=50922.6, bsz=3032.2, num_updates=174600, lr=0.000136223, gnorm=0.284, loss_scale=4, train_wall=179, wall=324812
2021-03-18 03:50:39 | INFO | train_inner | epoch 009:  12774 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27801.3, ups=0.55, wpb=50806.3, bsz=3096.5, num_updates=174700, lr=0.000136184, gnorm=0.274, loss_scale=4, train_wall=179, wall=324994
2021-03-18 03:53:42 | INFO | train_inner | epoch 009:  12874 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27853.6, ups=0.55, wpb=50918, bsz=3012.8, num_updates=174800, lr=0.000136145, gnorm=0.271, loss_scale=4, train_wall=180, wall=325177
2021-03-18 03:56:44 | INFO | train_inner | epoch 009:  12974 / 20258 loss=3.504, nll_loss=1.816, ppl=3.52, wps=27897.8, ups=0.55, wpb=50804.2, bsz=3075.9, num_updates=174900, lr=0.000136106, gnorm=0.294, loss_scale=4, train_wall=179, wall=325359
2021-03-18 03:59:46 | INFO | train_inner | epoch 009:  13074 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27843, ups=0.55, wpb=50673.1, bsz=2932.4, num_updates=175000, lr=0.000136067, gnorm=0.281, loss_scale=4, train_wall=179, wall=325541
2021-03-18 03:59:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 03:59:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 03:59:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 03:59:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 03:59:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 03:59:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 03:59:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 03:59:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 03:59:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 03:59:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 03:59:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 03:59:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 03:59:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 03:59:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 03:59:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 03:59:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 03:59:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 03:59:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 03:59:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 03:59:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 03:59:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 03:59:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:04 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.897 | nll_loss 2.188 | ppl 4.56 | bleu 29.54 | wps 4395.7 | wpb 2432 | bsz 90.4 | num_updates 175000 | best_loss 3.897
2021-03-18 04:00:04 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 04:00:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 04:00:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 04:00:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 04:00:56 | INFO | valid1 | epoch 009 | valid on 'valid1' subset | loss 3.899 | nll_loss 2.212 | ppl 4.63 | bleu 27.5 | wps 4262.3 | wpb 2359.4 | bsz 106.4 | num_updates 175000 | best_loss 3.899
2021-03-18 04:00:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 04:01:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_9_175000.pt (epoch 9 @ 175000 updates, score 3.897) (writing took 6.423654451034963 seconds)
2021-03-18 04:04:06 | INFO | train_inner | epoch 009:  13174 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=19695.2, ups=0.38, wpb=51242.9, bsz=2922.4, num_updates=175100, lr=0.000136028, gnorm=0.27, loss_scale=4, train_wall=180, wall=325801
2021-03-18 04:07:08 | INFO | train_inner | epoch 009:  13274 / 20258 loss=3.509, nll_loss=1.821, ppl=3.53, wps=28057, ups=0.55, wpb=51084, bsz=2902.8, num_updates=175200, lr=0.00013599, gnorm=0.277, loss_scale=4, train_wall=179, wall=325983
2021-03-18 04:10:11 | INFO | train_inner | epoch 009:  13374 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27887.2, ups=0.55, wpb=50985.2, bsz=3055.1, num_updates=175300, lr=0.000135951, gnorm=0.271, loss_scale=8, train_wall=179, wall=326166
2021-03-18 04:13:13 | INFO | train_inner | epoch 009:  13474 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27853.1, ups=0.55, wpb=50854.4, bsz=2902.4, num_updates=175400, lr=0.000135912, gnorm=0.275, loss_scale=8, train_wall=179, wall=326349
2021-03-18 04:16:16 | INFO | train_inner | epoch 009:  13574 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=27837.9, ups=0.55, wpb=50857.9, bsz=3171.8, num_updates=175500, lr=0.000135873, gnorm=0.275, loss_scale=8, train_wall=179, wall=326532
2021-03-18 04:19:19 | INFO | train_inner | epoch 009:  13674 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27912.7, ups=0.55, wpb=50948, bsz=2921.5, num_updates=175600, lr=0.000135835, gnorm=0.277, loss_scale=8, train_wall=179, wall=326714
2021-03-18 04:22:20 | INFO | train_inner | epoch 009:  13774 / 20258 loss=3.493, nll_loss=1.802, ppl=3.49, wps=27931.8, ups=0.55, wpb=50825.9, bsz=2835.3, num_updates=175700, lr=0.000135796, gnorm=0.28, loss_scale=8, train_wall=179, wall=326896
2021-03-18 04:25:24 | INFO | train_inner | epoch 009:  13874 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27901.9, ups=0.55, wpb=51184.4, bsz=3093.4, num_updates=175800, lr=0.000135757, gnorm=0.267, loss_scale=8, train_wall=180, wall=327079
2021-03-18 04:28:26 | INFO | train_inner | epoch 009:  13974 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27909.3, ups=0.55, wpb=50765, bsz=3069.1, num_updates=175900, lr=0.000135719, gnorm=0.278, loss_scale=8, train_wall=179, wall=327261
2021-03-18 04:31:28 | INFO | train_inner | epoch 009:  14074 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27849.4, ups=0.55, wpb=50868.5, bsz=3096.4, num_updates=176000, lr=0.00013568, gnorm=0.276, loss_scale=8, train_wall=179, wall=327444
2021-03-18 04:34:31 | INFO | train_inner | epoch 009:  14174 / 20258 loss=3.506, nll_loss=1.819, ppl=3.53, wps=27988.6, ups=0.55, wpb=51128.9, bsz=3111.9, num_updates=176100, lr=0.000135642, gnorm=0.278, loss_scale=8, train_wall=180, wall=327627
2021-03-18 04:37:34 | INFO | train_inner | epoch 009:  14274 / 20258 loss=3.491, nll_loss=1.801, ppl=3.48, wps=27993.1, ups=0.55, wpb=51046.2, bsz=2986.5, num_updates=176200, lr=0.000135603, gnorm=0.277, loss_scale=8, train_wall=179, wall=327809
2021-03-18 04:40:37 | INFO | train_inner | epoch 009:  14374 / 20258 loss=3.487, nll_loss=1.796, ppl=3.47, wps=27877.1, ups=0.55, wpb=51046.7, bsz=3025.2, num_updates=176300, lr=0.000135565, gnorm=0.273, loss_scale=16, train_wall=179, wall=327992
2021-03-18 04:43:39 | INFO | train_inner | epoch 009:  14474 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27881.4, ups=0.55, wpb=50816.7, bsz=2999.7, num_updates=176400, lr=0.000135526, gnorm=0.275, loss_scale=16, train_wall=179, wall=328174
2021-03-18 04:44:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 04:46:43 | INFO | train_inner | epoch 009:  14575 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27621.4, ups=0.54, wpb=50935.9, bsz=2991.8, num_updates=176500, lr=0.000135488, gnorm=0.279, loss_scale=8, train_wall=181, wall=328359
2021-03-18 04:49:45 | INFO | train_inner | epoch 009:  14675 / 20258 loss=3.498, nll_loss=1.808, ppl=3.5, wps=27929.7, ups=0.55, wpb=50796.8, bsz=2985.1, num_updates=176600, lr=0.000135449, gnorm=0.275, loss_scale=8, train_wall=179, wall=328541
2021-03-18 04:52:48 | INFO | train_inner | epoch 009:  14775 / 20258 loss=3.482, nll_loss=1.791, ppl=3.46, wps=27873.7, ups=0.55, wpb=50877.5, bsz=3099.3, num_updates=176700, lr=0.000135411, gnorm=0.274, loss_scale=8, train_wall=179, wall=328723
2021-03-18 04:55:50 | INFO | train_inner | epoch 009:  14875 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27843.2, ups=0.55, wpb=50868.4, bsz=2963.8, num_updates=176800, lr=0.000135373, gnorm=0.268, loss_scale=8, train_wall=179, wall=328906
2021-03-18 04:58:54 | INFO | train_inner | epoch 009:  14975 / 20258 loss=3.487, nll_loss=1.796, ppl=3.47, wps=27844, ups=0.55, wpb=51005.3, bsz=3015.8, num_updates=176900, lr=0.000135335, gnorm=0.282, loss_scale=8, train_wall=180, wall=329089
2021-03-18 05:01:56 | INFO | train_inner | epoch 009:  15075 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27943.4, ups=0.55, wpb=50852.2, bsz=2928.5, num_updates=177000, lr=0.000135296, gnorm=0.274, loss_scale=8, train_wall=179, wall=329271
2021-03-18 05:04:58 | INFO | train_inner | epoch 009:  15175 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27935.2, ups=0.55, wpb=50850.7, bsz=2982.2, num_updates=177100, lr=0.000135258, gnorm=0.273, loss_scale=8, train_wall=179, wall=329453
2021-03-18 05:08:00 | INFO | train_inner | epoch 009:  15275 / 20258 loss=3.498, nll_loss=1.808, ppl=3.5, wps=27906.7, ups=0.55, wpb=50759.3, bsz=3027.4, num_updates=177200, lr=0.00013522, gnorm=0.278, loss_scale=8, train_wall=179, wall=329635
2021-03-18 05:11:01 | INFO | train_inner | epoch 009:  15375 / 20258 loss=3.504, nll_loss=1.815, ppl=3.52, wps=27992.4, ups=0.55, wpb=50812.6, bsz=2926, num_updates=177300, lr=0.000135182, gnorm=0.274, loss_scale=8, train_wall=179, wall=329817
2021-03-18 05:14:03 | INFO | train_inner | epoch 009:  15475 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27703.7, ups=0.55, wpb=50525.2, bsz=3118.3, num_updates=177400, lr=0.000135144, gnorm=0.28, loss_scale=8, train_wall=179, wall=329999
2021-03-18 05:17:06 | INFO | train_inner | epoch 009:  15575 / 20258 loss=3.465, nll_loss=1.771, ppl=3.41, wps=27750.4, ups=0.55, wpb=50690.8, bsz=2948.1, num_updates=177500, lr=0.000135106, gnorm=0.279, loss_scale=16, train_wall=180, wall=330182
2021-03-18 05:20:09 | INFO | train_inner | epoch 009:  15675 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=27736.3, ups=0.55, wpb=50599.9, bsz=2907.8, num_updates=177600, lr=0.000135068, gnorm=0.276, loss_scale=16, train_wall=179, wall=330364
2021-03-18 05:23:11 | INFO | train_inner | epoch 009:  15775 / 20258 loss=3.484, nll_loss=1.792, ppl=3.46, wps=28025.1, ups=0.55, wpb=51259.8, bsz=2916.4, num_updates=177700, lr=0.00013503, gnorm=0.273, loss_scale=16, train_wall=180, wall=330547
2021-03-18 05:26:14 | INFO | train_inner | epoch 009:  15875 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27925, ups=0.55, wpb=50983.7, bsz=2971.1, num_updates=177800, lr=0.000134992, gnorm=0.273, loss_scale=16, train_wall=179, wall=330730
2021-03-18 05:27:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 05:29:19 | INFO | train_inner | epoch 009:  15976 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27637.1, ups=0.54, wpb=51066.3, bsz=3108.7, num_updates=177900, lr=0.000134954, gnorm=0.271, loss_scale=8, train_wall=182, wall=330914
2021-03-18 05:32:22 | INFO | train_inner | epoch 009:  16076 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27882.4, ups=0.55, wpb=50979.3, bsz=2999, num_updates=178000, lr=0.000134916, gnorm=0.282, loss_scale=8, train_wall=180, wall=331097
2021-03-18 05:35:24 | INFO | train_inner | epoch 009:  16176 / 20258 loss=3.495, nll_loss=1.806, ppl=3.5, wps=27852.4, ups=0.55, wpb=50800.3, bsz=3060.6, num_updates=178100, lr=0.000134878, gnorm=0.275, loss_scale=8, train_wall=179, wall=331280
2021-03-18 05:38:26 | INFO | train_inner | epoch 009:  16276 / 20258 loss=3.5, nll_loss=1.811, ppl=3.51, wps=27796, ups=0.55, wpb=50466.2, bsz=2967.4, num_updates=178200, lr=0.00013484, gnorm=0.276, loss_scale=8, train_wall=178, wall=331461
2021-03-18 05:41:28 | INFO | train_inner | epoch 009:  16376 / 20258 loss=3.514, nll_loss=1.826, ppl=3.55, wps=27970.6, ups=0.55, wpb=50998.2, bsz=2972, num_updates=178300, lr=0.000134802, gnorm=0.278, loss_scale=8, train_wall=179, wall=331643
2021-03-18 05:44:29 | INFO | train_inner | epoch 009:  16476 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27907.8, ups=0.55, wpb=50645.8, bsz=2941.6, num_updates=178400, lr=0.000134764, gnorm=0.279, loss_scale=8, train_wall=179, wall=331825
2021-03-18 05:47:31 | INFO | train_inner | epoch 009:  16576 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27820, ups=0.55, wpb=50532.5, bsz=2967.2, num_updates=178500, lr=0.000134727, gnorm=0.276, loss_scale=8, train_wall=179, wall=332007
2021-03-18 05:50:34 | INFO | train_inner | epoch 009:  16676 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27824.9, ups=0.55, wpb=50817.6, bsz=2975.4, num_updates=178600, lr=0.000134689, gnorm=0.275, loss_scale=8, train_wall=179, wall=332189
2021-03-18 05:53:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 05:53:37 | INFO | train_inner | epoch 009:  16777 / 20258 loss=3.503, nll_loss=1.814, ppl=3.52, wps=27589.4, ups=0.54, wpb=50671.3, bsz=2975.4, num_updates=178700, lr=0.000134651, gnorm=0.277, loss_scale=4, train_wall=181, wall=332373
2021-03-18 05:56:40 | INFO | train_inner | epoch 009:  16877 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27698, ups=0.55, wpb=50528.2, bsz=3162.2, num_updates=178800, lr=0.000134614, gnorm=0.279, loss_scale=4, train_wall=179, wall=332555
2021-03-18 05:59:42 | INFO | train_inner | epoch 009:  16977 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=28021.6, ups=0.55, wpb=51111.2, bsz=3034.6, num_updates=178900, lr=0.000134576, gnorm=0.275, loss_scale=4, train_wall=179, wall=332738
2021-03-18 06:02:45 | INFO | train_inner | epoch 009:  17077 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27957.8, ups=0.55, wpb=51228.8, bsz=3050.2, num_updates=179000, lr=0.000134538, gnorm=0.28, loss_scale=4, train_wall=180, wall=332921
2021-03-18 06:05:47 | INFO | train_inner | epoch 009:  17177 / 20258 loss=3.498, nll_loss=1.809, ppl=3.5, wps=28025.4, ups=0.55, wpb=50930.1, bsz=3068.7, num_updates=179100, lr=0.000134501, gnorm=0.279, loss_scale=4, train_wall=179, wall=333103
2021-03-18 06:08:49 | INFO | train_inner | epoch 009:  17277 / 20258 loss=3.48, nll_loss=1.789, ppl=3.45, wps=27938.5, ups=0.55, wpb=50815.3, bsz=2922.8, num_updates=179200, lr=0.000134463, gnorm=0.275, loss_scale=4, train_wall=179, wall=333285
2021-03-18 06:11:52 | INFO | train_inner | epoch 009:  17377 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27851.6, ups=0.55, wpb=50912.4, bsz=3055.6, num_updates=179300, lr=0.000134426, gnorm=0.275, loss_scale=4, train_wall=180, wall=333467
2021-03-18 06:14:54 | INFO | train_inner | epoch 009:  17477 / 20258 loss=3.481, nll_loss=1.789, ppl=3.46, wps=27899, ups=0.55, wpb=50806.6, bsz=3034.5, num_updates=179400, lr=0.000134388, gnorm=0.276, loss_scale=4, train_wall=179, wall=333649
2021-03-18 06:17:57 | INFO | train_inner | epoch 009:  17577 / 20258 loss=3.487, nll_loss=1.797, ppl=3.47, wps=27964.8, ups=0.55, wpb=51272.3, bsz=3115, num_updates=179500, lr=0.000134351, gnorm=0.277, loss_scale=4, train_wall=180, wall=333833
2021-03-18 06:21:00 | INFO | train_inner | epoch 009:  17677 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27854.8, ups=0.55, wpb=50888.9, bsz=3106.6, num_updates=179600, lr=0.000134313, gnorm=0.275, loss_scale=4, train_wall=180, wall=334015
2021-03-18 06:24:02 | INFO | train_inner | epoch 009:  17777 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27745.5, ups=0.55, wpb=50547.2, bsz=3155.1, num_updates=179700, lr=0.000134276, gnorm=0.277, loss_scale=4, train_wall=179, wall=334198
2021-03-18 06:27:05 | INFO | train_inner | epoch 009:  17877 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27846.2, ups=0.55, wpb=50878.6, bsz=3067.5, num_updates=179800, lr=0.000134239, gnorm=0.273, loss_scale=8, train_wall=179, wall=334380
2021-03-18 06:30:07 | INFO | train_inner | epoch 009:  17977 / 20258 loss=3.483, nll_loss=1.791, ppl=3.46, wps=27864.2, ups=0.55, wpb=50662.4, bsz=2837.5, num_updates=179900, lr=0.000134201, gnorm=0.292, loss_scale=8, train_wall=179, wall=334562
2021-03-18 06:33:08 | INFO | train_inner | epoch 009:  18077 / 20258 loss=3.492, nll_loss=1.802, ppl=3.49, wps=27994.3, ups=0.55, wpb=50835.1, bsz=2933.4, num_updates=180000, lr=0.000134164, gnorm=0.275, loss_scale=8, train_wall=179, wall=334744
2021-03-18 06:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 06:33:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:27 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.888 | nll_loss 2.175 | ppl 4.52 | bleu 29.67 | wps 4384.5 | wpb 2432 | bsz 90.4 | num_updates 180000 | best_loss 3.888
2021-03-18 06:33:27 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 06:33:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:33:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 06:33:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 06:33:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 06:34:19 | INFO | valid1 | epoch 009 | valid on 'valid1' subset | loss 3.891 | nll_loss 2.202 | ppl 4.6 | bleu 27.81 | wps 4233.8 | wpb 2359.4 | bsz 106.4 | num_updates 180000 | best_loss 3.891
2021-03-18 06:34:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 06:34:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_9_180000.pt (epoch 9 @ 180000 updates, score 3.888) (writing took 6.329996764892712 seconds)
2021-03-18 06:37:29 | INFO | train_inner | epoch 009:  18177 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=19609.5, ups=0.38, wpb=51064.1, bsz=2952.2, num_updates=180100, lr=0.000134127, gnorm=0.275, loss_scale=8, train_wall=180, wall=335004
2021-03-18 06:40:31 | INFO | train_inner | epoch 009:  18277 / 20258 loss=3.495, nll_loss=1.805, ppl=3.49, wps=27908.7, ups=0.55, wpb=50796, bsz=2835.7, num_updates=180200, lr=0.00013409, gnorm=0.278, loss_scale=8, train_wall=179, wall=335186
2021-03-18 06:43:33 | INFO | train_inner | epoch 009:  18377 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27909.9, ups=0.55, wpb=50906.7, bsz=2932.6, num_updates=180300, lr=0.000134052, gnorm=0.278, loss_scale=8, train_wall=179, wall=335369
2021-03-18 06:46:35 | INFO | train_inner | epoch 009:  18477 / 20258 loss=3.49, nll_loss=1.799, ppl=3.48, wps=27922.5, ups=0.55, wpb=50918.1, bsz=3022.3, num_updates=180400, lr=0.000134015, gnorm=0.28, loss_scale=8, train_wall=179, wall=335551
2021-03-18 06:49:37 | INFO | train_inner | epoch 009:  18577 / 20258 loss=3.493, nll_loss=1.804, ppl=3.49, wps=27853.5, ups=0.55, wpb=50630.6, bsz=2985.3, num_updates=180500, lr=0.000133978, gnorm=0.273, loss_scale=8, train_wall=179, wall=335733
2021-03-18 06:52:39 | INFO | train_inner | epoch 009:  18677 / 20258 loss=3.497, nll_loss=1.807, ppl=3.5, wps=27893.5, ups=0.55, wpb=50789.7, bsz=3026.6, num_updates=180600, lr=0.000133941, gnorm=0.275, loss_scale=8, train_wall=179, wall=335915
2021-03-18 06:55:42 | INFO | train_inner | epoch 009:  18777 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27996.2, ups=0.55, wpb=51131.9, bsz=2991.8, num_updates=180700, lr=0.000133904, gnorm=0.279, loss_scale=8, train_wall=179, wall=336097
2021-03-18 06:58:45 | INFO | train_inner | epoch 009:  18877 / 20258 loss=3.493, nll_loss=1.804, ppl=3.49, wps=27958.8, ups=0.55, wpb=51135.5, bsz=2983.1, num_updates=180800, lr=0.000133867, gnorm=0.272, loss_scale=16, train_wall=180, wall=336280
2021-03-18 07:01:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 07:01:49 | INFO | train_inner | epoch 009:  18978 / 20258 loss=3.497, nll_loss=1.808, ppl=3.5, wps=27624.2, ups=0.54, wpb=50841.6, bsz=3065.5, num_updates=180900, lr=0.00013383, gnorm=0.272, loss_scale=8, train_wall=181, wall=336464
2021-03-18 07:04:52 | INFO | train_inner | epoch 009:  19078 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27845.2, ups=0.55, wpb=50872.8, bsz=3100.6, num_updates=181000, lr=0.000133793, gnorm=0.277, loss_scale=8, train_wall=179, wall=336647
2021-03-18 07:07:54 | INFO | train_inner | epoch 009:  19178 / 20258 loss=3.496, nll_loss=1.806, ppl=3.5, wps=28009, ups=0.55, wpb=51103.9, bsz=2962.2, num_updates=181100, lr=0.000133756, gnorm=0.273, loss_scale=8, train_wall=179, wall=336830
2021-03-18 07:10:57 | INFO | train_inner | epoch 009:  19278 / 20258 loss=3.487, nll_loss=1.796, ppl=3.47, wps=27907.2, ups=0.55, wpb=51102.4, bsz=3014.1, num_updates=181200, lr=0.000133719, gnorm=0.27, loss_scale=8, train_wall=180, wall=337013
2021-03-18 07:14:00 | INFO | train_inner | epoch 009:  19378 / 20258 loss=3.509, nll_loss=1.822, ppl=3.53, wps=28000.7, ups=0.55, wpb=51098.9, bsz=3120.9, num_updates=181300, lr=0.000133682, gnorm=0.277, loss_scale=8, train_wall=179, wall=337195
2021-03-18 07:17:02 | INFO | train_inner | epoch 009:  19478 / 20258 loss=3.49, nll_loss=1.799, ppl=3.48, wps=27918.8, ups=0.55, wpb=51039, bsz=2964.2, num_updates=181400, lr=0.000133645, gnorm=0.276, loss_scale=8, train_wall=180, wall=337378
2021-03-18 07:20:04 | INFO | train_inner | epoch 009:  19578 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27875.7, ups=0.55, wpb=50676, bsz=3057.3, num_updates=181500, lr=0.000133609, gnorm=0.278, loss_scale=8, train_wall=179, wall=337560
2021-03-18 07:23:06 | INFO | train_inner | epoch 009:  19678 / 20258 loss=3.492, nll_loss=1.802, ppl=3.49, wps=27959.2, ups=0.55, wpb=50948.8, bsz=2983.8, num_updates=181600, lr=0.000133572, gnorm=0.274, loss_scale=8, train_wall=179, wall=337742
2021-03-18 07:26:09 | INFO | train_inner | epoch 009:  19778 / 20258 loss=3.499, nll_loss=1.81, ppl=3.51, wps=27981.2, ups=0.55, wpb=50946.3, bsz=3045.8, num_updates=181700, lr=0.000133535, gnorm=0.275, loss_scale=8, train_wall=179, wall=337924
2021-03-18 07:27:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 07:29:12 | INFO | train_inner | epoch 009:  19879 / 20258 loss=3.502, nll_loss=1.813, ppl=3.51, wps=27680.3, ups=0.54, wpb=50873.6, bsz=2919.7, num_updates=181800, lr=0.000133498, gnorm=0.277, loss_scale=4, train_wall=181, wall=338108
2021-03-18 07:32:15 | INFO | train_inner | epoch 009:  19979 / 20258 loss=3.488, nll_loss=1.797, ppl=3.48, wps=28046.8, ups=0.55, wpb=51106.6, bsz=2989, num_updates=181900, lr=0.000133462, gnorm=0.278, loss_scale=4, train_wall=179, wall=338290
2021-03-18 07:35:17 | INFO | train_inner | epoch 009:  20079 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27798.6, ups=0.55, wpb=50717.6, bsz=3108.5, num_updates=182000, lr=0.000133425, gnorm=0.274, loss_scale=4, train_wall=179, wall=338473
2021-03-18 07:38:19 | INFO | train_inner | epoch 009:  20179 / 20258 loss=3.485, nll_loss=1.795, ppl=3.47, wps=27919, ups=0.55, wpb=50920.1, bsz=3001, num_updates=182100, lr=0.000133388, gnorm=0.277, loss_scale=4, train_wall=179, wall=338655
2021-03-18 07:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 07:40:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:40:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:40:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:40:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:40:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:40:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:40:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:40:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:40:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:40:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:40:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:40:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:40:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:40:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:40:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:40:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:40:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:40:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:40:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:40:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:40:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:02 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.893 | nll_loss 2.176 | ppl 4.52 | bleu 29.99 | wps 4377.6 | wpb 2432 | bsz 90.4 | num_updates 182179 | best_loss 3.888
2021-03-18 07:41:02 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 07:41:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 07:41:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 07:41:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 07:41:54 | INFO | valid1 | epoch 009 | valid on 'valid1' subset | loss 3.897 | nll_loss 2.202 | ppl 4.6 | bleu 27.67 | wps 4226.6 | wpb 2359.4 | bsz 106.4 | num_updates 182179 | best_loss 3.888
2021-03-18 07:41:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 07:41:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint9.pt (epoch 9 @ 182179 updates, score 3.893) (writing took 4.653038399992511 seconds)
2021-03-18 07:41:59 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-03-18 07:41:59 | INFO | train | epoch 009 | loss 3.488 | nll_loss 1.797 | ppl 3.48 | wps 27582.1 | ups 0.54 | wpb 50906.1 | bsz 3010.1 | num_updates 182179 | lr 0.000133359 | gnorm 0.275 | loss_scale 4 | train_wall 36332 | wall 338875
2021-03-18 07:41:59 | INFO | fairseq.trainer | begin training epoch 10
2021-03-18 07:42:38 | INFO | train_inner | epoch 010:     21 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=19709.9, ups=0.39, wpb=50885.1, bsz=2996.3, num_updates=182200, lr=0.000133352, gnorm=0.273, loss_scale=4, train_wall=179, wall=338913
2021-03-18 07:45:40 | INFO | train_inner | epoch 010:    121 / 20258 loss=3.485, nll_loss=1.793, ppl=3.47, wps=27926.7, ups=0.55, wpb=50974.5, bsz=3071.4, num_updates=182300, lr=0.000133315, gnorm=0.276, loss_scale=4, train_wall=179, wall=339096
2021-03-18 07:48:42 | INFO | train_inner | epoch 010:    221 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27871.5, ups=0.55, wpb=50755.5, bsz=2970.8, num_updates=182400, lr=0.000133278, gnorm=0.277, loss_scale=4, train_wall=179, wall=339278
2021-03-18 07:51:45 | INFO | train_inner | epoch 010:    321 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27939, ups=0.55, wpb=51023.4, bsz=3120.8, num_updates=182500, lr=0.000133242, gnorm=0.274, loss_scale=4, train_wall=180, wall=339460
2021-03-18 07:54:47 | INFO | train_inner | epoch 010:    421 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27876.8, ups=0.55, wpb=50858.5, bsz=3086.6, num_updates=182600, lr=0.000133205, gnorm=0.276, loss_scale=4, train_wall=179, wall=339643
2021-03-18 07:57:50 | INFO | train_inner | epoch 010:    521 / 20258 loss=3.462, nll_loss=1.768, ppl=3.41, wps=27822, ups=0.55, wpb=50824.8, bsz=2984.2, num_updates=182700, lr=0.000133169, gnorm=0.273, loss_scale=4, train_wall=179, wall=339825
2021-03-18 08:00:51 | INFO | train_inner | epoch 010:    621 / 20258 loss=3.478, nll_loss=1.785, ppl=3.45, wps=27849.2, ups=0.55, wpb=50554, bsz=2905.2, num_updates=182800, lr=0.000133133, gnorm=0.282, loss_scale=8, train_wall=179, wall=340007
2021-03-18 08:03:54 | INFO | train_inner | epoch 010:    721 / 20258 loss=3.473, nll_loss=1.78, ppl=3.43, wps=27842.3, ups=0.55, wpb=50754.7, bsz=2914.2, num_updates=182900, lr=0.000133096, gnorm=0.275, loss_scale=8, train_wall=179, wall=340189
2021-03-18 08:06:57 | INFO | train_inner | epoch 010:    821 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=27963.2, ups=0.55, wpb=51099.7, bsz=2961.4, num_updates=183000, lr=0.00013306, gnorm=0.274, loss_scale=8, train_wall=180, wall=340372
2021-03-18 08:10:00 | INFO | train_inner | epoch 010:    921 / 20258 loss=3.468, nll_loss=1.774, ppl=3.42, wps=27780.9, ups=0.55, wpb=50867.3, bsz=2985.9, num_updates=183100, lr=0.000133023, gnorm=0.27, loss_scale=8, train_wall=180, wall=340555
2021-03-18 08:13:02 | INFO | train_inner | epoch 010:   1021 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27929.8, ups=0.55, wpb=50825.4, bsz=3019.6, num_updates=183200, lr=0.000132987, gnorm=0.274, loss_scale=8, train_wall=179, wall=340737
2021-03-18 08:13:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 08:16:06 | INFO | train_inner | epoch 010:   1122 / 20258 loss=3.473, nll_loss=1.78, ppl=3.43, wps=27733.7, ups=0.54, wpb=51080.4, bsz=2932, num_updates=183300, lr=0.000132951, gnorm=0.272, loss_scale=4, train_wall=181, wall=340921
2021-03-18 08:19:08 | INFO | train_inner | epoch 010:   1222 / 20258 loss=3.48, nll_loss=1.787, ppl=3.45, wps=27929.4, ups=0.55, wpb=50956.2, bsz=3018.1, num_updates=183400, lr=0.000132915, gnorm=0.273, loss_scale=4, train_wall=179, wall=341104
2021-03-18 08:22:11 | INFO | train_inner | epoch 010:   1322 / 20258 loss=3.472, nll_loss=1.779, ppl=3.43, wps=27873, ups=0.55, wpb=50900.8, bsz=3029.3, num_updates=183500, lr=0.000132878, gnorm=0.273, loss_scale=4, train_wall=180, wall=341286
2021-03-18 08:25:13 | INFO | train_inner | epoch 010:   1422 / 20258 loss=3.474, nll_loss=1.781, ppl=3.44, wps=27939.7, ups=0.55, wpb=50923.5, bsz=2990.8, num_updates=183600, lr=0.000132842, gnorm=0.275, loss_scale=4, train_wall=179, wall=341469
2021-03-18 08:28:17 | INFO | train_inner | epoch 010:   1522 / 20258 loss=3.453, nll_loss=1.757, ppl=3.38, wps=27963.6, ups=0.55, wpb=51299.4, bsz=3111.9, num_updates=183700, lr=0.000132806, gnorm=0.274, loss_scale=4, train_wall=180, wall=341652
2021-03-18 08:31:19 | INFO | train_inner | epoch 010:   1622 / 20258 loss=3.463, nll_loss=1.769, ppl=3.41, wps=27824.5, ups=0.55, wpb=50765.6, bsz=3035.4, num_updates=183800, lr=0.00013277, gnorm=0.276, loss_scale=4, train_wall=179, wall=341835
2021-03-18 08:34:21 | INFO | train_inner | epoch 010:   1722 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=27961.2, ups=0.55, wpb=50981.7, bsz=2983.8, num_updates=183900, lr=0.000132734, gnorm=0.271, loss_scale=4, train_wall=179, wall=342017
2021-03-18 08:37:23 | INFO | train_inner | epoch 010:   1822 / 20258 loss=3.482, nll_loss=1.79, ppl=3.46, wps=28005.9, ups=0.55, wpb=50873.5, bsz=2991.9, num_updates=184000, lr=0.000132698, gnorm=0.278, loss_scale=4, train_wall=179, wall=342199
2021-03-18 08:40:26 | INFO | train_inner | epoch 010:   1922 / 20258 loss=3.468, nll_loss=1.774, ppl=3.42, wps=28013.8, ups=0.55, wpb=51152.5, bsz=3025.8, num_updates=184100, lr=0.000132662, gnorm=0.277, loss_scale=4, train_wall=180, wall=342381
2021-03-18 08:43:28 | INFO | train_inner | epoch 010:   2022 / 20258 loss=3.478, nll_loss=1.785, ppl=3.45, wps=27897, ups=0.55, wpb=50931.5, bsz=2985.3, num_updates=184200, lr=0.000132626, gnorm=0.277, loss_scale=4, train_wall=179, wall=342564
2021-03-18 08:46:31 | INFO | train_inner | epoch 010:   2122 / 20258 loss=3.458, nll_loss=1.764, ppl=3.4, wps=27903.7, ups=0.55, wpb=50979, bsz=3001, num_updates=184300, lr=0.00013259, gnorm=0.28, loss_scale=8, train_wall=180, wall=342746
2021-03-18 08:48:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 08:49:36 | INFO | train_inner | epoch 010:   2223 / 20258 loss=3.47, nll_loss=1.777, ppl=3.43, wps=27566.3, ups=0.54, wpb=50959.8, bsz=3055.8, num_updates=184400, lr=0.000132554, gnorm=0.273, loss_scale=4, train_wall=181, wall=342931
2021-03-18 08:52:38 | INFO | train_inner | epoch 010:   2323 / 20258 loss=3.482, nll_loss=1.791, ppl=3.46, wps=27915.4, ups=0.55, wpb=50756.7, bsz=2980.3, num_updates=184500, lr=0.000132518, gnorm=0.28, loss_scale=4, train_wall=179, wall=343113
2021-03-18 08:55:40 | INFO | train_inner | epoch 010:   2423 / 20258 loss=3.464, nll_loss=1.77, ppl=3.41, wps=27938.5, ups=0.55, wpb=51031.4, bsz=3016.2, num_updates=184600, lr=0.000132482, gnorm=0.276, loss_scale=4, train_wall=180, wall=343296
2021-03-18 08:58:42 | INFO | train_inner | epoch 010:   2523 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27991.9, ups=0.55, wpb=50940.8, bsz=3052.2, num_updates=184700, lr=0.000132446, gnorm=0.279, loss_scale=4, train_wall=179, wall=343478
2021-03-18 09:01:45 | INFO | train_inner | epoch 010:   2623 / 20258 loss=3.451, nll_loss=1.756, ppl=3.38, wps=27874.9, ups=0.55, wpb=50971.6, bsz=3022.1, num_updates=184800, lr=0.00013241, gnorm=0.273, loss_scale=4, train_wall=180, wall=343661
2021-03-18 09:04:47 | INFO | train_inner | epoch 010:   2723 / 20258 loss=3.477, nll_loss=1.784, ppl=3.44, wps=27953.7, ups=0.55, wpb=50789.2, bsz=2820.4, num_updates=184900, lr=0.000132374, gnorm=0.276, loss_scale=4, train_wall=179, wall=343842
2021-03-18 09:07:49 | INFO | train_inner | epoch 010:   2823 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27962.5, ups=0.55, wpb=50933.7, bsz=3048.3, num_updates=185000, lr=0.000132339, gnorm=0.275, loss_scale=4, train_wall=179, wall=344024
2021-03-18 09:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 09:07:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:07:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:07:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:07:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:07:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:07:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:07:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:07:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:07:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:07:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:07:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:07:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:07:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:07:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:07:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:07:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:07:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:07:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:07:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:07:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:07:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:07 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.89 | nll_loss 2.181 | ppl 4.53 | bleu 29.82 | wps 4480 | wpb 2432 | bsz 90.4 | num_updates 185000 | best_loss 3.888
2021-03-18 09:08:07 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 09:08:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 09:08:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 09:08:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 09:08:59 | INFO | valid1 | epoch 010 | valid on 'valid1' subset | loss 3.896 | nll_loss 2.209 | ppl 4.62 | bleu 27.55 | wps 4268.6 | wpb 2359.4 | bsz 106.4 | num_updates 185000 | best_loss 3.888
2021-03-18 09:08:59 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 09:09:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_10_185000.pt (epoch 10 @ 185000 updates, score 3.89) (writing took 4.579256878001615 seconds)
2021-03-18 09:12:06 | INFO | train_inner | epoch 010:   2923 / 20258 loss=3.473, nll_loss=1.78, ppl=3.44, wps=19848.8, ups=0.39, wpb=51039.7, bsz=2983.6, num_updates=185100, lr=0.000132303, gnorm=0.272, loss_scale=4, train_wall=179, wall=344282
2021-03-18 09:15:09 | INFO | train_inner | epoch 010:   3023 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27887.8, ups=0.55, wpb=50896.6, bsz=2967.4, num_updates=185200, lr=0.000132267, gnorm=0.279, loss_scale=4, train_wall=179, wall=344464
2021-03-18 09:18:11 | INFO | train_inner | epoch 010:   3123 / 20258 loss=3.484, nll_loss=1.793, ppl=3.46, wps=27938.2, ups=0.55, wpb=51033.3, bsz=3010.2, num_updates=185300, lr=0.000132231, gnorm=0.275, loss_scale=4, train_wall=179, wall=344647
2021-03-18 09:21:14 | INFO | train_inner | epoch 010:   3223 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=27959.4, ups=0.55, wpb=51039.1, bsz=2936.1, num_updates=185400, lr=0.000132196, gnorm=0.276, loss_scale=8, train_wall=179, wall=344829
2021-03-18 09:24:16 | INFO | train_inner | epoch 010:   3323 / 20258 loss=3.467, nll_loss=1.773, ppl=3.42, wps=27810, ups=0.55, wpb=50673.2, bsz=3026.8, num_updates=185500, lr=0.00013216, gnorm=0.281, loss_scale=8, train_wall=179, wall=345011
2021-03-18 09:27:18 | INFO | train_inner | epoch 010:   3423 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27821.9, ups=0.55, wpb=50669.2, bsz=3136.6, num_updates=185600, lr=0.000132125, gnorm=0.284, loss_scale=8, train_wall=179, wall=345194
2021-03-18 09:30:20 | INFO | train_inner | epoch 010:   3523 / 20258 loss=3.48, nll_loss=1.789, ppl=3.45, wps=27949.9, ups=0.55, wpb=50961.4, bsz=2959.2, num_updates=185700, lr=0.000132089, gnorm=0.272, loss_scale=8, train_wall=179, wall=345376
2021-03-18 09:33:22 | INFO | train_inner | epoch 010:   3623 / 20258 loss=3.491, nll_loss=1.8, ppl=3.48, wps=28086.6, ups=0.55, wpb=50935.1, bsz=2870.1, num_updates=185800, lr=0.000132053, gnorm=0.279, loss_scale=8, train_wall=179, wall=345557
2021-03-18 09:36:24 | INFO | train_inner | epoch 010:   3723 / 20258 loss=3.482, nll_loss=1.79, ppl=3.46, wps=27955.2, ups=0.55, wpb=50958.6, bsz=2945.9, num_updates=185900, lr=0.000132018, gnorm=0.27, loss_scale=8, train_wall=179, wall=345740
2021-03-18 09:39:27 | INFO | train_inner | epoch 010:   3823 / 20258 loss=3.472, nll_loss=1.779, ppl=3.43, wps=27910.7, ups=0.55, wpb=51014.5, bsz=3031.6, num_updates=186000, lr=0.000131982, gnorm=0.278, loss_scale=8, train_wall=180, wall=345922
2021-03-18 09:39:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 09:42:31 | INFO | train_inner | epoch 010:   3924 / 20258 loss=3.468, nll_loss=1.775, ppl=3.42, wps=27543, ups=0.54, wpb=50790.3, bsz=2974, num_updates=186100, lr=0.000131947, gnorm=0.279, loss_scale=4, train_wall=181, wall=346107
2021-03-18 09:45:34 | INFO | train_inner | epoch 010:   4024 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27963.3, ups=0.55, wpb=50990.8, bsz=2953.3, num_updates=186200, lr=0.000131912, gnorm=0.275, loss_scale=4, train_wall=179, wall=346289
2021-03-18 09:48:36 | INFO | train_inner | epoch 010:   4124 / 20258 loss=3.47, nll_loss=1.777, ppl=3.43, wps=27797.2, ups=0.55, wpb=50724.3, bsz=2965.8, num_updates=186300, lr=0.000131876, gnorm=0.276, loss_scale=4, train_wall=179, wall=346472
2021-03-18 09:51:38 | INFO | train_inner | epoch 010:   4224 / 20258 loss=3.497, nll_loss=1.807, ppl=3.5, wps=27956.9, ups=0.55, wpb=50940.6, bsz=2990.6, num_updates=186400, lr=0.000131841, gnorm=0.277, loss_scale=4, train_wall=179, wall=346654
2021-03-18 09:54:41 | INFO | train_inner | epoch 010:   4324 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27865.5, ups=0.55, wpb=50924.7, bsz=3035.7, num_updates=186500, lr=0.000131805, gnorm=0.274, loss_scale=4, train_wall=180, wall=346837
2021-03-18 09:57:44 | INFO | train_inner | epoch 010:   4424 / 20258 loss=3.457, nll_loss=1.763, ppl=3.39, wps=27803.7, ups=0.55, wpb=50855.7, bsz=3013.1, num_updates=186600, lr=0.00013177, gnorm=0.275, loss_scale=4, train_wall=180, wall=347019
2021-03-18 10:00:46 | INFO | train_inner | epoch 010:   4524 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27898.6, ups=0.55, wpb=50887.9, bsz=3125, num_updates=186700, lr=0.000131735, gnorm=0.27, loss_scale=4, train_wall=179, wall=347202
2021-03-18 10:03:49 | INFO | train_inner | epoch 010:   4624 / 20258 loss=3.462, nll_loss=1.768, ppl=3.4, wps=27854, ups=0.55, wpb=50785.4, bsz=2929.8, num_updates=186800, lr=0.000131699, gnorm=0.274, loss_scale=4, train_wall=179, wall=347384
2021-03-18 10:06:50 | INFO | train_inner | epoch 010:   4724 / 20258 loss=3.497, nll_loss=1.808, ppl=3.5, wps=27932.3, ups=0.55, wpb=50745, bsz=3010.7, num_updates=186900, lr=0.000131664, gnorm=0.279, loss_scale=4, train_wall=179, wall=347566
2021-03-18 10:09:53 | INFO | train_inner | epoch 010:   4824 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27804.2, ups=0.55, wpb=50843.5, bsz=3113.7, num_updates=187000, lr=0.000131629, gnorm=0.28, loss_scale=4, train_wall=179, wall=347749
2021-03-18 10:12:55 | INFO | train_inner | epoch 010:   4924 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=27952.2, ups=0.55, wpb=50874.2, bsz=3018.2, num_updates=187100, lr=0.000131594, gnorm=0.279, loss_scale=8, train_wall=179, wall=347931
2021-03-18 10:15:58 | INFO | train_inner | epoch 010:   5024 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27897.2, ups=0.55, wpb=50998.7, bsz=3004.4, num_updates=187200, lr=0.000131559, gnorm=0.275, loss_scale=8, train_wall=179, wall=348114
2021-03-18 10:19:01 | INFO | train_inner | epoch 010:   5124 / 20258 loss=3.467, nll_loss=1.773, ppl=3.42, wps=27901.1, ups=0.55, wpb=50934, bsz=2983.4, num_updates=187300, lr=0.000131524, gnorm=0.273, loss_scale=8, train_wall=179, wall=348296
2021-03-18 10:22:03 | INFO | train_inner | epoch 010:   5224 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27944.7, ups=0.55, wpb=50974.8, bsz=3060.2, num_updates=187400, lr=0.000131488, gnorm=0.274, loss_scale=8, train_wall=179, wall=348479
2021-03-18 10:25:05 | INFO | train_inner | epoch 010:   5324 / 20258 loss=3.466, nll_loss=1.772, ppl=3.42, wps=27740.6, ups=0.55, wpb=50464.4, bsz=2956.9, num_updates=187500, lr=0.000131453, gnorm=0.277, loss_scale=8, train_wall=179, wall=348660
2021-03-18 10:28:07 | INFO | train_inner | epoch 010:   5424 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=27906.3, ups=0.55, wpb=50824.4, bsz=2953.8, num_updates=187600, lr=0.000131418, gnorm=0.274, loss_scale=8, train_wall=179, wall=348843
2021-03-18 10:31:09 | INFO | train_inner | epoch 010:   5524 / 20258 loss=3.487, nll_loss=1.796, ppl=3.47, wps=27804.8, ups=0.55, wpb=50637.2, bsz=2896.2, num_updates=187700, lr=0.000131383, gnorm=0.282, loss_scale=8, train_wall=179, wall=349025
2021-03-18 10:34:11 | INFO | train_inner | epoch 010:   5624 / 20258 loss=3.472, nll_loss=1.779, ppl=3.43, wps=27896.9, ups=0.55, wpb=50831.7, bsz=2933.5, num_updates=187800, lr=0.000131348, gnorm=0.277, loss_scale=8, train_wall=179, wall=349207
2021-03-18 10:37:15 | INFO | train_inner | epoch 010:   5724 / 20258 loss=3.471, nll_loss=1.778, ppl=3.43, wps=27858.1, ups=0.55, wpb=51072.4, bsz=3045.5, num_updates=187900, lr=0.000131313, gnorm=0.272, loss_scale=8, train_wall=180, wall=349390
2021-03-18 10:40:18 | INFO | train_inner | epoch 010:   5824 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27910.2, ups=0.55, wpb=51103.1, bsz=3123.7, num_updates=188000, lr=0.000131278, gnorm=0.276, loss_scale=8, train_wall=180, wall=349573
2021-03-18 10:42:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 10:43:22 | INFO | train_inner | epoch 010:   5925 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27506.3, ups=0.54, wpb=50595.3, bsz=2995.2, num_updates=188100, lr=0.000131244, gnorm=0.28, loss_scale=8, train_wall=181, wall=349757
2021-03-18 10:46:24 | INFO | train_inner | epoch 010:   6025 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27702.5, ups=0.55, wpb=50604.7, bsz=3008.6, num_updates=188200, lr=0.000131209, gnorm=0.276, loss_scale=8, train_wall=179, wall=349940
2021-03-18 10:49:27 | INFO | train_inner | epoch 010:   6125 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27874.5, ups=0.55, wpb=50888.2, bsz=2994.8, num_updates=188300, lr=0.000131174, gnorm=0.278, loss_scale=8, train_wall=179, wall=350123
2021-03-18 10:52:30 | INFO | train_inner | epoch 010:   6225 / 20258 loss=3.482, nll_loss=1.791, ppl=3.46, wps=27817.4, ups=0.55, wpb=50804.2, bsz=3094.7, num_updates=188400, lr=0.000131139, gnorm=0.274, loss_scale=8, train_wall=179, wall=350305
2021-03-18 10:55:32 | INFO | train_inner | epoch 010:   6325 / 20258 loss=3.464, nll_loss=1.77, ppl=3.41, wps=28073.7, ups=0.55, wpb=51287.7, bsz=3082.2, num_updates=188500, lr=0.000131104, gnorm=0.276, loss_scale=8, train_wall=180, wall=350488
2021-03-18 10:58:34 | INFO | train_inner | epoch 010:   6425 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27835.4, ups=0.55, wpb=50649.8, bsz=3018.8, num_updates=188600, lr=0.00013107, gnorm=0.275, loss_scale=8, train_wall=179, wall=350670
2021-03-18 11:01:37 | INFO | train_inner | epoch 010:   6525 / 20258 loss=3.471, nll_loss=1.778, ppl=3.43, wps=27943.5, ups=0.55, wpb=51006.5, bsz=2995.4, num_updates=188700, lr=0.000131035, gnorm=0.278, loss_scale=8, train_wall=179, wall=350852
2021-03-18 11:04:39 | INFO | train_inner | epoch 010:   6625 / 20258 loss=3.488, nll_loss=1.797, ppl=3.48, wps=28033.1, ups=0.55, wpb=51103.1, bsz=2967.5, num_updates=188800, lr=0.000131, gnorm=0.278, loss_scale=8, train_wall=179, wall=351035
2021-03-18 11:07:41 | INFO | train_inner | epoch 010:   6725 / 20258 loss=3.496, nll_loss=1.807, ppl=3.5, wps=28075.5, ups=0.55, wpb=51117.3, bsz=3086.3, num_updates=188900, lr=0.000130965, gnorm=0.278, loss_scale=8, train_wall=179, wall=351217
2021-03-18 11:10:43 | INFO | train_inner | epoch 010:   6825 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27818.5, ups=0.55, wpb=50713.4, bsz=3019.4, num_updates=189000, lr=0.000130931, gnorm=0.274, loss_scale=8, train_wall=179, wall=351399
2021-03-18 11:13:46 | INFO | train_inner | epoch 010:   6925 / 20258 loss=3.488, nll_loss=1.798, ppl=3.48, wps=27963, ups=0.55, wpb=50927, bsz=2917.8, num_updates=189100, lr=0.000130896, gnorm=0.279, loss_scale=8, train_wall=179, wall=351581
2021-03-18 11:16:48 | INFO | train_inner | epoch 010:   7025 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27800.1, ups=0.55, wpb=50745.9, bsz=2971.3, num_updates=189200, lr=0.000130862, gnorm=0.272, loss_scale=16, train_wall=179, wall=351764
2021-03-18 11:19:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 11:19:52 | INFO | train_inner | epoch 010:   7126 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27564, ups=0.54, wpb=50758.3, bsz=2949.3, num_updates=189300, lr=0.000130827, gnorm=0.28, loss_scale=8, train_wall=181, wall=351948
2021-03-18 11:22:55 | INFO | train_inner | epoch 010:   7226 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=27957.2, ups=0.55, wpb=51024.8, bsz=2960.5, num_updates=189400, lr=0.000130792, gnorm=0.273, loss_scale=8, train_wall=180, wall=352130
2021-03-18 11:25:57 | INFO | train_inner | epoch 010:   7326 / 20258 loss=3.494, nll_loss=1.804, ppl=3.49, wps=27874.2, ups=0.55, wpb=50861.8, bsz=3162.4, num_updates=189500, lr=0.000130758, gnorm=0.277, loss_scale=8, train_wall=179, wall=352313
2021-03-18 11:29:00 | INFO | train_inner | epoch 010:   7426 / 20258 loss=3.47, nll_loss=1.777, ppl=3.43, wps=27941.4, ups=0.55, wpb=50975.8, bsz=2911.9, num_updates=189600, lr=0.000130723, gnorm=0.274, loss_scale=8, train_wall=179, wall=352495
2021-03-18 11:32:03 | INFO | train_inner | epoch 010:   7526 / 20258 loss=3.474, nll_loss=1.781, ppl=3.44, wps=27952.2, ups=0.55, wpb=51103, bsz=3087, num_updates=189700, lr=0.000130689, gnorm=0.276, loss_scale=8, train_wall=180, wall=352678
2021-03-18 11:35:05 | INFO | train_inner | epoch 010:   7626 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27746.3, ups=0.55, wpb=50572.2, bsz=3026.8, num_updates=189800, lr=0.000130655, gnorm=0.277, loss_scale=8, train_wall=179, wall=352860
2021-03-18 11:38:07 | INFO | train_inner | epoch 010:   7726 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27855.6, ups=0.55, wpb=50759.5, bsz=3005.9, num_updates=189900, lr=0.00013062, gnorm=0.283, loss_scale=8, train_wall=179, wall=353043
2021-03-18 11:41:10 | INFO | train_inner | epoch 010:   7826 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=28001.9, ups=0.55, wpb=51171.7, bsz=2973.4, num_updates=190000, lr=0.000130586, gnorm=0.271, loss_scale=8, train_wall=180, wall=353225
2021-03-18 11:41:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 11:41:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:28 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.897 | nll_loss 2.181 | ppl 4.53 | bleu 29.76 | wps 4378.7 | wpb 2432 | bsz 90.4 | num_updates 190000 | best_loss 3.888
2021-03-18 11:41:28 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 11:41:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:41:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 11:41:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 11:41:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 11:42:21 | INFO | valid1 | epoch 010 | valid on 'valid1' subset | loss 3.897 | nll_loss 2.205 | ppl 4.61 | bleu 27.75 | wps 4213.5 | wpb 2359.4 | bsz 106.4 | num_updates 190000 | best_loss 3.888
2021-03-18 11:42:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 11:42:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_10_190000.pt (epoch 10 @ 190000 updates, score 3.897) (writing took 4.666375948116183 seconds)
2021-03-18 11:45:28 | INFO | train_inner | epoch 010:   7926 / 20258 loss=3.468, nll_loss=1.775, ppl=3.42, wps=19747.7, ups=0.39, wpb=51036.9, bsz=2915, num_updates=190100, lr=0.000130551, gnorm=0.274, loss_scale=8, train_wall=179, wall=353484
2021-03-18 11:48:31 | INFO | train_inner | epoch 010:   8026 / 20258 loss=3.473, nll_loss=1.78, ppl=3.44, wps=27888.1, ups=0.55, wpb=50987.7, bsz=3029.4, num_updates=190200, lr=0.000130517, gnorm=0.276, loss_scale=8, train_wall=180, wall=353667
2021-03-18 11:51:33 | INFO | train_inner | epoch 010:   8126 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27876.7, ups=0.55, wpb=50851.3, bsz=3129.4, num_updates=190300, lr=0.000130483, gnorm=0.28, loss_scale=8, train_wall=179, wall=353849
2021-03-18 11:52:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 11:54:38 | INFO | train_inner | epoch 010:   8227 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27542.6, ups=0.54, wpb=50955.2, bsz=3119.8, num_updates=190400, lr=0.000130448, gnorm=0.274, loss_scale=8, train_wall=181, wall=354034
2021-03-18 11:57:41 | INFO | train_inner | epoch 010:   8327 / 20258 loss=3.5, nll_loss=1.812, ppl=3.51, wps=27943.4, ups=0.55, wpb=51050.9, bsz=3111.1, num_updates=190500, lr=0.000130414, gnorm=0.273, loss_scale=8, train_wall=179, wall=354217
2021-03-18 12:00:44 | INFO | train_inner | epoch 010:   8427 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27953.8, ups=0.55, wpb=51103.9, bsz=3024.5, num_updates=190600, lr=0.00013038, gnorm=0.273, loss_scale=8, train_wall=180, wall=354400
2021-03-18 12:03:47 | INFO | train_inner | epoch 010:   8527 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27917.2, ups=0.55, wpb=50961.7, bsz=3049.2, num_updates=190700, lr=0.000130346, gnorm=0.276, loss_scale=8, train_wall=179, wall=354582
2021-03-18 12:06:49 | INFO | train_inner | epoch 010:   8627 / 20258 loss=3.468, nll_loss=1.775, ppl=3.42, wps=27840.3, ups=0.55, wpb=50888.5, bsz=3092.6, num_updates=190800, lr=0.000130312, gnorm=0.275, loss_scale=8, train_wall=180, wall=354765
2021-03-18 12:09:52 | INFO | train_inner | epoch 010:   8727 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27841.2, ups=0.55, wpb=50737.1, bsz=2946.2, num_updates=190900, lr=0.000130278, gnorm=0.277, loss_scale=8, train_wall=179, wall=354947
2021-03-18 12:12:54 | INFO | train_inner | epoch 010:   8827 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=27951.5, ups=0.55, wpb=50994.7, bsz=3021.1, num_updates=191000, lr=0.000130243, gnorm=0.278, loss_scale=8, train_wall=179, wall=355130
2021-03-18 12:15:56 | INFO | train_inner | epoch 010:   8927 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27914.2, ups=0.55, wpb=50916.5, bsz=2903.4, num_updates=191100, lr=0.000130209, gnorm=0.283, loss_scale=8, train_wall=179, wall=355312
2021-03-18 12:18:58 | INFO | train_inner | epoch 010:   9027 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27913.2, ups=0.55, wpb=50772.1, bsz=3016.2, num_updates=191200, lr=0.000130175, gnorm=0.273, loss_scale=8, train_wall=179, wall=355494
2021-03-18 12:22:01 | INFO | train_inner | epoch 010:   9127 / 20258 loss=3.485, nll_loss=1.795, ppl=3.47, wps=27869.6, ups=0.55, wpb=50806.2, bsz=3110.8, num_updates=191300, lr=0.000130141, gnorm=0.277, loss_scale=8, train_wall=179, wall=355676
2021-03-18 12:25:03 | INFO | train_inner | epoch 010:   9227 / 20258 loss=3.489, nll_loss=1.799, ppl=3.48, wps=27803.6, ups=0.55, wpb=50827.3, bsz=3082.7, num_updates=191400, lr=0.000130107, gnorm=0.278, loss_scale=16, train_wall=179, wall=355859
2021-03-18 12:27:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 12:28:08 | INFO | train_inner | epoch 010:   9328 / 20258 loss=3.458, nll_loss=1.764, ppl=3.4, wps=27611.1, ups=0.54, wpb=51038, bsz=3009, num_updates=191500, lr=0.000130073, gnorm=0.275, loss_scale=8, train_wall=182, wall=356044
2021-03-18 12:31:11 | INFO | train_inner | epoch 010:   9428 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27823.6, ups=0.55, wpb=50789.1, bsz=3020.6, num_updates=191600, lr=0.000130039, gnorm=0.274, loss_scale=8, train_wall=179, wall=356226
2021-03-18 12:34:13 | INFO | train_inner | epoch 010:   9528 / 20258 loss=3.498, nll_loss=1.809, ppl=3.5, wps=27888.5, ups=0.55, wpb=50913.6, bsz=2918.2, num_updates=191700, lr=0.000130005, gnorm=0.277, loss_scale=8, train_wall=179, wall=356409
2021-03-18 12:37:16 | INFO | train_inner | epoch 010:   9628 / 20258 loss=3.481, nll_loss=1.79, ppl=3.46, wps=27764.3, ups=0.55, wpb=50733.5, bsz=3064.4, num_updates=191800, lr=0.000129972, gnorm=0.276, loss_scale=8, train_wall=179, wall=356592
2021-03-18 12:40:19 | INFO | train_inner | epoch 010:   9728 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27775.6, ups=0.55, wpb=50851.9, bsz=3046.2, num_updates=191900, lr=0.000129938, gnorm=0.275, loss_scale=8, train_wall=180, wall=356775
2021-03-18 12:43:22 | INFO | train_inner | epoch 010:   9828 / 20258 loss=3.467, nll_loss=1.774, ppl=3.42, wps=27810.8, ups=0.55, wpb=50778.6, bsz=2927.5, num_updates=192000, lr=0.000129904, gnorm=0.269, loss_scale=8, train_wall=180, wall=356957
2021-03-18 12:46:25 | INFO | train_inner | epoch 010:   9928 / 20258 loss=3.471, nll_loss=1.778, ppl=3.43, wps=27766.5, ups=0.55, wpb=50888, bsz=2954.3, num_updates=192100, lr=0.00012987, gnorm=0.278, loss_scale=8, train_wall=180, wall=357141
2021-03-18 12:49:28 | INFO | train_inner | epoch 010:  10028 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27898, ups=0.55, wpb=50980.4, bsz=3105, num_updates=192200, lr=0.000129836, gnorm=0.279, loss_scale=8, train_wall=180, wall=357323
2021-03-18 12:52:31 | INFO | train_inner | epoch 010:  10128 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27813.5, ups=0.55, wpb=50919.4, bsz=2986.2, num_updates=192300, lr=0.000129802, gnorm=0.289, loss_scale=8, train_wall=180, wall=357506
2021-03-18 12:55:34 | INFO | train_inner | epoch 010:  10228 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27901.7, ups=0.55, wpb=51041.8, bsz=3053.8, num_updates=192400, lr=0.000129769, gnorm=0.271, loss_scale=8, train_wall=180, wall=357689
2021-03-18 12:57:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 12:58:38 | INFO | train_inner | epoch 010:  10329 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27658, ups=0.54, wpb=50977.8, bsz=3010.6, num_updates=192500, lr=0.000129735, gnorm=0.274, loss_scale=4, train_wall=181, wall=357874
2021-03-18 13:01:41 | INFO | train_inner | epoch 010:  10429 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27842, ups=0.55, wpb=50968.9, bsz=3022.2, num_updates=192600, lr=0.000129701, gnorm=0.272, loss_scale=4, train_wall=180, wall=358057
2021-03-18 13:04:44 | INFO | train_inner | epoch 010:  10529 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27837.7, ups=0.55, wpb=50766.4, bsz=2967.1, num_updates=192700, lr=0.000129668, gnorm=0.279, loss_scale=4, train_wall=179, wall=358239
2021-03-18 13:07:47 | INFO | train_inner | epoch 010:  10629 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=27953.4, ups=0.55, wpb=51179.4, bsz=3146.2, num_updates=192800, lr=0.000129634, gnorm=0.275, loss_scale=4, train_wall=180, wall=358422
2021-03-18 13:10:49 | INFO | train_inner | epoch 010:  10729 / 20258 loss=3.484, nll_loss=1.793, ppl=3.46, wps=28009.7, ups=0.55, wpb=50959.2, bsz=2890.5, num_updates=192900, lr=0.0001296, gnorm=0.277, loss_scale=4, train_wall=179, wall=358604
2021-03-18 13:13:51 | INFO | train_inner | epoch 010:  10829 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27724.7, ups=0.55, wpb=50473.4, bsz=3083.1, num_updates=193000, lr=0.000129567, gnorm=0.275, loss_scale=4, train_wall=179, wall=358786
2021-03-18 13:16:53 | INFO | train_inner | epoch 010:  10929 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27883.6, ups=0.55, wpb=50780.2, bsz=2921, num_updates=193100, lr=0.000129533, gnorm=0.283, loss_scale=4, train_wall=179, wall=358968
2021-03-18 13:19:54 | INFO | train_inner | epoch 010:  11029 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27921, ups=0.55, wpb=50707.6, bsz=2967, num_updates=193200, lr=0.0001295, gnorm=0.28, loss_scale=4, train_wall=179, wall=359150
2021-03-18 13:22:57 | INFO | train_inner | epoch 010:  11129 / 20258 loss=3.472, nll_loss=1.779, ppl=3.43, wps=27920.4, ups=0.55, wpb=50988.4, bsz=3039.3, num_updates=193300, lr=0.000129466, gnorm=0.273, loss_scale=4, train_wall=179, wall=359332
2021-03-18 13:25:59 | INFO | train_inner | epoch 010:  11229 / 20258 loss=3.484, nll_loss=1.794, ppl=3.47, wps=27934.8, ups=0.55, wpb=50953, bsz=3000.6, num_updates=193400, lr=0.000129433, gnorm=0.277, loss_scale=4, train_wall=179, wall=359515
2021-03-18 13:29:02 | INFO | train_inner | epoch 010:  11329 / 20258 loss=3.504, nll_loss=1.816, ppl=3.52, wps=27971.5, ups=0.55, wpb=51008.1, bsz=3035.6, num_updates=193500, lr=0.000129399, gnorm=0.285, loss_scale=8, train_wall=179, wall=359697
2021-03-18 13:32:04 | INFO | train_inner | epoch 010:  11429 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27895.9, ups=0.55, wpb=50844.6, bsz=3052.6, num_updates=193600, lr=0.000129366, gnorm=0.273, loss_scale=8, train_wall=179, wall=359880
2021-03-18 13:35:06 | INFO | train_inner | epoch 010:  11529 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27935.6, ups=0.55, wpb=50971.1, bsz=3045, num_updates=193700, lr=0.000129333, gnorm=0.277, loss_scale=8, train_wall=179, wall=360062
2021-03-18 13:37:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 13:38:11 | INFO | train_inner | epoch 010:  11630 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27571, ups=0.54, wpb=50921.2, bsz=2991.3, num_updates=193800, lr=0.000129299, gnorm=0.279, loss_scale=4, train_wall=181, wall=360247
2021-03-18 13:41:14 | INFO | train_inner | epoch 010:  11730 / 20258 loss=3.469, nll_loss=1.776, ppl=3.42, wps=27882.6, ups=0.55, wpb=51018, bsz=3074.3, num_updates=193900, lr=0.000129266, gnorm=0.275, loss_scale=4, train_wall=180, wall=360430
2021-03-18 13:44:17 | INFO | train_inner | epoch 010:  11830 / 20258 loss=3.495, nll_loss=1.806, ppl=3.5, wps=27957.9, ups=0.55, wpb=51085.5, bsz=3103, num_updates=194000, lr=0.000129232, gnorm=0.278, loss_scale=4, train_wall=179, wall=360612
2021-03-18 13:47:19 | INFO | train_inner | epoch 010:  11930 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27973.1, ups=0.55, wpb=51038.6, bsz=2959.4, num_updates=194100, lr=0.000129199, gnorm=0.272, loss_scale=4, train_wall=179, wall=360795
2021-03-18 13:50:22 | INFO | train_inner | epoch 010:  12030 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27812.5, ups=0.55, wpb=50683, bsz=2938.2, num_updates=194200, lr=0.000129166, gnorm=0.284, loss_scale=4, train_wall=179, wall=360977
2021-03-18 13:53:24 | INFO | train_inner | epoch 010:  12130 / 20258 loss=3.485, nll_loss=1.794, ppl=3.47, wps=27903.7, ups=0.55, wpb=50986, bsz=2978.9, num_updates=194300, lr=0.000129133, gnorm=0.28, loss_scale=4, train_wall=179, wall=361160
2021-03-18 13:56:26 | INFO | train_inner | epoch 010:  12230 / 20258 loss=3.488, nll_loss=1.798, ppl=3.48, wps=27869.3, ups=0.55, wpb=50745.3, bsz=3012.3, num_updates=194400, lr=0.000129099, gnorm=0.282, loss_scale=4, train_wall=179, wall=361342
2021-03-18 13:59:29 | INFO | train_inner | epoch 010:  12330 / 20258 loss=3.49, nll_loss=1.8, ppl=3.48, wps=27813.8, ups=0.55, wpb=50670.1, bsz=3022.4, num_updates=194500, lr=0.000129066, gnorm=0.279, loss_scale=4, train_wall=179, wall=361524
2021-03-18 14:02:31 | INFO | train_inner | epoch 010:  12430 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27825.7, ups=0.55, wpb=50641.9, bsz=2990.1, num_updates=194600, lr=0.000129033, gnorm=0.274, loss_scale=4, train_wall=179, wall=361706
2021-03-18 14:05:33 | INFO | train_inner | epoch 010:  12530 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27829.4, ups=0.55, wpb=50924.3, bsz=3176.9, num_updates=194700, lr=0.000129, gnorm=0.283, loss_scale=4, train_wall=179, wall=361889
2021-03-18 14:08:36 | INFO | train_inner | epoch 010:  12630 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27949.5, ups=0.55, wpb=51029.8, bsz=2888.6, num_updates=194800, lr=0.000128967, gnorm=0.275, loss_scale=8, train_wall=180, wall=362072
2021-03-18 14:11:39 | INFO | train_inner | epoch 010:  12730 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27834.4, ups=0.55, wpb=50881.5, bsz=2971.8, num_updates=194900, lr=0.000128934, gnorm=0.278, loss_scale=8, train_wall=179, wall=362254
2021-03-18 14:14:41 | INFO | train_inner | epoch 010:  12830 / 20258 loss=3.482, nll_loss=1.791, ppl=3.46, wps=27931.3, ups=0.55, wpb=50957.4, bsz=2973.6, num_updates=195000, lr=0.000128901, gnorm=0.275, loss_scale=8, train_wall=179, wall=362437
2021-03-18 14:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 14:14:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:14:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:14:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:14:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:14:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:14:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:14:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:14:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:14:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:14:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:14:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:14:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:14:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:14:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:14:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:14:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:14:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:14:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:14:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:14:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:14:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:00 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.889 | nll_loss 2.176 | ppl 4.52 | bleu 29.94 | wps 4286.1 | wpb 2432 | bsz 90.4 | num_updates 195000 | best_loss 3.888
2021-03-18 14:15:00 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 14:15:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 14:15:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 14:15:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 14:15:52 | INFO | valid1 | epoch 010 | valid on 'valid1' subset | loss 3.886 | nll_loss 2.195 | ppl 4.58 | bleu 27.99 | wps 4270.6 | wpb 2359.4 | bsz 106.4 | num_updates 195000 | best_loss 3.886
2021-03-18 14:15:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 14:15:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_10_195000.pt (epoch 10 @ 195000 updates, score 3.889) (writing took 4.596904306905344 seconds)
2021-03-18 14:18:59 | INFO | train_inner | epoch 010:  12930 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=19695.6, ups=0.39, wpb=50734.1, bsz=3021.4, num_updates=195100, lr=0.000128868, gnorm=0.279, loss_scale=8, train_wall=179, wall=362694
2021-03-18 14:22:02 | INFO | train_inner | epoch 010:  13030 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27970.2, ups=0.55, wpb=51162.9, bsz=2968, num_updates=195200, lr=0.000128835, gnorm=0.273, loss_scale=8, train_wall=180, wall=362877
2021-03-18 14:25:04 | INFO | train_inner | epoch 010:  13130 / 20258 loss=3.488, nll_loss=1.797, ppl=3.48, wps=28019.9, ups=0.55, wpb=51146, bsz=2918.2, num_updates=195300, lr=0.000128802, gnorm=0.278, loss_scale=8, train_wall=179, wall=363060
2021-03-18 14:28:07 | INFO | train_inner | epoch 010:  13230 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27798.3, ups=0.55, wpb=50746.5, bsz=3021.1, num_updates=195400, lr=0.000128769, gnorm=0.278, loss_scale=8, train_wall=179, wall=363242
2021-03-18 14:31:09 | INFO | train_inner | epoch 010:  13330 / 20258 loss=3.487, nll_loss=1.796, ppl=3.47, wps=27963.1, ups=0.55, wpb=50877.4, bsz=2887.8, num_updates=195500, lr=0.000128736, gnorm=0.281, loss_scale=8, train_wall=179, wall=363424
2021-03-18 14:32:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 14:34:14 | INFO | train_inner | epoch 010:  13431 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27698.8, ups=0.54, wpb=51146, bsz=3067.4, num_updates=195600, lr=0.000128703, gnorm=0.278, loss_scale=4, train_wall=181, wall=363609
2021-03-18 14:37:16 | INFO | train_inner | epoch 010:  13531 / 20258 loss=3.489, nll_loss=1.798, ppl=3.48, wps=27944, ups=0.55, wpb=51045.3, bsz=2965.6, num_updates=195700, lr=0.00012867, gnorm=0.277, loss_scale=4, train_wall=179, wall=363792
2021-03-18 14:38:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-18 14:40:21 | INFO | train_inner | epoch 010:  13632 / 20258 loss=3.47, nll_loss=1.777, ppl=3.43, wps=27651.6, ups=0.54, wpb=50980.1, bsz=2966.4, num_updates=195800, lr=0.000128637, gnorm=0.282, loss_scale=2, train_wall=181, wall=363976
2021-03-18 14:43:23 | INFO | train_inner | epoch 010:  13732 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27843.6, ups=0.55, wpb=50894.6, bsz=2953.9, num_updates=195900, lr=0.000128604, gnorm=0.281, loss_scale=2, train_wall=179, wall=364159
2021-03-18 14:46:26 | INFO | train_inner | epoch 010:  13832 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=27806.4, ups=0.55, wpb=50817.9, bsz=3034.4, num_updates=196000, lr=0.000128571, gnorm=0.276, loss_scale=2, train_wall=179, wall=364342
2021-03-18 14:49:29 | INFO | train_inner | epoch 010:  13932 / 20258 loss=3.492, nll_loss=1.803, ppl=3.49, wps=27796, ups=0.55, wpb=50760.1, bsz=2988.6, num_updates=196100, lr=0.000128539, gnorm=0.282, loss_scale=2, train_wall=179, wall=364524
2021-03-18 14:50:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2021-03-18 14:52:33 | INFO | train_inner | epoch 010:  14033 / 20258 loss=3.487, nll_loss=1.797, ppl=3.47, wps=27705, ups=0.54, wpb=51156.3, bsz=3077.9, num_updates=196200, lr=0.000128506, gnorm=0.511, loss_scale=1, train_wall=181, wall=364709
2021-03-18 14:53:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2021-03-18 14:55:38 | INFO | train_inner | epoch 010:  14134 / 20258 loss=3.469, nll_loss=1.776, ppl=3.43, wps=27645.1, ups=0.54, wpb=50959.3, bsz=2953.3, num_updates=196300, lr=0.000128473, gnorm=0.302, loss_scale=0.5, train_wall=181, wall=364893
2021-03-18 14:58:41 | INFO | train_inner | epoch 010:  14234 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=27996.4, ups=0.55, wpb=51220.9, bsz=2887.4, num_updates=196400, lr=0.00012844, gnorm=0.284, loss_scale=0.5, train_wall=180, wall=365076
2021-03-18 15:01:44 | INFO | train_inner | epoch 010:  14334 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27804.5, ups=0.55, wpb=50934.8, bsz=3178.7, num_updates=196500, lr=0.000128408, gnorm=0.276, loss_scale=0.5, train_wall=180, wall=365259
2021-03-18 15:04:46 | INFO | train_inner | epoch 010:  14434 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27912.7, ups=0.55, wpb=50757.5, bsz=2993.1, num_updates=196600, lr=0.000128375, gnorm=0.281, loss_scale=0.5, train_wall=179, wall=365441
2021-03-18 15:07:48 | INFO | train_inner | epoch 010:  14534 / 20258 loss=3.475, nll_loss=1.782, ppl=3.44, wps=27931.2, ups=0.55, wpb=50824.4, bsz=2956.2, num_updates=196700, lr=0.000128342, gnorm=0.278, loss_scale=0.5, train_wall=179, wall=365623
2021-03-18 15:10:50 | INFO | train_inner | epoch 010:  14634 / 20258 loss=3.464, nll_loss=1.772, ppl=3.41, wps=27939.1, ups=0.55, wpb=51049.2, bsz=3113.3, num_updates=196800, lr=0.00012831, gnorm=0.275, loss_scale=0.5, train_wall=180, wall=365806
2021-03-18 15:13:53 | INFO | train_inner | epoch 010:  14734 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27943, ups=0.55, wpb=50986.1, bsz=3081.4, num_updates=196900, lr=0.000128277, gnorm=0.275, loss_scale=0.5, train_wall=180, wall=365988
2021-03-18 15:16:56 | INFO | train_inner | epoch 010:  14834 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=27791.1, ups=0.55, wpb=50891.6, bsz=3087.1, num_updates=197000, lr=0.000128245, gnorm=0.276, loss_scale=0.5, train_wall=179, wall=366172
2021-03-18 15:19:58 | INFO | train_inner | epoch 010:  14934 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27842.2, ups=0.55, wpb=50655.7, bsz=3062.2, num_updates=197100, lr=0.000128212, gnorm=0.279, loss_scale=0.5, train_wall=179, wall=366353
2021-03-18 15:23:01 | INFO | train_inner | epoch 010:  15034 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27886.7, ups=0.55, wpb=50935.2, bsz=3018, num_updates=197200, lr=0.00012818, gnorm=0.279, loss_scale=0.5, train_wall=179, wall=366536
2021-03-18 15:26:03 | INFO | train_inner | epoch 010:  15134 / 20258 loss=3.48, nll_loss=1.79, ppl=3.46, wps=27892.6, ups=0.55, wpb=50856.6, bsz=3123.1, num_updates=197300, lr=0.000128147, gnorm=0.276, loss_scale=1, train_wall=179, wall=366718
2021-03-18 15:29:04 | INFO | train_inner | epoch 010:  15234 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27848.6, ups=0.55, wpb=50461.9, bsz=2924.9, num_updates=197400, lr=0.000128115, gnorm=0.279, loss_scale=1, train_wall=178, wall=366900
2021-03-18 15:32:07 | INFO | train_inner | epoch 010:  15334 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27917.8, ups=0.55, wpb=50942.6, bsz=2957.7, num_updates=197500, lr=0.000128082, gnorm=0.28, loss_scale=1, train_wall=179, wall=367082
2021-03-18 15:35:08 | INFO | train_inner | epoch 010:  15434 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27964.1, ups=0.55, wpb=50824.3, bsz=2878.6, num_updates=197600, lr=0.00012805, gnorm=0.275, loss_scale=1, train_wall=179, wall=367264
2021-03-18 15:38:11 | INFO | train_inner | epoch 010:  15534 / 20258 loss=3.482, nll_loss=1.792, ppl=3.46, wps=27937.7, ups=0.55, wpb=51023.1, bsz=3040.6, num_updates=197700, lr=0.000128017, gnorm=0.276, loss_scale=1, train_wall=180, wall=367446
2021-03-18 15:41:13 | INFO | train_inner | epoch 010:  15634 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27749, ups=0.55, wpb=50628.9, bsz=2960.2, num_updates=197800, lr=0.000127985, gnorm=0.279, loss_scale=1, train_wall=179, wall=367629
2021-03-18 15:44:16 | INFO | train_inner | epoch 010:  15734 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27858.3, ups=0.55, wpb=51001, bsz=3013.2, num_updates=197900, lr=0.000127953, gnorm=0.27, loss_scale=1, train_wall=180, wall=367812
2021-03-18 15:47:19 | INFO | train_inner | epoch 010:  15834 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=28022.5, ups=0.55, wpb=51191, bsz=3038.5, num_updates=198000, lr=0.00012792, gnorm=0.274, loss_scale=1, train_wall=180, wall=367995
2021-03-18 15:50:21 | INFO | train_inner | epoch 010:  15934 / 20258 loss=3.48, nll_loss=1.789, ppl=3.45, wps=27937.4, ups=0.55, wpb=50901.5, bsz=3070.9, num_updates=198100, lr=0.000127888, gnorm=0.318, loss_scale=1, train_wall=179, wall=368177
2021-03-18 15:53:24 | INFO | train_inner | epoch 010:  16034 / 20258 loss=3.469, nll_loss=1.776, ppl=3.43, wps=27879.6, ups=0.55, wpb=51006.1, bsz=3040.7, num_updates=198200, lr=0.000127856, gnorm=0.275, loss_scale=1, train_wall=180, wall=368360
2021-03-18 15:56:27 | INFO | train_inner | epoch 010:  16134 / 20258 loss=3.481, nll_loss=1.79, ppl=3.46, wps=27812.6, ups=0.55, wpb=50764, bsz=2999.9, num_updates=198300, lr=0.000127824, gnorm=0.283, loss_scale=2, train_wall=179, wall=368542
2021-03-18 15:59:29 | INFO | train_inner | epoch 010:  16234 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27911.6, ups=0.55, wpb=50982, bsz=3125.7, num_updates=198400, lr=0.000127791, gnorm=0.275, loss_scale=2, train_wall=180, wall=368725
2021-03-18 16:02:32 | INFO | train_inner | epoch 010:  16334 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27900.8, ups=0.55, wpb=50881.9, bsz=2934.8, num_updates=198500, lr=0.000127759, gnorm=0.279, loss_scale=2, train_wall=180, wall=368907
2021-03-18 16:05:35 | INFO | train_inner | epoch 010:  16434 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=27959.8, ups=0.55, wpb=51158.2, bsz=3182.9, num_updates=198600, lr=0.000127727, gnorm=0.279, loss_scale=2, train_wall=180, wall=369090
2021-03-18 16:08:37 | INFO | train_inner | epoch 010:  16534 / 20258 loss=3.465, nll_loss=1.771, ppl=3.41, wps=27860.2, ups=0.55, wpb=50842.5, bsz=2925.7, num_updates=198700, lr=0.000127695, gnorm=0.276, loss_scale=2, train_wall=180, wall=369273
2021-03-18 16:11:39 | INFO | train_inner | epoch 010:  16634 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27954.4, ups=0.55, wpb=50862.7, bsz=3097.4, num_updates=198800, lr=0.000127663, gnorm=0.275, loss_scale=2, train_wall=179, wall=369455
2021-03-18 16:14:41 | INFO | train_inner | epoch 010:  16734 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27902.5, ups=0.55, wpb=50772.6, bsz=3019.4, num_updates=198900, lr=0.000127631, gnorm=0.274, loss_scale=2, train_wall=179, wall=369637
2021-03-18 16:17:44 | INFO | train_inner | epoch 010:  16834 / 20258 loss=3.495, nll_loss=1.807, ppl=3.5, wps=27923.8, ups=0.55, wpb=51042.7, bsz=3152, num_updates=199000, lr=0.000127599, gnorm=0.284, loss_scale=2, train_wall=179, wall=369820
2021-03-18 16:20:46 | INFO | train_inner | epoch 010:  16934 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27850.4, ups=0.55, wpb=50700.8, bsz=3000.4, num_updates=199100, lr=0.000127567, gnorm=0.276, loss_scale=2, train_wall=179, wall=370002
2021-03-18 16:23:49 | INFO | train_inner | epoch 010:  17034 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27868.8, ups=0.55, wpb=50968.5, bsz=3046.9, num_updates=199200, lr=0.000127535, gnorm=0.384, loss_scale=2, train_wall=180, wall=370185
2021-03-18 16:26:52 | INFO | train_inner | epoch 010:  17134 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27880.6, ups=0.55, wpb=50920.9, bsz=3064.9, num_updates=199300, lr=0.000127503, gnorm=0.286, loss_scale=4, train_wall=179, wall=370367
2021-03-18 16:29:54 | INFO | train_inner | epoch 010:  17234 / 20258 loss=3.484, nll_loss=1.792, ppl=3.46, wps=27934.4, ups=0.55, wpb=50917.1, bsz=2852.4, num_updates=199400, lr=0.000127471, gnorm=0.275, loss_scale=4, train_wall=179, wall=370549
2021-03-18 16:32:56 | INFO | train_inner | epoch 010:  17334 / 20258 loss=3.497, nll_loss=1.808, ppl=3.5, wps=27758.7, ups=0.55, wpb=50481.9, bsz=2969.9, num_updates=199500, lr=0.000127439, gnorm=0.285, loss_scale=4, train_wall=178, wall=370731
2021-03-18 16:35:59 | INFO | train_inner | epoch 010:  17434 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27904.7, ups=0.55, wpb=51022.9, bsz=3048, num_updates=199600, lr=0.000127407, gnorm=0.279, loss_scale=4, train_wall=180, wall=370914
2021-03-18 16:39:01 | INFO | train_inner | epoch 010:  17534 / 20258 loss=3.474, nll_loss=1.783, ppl=3.44, wps=27770.8, ups=0.55, wpb=50590.2, bsz=3038.5, num_updates=199700, lr=0.000127375, gnorm=0.289, loss_scale=4, train_wall=179, wall=371096
2021-03-18 16:40:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-18 16:42:06 | INFO | train_inner | epoch 010:  17635 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=27675.2, ups=0.54, wpb=51142, bsz=2909.6, num_updates=199800, lr=0.000127343, gnorm=0.29, loss_scale=2, train_wall=181, wall=371281
2021-03-18 16:45:09 | INFO | train_inner | epoch 010:  17735 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27865.2, ups=0.55, wpb=51039.2, bsz=3075.4, num_updates=199900, lr=0.000127311, gnorm=0.274, loss_scale=2, train_wall=180, wall=371464
2021-03-18 16:48:12 | INFO | train_inner | epoch 010:  17835 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27894.9, ups=0.55, wpb=50996.9, bsz=2961.3, num_updates=200000, lr=0.000127279, gnorm=0.281, loss_scale=2, train_wall=179, wall=371647
2021-03-18 16:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 16:48:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:30 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.886 | nll_loss 2.17 | ppl 4.5 | bleu 29.92 | wps 4340.5 | wpb 2432 | bsz 90.4 | num_updates 200000 | best_loss 3.886
2021-03-18 16:48:30 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 16:48:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:48:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 16:48:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 16:48:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 16:49:23 | INFO | valid1 | epoch 010 | valid on 'valid1' subset | loss 3.889 | nll_loss 2.198 | ppl 4.59 | bleu 27.68 | wps 4202.5 | wpb 2359.4 | bsz 106.4 | num_updates 200000 | best_loss 3.888
2021-03-18 16:49:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 16:49:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_10_200000.pt (epoch 10 @ 200000 updates, score 3.886) (writing took 6.6388109910767525 seconds)
2021-03-18 16:52:32 | INFO | train_inner | epoch 010:  17935 / 20258 loss=3.481, nll_loss=1.789, ppl=3.46, wps=19528.1, ups=0.38, wpb=50919.9, bsz=2926.6, num_updates=200100, lr=0.000127247, gnorm=0.296, loss_scale=2, train_wall=180, wall=371908
2021-03-18 16:55:36 | INFO | train_inner | epoch 010:  18035 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27834.3, ups=0.55, wpb=50992, bsz=3080.3, num_updates=200200, lr=0.000127216, gnorm=0.273, loss_scale=2, train_wall=180, wall=372091
2021-03-18 16:58:38 | INFO | train_inner | epoch 010:  18135 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27790.5, ups=0.55, wpb=50664.3, bsz=3047, num_updates=200300, lr=0.000127184, gnorm=0.278, loss_scale=2, train_wall=179, wall=372273
2021-03-18 17:01:40 | INFO | train_inner | epoch 010:  18235 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27915.3, ups=0.55, wpb=50895.2, bsz=2914.1, num_updates=200400, lr=0.000127152, gnorm=0.278, loss_scale=2, train_wall=179, wall=372456
2021-03-18 17:04:43 | INFO | train_inner | epoch 010:  18335 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27930.3, ups=0.55, wpb=50989, bsz=3051.8, num_updates=200500, lr=0.00012712, gnorm=0.29, loss_scale=2, train_wall=179, wall=372638
2021-03-18 17:07:45 | INFO | train_inner | epoch 010:  18435 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=28002.3, ups=0.55, wpb=50987.2, bsz=3036.2, num_updates=200600, lr=0.000127089, gnorm=0.279, loss_scale=2, train_wall=179, wall=372820
2021-03-18 17:10:48 | INFO | train_inner | epoch 010:  18535 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27910.7, ups=0.55, wpb=51082.8, bsz=3087, num_updates=200700, lr=0.000127057, gnorm=0.274, loss_scale=2, train_wall=180, wall=373003
2021-03-18 17:13:50 | INFO | train_inner | epoch 010:  18635 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27890.6, ups=0.55, wpb=50906.8, bsz=2985, num_updates=200800, lr=0.000127025, gnorm=0.275, loss_scale=4, train_wall=179, wall=373186
2021-03-18 17:16:53 | INFO | train_inner | epoch 010:  18735 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27947.4, ups=0.55, wpb=51018.2, bsz=2984.3, num_updates=200900, lr=0.000126994, gnorm=0.275, loss_scale=4, train_wall=179, wall=373368
2021-03-18 17:19:55 | INFO | train_inner | epoch 010:  18835 / 20258 loss=3.493, nll_loss=1.803, ppl=3.49, wps=27926, ups=0.55, wpb=50857.1, bsz=2881.8, num_updates=201000, lr=0.000126962, gnorm=0.28, loss_scale=4, train_wall=179, wall=373551
2021-03-18 17:22:58 | INFO | train_inner | epoch 010:  18935 / 20258 loss=3.464, nll_loss=1.772, ppl=3.42, wps=27902.2, ups=0.55, wpb=51064.2, bsz=3174.7, num_updates=201100, lr=0.000126931, gnorm=0.278, loss_scale=4, train_wall=180, wall=373734
2021-03-18 17:26:01 | INFO | train_inner | epoch 010:  19035 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27856.8, ups=0.55, wpb=50875.4, bsz=3093.7, num_updates=201200, lr=0.000126899, gnorm=0.281, loss_scale=4, train_wall=179, wall=373916
2021-03-18 17:29:03 | INFO | train_inner | epoch 010:  19135 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27967.8, ups=0.55, wpb=51073.6, bsz=3051.3, num_updates=201300, lr=0.000126868, gnorm=0.271, loss_scale=4, train_wall=180, wall=374099
2021-03-18 17:32:06 | INFO | train_inner | epoch 010:  19235 / 20258 loss=3.483, nll_loss=1.793, ppl=3.46, wps=27852.3, ups=0.55, wpb=50821.1, bsz=2957, num_updates=201400, lr=0.000126836, gnorm=0.281, loss_scale=4, train_wall=179, wall=374281
2021-03-18 17:35:08 | INFO | train_inner | epoch 010:  19335 / 20258 loss=3.488, nll_loss=1.797, ppl=3.48, wps=27921.5, ups=0.55, wpb=50808.5, bsz=2882.6, num_updates=201500, lr=0.000126805, gnorm=0.28, loss_scale=4, train_wall=179, wall=374463
2021-03-18 17:38:11 | INFO | train_inner | epoch 010:  19435 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27901.2, ups=0.55, wpb=51145.5, bsz=3056.9, num_updates=201600, lr=0.000126773, gnorm=0.275, loss_scale=4, train_wall=180, wall=374647
2021-03-18 17:41:14 | INFO | train_inner | epoch 010:  19535 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27940, ups=0.55, wpb=51046.2, bsz=3049.7, num_updates=201700, lr=0.000126742, gnorm=0.273, loss_scale=4, train_wall=179, wall=374829
2021-03-18 17:44:17 | INFO | train_inner | epoch 010:  19635 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=27996.3, ups=0.55, wpb=51252.4, bsz=2922.8, num_updates=201800, lr=0.00012671, gnorm=0.276, loss_scale=8, train_wall=180, wall=375012
2021-03-18 17:47:20 | INFO | train_inner | epoch 010:  19735 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27829.1, ups=0.55, wpb=50953, bsz=3027.5, num_updates=201900, lr=0.000126679, gnorm=0.275, loss_scale=8, train_wall=180, wall=375195
2021-03-18 17:50:22 | INFO | train_inner | epoch 010:  19835 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27913.1, ups=0.55, wpb=50875.6, bsz=2979.5, num_updates=202000, lr=0.000126648, gnorm=0.277, loss_scale=8, train_wall=179, wall=375378
2021-03-18 17:53:24 | INFO | train_inner | epoch 010:  19935 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27711.1, ups=0.55, wpb=50531.4, bsz=2861.2, num_updates=202100, lr=0.000126616, gnorm=0.287, loss_scale=8, train_wall=179, wall=375560
2021-03-18 17:56:27 | INFO | train_inner | epoch 010:  20035 / 20258 loss=3.489, nll_loss=1.8, ppl=3.48, wps=27835.3, ups=0.55, wpb=50869.6, bsz=2993, num_updates=202200, lr=0.000126585, gnorm=0.28, loss_scale=8, train_wall=180, wall=375743
2021-03-18 17:59:30 | INFO | train_inner | epoch 010:  20135 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27870.1, ups=0.55, wpb=50864.8, bsz=3020.4, num_updates=202300, lr=0.000126554, gnorm=0.277, loss_scale=8, train_wall=179, wall=375925
2021-03-18 18:02:33 | INFO | train_inner | epoch 010:  20235 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27865.8, ups=0.55, wpb=50946.8, bsz=3013.1, num_updates=202400, lr=0.000126522, gnorm=0.275, loss_scale=8, train_wall=180, wall=376108
2021-03-18 18:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 18:03:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:33 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.887 | nll_loss 2.172 | ppl 4.51 | bleu 29.75 | wps 4439.3 | wpb 2432 | bsz 90.4 | num_updates 202423 | best_loss 3.886
2021-03-18 18:03:33 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 18:03:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:03:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 18:03:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 18:03:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 18:04:25 | INFO | valid1 | epoch 010 | valid on 'valid1' subset | loss 3.887 | nll_loss 2.195 | ppl 4.58 | bleu 27.95 | wps 4279 | wpb 2359.4 | bsz 106.4 | num_updates 202423 | best_loss 3.886
2021-03-18 18:04:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 18:04:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint10.pt (epoch 10 @ 202423 updates, score 3.887) (writing took 4.6287244209088385 seconds)
2021-03-18 18:04:29 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-03-18 18:04:29 | INFO | train | epoch 010 | loss 3.477 | nll_loss 1.786 | ppl 3.45 | wps 27591 | ups 0.54 | wpb 50905.5 | bsz 3010.2 | num_updates 202423 | lr 0.000126515 | gnorm 0.279 | loss_scale 8 | train_wall 36328 | wall 376225
2021-03-18 18:04:30 | INFO | fairseq.trainer | begin training epoch 11
2021-03-18 18:06:50 | INFO | train_inner | epoch 011:     77 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=19773, ups=0.39, wpb=50943.3, bsz=3098.3, num_updates=202500, lr=0.000126491, gnorm=0.28, loss_scale=8, train_wall=179, wall=376366
2021-03-18 18:09:53 | INFO | train_inner | epoch 011:    177 / 20258 loss=3.446, nll_loss=1.75, ppl=3.36, wps=27685.1, ups=0.55, wpb=50559.7, bsz=3081, num_updates=202600, lr=0.00012646, gnorm=0.276, loss_scale=8, train_wall=179, wall=376548
2021-03-18 18:12:55 | INFO | train_inner | epoch 011:    277 / 20258 loss=3.448, nll_loss=1.752, ppl=3.37, wps=27903, ups=0.55, wpb=50867.2, bsz=3024.2, num_updates=202700, lr=0.000126429, gnorm=0.277, loss_scale=8, train_wall=179, wall=376731
2021-03-18 18:15:59 | INFO | train_inner | epoch 011:    377 / 20258 loss=3.453, nll_loss=1.758, ppl=3.38, wps=27789.9, ups=0.55, wpb=50982.5, bsz=3108.6, num_updates=202800, lr=0.000126398, gnorm=0.276, loss_scale=8, train_wall=180, wall=376914
2021-03-18 18:19:02 | INFO | train_inner | epoch 011:    477 / 20258 loss=3.46, nll_loss=1.766, ppl=3.4, wps=27914.6, ups=0.55, wpb=51106.8, bsz=2904.2, num_updates=202900, lr=0.000126366, gnorm=0.274, loss_scale=16, train_wall=180, wall=377097
2021-03-18 18:19:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 18:22:06 | INFO | train_inner | epoch 011:    578 / 20258 loss=3.482, nll_loss=1.791, ppl=3.46, wps=27693, ups=0.54, wpb=51131.2, bsz=2978.1, num_updates=203000, lr=0.000126335, gnorm=0.275, loss_scale=8, train_wall=181, wall=377282
2021-03-18 18:24:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 18:25:11 | INFO | train_inner | epoch 011:    679 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27701.1, ups=0.54, wpb=51163.3, bsz=2958.7, num_updates=203100, lr=0.000126304, gnorm=0.279, loss_scale=4, train_wall=182, wall=377467
2021-03-18 18:28:14 | INFO | train_inner | epoch 011:    779 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=27804.4, ups=0.55, wpb=50877.1, bsz=2966.2, num_updates=203200, lr=0.000126273, gnorm=0.272, loss_scale=4, train_wall=180, wall=377650
2021-03-18 18:31:17 | INFO | train_inner | epoch 011:    879 / 20258 loss=3.469, nll_loss=1.776, ppl=3.42, wps=27940.2, ups=0.55, wpb=51073.4, bsz=3053.3, num_updates=203300, lr=0.000126242, gnorm=0.281, loss_scale=4, train_wall=180, wall=377832
2021-03-18 18:34:19 | INFO | train_inner | epoch 011:    979 / 20258 loss=3.453, nll_loss=1.758, ppl=3.38, wps=27803, ups=0.55, wpb=50708.4, bsz=2948.6, num_updates=203400, lr=0.000126211, gnorm=0.274, loss_scale=4, train_wall=179, wall=378015
2021-03-18 18:37:22 | INFO | train_inner | epoch 011:   1079 / 20258 loss=3.472, nll_loss=1.779, ppl=3.43, wps=27912.2, ups=0.55, wpb=50975.5, bsz=3011.8, num_updates=203500, lr=0.00012618, gnorm=0.276, loss_scale=4, train_wall=179, wall=378197
2021-03-18 18:40:24 | INFO | train_inner | epoch 011:   1179 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27800.7, ups=0.55, wpb=50745.9, bsz=3017.7, num_updates=203600, lr=0.000126149, gnorm=0.279, loss_scale=4, train_wall=179, wall=378380
2021-03-18 18:43:27 | INFO | train_inner | epoch 011:   1279 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27953, ups=0.55, wpb=50989.4, bsz=2925.5, num_updates=203700, lr=0.000126118, gnorm=0.277, loss_scale=4, train_wall=179, wall=378562
2021-03-18 18:46:30 | INFO | train_inner | epoch 011:   1379 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27865.6, ups=0.55, wpb=50932.3, bsz=2999.4, num_updates=203800, lr=0.000126087, gnorm=0.274, loss_scale=4, train_wall=180, wall=378745
2021-03-18 18:49:32 | INFO | train_inner | epoch 011:   1479 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27793.7, ups=0.55, wpb=50747.7, bsz=3014.8, num_updates=203900, lr=0.000126056, gnorm=0.276, loss_scale=4, train_wall=179, wall=378928
2021-03-18 18:52:35 | INFO | train_inner | epoch 011:   1579 / 20258 loss=3.477, nll_loss=1.785, ppl=3.45, wps=28034.5, ups=0.55, wpb=51131.5, bsz=3005, num_updates=204000, lr=0.000126025, gnorm=0.273, loss_scale=4, train_wall=179, wall=379110
2021-03-18 18:55:38 | INFO | train_inner | epoch 011:   1679 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27985.2, ups=0.55, wpb=51260.2, bsz=3059.3, num_updates=204100, lr=0.000125994, gnorm=0.278, loss_scale=4, train_wall=180, wall=379293
2021-03-18 18:58:41 | INFO | train_inner | epoch 011:   1779 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=27833.7, ups=0.55, wpb=50990.5, bsz=3023.5, num_updates=204200, lr=0.000125963, gnorm=0.281, loss_scale=8, train_wall=180, wall=379476
2021-03-18 19:01:43 | INFO | train_inner | epoch 011:   1879 / 20258 loss=3.46, nll_loss=1.766, ppl=3.4, wps=27849.9, ups=0.55, wpb=50802.4, bsz=3060.5, num_updates=204300, lr=0.000125933, gnorm=0.277, loss_scale=8, train_wall=179, wall=379659
2021-03-18 19:04:46 | INFO | train_inner | epoch 011:   1979 / 20258 loss=3.45, nll_loss=1.755, ppl=3.38, wps=27699.1, ups=0.55, wpb=50617.2, bsz=2936.6, num_updates=204400, lr=0.000125902, gnorm=0.277, loss_scale=8, train_wall=179, wall=379842
2021-03-18 19:07:48 | INFO | train_inner | epoch 011:   2079 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27815, ups=0.55, wpb=50656.7, bsz=3060.5, num_updates=204500, lr=0.000125871, gnorm=0.282, loss_scale=8, train_wall=179, wall=380024
2021-03-18 19:10:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 19:10:53 | INFO | train_inner | epoch 011:   2180 / 20258 loss=3.465, nll_loss=1.771, ppl=3.41, wps=27505.3, ups=0.54, wpb=50938.4, bsz=2877.8, num_updates=204600, lr=0.00012584, gnorm=0.276, loss_scale=4, train_wall=182, wall=380209
2021-03-18 19:13:56 | INFO | train_inner | epoch 011:   2280 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27916.4, ups=0.55, wpb=51056.9, bsz=3123, num_updates=204700, lr=0.00012581, gnorm=0.274, loss_scale=4, train_wall=180, wall=380392
2021-03-18 19:16:59 | INFO | train_inner | epoch 011:   2380 / 20258 loss=3.483, nll_loss=1.792, ppl=3.46, wps=27938.7, ups=0.55, wpb=50941.8, bsz=3039.1, num_updates=204800, lr=0.000125779, gnorm=0.283, loss_scale=4, train_wall=179, wall=380574
2021-03-18 19:20:01 | INFO | train_inner | epoch 011:   2480 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27926.7, ups=0.55, wpb=50975.3, bsz=2926.9, num_updates=204900, lr=0.000125748, gnorm=0.283, loss_scale=4, train_wall=179, wall=380757
2021-03-18 19:23:03 | INFO | train_inner | epoch 011:   2580 / 20258 loss=3.468, nll_loss=1.775, ppl=3.42, wps=27871.6, ups=0.55, wpb=50802.2, bsz=3121.4, num_updates=205000, lr=0.000125717, gnorm=0.277, loss_scale=4, train_wall=179, wall=380939
2021-03-18 19:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 19:23:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:22 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.883 | nll_loss 2.17 | ppl 4.5 | bleu 29.86 | wps 4409.8 | wpb 2432 | bsz 90.4 | num_updates 205000 | best_loss 3.883
2021-03-18 19:23:22 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 19:23:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:23:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 19:23:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 19:23:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 19:24:14 | INFO | valid1 | epoch 011 | valid on 'valid1' subset | loss 3.888 | nll_loss 2.199 | ppl 4.59 | bleu 27.69 | wps 4236.5 | wpb 2359.4 | bsz 106.4 | num_updates 205000 | best_loss 3.886
2021-03-18 19:24:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 19:24:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_11_205000.pt (epoch 11 @ 205000 updates, score 3.883) (writing took 6.557702380931005 seconds)
2021-03-18 19:27:23 | INFO | train_inner | epoch 011:   2680 / 20258 loss=3.46, nll_loss=1.766, ppl=3.4, wps=19541.2, ups=0.39, wpb=50706.7, bsz=2985, num_updates=205100, lr=0.000125687, gnorm=0.279, loss_scale=4, train_wall=179, wall=381198
2021-03-18 19:30:26 | INFO | train_inner | epoch 011:   2780 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27851.5, ups=0.54, wpb=51110.1, bsz=3119.6, num_updates=205200, lr=0.000125656, gnorm=0.278, loss_scale=4, train_wall=180, wall=381382
2021-03-18 19:33:29 | INFO | train_inner | epoch 011:   2880 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27811.6, ups=0.55, wpb=50766.8, bsz=2977.5, num_updates=205300, lr=0.000125626, gnorm=0.275, loss_scale=4, train_wall=179, wall=381564
2021-03-18 19:36:31 | INFO | train_inner | epoch 011:   2980 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27949.8, ups=0.55, wpb=50997.3, bsz=2950.8, num_updates=205400, lr=0.000125595, gnorm=0.275, loss_scale=4, train_wall=179, wall=381747
2021-03-18 19:39:35 | INFO | train_inner | epoch 011:   3080 / 20258 loss=3.464, nll_loss=1.77, ppl=3.41, wps=27884, ups=0.55, wpb=51118.4, bsz=2999.8, num_updates=205500, lr=0.000125564, gnorm=0.275, loss_scale=4, train_wall=180, wall=381930
2021-03-18 19:42:38 | INFO | train_inner | epoch 011:   3180 / 20258 loss=3.451, nll_loss=1.756, ppl=3.38, wps=27917, ups=0.55, wpb=51072.6, bsz=2925, num_updates=205600, lr=0.000125534, gnorm=0.274, loss_scale=8, train_wall=180, wall=382113
2021-03-18 19:45:40 | INFO | train_inner | epoch 011:   3280 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27862.1, ups=0.55, wpb=50879.6, bsz=3014.7, num_updates=205700, lr=0.000125503, gnorm=0.281, loss_scale=8, train_wall=179, wall=382296
2021-03-18 19:48:43 | INFO | train_inner | epoch 011:   3380 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27862.7, ups=0.55, wpb=50886.4, bsz=3067.4, num_updates=205800, lr=0.000125473, gnorm=0.276, loss_scale=8, train_wall=179, wall=382478
2021-03-18 19:51:46 | INFO | train_inner | epoch 011:   3480 / 20258 loss=3.469, nll_loss=1.776, ppl=3.42, wps=27819, ups=0.55, wpb=50881.3, bsz=3024.2, num_updates=205900, lr=0.000125442, gnorm=0.276, loss_scale=8, train_wall=179, wall=382661
2021-03-18 19:54:49 | INFO | train_inner | epoch 011:   3580 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=27681.2, ups=0.55, wpb=50677.6, bsz=3075.5, num_updates=206000, lr=0.000125412, gnorm=0.276, loss_scale=8, train_wall=180, wall=382844
2021-03-18 19:57:52 | INFO | train_inner | epoch 011:   3680 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=27931.4, ups=0.55, wpb=51018, bsz=3067.9, num_updates=206100, lr=0.000125382, gnorm=0.277, loss_scale=8, train_wall=180, wall=383027
2021-03-18 20:00:54 | INFO | train_inner | epoch 011:   3780 / 20258 loss=3.459, nll_loss=1.765, ppl=3.4, wps=27801.1, ups=0.55, wpb=50803.4, bsz=3053.7, num_updates=206200, lr=0.000125351, gnorm=0.272, loss_scale=8, train_wall=180, wall=383210
2021-03-18 20:03:56 | INFO | train_inner | epoch 011:   3880 / 20258 loss=3.499, nll_loss=1.81, ppl=3.51, wps=27937.1, ups=0.55, wpb=50694.6, bsz=2901.5, num_updates=206300, lr=0.000125321, gnorm=0.287, loss_scale=8, train_wall=178, wall=383391
2021-03-18 20:06:59 | INFO | train_inner | epoch 011:   3980 / 20258 loss=3.464, nll_loss=1.77, ppl=3.41, wps=27999.6, ups=0.55, wpb=51190.1, bsz=3019, num_updates=206400, lr=0.00012529, gnorm=0.279, loss_scale=8, train_wall=180, wall=383574
2021-03-18 20:10:01 | INFO | train_inner | epoch 011:   4080 / 20258 loss=3.481, nll_loss=1.789, ppl=3.46, wps=27981.7, ups=0.55, wpb=51006.7, bsz=2906.7, num_updates=206500, lr=0.00012526, gnorm=0.283, loss_scale=8, train_wall=179, wall=383756
2021-03-18 20:13:03 | INFO | train_inner | epoch 011:   4180 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27966.1, ups=0.55, wpb=51011.9, bsz=3020.6, num_updates=206600, lr=0.00012523, gnorm=0.282, loss_scale=8, train_wall=180, wall=383939
2021-03-18 20:14:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 20:16:08 | INFO | train_inner | epoch 011:   4281 / 20258 loss=3.458, nll_loss=1.764, ppl=3.4, wps=27456.3, ups=0.54, wpb=50639.6, bsz=2951.7, num_updates=206700, lr=0.000125199, gnorm=0.279, loss_scale=8, train_wall=181, wall=384123
2021-03-18 20:19:10 | INFO | train_inner | epoch 011:   4381 / 20258 loss=3.462, nll_loss=1.768, ppl=3.41, wps=27866.5, ups=0.55, wpb=50797.9, bsz=2998.7, num_updates=206800, lr=0.000125169, gnorm=0.276, loss_scale=8, train_wall=179, wall=384306
2021-03-18 20:22:13 | INFO | train_inner | epoch 011:   4481 / 20258 loss=3.455, nll_loss=1.76, ppl=3.39, wps=27707.5, ups=0.55, wpb=50815.7, bsz=3089.7, num_updates=206900, lr=0.000125139, gnorm=0.275, loss_scale=8, train_wall=180, wall=384489
2021-03-18 20:25:16 | INFO | train_inner | epoch 011:   4581 / 20258 loss=3.481, nll_loss=1.79, ppl=3.46, wps=27963.7, ups=0.55, wpb=51113.5, bsz=3173.4, num_updates=207000, lr=0.000125109, gnorm=0.272, loss_scale=8, train_wall=180, wall=384672
2021-03-18 20:28:19 | INFO | train_inner | epoch 011:   4681 / 20258 loss=3.471, nll_loss=1.778, ppl=3.43, wps=27936.9, ups=0.55, wpb=50977.3, bsz=2928.1, num_updates=207100, lr=0.000125078, gnorm=0.281, loss_scale=8, train_wall=179, wall=384854
2021-03-18 20:31:22 | INFO | train_inner | epoch 011:   4781 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=27886.4, ups=0.55, wpb=51090.5, bsz=3017.4, num_updates=207200, lr=0.000125048, gnorm=0.278, loss_scale=8, train_wall=180, wall=385037
2021-03-18 20:34:25 | INFO | train_inner | epoch 011:   4881 / 20258 loss=3.467, nll_loss=1.774, ppl=3.42, wps=27888.7, ups=0.55, wpb=51026.3, bsz=3078.9, num_updates=207300, lr=0.000125018, gnorm=0.279, loss_scale=8, train_wall=180, wall=385220
2021-03-18 20:37:28 | INFO | train_inner | epoch 011:   4981 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27855, ups=0.55, wpb=50932.9, bsz=3085.5, num_updates=207400, lr=0.000124988, gnorm=0.286, loss_scale=8, train_wall=179, wall=385403
2021-03-18 20:40:30 | INFO | train_inner | epoch 011:   5081 / 20258 loss=3.486, nll_loss=1.795, ppl=3.47, wps=27968.8, ups=0.55, wpb=50938.6, bsz=3014.3, num_updates=207500, lr=0.000124958, gnorm=0.275, loss_scale=8, train_wall=179, wall=385585
2021-03-18 20:43:32 | INFO | train_inner | epoch 011:   5181 / 20258 loss=3.464, nll_loss=1.77, ppl=3.41, wps=27829.2, ups=0.55, wpb=50799.3, bsz=2887.7, num_updates=207600, lr=0.000124928, gnorm=0.275, loss_scale=8, train_wall=179, wall=385768
2021-03-18 20:46:35 | INFO | train_inner | epoch 011:   5281 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=27789.3, ups=0.55, wpb=50729.5, bsz=3020.7, num_updates=207700, lr=0.000124898, gnorm=0.282, loss_scale=16, train_wall=179, wall=385950
2021-03-18 20:49:37 | INFO | train_inner | epoch 011:   5381 / 20258 loss=3.468, nll_loss=1.775, ppl=3.42, wps=27977.9, ups=0.55, wpb=50995.5, bsz=3003.5, num_updates=207800, lr=0.000124868, gnorm=0.276, loss_scale=16, train_wall=179, wall=386133
2021-03-18 20:52:40 | INFO | train_inner | epoch 011:   5481 / 20258 loss=3.445, nll_loss=1.749, ppl=3.36, wps=27882.4, ups=0.55, wpb=51006.4, bsz=2966.6, num_updates=207900, lr=0.000124838, gnorm=0.278, loss_scale=16, train_wall=180, wall=386316
2021-03-18 20:55:43 | INFO | train_inner | epoch 011:   5581 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=27845.5, ups=0.55, wpb=51039.1, bsz=2972.6, num_updates=208000, lr=0.000124808, gnorm=0.278, loss_scale=16, train_wall=180, wall=386499
2021-03-18 20:55:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 20:58:48 | INFO | train_inner | epoch 011:   5682 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27589.5, ups=0.54, wpb=50951.6, bsz=2982.8, num_updates=208100, lr=0.000124778, gnorm=0.277, loss_scale=8, train_wall=181, wall=386684
2021-03-18 21:01:50 | INFO | train_inner | epoch 011:   5782 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27881.9, ups=0.55, wpb=50806.1, bsz=3062.1, num_updates=208200, lr=0.000124748, gnorm=0.277, loss_scale=8, train_wall=179, wall=386866
2021-03-18 21:02:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 21:04:55 | INFO | train_inner | epoch 011:   5883 / 20258 loss=3.48, nll_loss=1.789, ppl=3.45, wps=27696.7, ups=0.54, wpb=51144.8, bsz=3026.5, num_updates=208300, lr=0.000124718, gnorm=0.28, loss_scale=4, train_wall=182, wall=387051
2021-03-18 21:07:58 | INFO | train_inner | epoch 011:   5983 / 20258 loss=3.479, nll_loss=1.787, ppl=3.45, wps=27859.6, ups=0.55, wpb=51087.9, bsz=3001.1, num_updates=208400, lr=0.000124688, gnorm=0.282, loss_scale=4, train_wall=180, wall=387234
2021-03-18 21:11:01 | INFO | train_inner | epoch 011:   6083 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27852.4, ups=0.55, wpb=50826.3, bsz=2936.7, num_updates=208500, lr=0.000124658, gnorm=0.28, loss_scale=4, train_wall=179, wall=387416
2021-03-18 21:14:03 | INFO | train_inner | epoch 011:   6183 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=27864.7, ups=0.55, wpb=50682.5, bsz=3011, num_updates=208600, lr=0.000124628, gnorm=0.279, loss_scale=4, train_wall=179, wall=387598
2021-03-18 21:17:05 | INFO | train_inner | epoch 011:   6283 / 20258 loss=3.467, nll_loss=1.774, ppl=3.42, wps=27986.6, ups=0.55, wpb=51006.8, bsz=2964.9, num_updates=208700, lr=0.000124598, gnorm=0.279, loss_scale=4, train_wall=179, wall=387781
2021-03-18 21:20:08 | INFO | train_inner | epoch 011:   6383 / 20258 loss=3.481, nll_loss=1.79, ppl=3.46, wps=27817.9, ups=0.55, wpb=50848.8, bsz=3061.4, num_updates=208800, lr=0.000124568, gnorm=0.28, loss_scale=4, train_wall=179, wall=387963
2021-03-18 21:23:12 | INFO | train_inner | epoch 011:   6483 / 20258 loss=3.463, nll_loss=1.769, ppl=3.41, wps=27669.9, ups=0.54, wpb=50891.8, bsz=3022.7, num_updates=208900, lr=0.000124538, gnorm=0.281, loss_scale=4, train_wall=180, wall=388147
2021-03-18 21:26:17 | INFO | train_inner | epoch 011:   6583 / 20258 loss=3.475, nll_loss=1.782, ppl=3.44, wps=27454.9, ups=0.54, wpb=50830.2, bsz=2923.7, num_updates=209000, lr=0.000124509, gnorm=0.28, loss_scale=4, train_wall=181, wall=388332
2021-03-18 21:29:22 | INFO | train_inner | epoch 011:   6683 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27455.4, ups=0.54, wpb=50920.7, bsz=3153.3, num_updates=209100, lr=0.000124479, gnorm=0.276, loss_scale=4, train_wall=181, wall=388518
2021-03-18 21:32:27 | INFO | train_inner | epoch 011:   6783 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27369.1, ups=0.54, wpb=50628.4, bsz=2991.8, num_updates=209200, lr=0.000124449, gnorm=0.283, loss_scale=4, train_wall=181, wall=388703
2021-03-18 21:35:33 | INFO | train_inner | epoch 011:   6883 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27442.1, ups=0.54, wpb=51027, bsz=3010.8, num_updates=209300, lr=0.000124419, gnorm=0.278, loss_scale=8, train_wall=181, wall=388889
2021-03-18 21:38:38 | INFO | train_inner | epoch 011:   6983 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27634.5, ups=0.54, wpb=50933.8, bsz=3049.6, num_updates=209400, lr=0.00012439, gnorm=0.287, loss_scale=8, train_wall=181, wall=389073
2021-03-18 21:41:40 | INFO | train_inner | epoch 011:   7083 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27942.8, ups=0.55, wpb=51009.8, bsz=2939.6, num_updates=209500, lr=0.00012436, gnorm=0.277, loss_scale=8, train_wall=179, wall=389256
2021-03-18 21:44:42 | INFO | train_inner | epoch 011:   7183 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27994.3, ups=0.55, wpb=50999.3, bsz=2916.6, num_updates=209600, lr=0.00012433, gnorm=0.281, loss_scale=8, train_wall=179, wall=389438
2021-03-18 21:47:46 | INFO | train_inner | epoch 011:   7283 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27901.2, ups=0.55, wpb=51122.3, bsz=3080.9, num_updates=209700, lr=0.000124301, gnorm=0.278, loss_scale=8, train_wall=180, wall=389621
2021-03-18 21:50:48 | INFO | train_inner | epoch 011:   7383 / 20258 loss=3.465, nll_loss=1.771, ppl=3.41, wps=27834.5, ups=0.55, wpb=50866.5, bsz=2886, num_updates=209800, lr=0.000124271, gnorm=0.277, loss_scale=8, train_wall=179, wall=389804
2021-03-18 21:53:51 | INFO | train_inner | epoch 011:   7483 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27787, ups=0.55, wpb=50910.4, bsz=3139.2, num_updates=209900, lr=0.000124241, gnorm=0.283, loss_scale=8, train_wall=180, wall=389987
2021-03-18 21:56:54 | INFO | train_inner | epoch 011:   7583 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27939.7, ups=0.55, wpb=51093.7, bsz=2958.3, num_updates=210000, lr=0.000124212, gnorm=0.275, loss_scale=8, train_wall=180, wall=390170
2021-03-18 21:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-18 21:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:56:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:56:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:56:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:56:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:56:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:56:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:56:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:56:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:56:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:56:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:56:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:56:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:56:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:56:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:56:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:13 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.883 | nll_loss 2.171 | ppl 4.5 | bleu 30 | wps 4239 | wpb 2432 | bsz 90.4 | num_updates 210000 | best_loss 3.883
2021-03-18 21:57:13 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-18 21:57:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:57:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-18 21:57:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-18 21:57:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-18 21:58:06 | INFO | valid1 | epoch 011 | valid on 'valid1' subset | loss 3.887 | nll_loss 2.197 | ppl 4.58 | bleu 27.62 | wps 4220 | wpb 2359.4 | bsz 106.4 | num_updates 210000 | best_loss 3.883
2021-03-18 21:58:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-18 21:58:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_11_210000.pt (epoch 11 @ 210000 updates, score 3.883) (writing took 7.912483363877982 seconds)
2021-03-18 22:01:18 | INFO | train_inner | epoch 011:   7683 / 20258 loss=3.462, nll_loss=1.768, ppl=3.41, wps=19358, ups=0.38, wpb=50943.7, bsz=3011.4, num_updates=210100, lr=0.000124182, gnorm=0.282, loss_scale=8, train_wall=180, wall=390433
2021-03-18 22:04:20 | INFO | train_inner | epoch 011:   7783 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27686, ups=0.55, wpb=50447.4, bsz=3076.1, num_updates=210200, lr=0.000124153, gnorm=0.283, loss_scale=8, train_wall=179, wall=390615
2021-03-18 22:07:22 | INFO | train_inner | epoch 011:   7883 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27863.3, ups=0.55, wpb=50752, bsz=2941, num_updates=210300, lr=0.000124123, gnorm=0.28, loss_scale=16, train_wall=179, wall=390797
2021-03-18 22:10:25 | INFO | train_inner | epoch 011:   7983 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27743.7, ups=0.55, wpb=50769.2, bsz=3161.9, num_updates=210400, lr=0.000124094, gnorm=0.278, loss_scale=16, train_wall=180, wall=390980
2021-03-18 22:10:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 22:13:29 | INFO | train_inner | epoch 011:   8084 / 20258 loss=3.488, nll_loss=1.798, ppl=3.48, wps=27635.5, ups=0.54, wpb=50832.8, bsz=2964.2, num_updates=210500, lr=0.000124064, gnorm=0.284, loss_scale=8, train_wall=181, wall=391164
2021-03-18 22:16:31 | INFO | train_inner | epoch 011:   8184 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=27875.1, ups=0.55, wpb=50916.5, bsz=2995.3, num_updates=210600, lr=0.000124035, gnorm=0.28, loss_scale=8, train_wall=180, wall=391347
2021-03-18 22:19:34 | INFO | train_inner | epoch 011:   8284 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27860.9, ups=0.55, wpb=50770.6, bsz=2934.8, num_updates=210700, lr=0.000124005, gnorm=0.273, loss_scale=8, train_wall=179, wall=391529
2021-03-18 22:22:36 | INFO | train_inner | epoch 011:   8384 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27900.3, ups=0.55, wpb=50923.3, bsz=3084.5, num_updates=210800, lr=0.000123976, gnorm=0.273, loss_scale=8, train_wall=180, wall=391712
2021-03-18 22:25:39 | INFO | train_inner | epoch 011:   8484 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27842, ups=0.55, wpb=50953.8, bsz=2997.3, num_updates=210900, lr=0.000123946, gnorm=0.28, loss_scale=8, train_wall=180, wall=391895
2021-03-18 22:28:41 | INFO | train_inner | epoch 011:   8584 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27915.1, ups=0.55, wpb=50824.5, bsz=2936.1, num_updates=211000, lr=0.000123917, gnorm=0.285, loss_scale=8, train_wall=179, wall=392077
2021-03-18 22:31:44 | INFO | train_inner | epoch 011:   8684 / 20258 loss=3.471, nll_loss=1.778, ppl=3.43, wps=27869.9, ups=0.55, wpb=50862, bsz=2982.6, num_updates=211100, lr=0.000123888, gnorm=0.277, loss_scale=8, train_wall=179, wall=392259
2021-03-18 22:34:47 | INFO | train_inner | epoch 011:   8784 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27736.6, ups=0.55, wpb=50887.3, bsz=3049.4, num_updates=211200, lr=0.000123858, gnorm=0.276, loss_scale=8, train_wall=180, wall=392443
2021-03-18 22:37:50 | INFO | train_inner | epoch 011:   8884 / 20258 loss=3.474, nll_loss=1.782, ppl=3.44, wps=27822.1, ups=0.55, wpb=50744.3, bsz=3130.4, num_updates=211300, lr=0.000123829, gnorm=0.281, loss_scale=8, train_wall=179, wall=392625
2021-03-18 22:40:53 | INFO | train_inner | epoch 011:   8984 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27901.5, ups=0.55, wpb=51023.1, bsz=3036, num_updates=211400, lr=0.0001238, gnorm=0.274, loss_scale=8, train_wall=180, wall=392808
2021-03-18 22:43:55 | INFO | train_inner | epoch 011:   9084 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27866.6, ups=0.55, wpb=50812.2, bsz=3019.9, num_updates=211500, lr=0.000123771, gnorm=0.28, loss_scale=16, train_wall=179, wall=392990
2021-03-18 22:44:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 22:47:00 | INFO | train_inner | epoch 011:   9185 / 20258 loss=3.476, nll_loss=1.784, ppl=3.44, wps=27549.9, ups=0.54, wpb=50897.4, bsz=2983.2, num_updates=211600, lr=0.000123741, gnorm=0.28, loss_scale=8, train_wall=181, wall=393175
2021-03-18 22:50:01 | INFO | train_inner | epoch 011:   9285 / 20258 loss=3.465, nll_loss=1.772, ppl=3.41, wps=27745.6, ups=0.55, wpb=50397.2, bsz=2873.6, num_updates=211700, lr=0.000123712, gnorm=0.281, loss_scale=8, train_wall=178, wall=393357
2021-03-18 22:53:04 | INFO | train_inner | epoch 011:   9385 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27982, ups=0.55, wpb=51225.4, bsz=3056.8, num_updates=211800, lr=0.000123683, gnorm=0.276, loss_scale=8, train_wall=180, wall=393540
2021-03-18 22:56:07 | INFO | train_inner | epoch 011:   9485 / 20258 loss=3.468, nll_loss=1.775, ppl=3.42, wps=27884.3, ups=0.55, wpb=50906.8, bsz=2905, num_updates=211900, lr=0.000123654, gnorm=0.284, loss_scale=8, train_wall=179, wall=393722
2021-03-18 22:59:09 | INFO | train_inner | epoch 011:   9585 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27783.9, ups=0.55, wpb=50698.2, bsz=2908, num_updates=212000, lr=0.000123625, gnorm=0.28, loss_scale=8, train_wall=179, wall=393905
2021-03-18 23:02:12 | INFO | train_inner | epoch 011:   9685 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27931.6, ups=0.55, wpb=50868.6, bsz=3011, num_updates=212100, lr=0.000123595, gnorm=0.28, loss_scale=8, train_wall=179, wall=394087
2021-03-18 23:05:14 | INFO | train_inner | epoch 011:   9785 / 20258 loss=3.483, nll_loss=1.793, ppl=3.46, wps=27883.5, ups=0.55, wpb=50925.9, bsz=2915, num_updates=212200, lr=0.000123566, gnorm=0.277, loss_scale=8, train_wall=179, wall=394270
2021-03-18 23:08:17 | INFO | train_inner | epoch 011:   9885 / 20258 loss=3.458, nll_loss=1.764, ppl=3.4, wps=27872.6, ups=0.55, wpb=50952.8, bsz=3046.3, num_updates=212300, lr=0.000123537, gnorm=0.274, loss_scale=8, train_wall=179, wall=394452
2021-03-18 23:11:19 | INFO | train_inner | epoch 011:   9985 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27908, ups=0.55, wpb=50933.5, bsz=3079, num_updates=212400, lr=0.000123508, gnorm=0.275, loss_scale=8, train_wall=179, wall=394635
2021-03-18 23:14:21 | INFO | train_inner | epoch 011:  10085 / 20258 loss=3.496, nll_loss=1.807, ppl=3.5, wps=27946.6, ups=0.55, wpb=50788.2, bsz=2965.7, num_updates=212500, lr=0.000123479, gnorm=0.281, loss_scale=8, train_wall=178, wall=394817
2021-03-18 23:17:23 | INFO | train_inner | epoch 011:  10185 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27906.6, ups=0.55, wpb=50845.4, bsz=2977.2, num_updates=212600, lr=0.00012345, gnorm=0.278, loss_scale=16, train_wall=179, wall=394999
2021-03-18 23:18:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-18 23:20:27 | INFO | train_inner | epoch 011:  10286 / 20258 loss=3.463, nll_loss=1.769, ppl=3.41, wps=27598.2, ups=0.54, wpb=50751, bsz=2796.6, num_updates=212700, lr=0.000123421, gnorm=0.276, loss_scale=8, train_wall=181, wall=395183
2021-03-18 23:23:30 | INFO | train_inner | epoch 011:  10386 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27813.2, ups=0.55, wpb=50858.7, bsz=3012.6, num_updates=212800, lr=0.000123392, gnorm=0.283, loss_scale=8, train_wall=180, wall=395366
2021-03-18 23:26:33 | INFO | train_inner | epoch 011:  10486 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=27804, ups=0.55, wpb=50819.2, bsz=3060.5, num_updates=212900, lr=0.000123363, gnorm=0.284, loss_scale=8, train_wall=179, wall=395548
2021-03-18 23:27:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-18 23:29:37 | INFO | train_inner | epoch 011:  10587 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27528.7, ups=0.54, wpb=50775.6, bsz=2983.7, num_updates=213000, lr=0.000123334, gnorm=0.276, loss_scale=4, train_wall=181, wall=395733
2021-03-18 23:32:40 | INFO | train_inner | epoch 011:  10687 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=27919.8, ups=0.55, wpb=50884.4, bsz=2987.6, num_updates=213100, lr=0.000123305, gnorm=0.279, loss_scale=4, train_wall=179, wall=395915
2021-03-18 23:35:43 | INFO | train_inner | epoch 011:  10787 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27873.6, ups=0.55, wpb=51053.7, bsz=3160.4, num_updates=213200, lr=0.000123276, gnorm=0.278, loss_scale=4, train_wall=180, wall=396098
2021-03-18 23:38:46 | INFO | train_inner | epoch 011:  10887 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27846.5, ups=0.55, wpb=50987.7, bsz=3064.4, num_updates=213300, lr=0.000123247, gnorm=0.283, loss_scale=4, train_wall=180, wall=396281
2021-03-18 23:41:49 | INFO | train_inner | epoch 011:  10987 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27779.6, ups=0.55, wpb=50768.7, bsz=3067.5, num_updates=213400, lr=0.000123218, gnorm=0.276, loss_scale=4, train_wall=179, wall=396464
2021-03-18 23:44:51 | INFO | train_inner | epoch 011:  11087 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27971, ups=0.55, wpb=51061.1, bsz=2969.4, num_updates=213500, lr=0.000123189, gnorm=0.282, loss_scale=4, train_wall=179, wall=396647
2021-03-18 23:47:54 | INFO | train_inner | epoch 011:  11187 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27913.4, ups=0.55, wpb=51000.7, bsz=3081.4, num_updates=213600, lr=0.000123161, gnorm=0.28, loss_scale=4, train_wall=180, wall=396829
2021-03-18 23:50:57 | INFO | train_inner | epoch 011:  11287 / 20258 loss=3.465, nll_loss=1.772, ppl=3.41, wps=27988.2, ups=0.55, wpb=51187.7, bsz=2980.2, num_updates=213700, lr=0.000123132, gnorm=0.272, loss_scale=4, train_wall=180, wall=397012
2021-03-18 23:53:59 | INFO | train_inner | epoch 011:  11387 / 20258 loss=3.452, nll_loss=1.757, ppl=3.38, wps=27837.7, ups=0.55, wpb=50830.7, bsz=3019.2, num_updates=213800, lr=0.000123103, gnorm=0.278, loss_scale=4, train_wall=179, wall=397195
2021-03-18 23:57:02 | INFO | train_inner | epoch 011:  11487 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27876.3, ups=0.55, wpb=50895.8, bsz=3001.6, num_updates=213900, lr=0.000123074, gnorm=0.285, loss_scale=4, train_wall=179, wall=397378
2021-03-19 00:00:05 | INFO | train_inner | epoch 011:  11587 / 20258 loss=3.469, nll_loss=1.776, ppl=3.43, wps=27787.9, ups=0.55, wpb=50723.5, bsz=2948.9, num_updates=214000, lr=0.000123045, gnorm=0.274, loss_scale=8, train_wall=179, wall=397560
2021-03-19 00:03:07 | INFO | train_inner | epoch 011:  11687 / 20258 loss=3.472, nll_loss=1.78, ppl=3.44, wps=27978.6, ups=0.55, wpb=51191.8, bsz=3109, num_updates=214100, lr=0.000123017, gnorm=0.274, loss_scale=8, train_wall=180, wall=397743
2021-03-19 00:06:10 | INFO | train_inner | epoch 011:  11787 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=28004.2, ups=0.55, wpb=51105.8, bsz=2958.6, num_updates=214200, lr=0.000122988, gnorm=0.276, loss_scale=8, train_wall=180, wall=397926
2021-03-19 00:09:12 | INFO | train_inner | epoch 011:  11887 / 20258 loss=3.467, nll_loss=1.774, ppl=3.42, wps=27987.8, ups=0.55, wpb=50992.6, bsz=2934.5, num_updates=214300, lr=0.000122959, gnorm=0.278, loss_scale=8, train_wall=179, wall=398108
2021-03-19 00:10:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 00:12:17 | INFO | train_inner | epoch 011:  11988 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27698.2, ups=0.54, wpb=51057.5, bsz=3043.7, num_updates=214400, lr=0.000122931, gnorm=0.277, loss_scale=4, train_wall=181, wall=398292
2021-03-19 00:15:19 | INFO | train_inner | epoch 011:  12088 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27879.8, ups=0.55, wpb=50776.3, bsz=2981.2, num_updates=214500, lr=0.000122902, gnorm=0.281, loss_scale=4, train_wall=179, wall=398474
2021-03-19 00:18:21 | INFO | train_inner | epoch 011:  12188 / 20258 loss=3.479, nll_loss=1.788, ppl=3.45, wps=27884.8, ups=0.55, wpb=50987.8, bsz=3109.9, num_updates=214600, lr=0.000122873, gnorm=0.285, loss_scale=4, train_wall=179, wall=398657
2021-03-19 00:20:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-19 00:21:26 | INFO | train_inner | epoch 011:  12289 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27575.8, ups=0.54, wpb=50883.6, bsz=3029.1, num_updates=214700, lr=0.000122845, gnorm=0.285, loss_scale=2, train_wall=181, wall=398842
2021-03-19 00:24:28 | INFO | train_inner | epoch 011:  12389 / 20258 loss=3.458, nll_loss=1.764, ppl=3.4, wps=27887.1, ups=0.55, wpb=50834.3, bsz=2980.2, num_updates=214800, lr=0.000122816, gnorm=0.282, loss_scale=2, train_wall=179, wall=399024
2021-03-19 00:27:30 | INFO | train_inner | epoch 011:  12489 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27842.7, ups=0.55, wpb=50693.6, bsz=2913.1, num_updates=214900, lr=0.000122788, gnorm=0.28, loss_scale=2, train_wall=179, wall=399206
2021-03-19 00:30:33 | INFO | train_inner | epoch 011:  12589 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27847.6, ups=0.55, wpb=50809.2, bsz=3096.9, num_updates=215000, lr=0.000122759, gnorm=0.276, loss_scale=2, train_wall=179, wall=399388
2021-03-19 00:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 00:30:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:52 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.885 | nll_loss 2.172 | ppl 4.51 | bleu 29.96 | wps 4300.5 | wpb 2432 | bsz 90.4 | num_updates 215000 | best_loss 3.883
2021-03-19 00:30:52 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 00:30:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:30:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:30:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:30:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 00:31:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 00:31:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 00:31:44 | INFO | valid1 | epoch 011 | valid on 'valid1' subset | loss 3.887 | nll_loss 2.198 | ppl 4.59 | bleu 27.71 | wps 4242.3 | wpb 2359.4 | bsz 106.4 | num_updates 215000 | best_loss 3.883
2021-03-19 00:31:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 00:31:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_11_215000.pt (epoch 11 @ 215000 updates, score 3.885) (writing took 4.559209110680968 seconds)
2021-03-19 00:34:50 | INFO | train_inner | epoch 011:  12689 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=19686.1, ups=0.39, wpb=50694.5, bsz=2954.2, num_updates=215100, lr=0.00012273, gnorm=0.276, loss_scale=2, train_wall=179, wall=399646
2021-03-19 00:37:53 | INFO | train_inner | epoch 011:  12789 / 20258 loss=3.48, nll_loss=1.789, ppl=3.45, wps=27846.6, ups=0.55, wpb=50895.3, bsz=2989.1, num_updates=215200, lr=0.000122702, gnorm=0.283, loss_scale=2, train_wall=179, wall=399829
2021-03-19 00:40:56 | INFO | train_inner | epoch 011:  12889 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27968.5, ups=0.55, wpb=51058.2, bsz=3050.2, num_updates=215300, lr=0.000122673, gnorm=0.283, loss_scale=2, train_wall=179, wall=400011
2021-03-19 00:43:58 | INFO | train_inner | epoch 011:  12989 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27879.8, ups=0.55, wpb=50897.9, bsz=3087.8, num_updates=215400, lr=0.000122645, gnorm=0.279, loss_scale=2, train_wall=179, wall=400194
2021-03-19 00:47:01 | INFO | train_inner | epoch 011:  13089 / 20258 loss=3.472, nll_loss=1.779, ppl=3.43, wps=27891.9, ups=0.55, wpb=50850.7, bsz=2848.9, num_updates=215500, lr=0.000122616, gnorm=0.278, loss_scale=2, train_wall=179, wall=400376
2021-03-19 00:50:03 | INFO | train_inner | epoch 011:  13189 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27828.8, ups=0.55, wpb=50899.5, bsz=3086.3, num_updates=215600, lr=0.000122588, gnorm=0.282, loss_scale=2, train_wall=180, wall=400559
2021-03-19 00:53:06 | INFO | train_inner | epoch 011:  13289 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27915.2, ups=0.55, wpb=51057.6, bsz=3086.6, num_updates=215700, lr=0.00012256, gnorm=0.271, loss_scale=2, train_wall=180, wall=400742
2021-03-19 00:56:09 | INFO | train_inner | epoch 011:  13389 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27848.6, ups=0.55, wpb=50759.5, bsz=2903.7, num_updates=215800, lr=0.000122531, gnorm=0.278, loss_scale=4, train_wall=179, wall=400924
2021-03-19 00:59:11 | INFO | train_inner | epoch 011:  13489 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27925.5, ups=0.55, wpb=50953.2, bsz=2938.8, num_updates=215900, lr=0.000122503, gnorm=0.282, loss_scale=4, train_wall=179, wall=401107
2021-03-19 01:02:14 | INFO | train_inner | epoch 011:  13589 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27853.8, ups=0.55, wpb=50925.6, bsz=3038.2, num_updates=216000, lr=0.000122474, gnorm=0.274, loss_scale=4, train_wall=179, wall=401289
2021-03-19 01:05:16 | INFO | train_inner | epoch 011:  13689 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27952.1, ups=0.55, wpb=50892.5, bsz=2990.4, num_updates=216100, lr=0.000122446, gnorm=0.279, loss_scale=4, train_wall=179, wall=401472
2021-03-19 01:08:19 | INFO | train_inner | epoch 011:  13789 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27809.7, ups=0.55, wpb=50790.8, bsz=3091.7, num_updates=216200, lr=0.000122418, gnorm=0.276, loss_scale=4, train_wall=180, wall=401654
2021-03-19 01:11:21 | INFO | train_inner | epoch 011:  13889 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27880.5, ups=0.55, wpb=50725.7, bsz=3037.4, num_updates=216300, lr=0.00012239, gnorm=0.275, loss_scale=4, train_wall=179, wall=401836
2021-03-19 01:14:23 | INFO | train_inner | epoch 011:  13989 / 20258 loss=3.468, nll_loss=1.776, ppl=3.43, wps=27967.1, ups=0.55, wpb=51010.8, bsz=3127.2, num_updates=216400, lr=0.000122361, gnorm=0.279, loss_scale=4, train_wall=179, wall=402019
2021-03-19 01:17:25 | INFO | train_inner | epoch 011:  14089 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27895.8, ups=0.55, wpb=50861.8, bsz=2920.6, num_updates=216500, lr=0.000122333, gnorm=0.276, loss_scale=4, train_wall=179, wall=402201
2021-03-19 01:20:28 | INFO | train_inner | epoch 011:  14189 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27870.2, ups=0.55, wpb=50875, bsz=3045.5, num_updates=216600, lr=0.000122305, gnorm=0.275, loss_scale=4, train_wall=179, wall=402383
2021-03-19 01:23:31 | INFO | train_inner | epoch 011:  14289 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27890, ups=0.55, wpb=50975.8, bsz=2970.8, num_updates=216700, lr=0.000122277, gnorm=0.276, loss_scale=4, train_wall=180, wall=402566
2021-03-19 01:26:33 | INFO | train_inner | epoch 011:  14389 / 20258 loss=3.472, nll_loss=1.781, ppl=3.44, wps=27848.3, ups=0.55, wpb=50868.1, bsz=3025.9, num_updates=216800, lr=0.000122248, gnorm=0.281, loss_scale=8, train_wall=179, wall=402749
2021-03-19 01:29:36 | INFO | train_inner | epoch 011:  14489 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27861.6, ups=0.55, wpb=50777.3, bsz=2997.8, num_updates=216900, lr=0.00012222, gnorm=0.285, loss_scale=8, train_wall=179, wall=402931
2021-03-19 01:32:38 | INFO | train_inner | epoch 011:  14589 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=28023, ups=0.55, wpb=51174.3, bsz=3012.3, num_updates=217000, lr=0.000122192, gnorm=0.282, loss_scale=8, train_wall=180, wall=403114
2021-03-19 01:35:40 | INFO | train_inner | epoch 011:  14689 / 20258 loss=3.488, nll_loss=1.798, ppl=3.48, wps=27843.6, ups=0.55, wpb=50610.9, bsz=3017.1, num_updates=217100, lr=0.000122164, gnorm=0.285, loss_scale=8, train_wall=179, wall=403295
2021-03-19 01:38:43 | INFO | train_inner | epoch 011:  14789 / 20258 loss=3.485, nll_loss=1.795, ppl=3.47, wps=27889.1, ups=0.55, wpb=51125.9, bsz=3089.9, num_updates=217200, lr=0.000122136, gnorm=0.278, loss_scale=8, train_wall=180, wall=403479
2021-03-19 01:41:47 | INFO | train_inner | epoch 011:  14889 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27907, ups=0.55, wpb=51201.1, bsz=3152.2, num_updates=217300, lr=0.000122108, gnorm=0.278, loss_scale=8, train_wall=180, wall=403662
2021-03-19 01:44:49 | INFO | train_inner | epoch 011:  14989 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27988.8, ups=0.55, wpb=51000.8, bsz=3021.6, num_updates=217400, lr=0.000122079, gnorm=0.281, loss_scale=8, train_wall=179, wall=403844
2021-03-19 01:47:52 | INFO | train_inner | epoch 011:  15089 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27804.7, ups=0.55, wpb=50764.1, bsz=3057, num_updates=217500, lr=0.000122051, gnorm=0.281, loss_scale=8, train_wall=179, wall=404027
2021-03-19 01:50:54 | INFO | train_inner | epoch 011:  15189 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27768.5, ups=0.55, wpb=50697.9, bsz=2997, num_updates=217600, lr=0.000122023, gnorm=0.279, loss_scale=8, train_wall=179, wall=404210
2021-03-19 01:53:57 | INFO | train_inner | epoch 011:  15289 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27784.6, ups=0.55, wpb=50812.5, bsz=2973.9, num_updates=217700, lr=0.000121995, gnorm=0.275, loss_scale=8, train_wall=180, wall=404392
2021-03-19 01:56:59 | INFO | train_inner | epoch 011:  15389 / 20258 loss=3.478, nll_loss=1.786, ppl=3.45, wps=27981.3, ups=0.55, wpb=50921.1, bsz=2926.2, num_updates=217800, lr=0.000121967, gnorm=0.28, loss_scale=16, train_wall=179, wall=404574
2021-03-19 01:59:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 02:00:03 | INFO | train_inner | epoch 011:  15490 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27598.3, ups=0.54, wpb=50717.8, bsz=2980.2, num_updates=217900, lr=0.000121939, gnorm=0.279, loss_scale=8, train_wall=181, wall=404758
2021-03-19 02:03:06 | INFO | train_inner | epoch 011:  15590 / 20258 loss=3.457, nll_loss=1.763, ppl=3.4, wps=27859, ups=0.55, wpb=51046.7, bsz=2965, num_updates=218000, lr=0.000121911, gnorm=0.276, loss_scale=8, train_wall=180, wall=404941
2021-03-19 02:06:09 | INFO | train_inner | epoch 011:  15690 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27949, ups=0.55, wpb=51059.6, bsz=3167.3, num_updates=218100, lr=0.000121883, gnorm=0.278, loss_scale=8, train_wall=180, wall=405124
2021-03-19 02:09:12 | INFO | train_inner | epoch 011:  15790 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27886.5, ups=0.55, wpb=50993.8, bsz=2961.4, num_updates=218200, lr=0.000121855, gnorm=0.275, loss_scale=8, train_wall=180, wall=405307
2021-03-19 02:12:15 | INFO | train_inner | epoch 011:  15890 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27924.9, ups=0.55, wpb=51102.8, bsz=2997.8, num_updates=218300, lr=0.000121828, gnorm=0.281, loss_scale=8, train_wall=180, wall=405490
2021-03-19 02:15:17 | INFO | train_inner | epoch 011:  15990 / 20258 loss=3.466, nll_loss=1.773, ppl=3.42, wps=27897.4, ups=0.55, wpb=50968.3, bsz=2999.7, num_updates=218400, lr=0.0001218, gnorm=0.278, loss_scale=8, train_wall=180, wall=405673
2021-03-19 02:18:20 | INFO | train_inner | epoch 011:  16090 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27773.5, ups=0.55, wpb=50800.7, bsz=3123.2, num_updates=218500, lr=0.000121772, gnorm=0.277, loss_scale=8, train_wall=180, wall=405856
2021-03-19 02:21:23 | INFO | train_inner | epoch 011:  16190 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27862.6, ups=0.55, wpb=50839.1, bsz=3022.9, num_updates=218600, lr=0.000121744, gnorm=0.276, loss_scale=8, train_wall=179, wall=406038
2021-03-19 02:24:25 | INFO | train_inner | epoch 011:  16290 / 20258 loss=3.462, nll_loss=1.77, ppl=3.41, wps=27980.1, ups=0.55, wpb=51139.4, bsz=3048.5, num_updates=218700, lr=0.000121716, gnorm=0.275, loss_scale=8, train_wall=180, wall=406221
2021-03-19 02:27:28 | INFO | train_inner | epoch 011:  16390 / 20258 loss=3.45, nll_loss=1.755, ppl=3.38, wps=27863.5, ups=0.55, wpb=51008.1, bsz=2829.9, num_updates=218800, lr=0.000121688, gnorm=0.28, loss_scale=8, train_wall=180, wall=406404
2021-03-19 02:30:31 | INFO | train_inner | epoch 011:  16490 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27889.9, ups=0.55, wpb=50913.3, bsz=3047, num_updates=218900, lr=0.000121661, gnorm=0.279, loss_scale=8, train_wall=180, wall=406587
2021-03-19 02:33:34 | INFO | train_inner | epoch 011:  16590 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27889, ups=0.55, wpb=51120.7, bsz=3129.6, num_updates=219000, lr=0.000121633, gnorm=0.281, loss_scale=16, train_wall=180, wall=406770
2021-03-19 02:34:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 02:36:38 | INFO | train_inner | epoch 011:  16691 / 20258 loss=3.451, nll_loss=1.756, ppl=3.38, wps=27499.9, ups=0.54, wpb=50619.6, bsz=2936.5, num_updates=219100, lr=0.000121605, gnorm=0.281, loss_scale=8, train_wall=181, wall=406954
2021-03-19 02:39:41 | INFO | train_inner | epoch 011:  16791 / 20258 loss=3.479, nll_loss=1.789, ppl=3.46, wps=27953.3, ups=0.55, wpb=50987.8, bsz=3164.3, num_updates=219200, lr=0.000121577, gnorm=0.278, loss_scale=8, train_wall=179, wall=407136
2021-03-19 02:42:43 | INFO | train_inner | epoch 011:  16891 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=27911.3, ups=0.55, wpb=50911.7, bsz=2938.6, num_updates=219300, lr=0.00012155, gnorm=0.278, loss_scale=8, train_wall=179, wall=407319
2021-03-19 02:45:46 | INFO | train_inner | epoch 011:  16991 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=27759.4, ups=0.55, wpb=50697.3, bsz=3020.5, num_updates=219400, lr=0.000121522, gnorm=0.278, loss_scale=8, train_wall=179, wall=407501
2021-03-19 02:48:49 | INFO | train_inner | epoch 011:  17091 / 20258 loss=3.469, nll_loss=1.778, ppl=3.43, wps=27746.5, ups=0.55, wpb=50715.3, bsz=3081.6, num_updates=219500, lr=0.000121494, gnorm=0.29, loss_scale=8, train_wall=179, wall=407684
2021-03-19 02:51:51 | INFO | train_inner | epoch 011:  17191 / 20258 loss=3.486, nll_loss=1.797, ppl=3.47, wps=27843.5, ups=0.55, wpb=50762.9, bsz=3119.7, num_updates=219600, lr=0.000121466, gnorm=0.279, loss_scale=8, train_wall=179, wall=407866
2021-03-19 02:54:52 | INFO | train_inner | epoch 011:  17291 / 20258 loss=3.492, nll_loss=1.802, ppl=3.49, wps=27863.9, ups=0.55, wpb=50520.3, bsz=2821.4, num_updates=219700, lr=0.000121439, gnorm=0.282, loss_scale=8, train_wall=178, wall=408048
2021-03-19 02:57:55 | INFO | train_inner | epoch 011:  17391 / 20258 loss=3.478, nll_loss=1.787, ppl=3.45, wps=27934.2, ups=0.55, wpb=51032.4, bsz=3041.3, num_updates=219800, lr=0.000121411, gnorm=0.277, loss_scale=8, train_wall=180, wall=408230
2021-03-19 03:00:57 | INFO | train_inner | epoch 011:  17491 / 20258 loss=3.487, nll_loss=1.797, ppl=3.48, wps=27871.8, ups=0.55, wpb=50794.2, bsz=3039.6, num_updates=219900, lr=0.000121384, gnorm=0.28, loss_scale=8, train_wall=179, wall=408413
2021-03-19 03:04:00 | INFO | train_inner | epoch 011:  17591 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27903.5, ups=0.55, wpb=51036.8, bsz=3102.8, num_updates=220000, lr=0.000121356, gnorm=0.273, loss_scale=8, train_wall=180, wall=408596
2021-03-19 03:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 03:04:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:19 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.885 | nll_loss 2.172 | ppl 4.51 | bleu 29.82 | wps 4265.5 | wpb 2432 | bsz 90.4 | num_updates 220000 | best_loss 3.883
2021-03-19 03:04:19 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 03:04:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:04:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 03:04:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 03:04:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 03:05:11 | INFO | valid1 | epoch 011 | valid on 'valid1' subset | loss 3.885 | nll_loss 2.194 | ppl 4.58 | bleu 27.67 | wps 4256.2 | wpb 2359.4 | bsz 106.4 | num_updates 220000 | best_loss 3.883
2021-03-19 03:05:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 03:05:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_11_220000.pt (epoch 11 @ 220000 updates, score 3.885) (writing took 4.549083013087511 seconds)
2021-03-19 03:08:18 | INFO | train_inner | epoch 011:  17691 / 20258 loss=3.474, nll_loss=1.783, ppl=3.44, wps=19675.7, ups=0.39, wpb=50806.4, bsz=3046.1, num_updates=220100, lr=0.000121328, gnorm=0.279, loss_scale=16, train_wall=179, wall=408854
2021-03-19 03:11:21 | INFO | train_inner | epoch 011:  17791 / 20258 loss=3.475, nll_loss=1.783, ppl=3.44, wps=27827.5, ups=0.55, wpb=50834.8, bsz=2835.4, num_updates=220200, lr=0.000121301, gnorm=0.277, loss_scale=16, train_wall=180, wall=409036
2021-03-19 03:14:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 03:14:25 | INFO | train_inner | epoch 011:  17892 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27585.8, ups=0.54, wpb=50787.4, bsz=2907.9, num_updates=220300, lr=0.000121273, gnorm=0.284, loss_scale=8, train_wall=180, wall=409221
2021-03-19 03:17:27 | INFO | train_inner | epoch 011:  17992 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27846.9, ups=0.55, wpb=50729.4, bsz=2987.6, num_updates=220400, lr=0.000121246, gnorm=0.277, loss_scale=8, train_wall=179, wall=409403
2021-03-19 03:20:30 | INFO | train_inner | epoch 011:  18092 / 20258 loss=3.485, nll_loss=1.795, ppl=3.47, wps=27933.8, ups=0.55, wpb=51148.1, bsz=3027.3, num_updates=220500, lr=0.000121218, gnorm=0.279, loss_scale=8, train_wall=180, wall=409586
2021-03-19 03:23:33 | INFO | train_inner | epoch 011:  18192 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27797.7, ups=0.55, wpb=50738, bsz=3033.2, num_updates=220600, lr=0.000121191, gnorm=0.283, loss_scale=8, train_wall=179, wall=409768
2021-03-19 03:26:35 | INFO | train_inner | epoch 011:  18292 / 20258 loss=3.474, nll_loss=1.783, ppl=3.44, wps=27994.5, ups=0.55, wpb=51054.7, bsz=2980.4, num_updates=220700, lr=0.000121163, gnorm=0.282, loss_scale=8, train_wall=179, wall=409951
2021-03-19 03:29:38 | INFO | train_inner | epoch 011:  18392 / 20258 loss=3.481, nll_loss=1.79, ppl=3.46, wps=28012.1, ups=0.55, wpb=51155.5, bsz=3025.6, num_updates=220800, lr=0.000121136, gnorm=0.28, loss_scale=8, train_wall=179, wall=410133
2021-03-19 03:32:40 | INFO | train_inner | epoch 011:  18492 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=27871.2, ups=0.55, wpb=50677.8, bsz=3026.2, num_updates=220900, lr=0.000121109, gnorm=0.293, loss_scale=8, train_wall=179, wall=410315
2021-03-19 03:35:42 | INFO | train_inner | epoch 011:  18592 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27841.9, ups=0.55, wpb=50705.4, bsz=2970, num_updates=221000, lr=0.000121081, gnorm=0.281, loss_scale=8, train_wall=179, wall=410497
2021-03-19 03:38:45 | INFO | train_inner | epoch 011:  18692 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27944.9, ups=0.55, wpb=51084.6, bsz=3069.5, num_updates=221100, lr=0.000121054, gnorm=0.282, loss_scale=8, train_wall=180, wall=410680
2021-03-19 03:41:47 | INFO | train_inner | epoch 011:  18792 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27915.7, ups=0.55, wpb=51014.8, bsz=3032.6, num_updates=221200, lr=0.000121026, gnorm=0.279, loss_scale=8, train_wall=180, wall=410863
2021-03-19 03:43:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 03:44:52 | INFO | train_inner | epoch 011:  18893 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27707.8, ups=0.54, wpb=51026.4, bsz=2954.9, num_updates=221300, lr=0.000120999, gnorm=0.279, loss_scale=4, train_wall=181, wall=411047
2021-03-19 03:47:54 | INFO | train_inner | epoch 011:  18993 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27857.7, ups=0.55, wpb=50768.5, bsz=3162.2, num_updates=221400, lr=0.000120972, gnorm=0.278, loss_scale=4, train_wall=179, wall=411229
2021-03-19 03:50:57 | INFO | train_inner | epoch 011:  19093 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=27893.1, ups=0.55, wpb=51113.8, bsz=3079.7, num_updates=221500, lr=0.000120944, gnorm=0.284, loss_scale=4, train_wall=180, wall=411413
2021-03-19 03:54:00 | INFO | train_inner | epoch 011:  19193 / 20258 loss=3.464, nll_loss=1.772, ppl=3.41, wps=27894.5, ups=0.55, wpb=51003.1, bsz=3059, num_updates=221600, lr=0.000120917, gnorm=0.279, loss_scale=4, train_wall=179, wall=411595
2021-03-19 03:57:03 | INFO | train_inner | epoch 011:  19293 / 20258 loss=3.468, nll_loss=1.776, ppl=3.43, wps=27817.5, ups=0.55, wpb=50867.5, bsz=3111.4, num_updates=221700, lr=0.00012089, gnorm=0.277, loss_scale=4, train_wall=179, wall=411778
2021-03-19 04:00:05 | INFO | train_inner | epoch 011:  19393 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=28028.8, ups=0.55, wpb=51119.9, bsz=2949.8, num_updates=221800, lr=0.000120863, gnorm=0.28, loss_scale=4, train_wall=179, wall=411961
2021-03-19 04:03:07 | INFO | train_inner | epoch 011:  19493 / 20258 loss=3.484, nll_loss=1.793, ppl=3.47, wps=27909.1, ups=0.55, wpb=50684.6, bsz=3025.4, num_updates=221900, lr=0.000120835, gnorm=0.284, loss_scale=4, train_wall=179, wall=412142
2021-03-19 04:06:09 | INFO | train_inner | epoch 011:  19593 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=27862.7, ups=0.55, wpb=50751.8, bsz=3010.2, num_updates=222000, lr=0.000120808, gnorm=0.277, loss_scale=4, train_wall=179, wall=412324
2021-03-19 04:09:12 | INFO | train_inner | epoch 011:  19693 / 20258 loss=3.486, nll_loss=1.796, ppl=3.47, wps=27886.5, ups=0.55, wpb=50945.2, bsz=2980.3, num_updates=222100, lr=0.000120781, gnorm=0.284, loss_scale=4, train_wall=179, wall=412507
2021-03-19 04:09:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-19 04:12:16 | INFO | train_inner | epoch 011:  19794 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27612.9, ups=0.54, wpb=50881.3, bsz=2978.2, num_updates=222200, lr=0.000120754, gnorm=0.283, loss_scale=2, train_wall=181, wall=412691
2021-03-19 04:15:18 | INFO | train_inner | epoch 011:  19894 / 20258 loss=3.481, nll_loss=1.79, ppl=3.46, wps=28021.2, ups=0.55, wpb=51147.7, bsz=2903.4, num_updates=222300, lr=0.000120727, gnorm=0.277, loss_scale=2, train_wall=179, wall=412874
2021-03-19 04:18:21 | INFO | train_inner | epoch 011:  19994 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=27986.6, ups=0.55, wpb=51080.6, bsz=2850.5, num_updates=222400, lr=0.000120699, gnorm=0.282, loss_scale=2, train_wall=179, wall=413056
2021-03-19 04:21:23 | INFO | train_inner | epoch 011:  20094 / 20258 loss=3.489, nll_loss=1.8, ppl=3.48, wps=27823.9, ups=0.55, wpb=50609.3, bsz=3049.3, num_updates=222500, lr=0.000120672, gnorm=0.283, loss_scale=2, train_wall=179, wall=413238
2021-03-19 04:24:26 | INFO | train_inner | epoch 011:  20194 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=27947.4, ups=0.55, wpb=51106.6, bsz=3032.4, num_updates=222600, lr=0.000120645, gnorm=0.278, loss_scale=2, train_wall=180, wall=413421
2021-03-19 04:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 04:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.877 | nll_loss 2.163 | ppl 4.48 | bleu 29.8 | wps 4396.7 | wpb 2432 | bsz 90.4 | num_updates 222664 | best_loss 3.877
2021-03-19 04:26:40 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 04:26:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:26:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:26:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:26:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:27:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:27:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:27:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:27:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:27:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:27:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:27:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:27:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:27:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:27:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:27:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:27:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:27:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 04:27:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 04:27:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 04:27:33 | INFO | valid1 | epoch 011 | valid on 'valid1' subset | loss 3.879 | nll_loss 2.187 | ppl 4.55 | bleu 27.85 | wps 4248.4 | wpb 2359.4 | bsz 106.4 | num_updates 222664 | best_loss 3.879
2021-03-19 04:27:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 04:27:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint11.pt (epoch 11 @ 222664 updates, score 3.877) (writing took 6.345777246635407 seconds)
2021-03-19 04:27:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-03-19 04:27:39 | INFO | train | epoch 011 | loss 3.468 | nll_loss 1.776 | ppl 3.42 | wps 27557.5 | ups 0.54 | wpb 50905 | bsz 3010.1 | num_updates 222664 | lr 0.000120628 | gnorm 0.279 | loss_scale 2 | train_wall 36351 | wall 413615
2021-03-19 04:27:39 | INFO | fairseq.trainer | begin training epoch 12
2021-03-19 04:28:45 | INFO | train_inner | epoch 012:     36 / 20258 loss=3.459, nll_loss=1.765, ppl=3.4, wps=19652.8, ups=0.39, wpb=50927.8, bsz=3068.6, num_updates=222700, lr=0.000120618, gnorm=0.275, loss_scale=2, train_wall=179, wall=413680
2021-03-19 04:31:47 | INFO | train_inner | epoch 012:    136 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27840.1, ups=0.55, wpb=50748.2, bsz=3111.5, num_updates=222800, lr=0.000120591, gnorm=0.282, loss_scale=2, train_wall=179, wall=413863
2021-03-19 04:34:49 | INFO | train_inner | epoch 012:    236 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27922.2, ups=0.55, wpb=50858.2, bsz=3017.3, num_updates=222900, lr=0.000120564, gnorm=0.28, loss_scale=2, train_wall=179, wall=414045
2021-03-19 04:37:52 | INFO | train_inner | epoch 012:    336 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27981.7, ups=0.55, wpb=51054.5, bsz=3095, num_updates=223000, lr=0.000120537, gnorm=0.278, loss_scale=2, train_wall=179, wall=414227
2021-03-19 04:40:53 | INFO | train_inner | epoch 012:    436 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=27910.6, ups=0.55, wpb=50715.3, bsz=2928.6, num_updates=223100, lr=0.00012051, gnorm=0.277, loss_scale=2, train_wall=179, wall=414409
2021-03-19 04:43:56 | INFO | train_inner | epoch 012:    536 / 20258 loss=3.456, nll_loss=1.761, ppl=3.39, wps=27953.7, ups=0.55, wpb=51159, bsz=2904.9, num_updates=223200, lr=0.000120483, gnorm=0.273, loss_scale=4, train_wall=180, wall=414592
2021-03-19 04:46:59 | INFO | train_inner | epoch 012:    636 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27888.3, ups=0.55, wpb=50809.1, bsz=2988.5, num_updates=223300, lr=0.000120456, gnorm=0.278, loss_scale=4, train_wall=179, wall=414774
2021-03-19 04:50:01 | INFO | train_inner | epoch 012:    736 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27983.8, ups=0.55, wpb=50998, bsz=2967.2, num_updates=223400, lr=0.000120429, gnorm=0.278, loss_scale=4, train_wall=179, wall=414956
2021-03-19 04:53:04 | INFO | train_inner | epoch 012:    836 / 20258 loss=3.436, nll_loss=1.739, ppl=3.34, wps=27893.4, ups=0.55, wpb=51032.6, bsz=3051.5, num_updates=223500, lr=0.000120402, gnorm=0.279, loss_scale=4, train_wall=180, wall=415139
2021-03-19 04:56:06 | INFO | train_inner | epoch 012:    936 / 20258 loss=3.443, nll_loss=1.747, ppl=3.36, wps=27874.4, ups=0.55, wpb=50764.9, bsz=2999.7, num_updates=223600, lr=0.000120375, gnorm=0.292, loss_scale=4, train_wall=179, wall=415321
2021-03-19 04:59:08 | INFO | train_inner | epoch 012:   1036 / 20258 loss=3.443, nll_loss=1.747, ppl=3.36, wps=27886, ups=0.55, wpb=50894.5, bsz=2970.6, num_updates=223700, lr=0.000120348, gnorm=0.281, loss_scale=4, train_wall=179, wall=415504
2021-03-19 05:02:11 | INFO | train_inner | epoch 012:   1136 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27815.4, ups=0.55, wpb=50930.6, bsz=2972.2, num_updates=223800, lr=0.000120321, gnorm=0.28, loss_scale=4, train_wall=180, wall=415687
2021-03-19 05:05:14 | INFO | train_inner | epoch 012:   1236 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=27835.8, ups=0.55, wpb=50702, bsz=3019, num_updates=223900, lr=0.000120294, gnorm=0.281, loss_scale=4, train_wall=179, wall=415869
2021-03-19 05:08:16 | INFO | train_inner | epoch 012:   1336 / 20258 loss=3.441, nll_loss=1.744, ppl=3.35, wps=28004.2, ups=0.55, wpb=51116.6, bsz=2827.6, num_updates=224000, lr=0.000120268, gnorm=0.273, loss_scale=4, train_wall=179, wall=416052
2021-03-19 05:11:19 | INFO | train_inner | epoch 012:   1436 / 20258 loss=3.445, nll_loss=1.75, ppl=3.36, wps=27836.1, ups=0.55, wpb=50874.4, bsz=3055.6, num_updates=224100, lr=0.000120241, gnorm=0.332, loss_scale=4, train_wall=180, wall=416234
2021-03-19 05:14:22 | INFO | train_inner | epoch 012:   1536 / 20258 loss=3.445, nll_loss=1.75, ppl=3.36, wps=27980.2, ups=0.55, wpb=51185.8, bsz=3113.5, num_updates=224200, lr=0.000120214, gnorm=0.279, loss_scale=8, train_wall=180, wall=416417
2021-03-19 05:17:24 | INFO | train_inner | epoch 012:   1636 / 20258 loss=3.449, nll_loss=1.754, ppl=3.37, wps=27857.9, ups=0.55, wpb=50759.7, bsz=2996.3, num_updates=224300, lr=0.000120187, gnorm=0.284, loss_scale=8, train_wall=179, wall=416600
2021-03-19 05:20:27 | INFO | train_inner | epoch 012:   1736 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=27963.9, ups=0.55, wpb=51092.8, bsz=3034.4, num_updates=224400, lr=0.00012016, gnorm=0.28, loss_scale=8, train_wall=180, wall=416782
2021-03-19 05:23:29 | INFO | train_inner | epoch 012:   1836 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27792.4, ups=0.55, wpb=50722.2, bsz=3077.7, num_updates=224500, lr=0.000120134, gnorm=0.284, loss_scale=8, train_wall=179, wall=416965
2021-03-19 05:26:31 | INFO | train_inner | epoch 012:   1936 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27851.7, ups=0.55, wpb=50710.6, bsz=2999.7, num_updates=224600, lr=0.000120107, gnorm=0.276, loss_scale=8, train_wall=179, wall=417147
2021-03-19 05:29:34 | INFO | train_inner | epoch 012:   2036 / 20258 loss=3.457, nll_loss=1.763, ppl=3.39, wps=27926, ups=0.55, wpb=51044.5, bsz=2958.7, num_updates=224700, lr=0.00012008, gnorm=0.28, loss_scale=8, train_wall=179, wall=417330
2021-03-19 05:32:36 | INFO | train_inner | epoch 012:   2136 / 20258 loss=3.435, nll_loss=1.738, ppl=3.34, wps=27695.4, ups=0.55, wpb=50365.8, bsz=2999.8, num_updates=224800, lr=0.000120053, gnorm=0.284, loss_scale=8, train_wall=179, wall=417512
2021-03-19 05:35:39 | INFO | train_inner | epoch 012:   2236 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=27937.4, ups=0.55, wpb=50985, bsz=3043.5, num_updates=224900, lr=0.000120027, gnorm=0.28, loss_scale=8, train_wall=180, wall=417694
2021-03-19 05:38:40 | INFO | train_inner | epoch 012:   2336 / 20258 loss=3.462, nll_loss=1.768, ppl=3.41, wps=27872.8, ups=0.55, wpb=50685.3, bsz=2926.3, num_updates=225000, lr=0.00012, gnorm=0.278, loss_scale=8, train_wall=179, wall=417876
2021-03-19 05:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 05:38:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:59 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.879 | nll_loss 2.165 | ppl 4.48 | bleu 29.92 | wps 4418 | wpb 2432 | bsz 90.4 | num_updates 225000 | best_loss 3.877
2021-03-19 05:38:59 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 05:38:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:38:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:38:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:38:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 05:39:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 05:39:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 05:39:51 | INFO | valid1 | epoch 012 | valid on 'valid1' subset | loss 3.883 | nll_loss 2.192 | ppl 4.57 | bleu 28.06 | wps 4283.9 | wpb 2359.4 | bsz 106.4 | num_updates 225000 | best_loss 3.877
2021-03-19 05:39:51 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 05:39:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_12_225000.pt (epoch 12 @ 225000 updates, score 3.879) (writing took 4.751481685787439 seconds)
2021-03-19 05:42:58 | INFO | train_inner | epoch 012:   2436 / 20258 loss=3.447, nll_loss=1.751, ppl=3.37, wps=19804.4, ups=0.39, wpb=51008.8, bsz=3024.6, num_updates=225100, lr=0.000119973, gnorm=0.276, loss_scale=8, train_wall=179, wall=418133
2021-03-19 05:46:01 | INFO | train_inner | epoch 012:   2536 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=27982.6, ups=0.55, wpb=51120.4, bsz=2876.8, num_updates=225200, lr=0.000119947, gnorm=0.279, loss_scale=16, train_wall=180, wall=418316
2021-03-19 05:49:03 | INFO | train_inner | epoch 012:   2636 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=27782.3, ups=0.55, wpb=50749.7, bsz=3065.6, num_updates=225300, lr=0.00011992, gnorm=0.273, loss_scale=16, train_wall=179, wall=418499
2021-03-19 05:50:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 05:52:07 | INFO | train_inner | epoch 012:   2737 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=27636, ups=0.54, wpb=50891.4, bsz=3029.4, num_updates=225400, lr=0.000119893, gnorm=0.282, loss_scale=8, train_wall=181, wall=418683
2021-03-19 05:55:10 | INFO | train_inner | epoch 012:   2837 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=28053.6, ups=0.55, wpb=51103.9, bsz=2935.7, num_updates=225500, lr=0.000119867, gnorm=0.282, loss_scale=8, train_wall=179, wall=418865
2021-03-19 05:58:12 | INFO | train_inner | epoch 012:   2937 / 20258 loss=3.457, nll_loss=1.763, ppl=3.39, wps=27936.6, ups=0.55, wpb=51003.7, bsz=3088.5, num_updates=225600, lr=0.00011984, gnorm=0.278, loss_scale=8, train_wall=179, wall=419048
2021-03-19 06:01:15 | INFO | train_inner | epoch 012:   3037 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27962.9, ups=0.55, wpb=50985, bsz=2931.4, num_updates=225700, lr=0.000119814, gnorm=0.279, loss_scale=8, train_wall=179, wall=419230
2021-03-19 06:04:17 | INFO | train_inner | epoch 012:   3137 / 20258 loss=3.45, nll_loss=1.755, ppl=3.38, wps=27918.7, ups=0.55, wpb=51043.1, bsz=3076.1, num_updates=225800, lr=0.000119787, gnorm=0.276, loss_scale=8, train_wall=180, wall=419413
2021-03-19 06:07:20 | INFO | train_inner | epoch 012:   3237 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27967.6, ups=0.55, wpb=51052.3, bsz=3084, num_updates=225900, lr=0.000119761, gnorm=0.283, loss_scale=8, train_wall=179, wall=419595
2021-03-19 06:10:22 | INFO | train_inner | epoch 012:   3337 / 20258 loss=3.473, nll_loss=1.781, ppl=3.44, wps=27993.6, ups=0.55, wpb=51022.7, bsz=2855.1, num_updates=226000, lr=0.000119734, gnorm=0.276, loss_scale=8, train_wall=179, wall=419778
2021-03-19 06:13:25 | INFO | train_inner | epoch 012:   3437 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27867.4, ups=0.55, wpb=50816.1, bsz=3065.9, num_updates=226100, lr=0.000119708, gnorm=0.283, loss_scale=8, train_wall=179, wall=419960
2021-03-19 06:14:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 06:16:29 | INFO | train_inner | epoch 012:   3538 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27605, ups=0.54, wpb=50954.7, bsz=2937.8, num_updates=226200, lr=0.000119681, gnorm=0.279, loss_scale=4, train_wall=181, wall=420145
2021-03-19 06:19:31 | INFO | train_inner | epoch 012:   3638 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27797.1, ups=0.55, wpb=50660.4, bsz=3010, num_updates=226300, lr=0.000119655, gnorm=0.282, loss_scale=4, train_wall=179, wall=420327
2021-03-19 06:22:34 | INFO | train_inner | epoch 012:   3738 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=27837.9, ups=0.55, wpb=50888.5, bsz=3052.2, num_updates=226400, lr=0.000119628, gnorm=0.286, loss_scale=4, train_wall=180, wall=420510
2021-03-19 06:25:36 | INFO | train_inner | epoch 012:   3838 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27902, ups=0.55, wpb=50845.7, bsz=2928.8, num_updates=226500, lr=0.000119602, gnorm=0.28, loss_scale=4, train_wall=179, wall=420692
2021-03-19 06:28:39 | INFO | train_inner | epoch 012:   3938 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=27848.2, ups=0.55, wpb=50876.9, bsz=3052.6, num_updates=226600, lr=0.000119576, gnorm=0.276, loss_scale=4, train_wall=180, wall=420875
2021-03-19 06:31:41 | INFO | train_inner | epoch 012:   4038 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27959.3, ups=0.55, wpb=50818.7, bsz=3023.4, num_updates=226700, lr=0.000119549, gnorm=0.278, loss_scale=4, train_wall=179, wall=421056
2021-03-19 06:34:43 | INFO | train_inner | epoch 012:   4138 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27870.8, ups=0.55, wpb=50810.9, bsz=3010.1, num_updates=226800, lr=0.000119523, gnorm=0.284, loss_scale=4, train_wall=179, wall=421239
2021-03-19 06:37:46 | INFO | train_inner | epoch 012:   4238 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=28022, ups=0.55, wpb=51173.1, bsz=3011.2, num_updates=226900, lr=0.000119497, gnorm=0.282, loss_scale=4, train_wall=180, wall=421421
2021-03-19 06:40:48 | INFO | train_inner | epoch 012:   4338 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=27741.2, ups=0.55, wpb=50651.5, bsz=3094, num_updates=227000, lr=0.00011947, gnorm=0.282, loss_scale=4, train_wall=179, wall=421604
2021-03-19 06:43:50 | INFO | train_inner | epoch 012:   4438 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27966.2, ups=0.55, wpb=50908.7, bsz=2946.6, num_updates=227100, lr=0.000119444, gnorm=0.279, loss_scale=4, train_wall=179, wall=421786
2021-03-19 06:46:53 | INFO | train_inner | epoch 012:   4538 / 20258 loss=3.464, nll_loss=1.772, ppl=3.41, wps=27951.2, ups=0.55, wpb=50920.1, bsz=3035, num_updates=227200, lr=0.000119418, gnorm=0.282, loss_scale=8, train_wall=179, wall=421968
2021-03-19 06:49:55 | INFO | train_inner | epoch 012:   4638 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27862.7, ups=0.55, wpb=50940.5, bsz=3093, num_updates=227300, lr=0.000119391, gnorm=0.278, loss_scale=8, train_wall=179, wall=422151
2021-03-19 06:52:57 | INFO | train_inner | epoch 012:   4738 / 20258 loss=3.454, nll_loss=1.761, ppl=3.39, wps=27974.8, ups=0.55, wpb=50941.2, bsz=3051.8, num_updates=227400, lr=0.000119365, gnorm=0.277, loss_scale=8, train_wall=179, wall=422333
2021-03-19 06:56:01 | INFO | train_inner | epoch 012:   4838 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=27823.6, ups=0.55, wpb=50948, bsz=3146.5, num_updates=227500, lr=0.000119339, gnorm=0.281, loss_scale=8, train_wall=180, wall=422516
2021-03-19 06:59:03 | INFO | train_inner | epoch 012:   4938 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27822.3, ups=0.55, wpb=50681.3, bsz=3113.4, num_updates=227600, lr=0.000119313, gnorm=0.296, loss_scale=8, train_wall=179, wall=422698
2021-03-19 07:02:06 | INFO | train_inner | epoch 012:   5038 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27845.4, ups=0.54, wpb=51152.5, bsz=3123.9, num_updates=227700, lr=0.000119286, gnorm=0.276, loss_scale=8, train_wall=180, wall=422882
2021-03-19 07:05:09 | INFO | train_inner | epoch 012:   5138 / 20258 loss=3.471, nll_loss=1.78, ppl=3.43, wps=27939.2, ups=0.55, wpb=50924.3, bsz=3044.2, num_updates=227800, lr=0.00011926, gnorm=0.281, loss_scale=8, train_wall=179, wall=423064
2021-03-19 07:08:11 | INFO | train_inner | epoch 012:   5238 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27893.6, ups=0.55, wpb=50886.7, bsz=3012.3, num_updates=227900, lr=0.000119234, gnorm=0.277, loss_scale=8, train_wall=179, wall=423247
2021-03-19 07:11:14 | INFO | train_inner | epoch 012:   5338 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=27852.5, ups=0.55, wpb=51023.9, bsz=2885, num_updates=228000, lr=0.000119208, gnorm=0.279, loss_scale=8, train_wall=180, wall=423430
2021-03-19 07:14:17 | INFO | train_inner | epoch 012:   5438 / 20258 loss=3.449, nll_loss=1.754, ppl=3.37, wps=27856.1, ups=0.55, wpb=50838.7, bsz=2867.1, num_updates=228100, lr=0.000119182, gnorm=0.273, loss_scale=8, train_wall=180, wall=423612
2021-03-19 07:17:20 | INFO | train_inner | epoch 012:   5538 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=27832.5, ups=0.55, wpb=50904.3, bsz=3096.5, num_updates=228200, lr=0.000119156, gnorm=0.282, loss_scale=16, train_wall=179, wall=423795
2021-03-19 07:20:23 | INFO | train_inner | epoch 012:   5638 / 20258 loss=3.472, nll_loss=1.781, ppl=3.44, wps=27800.3, ups=0.55, wpb=50842.9, bsz=3004.7, num_updates=228300, lr=0.00011913, gnorm=0.281, loss_scale=16, train_wall=180, wall=423978
2021-03-19 07:23:25 | INFO | train_inner | epoch 012:   5738 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=27932.2, ups=0.55, wpb=51007.6, bsz=2914.9, num_updates=228400, lr=0.000119103, gnorm=0.284, loss_scale=16, train_wall=180, wall=424161
2021-03-19 07:24:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 07:26:29 | INFO | train_inner | epoch 012:   5839 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27573.2, ups=0.54, wpb=50631, bsz=2965, num_updates=228500, lr=0.000119077, gnorm=0.284, loss_scale=8, train_wall=181, wall=424344
2021-03-19 07:29:31 | INFO | train_inner | epoch 012:   5939 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27757, ups=0.55, wpb=50585.8, bsz=3094, num_updates=228600, lr=0.000119051, gnorm=0.277, loss_scale=8, train_wall=179, wall=424527
2021-03-19 07:32:34 | INFO | train_inner | epoch 012:   6039 / 20258 loss=3.457, nll_loss=1.763, ppl=3.39, wps=27925, ups=0.55, wpb=51045.9, bsz=2962.3, num_updates=228700, lr=0.000119025, gnorm=0.278, loss_scale=8, train_wall=179, wall=424709
2021-03-19 07:35:37 | INFO | train_inner | epoch 012:   6139 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=27797.3, ups=0.55, wpb=50847.4, bsz=3101.4, num_updates=228800, lr=0.000118999, gnorm=0.278, loss_scale=8, train_wall=180, wall=424892
2021-03-19 07:38:39 | INFO | train_inner | epoch 012:   6239 / 20258 loss=3.467, nll_loss=1.774, ppl=3.42, wps=27963.3, ups=0.55, wpb=51031, bsz=3000, num_updates=228900, lr=0.000118973, gnorm=0.288, loss_scale=8, train_wall=179, wall=425075
2021-03-19 07:41:41 | INFO | train_inner | epoch 012:   6339 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27980.5, ups=0.55, wpb=50912.8, bsz=2997.9, num_updates=229000, lr=0.000118947, gnorm=0.286, loss_scale=8, train_wall=179, wall=425257
2021-03-19 07:44:44 | INFO | train_inner | epoch 012:   6439 / 20258 loss=3.445, nll_loss=1.75, ppl=3.36, wps=27920.4, ups=0.55, wpb=50925.4, bsz=3032.7, num_updates=229100, lr=0.000118921, gnorm=0.276, loss_scale=8, train_wall=179, wall=425439
2021-03-19 07:47:45 | INFO | train_inner | epoch 012:   6539 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27838.9, ups=0.55, wpb=50591.5, bsz=2943, num_updates=229200, lr=0.000118895, gnorm=0.281, loss_scale=8, train_wall=179, wall=425621
2021-03-19 07:50:48 | INFO | train_inner | epoch 012:   6639 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27860.1, ups=0.55, wpb=50913.9, bsz=3026.2, num_updates=229300, lr=0.00011887, gnorm=0.278, loss_scale=8, train_wall=179, wall=425804
2021-03-19 07:53:51 | INFO | train_inner | epoch 012:   6739 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27911.7, ups=0.55, wpb=50927.8, bsz=3049.9, num_updates=229400, lr=0.000118844, gnorm=0.286, loss_scale=8, train_wall=179, wall=425986
2021-03-19 07:56:53 | INFO | train_inner | epoch 012:   6839 / 20258 loss=3.46, nll_loss=1.766, ppl=3.4, wps=27804.2, ups=0.55, wpb=50788.2, bsz=3006.1, num_updates=229500, lr=0.000118818, gnorm=0.281, loss_scale=16, train_wall=179, wall=426169
2021-03-19 07:59:57 | INFO | train_inner | epoch 012:   6939 / 20258 loss=3.45, nll_loss=1.755, ppl=3.38, wps=27833.1, ups=0.55, wpb=51052.8, bsz=3033.1, num_updates=229600, lr=0.000118792, gnorm=0.281, loss_scale=16, train_wall=180, wall=426352
2021-03-19 08:02:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 08:03:01 | INFO | train_inner | epoch 012:   7040 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27601.4, ups=0.54, wpb=50922.9, bsz=3014.2, num_updates=229700, lr=0.000118766, gnorm=0.279, loss_scale=8, train_wall=181, wall=426537
2021-03-19 08:06:03 | INFO | train_inner | epoch 012:   7140 / 20258 loss=3.47, nll_loss=1.778, ppl=3.43, wps=27910.6, ups=0.55, wpb=50759.6, bsz=2888.7, num_updates=229800, lr=0.00011874, gnorm=0.279, loss_scale=8, train_wall=179, wall=426719
2021-03-19 08:09:06 | INFO | train_inner | epoch 012:   7240 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27807.9, ups=0.55, wpb=50909.3, bsz=3033, num_updates=229900, lr=0.000118714, gnorm=0.279, loss_scale=8, train_wall=179, wall=426902
2021-03-19 08:12:08 | INFO | train_inner | epoch 012:   7340 / 20258 loss=3.453, nll_loss=1.759, ppl=3.39, wps=27854.8, ups=0.55, wpb=50688.2, bsz=3000.9, num_updates=230000, lr=0.000118688, gnorm=0.281, loss_scale=8, train_wall=179, wall=427084
2021-03-19 08:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 08:12:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:26 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.875 | nll_loss 2.159 | ppl 4.47 | bleu 29.91 | wps 4419.6 | wpb 2432 | bsz 90.4 | num_updates 230000 | best_loss 3.875
2021-03-19 08:12:26 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 08:12:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:12:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 08:12:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 08:12:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 08:13:19 | INFO | valid1 | epoch 012 | valid on 'valid1' subset | loss 3.879 | nll_loss 2.187 | ppl 4.55 | bleu 27.85 | wps 4223.4 | wpb 2359.4 | bsz 106.4 | num_updates 230000 | best_loss 3.877
2021-03-19 08:13:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 08:13:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_12_230000.pt (epoch 12 @ 230000 updates, score 3.875) (writing took 6.24861216917634 seconds)
2021-03-19 08:14:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 08:16:30 | INFO | train_inner | epoch 012:   7441 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=19450.7, ups=0.38, wpb=50896.2, bsz=3037.1, num_updates=230100, lr=0.000118663, gnorm=0.287, loss_scale=4, train_wall=181, wall=427345
2021-03-19 08:19:32 | INFO | train_inner | epoch 012:   7541 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27890, ups=0.55, wpb=50827.3, bsz=2995.7, num_updates=230200, lr=0.000118637, gnorm=0.281, loss_scale=4, train_wall=179, wall=427528
2021-03-19 08:22:35 | INFO | train_inner | epoch 012:   7641 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27939.7, ups=0.55, wpb=51065, bsz=2937.4, num_updates=230300, lr=0.000118611, gnorm=0.277, loss_scale=4, train_wall=180, wall=427710
2021-03-19 08:25:37 | INFO | train_inner | epoch 012:   7741 / 20258 loss=3.46, nll_loss=1.766, ppl=3.4, wps=27843.7, ups=0.55, wpb=50690, bsz=2915.5, num_updates=230400, lr=0.000118585, gnorm=0.275, loss_scale=4, train_wall=179, wall=427892
2021-03-19 08:28:39 | INFO | train_inner | epoch 012:   7841 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=27924.1, ups=0.55, wpb=50879.9, bsz=2938.3, num_updates=230500, lr=0.00011856, gnorm=0.284, loss_scale=4, train_wall=179, wall=428075
2021-03-19 08:31:42 | INFO | train_inner | epoch 012:   7941 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27913.6, ups=0.55, wpb=51043.4, bsz=2973.8, num_updates=230600, lr=0.000118534, gnorm=0.29, loss_scale=4, train_wall=179, wall=428257
2021-03-19 08:34:45 | INFO | train_inner | epoch 012:   8041 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27944.5, ups=0.55, wpb=51154.8, bsz=3033, num_updates=230700, lr=0.000118508, gnorm=0.276, loss_scale=4, train_wall=180, wall=428441
2021-03-19 08:37:48 | INFO | train_inner | epoch 012:   8141 / 20258 loss=3.45, nll_loss=1.755, ppl=3.38, wps=27830.6, ups=0.55, wpb=50973.8, bsz=3051, num_updates=230800, lr=0.000118483, gnorm=0.283, loss_scale=4, train_wall=180, wall=428624
2021-03-19 08:40:51 | INFO | train_inner | epoch 012:   8241 / 20258 loss=3.453, nll_loss=1.759, ppl=3.39, wps=27912.7, ups=0.55, wpb=51017.1, bsz=3045, num_updates=230900, lr=0.000118457, gnorm=0.276, loss_scale=4, train_wall=180, wall=428806
2021-03-19 08:43:54 | INFO | train_inner | epoch 012:   8341 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27838.5, ups=0.55, wpb=50832.5, bsz=3131.1, num_updates=231000, lr=0.000118431, gnorm=0.284, loss_scale=4, train_wall=179, wall=428989
2021-03-19 08:46:57 | INFO | train_inner | epoch 012:   8441 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27835.8, ups=0.55, wpb=50954.4, bsz=3029.2, num_updates=231100, lr=0.000118406, gnorm=0.279, loss_scale=8, train_wall=180, wall=429172
2021-03-19 08:49:59 | INFO | train_inner | epoch 012:   8541 / 20258 loss=3.452, nll_loss=1.757, ppl=3.38, wps=27947.6, ups=0.55, wpb=51047.5, bsz=2972.4, num_updates=231200, lr=0.00011838, gnorm=0.276, loss_scale=8, train_wall=180, wall=429355
2021-03-19 08:53:02 | INFO | train_inner | epoch 012:   8641 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27641.2, ups=0.55, wpb=50513, bsz=2935.4, num_updates=231300, lr=0.000118354, gnorm=0.286, loss_scale=8, train_wall=179, wall=429538
2021-03-19 08:56:05 | INFO | train_inner | epoch 012:   8741 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27902, ups=0.55, wpb=50956.9, bsz=2953, num_updates=231400, lr=0.000118329, gnorm=0.277, loss_scale=8, train_wall=179, wall=429720
2021-03-19 08:59:07 | INFO | train_inner | epoch 012:   8841 / 20258 loss=3.467, nll_loss=1.774, ppl=3.42, wps=27863.3, ups=0.55, wpb=50912.2, bsz=2968.6, num_updates=231500, lr=0.000118303, gnorm=0.289, loss_scale=8, train_wall=179, wall=429903
2021-03-19 09:02:10 | INFO | train_inner | epoch 012:   8941 / 20258 loss=3.47, nll_loss=1.777, ppl=3.43, wps=27995.2, ups=0.55, wpb=51107.3, bsz=2949.3, num_updates=231600, lr=0.000118278, gnorm=0.278, loss_scale=8, train_wall=179, wall=430085
2021-03-19 09:03:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 09:05:14 | INFO | train_inner | epoch 012:   9042 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27617.5, ups=0.54, wpb=50955.5, bsz=3075.1, num_updates=231700, lr=0.000118252, gnorm=0.279, loss_scale=4, train_wall=181, wall=430270
2021-03-19 09:08:17 | INFO | train_inner | epoch 012:   9142 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27770.4, ups=0.55, wpb=50705.2, bsz=3027.7, num_updates=231800, lr=0.000118227, gnorm=0.282, loss_scale=4, train_wall=179, wall=430453
2021-03-19 09:11:20 | INFO | train_inner | epoch 012:   9242 / 20258 loss=3.453, nll_loss=1.759, ppl=3.39, wps=27937.2, ups=0.55, wpb=51115.1, bsz=2990.3, num_updates=231900, lr=0.000118201, gnorm=0.277, loss_scale=4, train_wall=180, wall=430636
2021-03-19 09:14:22 | INFO | train_inner | epoch 012:   9342 / 20258 loss=3.443, nll_loss=1.747, ppl=3.36, wps=27847.6, ups=0.55, wpb=50793.6, bsz=2975.9, num_updates=232000, lr=0.000118176, gnorm=0.281, loss_scale=4, train_wall=179, wall=430818
2021-03-19 09:17:25 | INFO | train_inner | epoch 012:   9442 / 20258 loss=3.449, nll_loss=1.754, ppl=3.37, wps=27861, ups=0.55, wpb=50932.3, bsz=3084.6, num_updates=232100, lr=0.00011815, gnorm=0.282, loss_scale=4, train_wall=179, wall=431001
2021-03-19 09:20:27 | INFO | train_inner | epoch 012:   9542 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27794.9, ups=0.55, wpb=50538.8, bsz=2878.5, num_updates=232200, lr=0.000118125, gnorm=0.288, loss_scale=4, train_wall=179, wall=431183
2021-03-19 09:23:29 | INFO | train_inner | epoch 012:   9642 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27901.1, ups=0.55, wpb=50775.2, bsz=3044.1, num_updates=232300, lr=0.000118099, gnorm=0.282, loss_scale=4, train_wall=179, wall=431365
2021-03-19 09:26:32 | INFO | train_inner | epoch 012:   9742 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=28099.6, ups=0.55, wpb=51369.7, bsz=3055, num_updates=232400, lr=0.000118074, gnorm=0.276, loss_scale=4, train_wall=180, wall=431547
2021-03-19 09:29:34 | INFO | train_inner | epoch 012:   9842 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27952.7, ups=0.55, wpb=51030.1, bsz=2979.1, num_updates=232500, lr=0.000118049, gnorm=0.285, loss_scale=4, train_wall=180, wall=431730
2021-03-19 09:32:37 | INFO | train_inner | epoch 012:   9942 / 20258 loss=3.452, nll_loss=1.757, ppl=3.38, wps=27836.3, ups=0.55, wpb=50870, bsz=3034.6, num_updates=232600, lr=0.000118023, gnorm=0.28, loss_scale=4, train_wall=180, wall=431913
2021-03-19 09:35:40 | INFO | train_inner | epoch 012:  10042 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=27874.2, ups=0.55, wpb=50954.6, bsz=2965.3, num_updates=232700, lr=0.000117998, gnorm=0.281, loss_scale=8, train_wall=179, wall=432095
2021-03-19 09:38:42 | INFO | train_inner | epoch 012:  10142 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=27994.8, ups=0.55, wpb=51052.3, bsz=3048.6, num_updates=232800, lr=0.000117973, gnorm=0.277, loss_scale=8, train_wall=179, wall=432278
2021-03-19 09:41:44 | INFO | train_inner | epoch 012:  10242 / 20258 loss=3.48, nll_loss=1.789, ppl=3.46, wps=27868.5, ups=0.55, wpb=50738.5, bsz=2955.7, num_updates=232900, lr=0.000117947, gnorm=0.287, loss_scale=8, train_wall=179, wall=432460
2021-03-19 09:44:48 | INFO | train_inner | epoch 012:  10342 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27755, ups=0.55, wpb=50909, bsz=3059, num_updates=233000, lr=0.000117922, gnorm=0.275, loss_scale=8, train_wall=180, wall=432643
2021-03-19 09:47:51 | INFO | train_inner | epoch 012:  10442 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27839.7, ups=0.55, wpb=51059.7, bsz=2959.3, num_updates=233100, lr=0.000117897, gnorm=0.279, loss_scale=8, train_wall=180, wall=432827
2021-03-19 09:50:54 | INFO | train_inner | epoch 012:  10542 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27972.4, ups=0.55, wpb=51118.5, bsz=3021.1, num_updates=233200, lr=0.000117871, gnorm=0.278, loss_scale=8, train_wall=180, wall=433009
2021-03-19 09:53:56 | INFO | train_inner | epoch 012:  10642 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27848.5, ups=0.55, wpb=50834.4, bsz=3020.3, num_updates=233300, lr=0.000117846, gnorm=0.28, loss_scale=8, train_wall=179, wall=433192
2021-03-19 09:56:59 | INFO | train_inner | epoch 012:  10742 / 20258 loss=3.476, nll_loss=1.785, ppl=3.45, wps=27824.8, ups=0.55, wpb=50688.1, bsz=3098.6, num_updates=233400, lr=0.000117821, gnorm=0.28, loss_scale=8, train_wall=179, wall=433374
2021-03-19 10:00:02 | INFO | train_inner | epoch 012:  10842 / 20258 loss=3.46, nll_loss=1.766, ppl=3.4, wps=27871.7, ups=0.55, wpb=51036, bsz=2939.7, num_updates=233500, lr=0.000117796, gnorm=0.278, loss_scale=8, train_wall=180, wall=433557
2021-03-19 10:03:04 | INFO | train_inner | epoch 012:  10942 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=27892.3, ups=0.55, wpb=50825.1, bsz=2978.6, num_updates=233600, lr=0.00011777, gnorm=0.283, loss_scale=8, train_wall=179, wall=433740
2021-03-19 10:06:07 | INFO | train_inner | epoch 012:  11042 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27644.5, ups=0.55, wpb=50566, bsz=3029, num_updates=233700, lr=0.000117745, gnorm=0.28, loss_scale=16, train_wall=180, wall=433922
2021-03-19 10:08:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 10:09:11 | INFO | train_inner | epoch 012:  11143 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27606.1, ups=0.54, wpb=50711, bsz=2985.8, num_updates=233800, lr=0.00011772, gnorm=0.277, loss_scale=8, train_wall=181, wall=434106
2021-03-19 10:12:13 | INFO | train_inner | epoch 012:  11243 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=27893.1, ups=0.55, wpb=50875.3, bsz=3030.2, num_updates=233900, lr=0.000117695, gnorm=0.277, loss_scale=8, train_wall=179, wall=434289
2021-03-19 10:15:16 | INFO | train_inner | epoch 012:  11343 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=27874.7, ups=0.55, wpb=51071.8, bsz=3091.3, num_updates=234000, lr=0.00011767, gnorm=0.284, loss_scale=8, train_wall=180, wall=434472
2021-03-19 10:18:19 | INFO | train_inner | epoch 012:  11443 / 20258 loss=3.477, nll_loss=1.786, ppl=3.45, wps=27954.5, ups=0.55, wpb=51004.1, bsz=3121.8, num_updates=234100, lr=0.000117645, gnorm=0.283, loss_scale=8, train_wall=179, wall=434654
2021-03-19 10:21:21 | INFO | train_inner | epoch 012:  11543 / 20258 loss=3.462, nll_loss=1.77, ppl=3.41, wps=27904.1, ups=0.55, wpb=50948.1, bsz=3112.2, num_updates=234200, lr=0.000117619, gnorm=0.28, loss_scale=8, train_wall=180, wall=434837
2021-03-19 10:24:24 | INFO | train_inner | epoch 012:  11643 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27902.7, ups=0.55, wpb=50873.9, bsz=3014.7, num_updates=234300, lr=0.000117594, gnorm=0.274, loss_scale=8, train_wall=179, wall=435019
2021-03-19 10:27:25 | INFO | train_inner | epoch 012:  11743 / 20258 loss=3.471, nll_loss=1.78, ppl=3.43, wps=27885, ups=0.55, wpb=50727.7, bsz=3124.6, num_updates=234400, lr=0.000117569, gnorm=0.286, loss_scale=8, train_wall=179, wall=435201
2021-03-19 10:29:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 10:30:30 | INFO | train_inner | epoch 012:  11844 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27653.9, ups=0.54, wpb=50912.3, bsz=2992.3, num_updates=234500, lr=0.000117544, gnorm=0.276, loss_scale=4, train_wall=181, wall=435385
2021-03-19 10:33:32 | INFO | train_inner | epoch 012:  11944 / 20258 loss=3.472, nll_loss=1.781, ppl=3.44, wps=27885.7, ups=0.55, wpb=50733.1, bsz=3079.8, num_updates=234600, lr=0.000117519, gnorm=0.279, loss_scale=4, train_wall=179, wall=435567
2021-03-19 10:36:34 | INFO | train_inner | epoch 012:  12044 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27955.9, ups=0.55, wpb=51072.6, bsz=2953.8, num_updates=234700, lr=0.000117494, gnorm=0.277, loss_scale=4, train_wall=180, wall=435750
2021-03-19 10:39:37 | INFO | train_inner | epoch 012:  12144 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=27962.5, ups=0.55, wpb=51120.2, bsz=3022.2, num_updates=234800, lr=0.000117469, gnorm=0.276, loss_scale=4, train_wall=180, wall=435933
2021-03-19 10:42:39 | INFO | train_inner | epoch 012:  12244 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=28012.9, ups=0.55, wpb=51089.6, bsz=3053, num_updates=234900, lr=0.000117444, gnorm=0.282, loss_scale=4, train_wall=179, wall=436115
2021-03-19 10:45:41 | INFO | train_inner | epoch 012:  12344 / 20258 loss=3.472, nll_loss=1.78, ppl=3.44, wps=27848.6, ups=0.55, wpb=50639.7, bsz=2922, num_updates=235000, lr=0.000117419, gnorm=0.286, loss_scale=4, train_wall=179, wall=436297
2021-03-19 10:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 10:45:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:45:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:45:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:45:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:45:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:45:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:45:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:45:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:45:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:45:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:45:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:45:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:45:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:45:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:45:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:45:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:45:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:45:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:45:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:45:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:45:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:00 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.879 | nll_loss 2.164 | ppl 4.48 | bleu 29.99 | wps 4345.8 | wpb 2432 | bsz 90.4 | num_updates 235000 | best_loss 3.875
2021-03-19 10:46:00 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 10:46:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 10:46:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 10:46:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 10:46:53 | INFO | valid1 | epoch 012 | valid on 'valid1' subset | loss 3.883 | nll_loss 2.19 | ppl 4.56 | bleu 27.63 | wps 4217.6 | wpb 2359.4 | bsz 106.4 | num_updates 235000 | best_loss 3.875
2021-03-19 10:46:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 10:46:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_12_235000.pt (epoch 12 @ 235000 updates, score 3.879) (writing took 4.4732803869992495 seconds)
2021-03-19 10:49:59 | INFO | train_inner | epoch 012:  12444 / 20258 loss=3.462, nll_loss=1.77, ppl=3.41, wps=19711.9, ups=0.39, wpb=50858.3, bsz=3011.8, num_updates=235100, lr=0.000117394, gnorm=0.278, loss_scale=4, train_wall=179, wall=436555
2021-03-19 10:53:01 | INFO | train_inner | epoch 012:  12544 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27932.2, ups=0.55, wpb=50719.4, bsz=2829.7, num_updates=235200, lr=0.000117369, gnorm=0.281, loss_scale=4, train_wall=178, wall=436736
2021-03-19 10:56:03 | INFO | train_inner | epoch 012:  12644 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27910.6, ups=0.55, wpb=50829, bsz=2988.9, num_updates=235300, lr=0.000117344, gnorm=0.281, loss_scale=4, train_wall=179, wall=436918
2021-03-19 10:59:06 | INFO | train_inner | epoch 012:  12744 / 20258 loss=3.47, nll_loss=1.779, ppl=3.43, wps=27912.8, ups=0.55, wpb=51024.8, bsz=3109, num_updates=235400, lr=0.000117319, gnorm=0.28, loss_scale=4, train_wall=180, wall=437101
2021-03-19 11:02:08 | INFO | train_inner | epoch 012:  12844 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27924.2, ups=0.55, wpb=50952.3, bsz=3001.7, num_updates=235500, lr=0.000117294, gnorm=0.278, loss_scale=8, train_wall=179, wall=437284
2021-03-19 11:05:11 | INFO | train_inner | epoch 012:  12944 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=27885.6, ups=0.55, wpb=51004.1, bsz=2971.3, num_updates=235600, lr=0.000117269, gnorm=0.284, loss_scale=8, train_wall=179, wall=437467
2021-03-19 11:08:14 | INFO | train_inner | epoch 012:  13044 / 20258 loss=3.451, nll_loss=1.756, ppl=3.38, wps=27985.2, ups=0.55, wpb=51140.5, bsz=2994.1, num_updates=235700, lr=0.000117245, gnorm=0.278, loss_scale=8, train_wall=180, wall=437649
2021-03-19 11:11:16 | INFO | train_inner | epoch 012:  13144 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27967.4, ups=0.55, wpb=50991, bsz=3000, num_updates=235800, lr=0.00011722, gnorm=0.284, loss_scale=8, train_wall=179, wall=437832
2021-03-19 11:14:20 | INFO | train_inner | epoch 012:  13244 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27977.9, ups=0.54, wpb=51366.5, bsz=3061.1, num_updates=235900, lr=0.000117195, gnorm=0.277, loss_scale=8, train_wall=180, wall=438015
2021-03-19 11:17:21 | INFO | train_inner | epoch 012:  13344 / 20258 loss=3.484, nll_loss=1.794, ppl=3.47, wps=27933.8, ups=0.55, wpb=50701.8, bsz=2990.1, num_updates=236000, lr=0.00011717, gnorm=0.28, loss_scale=8, train_wall=178, wall=438197
2021-03-19 11:20:25 | INFO | train_inner | epoch 012:  13444 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27849.9, ups=0.55, wpb=51058, bsz=3026.2, num_updates=236100, lr=0.000117145, gnorm=0.277, loss_scale=8, train_wall=180, wall=438380
2021-03-19 11:23:27 | INFO | train_inner | epoch 012:  13544 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=28044.1, ups=0.55, wpb=51230.1, bsz=2989.4, num_updates=236200, lr=0.00011712, gnorm=0.28, loss_scale=8, train_wall=180, wall=438563
2021-03-19 11:26:30 | INFO | train_inner | epoch 012:  13644 / 20258 loss=3.464, nll_loss=1.772, ppl=3.42, wps=27787.7, ups=0.55, wpb=50730.5, bsz=3062.2, num_updates=236300, lr=0.000117096, gnorm=0.284, loss_scale=8, train_wall=179, wall=438745
2021-03-19 11:29:32 | INFO | train_inner | epoch 012:  13744 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27932.5, ups=0.55, wpb=50986.1, bsz=3005.6, num_updates=236400, lr=0.000117071, gnorm=0.279, loss_scale=8, train_wall=180, wall=438928
2021-03-19 11:32:34 | INFO | train_inner | epoch 012:  13844 / 20258 loss=3.481, nll_loss=1.791, ppl=3.46, wps=27915.1, ups=0.55, wpb=50756, bsz=2909.8, num_updates=236500, lr=0.000117046, gnorm=0.288, loss_scale=8, train_wall=179, wall=439110
2021-03-19 11:35:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 11:35:38 | INFO | train_inner | epoch 012:  13945 / 20258 loss=3.474, nll_loss=1.783, ppl=3.44, wps=27671.7, ups=0.54, wpb=50979.3, bsz=2936.4, num_updates=236600, lr=0.000117021, gnorm=0.281, loss_scale=8, train_wall=181, wall=439294
2021-03-19 11:38:41 | INFO | train_inner | epoch 012:  14045 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27979.5, ups=0.55, wpb=51111, bsz=3033.4, num_updates=236700, lr=0.000116997, gnorm=0.278, loss_scale=8, train_wall=180, wall=439477
2021-03-19 11:41:44 | INFO | train_inner | epoch 012:  14145 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27891.9, ups=0.55, wpb=51068.2, bsz=3049.7, num_updates=236800, lr=0.000116972, gnorm=0.28, loss_scale=8, train_wall=179, wall=439660
2021-03-19 11:44:47 | INFO | train_inner | epoch 012:  14245 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=27884.2, ups=0.55, wpb=50982.2, bsz=3096.9, num_updates=236900, lr=0.000116947, gnorm=0.28, loss_scale=8, train_wall=180, wall=439843
2021-03-19 11:47:50 | INFO | train_inner | epoch 012:  14345 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27782.9, ups=0.55, wpb=50865.7, bsz=3034.7, num_updates=237000, lr=0.000116923, gnorm=0.287, loss_scale=8, train_wall=179, wall=440026
2021-03-19 11:50:53 | INFO | train_inner | epoch 012:  14445 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27894.6, ups=0.55, wpb=50984.9, bsz=2982.2, num_updates=237100, lr=0.000116898, gnorm=0.281, loss_scale=8, train_wall=179, wall=440208
2021-03-19 11:53:55 | INFO | train_inner | epoch 012:  14545 / 20258 loss=3.472, nll_loss=1.781, ppl=3.44, wps=27816, ups=0.55, wpb=50745.8, bsz=3062.5, num_updates=237200, lr=0.000116873, gnorm=0.284, loss_scale=8, train_wall=179, wall=440391
2021-03-19 11:56:58 | INFO | train_inner | epoch 012:  14645 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=27919.5, ups=0.55, wpb=51051.6, bsz=3083.5, num_updates=237300, lr=0.000116849, gnorm=0.277, loss_scale=8, train_wall=180, wall=440574
2021-03-19 12:00:01 | INFO | train_inner | epoch 012:  14745 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=27897, ups=0.55, wpb=50939.9, bsz=3079.6, num_updates=237400, lr=0.000116824, gnorm=0.277, loss_scale=8, train_wall=179, wall=440756
2021-03-19 12:03:04 | INFO | train_inner | epoch 012:  14845 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=27847.9, ups=0.55, wpb=50890.3, bsz=3072.3, num_updates=237500, lr=0.000116799, gnorm=0.281, loss_scale=8, train_wall=180, wall=440939
2021-03-19 12:06:06 | INFO | train_inner | epoch 012:  14945 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27899.7, ups=0.55, wpb=50925.3, bsz=2950.6, num_updates=237600, lr=0.000116775, gnorm=0.277, loss_scale=8, train_wall=179, wall=441122
2021-03-19 12:08:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 12:09:10 | INFO | train_inner | epoch 012:  15046 / 20258 loss=3.451, nll_loss=1.756, ppl=3.38, wps=27581.4, ups=0.54, wpb=50837.4, bsz=2959.2, num_updates=237700, lr=0.00011675, gnorm=0.284, loss_scale=8, train_wall=181, wall=441306
2021-03-19 12:12:12 | INFO | train_inner | epoch 012:  15146 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=27890.3, ups=0.55, wpb=50745.7, bsz=2871.8, num_updates=237800, lr=0.000116726, gnorm=0.288, loss_scale=8, train_wall=179, wall=441488
2021-03-19 12:15:15 | INFO | train_inner | epoch 012:  15246 / 20258 loss=3.467, nll_loss=1.774, ppl=3.42, wps=27875, ups=0.55, wpb=50798.6, bsz=3002.5, num_updates=237900, lr=0.000116701, gnorm=0.283, loss_scale=8, train_wall=179, wall=441670
2021-03-19 12:18:17 | INFO | train_inner | epoch 012:  15346 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27859.4, ups=0.55, wpb=50911, bsz=2993.6, num_updates=238000, lr=0.000116677, gnorm=0.28, loss_scale=8, train_wall=179, wall=441853
2021-03-19 12:21:20 | INFO | train_inner | epoch 012:  15446 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27816.1, ups=0.55, wpb=50686.9, bsz=3004.9, num_updates=238100, lr=0.000116652, gnorm=0.283, loss_scale=8, train_wall=179, wall=442035
2021-03-19 12:24:22 | INFO | train_inner | epoch 012:  15546 / 20258 loss=3.471, nll_loss=1.78, ppl=3.43, wps=27896.8, ups=0.55, wpb=50783.3, bsz=3063.8, num_updates=238200, lr=0.000116628, gnorm=0.287, loss_scale=8, train_wall=179, wall=442217
2021-03-19 12:27:24 | INFO | train_inner | epoch 012:  15646 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27776.6, ups=0.55, wpb=50693.8, bsz=2980.5, num_updates=238300, lr=0.000116603, gnorm=0.286, loss_scale=8, train_wall=179, wall=442400
2021-03-19 12:30:27 | INFO | train_inner | epoch 012:  15746 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27867.1, ups=0.55, wpb=50889.7, bsz=2966.8, num_updates=238400, lr=0.000116579, gnorm=0.277, loss_scale=8, train_wall=179, wall=442582
2021-03-19 12:33:29 | INFO | train_inner | epoch 012:  15846 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=27804.7, ups=0.55, wpb=50626.4, bsz=3002.7, num_updates=238500, lr=0.000116554, gnorm=0.281, loss_scale=8, train_wall=179, wall=442764
2021-03-19 12:36:31 | INFO | train_inner | epoch 012:  15946 / 20258 loss=3.464, nll_loss=1.771, ppl=3.41, wps=27934.7, ups=0.55, wpb=51025.1, bsz=2972.2, num_updates=238600, lr=0.00011653, gnorm=0.277, loss_scale=8, train_wall=179, wall=442947
2021-03-19 12:39:35 | INFO | train_inner | epoch 012:  16046 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27846, ups=0.55, wpb=50964.9, bsz=3053.7, num_updates=238700, lr=0.000116505, gnorm=0.286, loss_scale=16, train_wall=180, wall=443130
2021-03-19 12:42:38 | INFO | train_inner | epoch 012:  16146 / 20258 loss=3.462, nll_loss=1.77, ppl=3.41, wps=27882.3, ups=0.54, wpb=51167.2, bsz=3055.4, num_updates=238800, lr=0.000116481, gnorm=0.279, loss_scale=16, train_wall=180, wall=443314
2021-03-19 12:43:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 12:45:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 12:45:45 | INFO | train_inner | epoch 012:  16248 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=27401.3, ups=0.54, wpb=51120.1, bsz=3033, num_updates=238900, lr=0.000116457, gnorm=0.284, loss_scale=4, train_wall=183, wall=443500
2021-03-19 12:48:47 | INFO | train_inner | epoch 012:  16348 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27898.5, ups=0.55, wpb=50982.9, bsz=3020.9, num_updates=239000, lr=0.000116432, gnorm=0.28, loss_scale=4, train_wall=180, wall=443683
2021-03-19 12:51:50 | INFO | train_inner | epoch 012:  16448 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=27809.6, ups=0.55, wpb=50788, bsz=3000, num_updates=239100, lr=0.000116408, gnorm=0.279, loss_scale=4, train_wall=179, wall=443865
2021-03-19 12:54:52 | INFO | train_inner | epoch 012:  16548 / 20258 loss=3.456, nll_loss=1.763, ppl=3.4, wps=27840.4, ups=0.55, wpb=50745.4, bsz=3048.1, num_updates=239200, lr=0.000116384, gnorm=0.283, loss_scale=4, train_wall=179, wall=444048
2021-03-19 12:57:55 | INFO | train_inner | epoch 012:  16648 / 20258 loss=3.467, nll_loss=1.775, ppl=3.42, wps=27947.4, ups=0.55, wpb=50977.5, bsz=3059, num_updates=239300, lr=0.000116359, gnorm=0.28, loss_scale=4, train_wall=179, wall=444230
2021-03-19 13:00:57 | INFO | train_inner | epoch 012:  16748 / 20258 loss=3.478, nll_loss=1.788, ppl=3.45, wps=27926.5, ups=0.55, wpb=50850.2, bsz=3028.2, num_updates=239400, lr=0.000116335, gnorm=0.286, loss_scale=4, train_wall=179, wall=444412
2021-03-19 13:03:59 | INFO | train_inner | epoch 012:  16848 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27888.5, ups=0.55, wpb=50954, bsz=3094.1, num_updates=239500, lr=0.000116311, gnorm=0.281, loss_scale=4, train_wall=179, wall=444595
2021-03-19 13:07:03 | INFO | train_inner | epoch 012:  16948 / 20258 loss=3.465, nll_loss=1.774, ppl=3.42, wps=27939.5, ups=0.55, wpb=51149.5, bsz=3041, num_updates=239600, lr=0.000116286, gnorm=0.282, loss_scale=4, train_wall=180, wall=444778
2021-03-19 13:10:05 | INFO | train_inner | epoch 012:  17048 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=27855.9, ups=0.55, wpb=50915.6, bsz=3020.7, num_updates=239700, lr=0.000116262, gnorm=0.284, loss_scale=4, train_wall=180, wall=444961
2021-03-19 13:13:08 | INFO | train_inner | epoch 012:  17148 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27893.8, ups=0.55, wpb=51041.3, bsz=3076.9, num_updates=239800, lr=0.000116238, gnorm=0.279, loss_scale=4, train_wall=179, wall=445144
2021-03-19 13:16:10 | INFO | train_inner | epoch 012:  17248 / 20258 loss=3.47, nll_loss=1.779, ppl=3.43, wps=27943.3, ups=0.55, wpb=50884.3, bsz=2956.6, num_updates=239900, lr=0.000116214, gnorm=0.28, loss_scale=4, train_wall=179, wall=445326
2021-03-19 13:19:12 | INFO | train_inner | epoch 012:  17348 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=27881.7, ups=0.55, wpb=50769.7, bsz=2967.2, num_updates=240000, lr=0.00011619, gnorm=0.281, loss_scale=8, train_wall=179, wall=445508
2021-03-19 13:19:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 13:19:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:31 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.869 | nll_loss 2.156 | ppl 4.46 | bleu 29.98 | wps 4347.4 | wpb 2432 | bsz 90.4 | num_updates 240000 | best_loss 3.869
2021-03-19 13:19:31 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 13:19:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:19:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 13:19:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 13:19:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 13:20:24 | INFO | valid1 | epoch 012 | valid on 'valid1' subset | loss 3.875 | nll_loss 2.184 | ppl 4.55 | bleu 27.89 | wps 4220.7 | wpb 2359.4 | bsz 106.4 | num_updates 240000 | best_loss 3.875
2021-03-19 13:20:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 13:20:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_12_240000.pt (epoch 12 @ 240000 updates, score 3.869) (writing took 6.37180533260107 seconds)
2021-03-19 13:23:33 | INFO | train_inner | epoch 012:  17448 / 20258 loss=3.473, nll_loss=1.782, ppl=3.44, wps=19510.6, ups=0.38, wpb=50761.5, bsz=3093.8, num_updates=240100, lr=0.000116165, gnorm=0.283, loss_scale=8, train_wall=179, wall=445768
2021-03-19 13:26:35 | INFO | train_inner | epoch 012:  17548 / 20258 loss=3.468, nll_loss=1.777, ppl=3.43, wps=27955.2, ups=0.55, wpb=50904.2, bsz=3004, num_updates=240200, lr=0.000116141, gnorm=0.28, loss_scale=8, train_wall=179, wall=445950
2021-03-19 13:29:38 | INFO | train_inner | epoch 012:  17648 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27808.6, ups=0.55, wpb=50852.1, bsz=3110.6, num_updates=240300, lr=0.000116117, gnorm=0.278, loss_scale=8, train_wall=179, wall=446133
2021-03-19 13:32:40 | INFO | train_inner | epoch 012:  17748 / 20258 loss=3.481, nll_loss=1.791, ppl=3.46, wps=28013, ups=0.55, wpb=51092, bsz=2947.1, num_updates=240400, lr=0.000116093, gnorm=0.281, loss_scale=8, train_wall=179, wall=446316
2021-03-19 13:35:42 | INFO | train_inner | epoch 012:  17848 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27924.8, ups=0.55, wpb=50868.4, bsz=2932, num_updates=240500, lr=0.000116069, gnorm=0.281, loss_scale=8, train_wall=179, wall=446498
2021-03-19 13:38:45 | INFO | train_inner | epoch 012:  17948 / 20258 loss=3.468, nll_loss=1.777, ppl=3.43, wps=27849.4, ups=0.55, wpb=50879, bsz=2966.2, num_updates=240600, lr=0.000116045, gnorm=0.281, loss_scale=8, train_wall=179, wall=446680
2021-03-19 13:41:48 | INFO | train_inner | epoch 012:  18048 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27971.6, ups=0.55, wpb=51101.3, bsz=3024, num_updates=240700, lr=0.00011602, gnorm=0.287, loss_scale=8, train_wall=179, wall=446863
2021-03-19 13:44:50 | INFO | train_inner | epoch 012:  18148 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27780.5, ups=0.55, wpb=50742.7, bsz=2959, num_updates=240800, lr=0.000115996, gnorm=0.279, loss_scale=8, train_wall=179, wall=447046
2021-03-19 13:47:52 | INFO | train_inner | epoch 012:  18248 / 20258 loss=3.475, nll_loss=1.784, ppl=3.44, wps=27887.6, ups=0.55, wpb=50714.5, bsz=2936.9, num_updates=240900, lr=0.000115972, gnorm=0.28, loss_scale=8, train_wall=179, wall=447228
2021-03-19 13:50:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 13:50:56 | INFO | train_inner | epoch 012:  18349 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27649.7, ups=0.54, wpb=50819.5, bsz=3090.6, num_updates=241000, lr=0.000115948, gnorm=0.282, loss_scale=8, train_wall=181, wall=447411
2021-03-19 13:53:59 | INFO | train_inner | epoch 012:  18449 / 20258 loss=3.467, nll_loss=1.776, ppl=3.42, wps=27865.2, ups=0.55, wpb=50933, bsz=3153.3, num_updates=241100, lr=0.000115924, gnorm=0.28, loss_scale=8, train_wall=179, wall=447594
2021-03-19 13:54:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 13:57:03 | INFO | train_inner | epoch 012:  18550 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27462.3, ups=0.54, wpb=50716.7, bsz=3024.2, num_updates=241200, lr=0.0001159, gnorm=0.281, loss_scale=4, train_wall=181, wall=447779
2021-03-19 14:00:06 | INFO | train_inner | epoch 012:  18650 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=28001.9, ups=0.55, wpb=51208.5, bsz=2949.4, num_updates=241300, lr=0.000115876, gnorm=0.277, loss_scale=4, train_wall=180, wall=447962
2021-03-19 14:03:09 | INFO | train_inner | epoch 012:  18750 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27899.6, ups=0.55, wpb=50923.9, bsz=2849, num_updates=241400, lr=0.000115852, gnorm=0.286, loss_scale=4, train_wall=179, wall=448144
2021-03-19 14:06:12 | INFO | train_inner | epoch 012:  18850 / 20258 loss=3.445, nll_loss=1.751, ppl=3.37, wps=27906.1, ups=0.55, wpb=51022.6, bsz=3039.9, num_updates=241500, lr=0.000115828, gnorm=0.278, loss_scale=4, train_wall=180, wall=448327
2021-03-19 14:09:14 | INFO | train_inner | epoch 012:  18950 / 20258 loss=3.482, nll_loss=1.792, ppl=3.46, wps=27839.3, ups=0.55, wpb=50828.6, bsz=2953, num_updates=241600, lr=0.000115804, gnorm=0.279, loss_scale=4, train_wall=179, wall=448510
2021-03-19 14:12:17 | INFO | train_inner | epoch 012:  19050 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27890, ups=0.55, wpb=50904.5, bsz=2976.6, num_updates=241700, lr=0.00011578, gnorm=0.282, loss_scale=4, train_wall=179, wall=448692
2021-03-19 14:15:19 | INFO | train_inner | epoch 012:  19150 / 20258 loss=3.473, nll_loss=1.782, ppl=3.44, wps=27901.5, ups=0.55, wpb=50957.1, bsz=3063, num_updates=241800, lr=0.000115756, gnorm=0.281, loss_scale=4, train_wall=179, wall=448875
2021-03-19 14:18:22 | INFO | train_inner | epoch 012:  19250 / 20258 loss=3.462, nll_loss=1.77, ppl=3.41, wps=27947.5, ups=0.55, wpb=50996.8, bsz=3051.8, num_updates=241900, lr=0.000115732, gnorm=0.276, loss_scale=4, train_wall=179, wall=449057
2021-03-19 14:21:25 | INFO | train_inner | epoch 012:  19350 / 20258 loss=3.472, nll_loss=1.78, ppl=3.43, wps=27958.6, ups=0.55, wpb=51200.1, bsz=2929.4, num_updates=242000, lr=0.000115708, gnorm=0.277, loss_scale=4, train_wall=180, wall=449240
2021-03-19 14:24:27 | INFO | train_inner | epoch 012:  19450 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27871.4, ups=0.55, wpb=50822.2, bsz=2944.2, num_updates=242100, lr=0.000115684, gnorm=0.277, loss_scale=4, train_wall=179, wall=449423
2021-03-19 14:27:30 | INFO | train_inner | epoch 012:  19550 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27761.3, ups=0.55, wpb=50680.5, bsz=2938.7, num_updates=242200, lr=0.000115661, gnorm=0.284, loss_scale=8, train_wall=179, wall=449605
2021-03-19 14:30:32 | INFO | train_inner | epoch 012:  19650 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=27974.7, ups=0.55, wpb=51073.2, bsz=3080.6, num_updates=242300, lr=0.000115637, gnorm=0.278, loss_scale=8, train_wall=179, wall=449788
2021-03-19 14:33:34 | INFO | train_inner | epoch 012:  19750 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=27952.5, ups=0.55, wpb=50896.2, bsz=2890.3, num_updates=242400, lr=0.000115613, gnorm=0.278, loss_scale=8, train_wall=179, wall=449970
2021-03-19 14:36:37 | INFO | train_inner | epoch 012:  19850 / 20258 loss=3.468, nll_loss=1.776, ppl=3.42, wps=27907.4, ups=0.55, wpb=50920.5, bsz=3044.5, num_updates=242500, lr=0.000115589, gnorm=0.278, loss_scale=8, train_wall=179, wall=450152
2021-03-19 14:39:40 | INFO | train_inner | epoch 012:  19950 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27762, ups=0.54, wpb=50940, bsz=3030.7, num_updates=242600, lr=0.000115565, gnorm=0.281, loss_scale=8, train_wall=180, wall=450336
2021-03-19 14:42:42 | INFO | train_inner | epoch 012:  20050 / 20258 loss=3.47, nll_loss=1.779, ppl=3.43, wps=27846.1, ups=0.55, wpb=50547.1, bsz=2895.9, num_updates=242700, lr=0.000115541, gnorm=0.285, loss_scale=8, train_wall=178, wall=450517
2021-03-19 14:45:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 14:46:00 | INFO | train_inner | epoch 012:  20151 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=25560.8, ups=0.5, wpb=50677.6, bsz=3062.7, num_updates=242800, lr=0.000115518, gnorm=0.276, loss_scale=4, train_wall=195, wall=450716
2021-03-19 14:50:22 | INFO | train_inner | epoch 012:  20251 / 20258 loss=3.465, nll_loss=1.774, ppl=3.42, wps=19486.5, ups=0.38, wpb=51029.3, bsz=3221.3, num_updates=242900, lr=0.000115494, gnorm=0.282, loss_scale=4, train_wall=259, wall=450978
2021-03-19 14:50:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 14:50:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:50:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:50:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:50:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:50:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:50:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:50:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:50:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:50:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:50:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:50:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:50:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:50:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:50:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:50:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:50:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:50:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:50:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:50:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:50:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:50:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:21 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.872 | nll_loss 2.159 | ppl 4.47 | bleu 29.76 | wps 2146.1 | wpb 2432 | bsz 90.4 | num_updates 242907 | best_loss 3.869
2021-03-19 14:51:21 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 14:51:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:51:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:51:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:51:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:52:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:52:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:52:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:52:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:52:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:52:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:52:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:52:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:52:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:52:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:52:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:52:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:52:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:52:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:52:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:52:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 14:52:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 14:52:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 14:53:10 | INFO | valid1 | epoch 012 | valid on 'valid1' subset | loss 3.876 | nll_loss 2.187 | ppl 4.55 | bleu 27.74 | wps 2037.8 | wpb 2359.4 | bsz 106.4 | num_updates 242907 | best_loss 3.869
2021-03-19 14:53:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 14:53:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint12.pt (epoch 12 @ 242907 updates, score 3.872) (writing took 4.697176660876721 seconds)
2021-03-19 14:53:15 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-03-19 14:53:15 | INFO | train | epoch 012 | loss 3.46 | nll_loss 1.767 | ppl 3.4 | wps 27453.3 | ups 0.54 | wpb 50905.3 | bsz 3010.2 | num_updates 242907 | lr 0.000115492 | gnorm 0.281 | loss_scale 4 | train_wall 36427 | wall 451150
2021-03-19 14:53:15 | INFO | fairseq.trainer | begin training epoch 13
2021-03-19 14:58:02 | INFO | train_inner | epoch 013:     93 / 20258 loss=3.446, nll_loss=1.751, ppl=3.37, wps=11038, ups=0.22, wpb=50765.7, bsz=2979.4, num_updates=243000, lr=0.00011547, gnorm=0.278, loss_scale=4, train_wall=306, wall=451438
2021-03-19 15:03:10 | INFO | train_inner | epoch 013:    193 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=16403.6, ups=0.32, wpb=50545.5, bsz=2999.3, num_updates=243100, lr=0.000115446, gnorm=0.28, loss_scale=4, train_wall=305, wall=451746
2021-03-19 15:08:19 | INFO | train_inner | epoch 013:    293 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=16400.1, ups=0.32, wpb=50728.3, bsz=3037, num_updates=243200, lr=0.000115423, gnorm=0.284, loss_scale=4, train_wall=306, wall=452055
2021-03-19 15:13:27 | INFO | train_inner | epoch 013:    393 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=16456.6, ups=0.32, wpb=50654.5, bsz=2968.6, num_updates=243300, lr=0.000115399, gnorm=0.282, loss_scale=4, train_wall=305, wall=452363
2021-03-19 15:18:36 | INFO | train_inner | epoch 013:    493 / 20258 loss=3.449, nll_loss=1.755, ppl=3.37, wps=16519.8, ups=0.32, wpb=50934.6, bsz=3013.3, num_updates=243400, lr=0.000115375, gnorm=0.281, loss_scale=4, train_wall=305, wall=452671
2021-03-19 15:23:44 | INFO | train_inner | epoch 013:    593 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=16480.2, ups=0.32, wpb=50871.7, bsz=3038.7, num_updates=243500, lr=0.000115351, gnorm=0.28, loss_scale=4, train_wall=305, wall=452980
2021-03-19 15:28:54 | INFO | train_inner | epoch 013:    693 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=16531.3, ups=0.32, wpb=51203.8, bsz=3077.6, num_updates=243600, lr=0.000115328, gnorm=0.278, loss_scale=4, train_wall=307, wall=453290
2021-03-19 15:34:01 | INFO | train_inner | epoch 013:    793 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=16543.1, ups=0.33, wpb=50806.5, bsz=2966.8, num_updates=243700, lr=0.000115304, gnorm=0.278, loss_scale=4, train_wall=304, wall=453597
2021-03-19 15:39:09 | INFO | train_inner | epoch 013:    893 / 20258 loss=3.446, nll_loss=1.75, ppl=3.36, wps=16494.9, ups=0.32, wpb=50758.3, bsz=2939.7, num_updates=243800, lr=0.00011528, gnorm=0.283, loss_scale=4, train_wall=305, wall=453904
2021-03-19 15:44:19 | INFO | train_inner | epoch 013:    993 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=16395.8, ups=0.32, wpb=50806.2, bsz=3134, num_updates=243900, lr=0.000115257, gnorm=0.276, loss_scale=8, train_wall=307, wall=454214
2021-03-19 15:49:27 | INFO | train_inner | epoch 013:   1093 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=16510, ups=0.32, wpb=50971.7, bsz=3106.8, num_updates=244000, lr=0.000115233, gnorm=0.277, loss_scale=8, train_wall=306, wall=454523
2021-03-19 15:54:35 | INFO | train_inner | epoch 013:   1193 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=16479.6, ups=0.33, wpb=50702.2, bsz=2975.4, num_updates=244100, lr=0.00011521, gnorm=0.279, loss_scale=8, train_wall=304, wall=454831
2021-03-19 15:59:44 | INFO | train_inner | epoch 013:   1293 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=16517.4, ups=0.32, wpb=51018.5, bsz=2975.8, num_updates=244200, lr=0.000115186, gnorm=0.286, loss_scale=8, train_wall=306, wall=455140
2021-03-19 16:04:53 | INFO | train_inner | epoch 013:   1393 / 20258 loss=3.454, nll_loss=1.761, ppl=3.39, wps=16530.8, ups=0.32, wpb=51111.8, bsz=3069.8, num_updates=244300, lr=0.000115162, gnorm=0.292, loss_scale=8, train_wall=306, wall=455449
2021-03-19 16:10:00 | INFO | train_inner | epoch 013:   1493 / 20258 loss=3.452, nll_loss=1.757, ppl=3.38, wps=16567.9, ups=0.33, wpb=50843.4, bsz=2897.8, num_updates=244400, lr=0.000115139, gnorm=0.276, loss_scale=8, train_wall=304, wall=455756
2021-03-19 16:15:09 | INFO | train_inner | epoch 013:   1593 / 20258 loss=3.438, nll_loss=1.741, ppl=3.34, wps=16515, ups=0.32, wpb=51066.4, bsz=3009.4, num_updates=244500, lr=0.000115115, gnorm=0.281, loss_scale=8, train_wall=306, wall=456065
2021-03-19 16:20:18 | INFO | train_inner | epoch 013:   1693 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=16500.6, ups=0.32, wpb=50903.1, bsz=2947, num_updates=244600, lr=0.000115092, gnorm=0.283, loss_scale=8, train_wall=306, wall=456373
2021-03-19 16:24:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 16:25:30 | INFO | train_inner | epoch 013:   1794 / 20258 loss=3.449, nll_loss=1.755, ppl=3.37, wps=16301.2, ups=0.32, wpb=50870.1, bsz=3036.8, num_updates=244700, lr=0.000115068, gnorm=0.286, loss_scale=4, train_wall=309, wall=456685
2021-03-19 16:30:38 | INFO | train_inner | epoch 013:   1894 / 20258 loss=3.457, nll_loss=1.763, ppl=3.39, wps=16582.6, ups=0.32, wpb=51159, bsz=2917.6, num_updates=244800, lr=0.000115045, gnorm=0.279, loss_scale=4, train_wall=305, wall=456994
2021-03-19 16:35:47 | INFO | train_inner | epoch 013:   1994 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=16448.9, ups=0.32, wpb=50828.3, bsz=3005.7, num_updates=244900, lr=0.000115021, gnorm=0.286, loss_scale=4, train_wall=306, wall=457303
2021-03-19 16:40:55 | INFO | train_inner | epoch 013:   2094 / 20258 loss=3.461, nll_loss=1.767, ppl=3.4, wps=16550.1, ups=0.32, wpb=50964, bsz=2930.4, num_updates=245000, lr=0.000114998, gnorm=0.286, loss_scale=4, train_wall=305, wall=457611
2021-03-19 16:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 16:40:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:40:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:40:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:40:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:40:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:40:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:40:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:40:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:40:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:40:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:40:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:40:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:34 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.871 | nll_loss 2.156 | ppl 4.46 | bleu 29.68 | wps 2110.5 | wpb 2432 | bsz 90.4 | num_updates 245000 | best_loss 3.869
2021-03-19 16:41:34 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 16:41:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:46 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:46 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:46 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:41:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:41:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:41:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:42:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 16:42:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 16:42:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 16:43:23 | INFO | valid1 | epoch 013 | valid on 'valid1' subset | loss 3.874 | nll_loss 2.183 | ppl 4.54 | bleu 27.9 | wps 2037.8 | wpb 2359.4 | bsz 106.4 | num_updates 245000 | best_loss 3.869
2021-03-19 16:43:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 16:43:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_13_245000.pt (epoch 13 @ 245000 updates, score 3.871) (writing took 5.018604647833854 seconds)
2021-03-19 16:48:35 | INFO | train_inner | epoch 013:   2194 / 20258 loss=3.449, nll_loss=1.754, ppl=3.37, wps=11062, ups=0.22, wpb=50851.1, bsz=3020.7, num_updates=245100, lr=0.000114974, gnorm=0.278, loss_scale=4, train_wall=304, wall=458071
2021-03-19 16:53:44 | INFO | train_inner | epoch 013:   2294 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=16452.5, ups=0.32, wpb=50833.9, bsz=3064.3, num_updates=245200, lr=0.000114951, gnorm=0.285, loss_scale=4, train_wall=306, wall=458380
2021-03-19 16:58:54 | INFO | train_inner | epoch 013:   2394 / 20258 loss=3.434, nll_loss=1.739, ppl=3.34, wps=16446, ups=0.32, wpb=50961.9, bsz=3140.2, num_updates=245300, lr=0.000114927, gnorm=0.28, loss_scale=4, train_wall=307, wall=458689
2021-03-19 17:04:03 | INFO | train_inner | epoch 013:   2494 / 20258 loss=3.446, nll_loss=1.751, ppl=3.37, wps=16449, ups=0.32, wpb=50839.5, bsz=3027.8, num_updates=245400, lr=0.000114904, gnorm=0.284, loss_scale=4, train_wall=306, wall=458998
2021-03-19 17:09:12 | INFO | train_inner | epoch 013:   2594 / 20258 loss=3.457, nll_loss=1.763, ppl=3.39, wps=16543.9, ups=0.32, wpb=51097.3, bsz=2947, num_updates=245500, lr=0.000114881, gnorm=0.281, loss_scale=4, train_wall=306, wall=459307
2021-03-19 17:14:20 | INFO | train_inner | epoch 013:   2694 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=16461.4, ups=0.32, wpb=50730.9, bsz=3152.3, num_updates=245600, lr=0.000114857, gnorm=0.283, loss_scale=4, train_wall=305, wall=459616
2021-03-19 17:19:30 | INFO | train_inner | epoch 013:   2794 / 20258 loss=3.442, nll_loss=1.747, ppl=3.36, wps=16470.6, ups=0.32, wpb=51053.8, bsz=3206.2, num_updates=245700, lr=0.000114834, gnorm=0.28, loss_scale=4, train_wall=307, wall=459925
2021-03-19 17:24:38 | INFO | train_inner | epoch 013:   2894 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=16470.2, ups=0.32, wpb=50754.6, bsz=2929.4, num_updates=245800, lr=0.00011481, gnorm=0.283, loss_scale=8, train_wall=305, wall=460234
2021-03-19 17:29:47 | INFO | train_inner | epoch 013:   2994 / 20258 loss=3.44, nll_loss=1.744, ppl=3.35, wps=16550.4, ups=0.32, wpb=51139.2, bsz=3113.1, num_updates=245900, lr=0.000114787, gnorm=0.282, loss_scale=8, train_wall=306, wall=460543
2021-03-19 17:34:57 | INFO | train_inner | epoch 013:   3094 / 20258 loss=3.453, nll_loss=1.759, ppl=3.39, wps=16398.6, ups=0.32, wpb=50769.3, bsz=3069.1, num_updates=246000, lr=0.000114764, gnorm=0.285, loss_scale=8, train_wall=306, wall=460852
2021-03-19 17:40:06 | INFO | train_inner | epoch 013:   3194 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=16532.4, ups=0.32, wpb=51184.7, bsz=3081.6, num_updates=246100, lr=0.00011474, gnorm=0.279, loss_scale=8, train_wall=306, wall=461162
2021-03-19 17:45:16 | INFO | train_inner | epoch 013:   3294 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=16514, ups=0.32, wpb=51078.8, bsz=3003.6, num_updates=246200, lr=0.000114717, gnorm=0.281, loss_scale=8, train_wall=306, wall=461471
2021-03-19 17:50:25 | INFO | train_inner | epoch 013:   3394 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=16471.4, ups=0.32, wpb=50966.7, bsz=3019.4, num_updates=246300, lr=0.000114694, gnorm=0.279, loss_scale=8, train_wall=306, wall=461781
2021-03-19 17:55:32 | INFO | train_inner | epoch 013:   3494 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=16412, ups=0.33, wpb=50406.1, bsz=3008.4, num_updates=246400, lr=0.000114671, gnorm=0.281, loss_scale=8, train_wall=304, wall=462088
2021-03-19 18:00:41 | INFO | train_inner | epoch 013:   3594 / 20258 loss=3.439, nll_loss=1.743, ppl=3.35, wps=16441.4, ups=0.32, wpb=50777.5, bsz=2933.8, num_updates=246500, lr=0.000114647, gnorm=0.281, loss_scale=8, train_wall=306, wall=462397
2021-03-19 18:05:50 | INFO | train_inner | epoch 013:   3694 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=16442.9, ups=0.32, wpb=50831.9, bsz=2969.9, num_updates=246600, lr=0.000114624, gnorm=0.289, loss_scale=8, train_wall=306, wall=462706
2021-03-19 18:10:59 | INFO | train_inner | epoch 013:   3794 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=16522.1, ups=0.32, wpb=51028.3, bsz=3031.3, num_updates=246700, lr=0.000114601, gnorm=0.282, loss_scale=8, train_wall=306, wall=463015
2021-03-19 18:16:07 | INFO | train_inner | epoch 013:   3894 / 20258 loss=3.458, nll_loss=1.764, ppl=3.4, wps=16471.5, ups=0.32, wpb=50724.5, bsz=3019.9, num_updates=246800, lr=0.000114578, gnorm=0.287, loss_scale=16, train_wall=305, wall=463323
2021-03-19 18:21:16 | INFO | train_inner | epoch 013:   3994 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=16496.8, ups=0.32, wpb=50944.1, bsz=2999.2, num_updates=246900, lr=0.000114554, gnorm=0.281, loss_scale=16, train_wall=306, wall=463631
2021-03-19 18:24:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 18:25:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 18:26:31 | INFO | train_inner | epoch 013:   4096 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=16233.4, ups=0.32, wpb=51175.1, bsz=2966.1, num_updates=247000, lr=0.000114531, gnorm=0.282, loss_scale=4, train_wall=312, wall=463947
2021-03-19 18:31:41 | INFO | train_inner | epoch 013:   4196 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=16491.3, ups=0.32, wpb=51057.3, bsz=2966.5, num_updates=247100, lr=0.000114508, gnorm=0.28, loss_scale=4, train_wall=306, wall=464256
2021-03-19 18:36:50 | INFO | train_inner | epoch 013:   4296 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=16435.1, ups=0.32, wpb=50859.3, bsz=3045.3, num_updates=247200, lr=0.000114485, gnorm=0.279, loss_scale=4, train_wall=306, wall=464566
2021-03-19 18:41:59 | INFO | train_inner | epoch 013:   4396 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=16504.4, ups=0.32, wpb=50937.2, bsz=2996.2, num_updates=247300, lr=0.000114462, gnorm=0.279, loss_scale=4, train_wall=306, wall=464874
2021-03-19 18:47:08 | INFO | train_inner | epoch 013:   4496 / 20258 loss=3.464, nll_loss=1.772, ppl=3.41, wps=16488.4, ups=0.32, wpb=50967.8, bsz=3084.7, num_updates=247400, lr=0.000114439, gnorm=0.284, loss_scale=4, train_wall=306, wall=465183
2021-03-19 18:52:18 | INFO | train_inner | epoch 013:   4596 / 20258 loss=3.437, nll_loss=1.741, ppl=3.34, wps=16399.7, ups=0.32, wpb=50781.6, bsz=2995.8, num_updates=247500, lr=0.000114416, gnorm=0.279, loss_scale=4, train_wall=307, wall=465493
2021-03-19 18:57:27 | INFO | train_inner | epoch 013:   4696 / 20258 loss=3.44, nll_loss=1.745, ppl=3.35, wps=16496.8, ups=0.32, wpb=51070.7, bsz=2980.6, num_updates=247600, lr=0.000114392, gnorm=0.273, loss_scale=4, train_wall=306, wall=465803
2021-03-19 19:02:35 | INFO | train_inner | epoch 013:   4796 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=16488.2, ups=0.32, wpb=50827.6, bsz=3032.3, num_updates=247700, lr=0.000114369, gnorm=0.281, loss_scale=4, train_wall=305, wall=466111
2021-03-19 19:07:45 | INFO | train_inner | epoch 013:   4896 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=16499, ups=0.32, wpb=51091, bsz=2933.2, num_updates=247800, lr=0.000114346, gnorm=0.28, loss_scale=4, train_wall=307, wall=466421
2021-03-19 19:12:53 | INFO | train_inner | epoch 013:   4996 / 20258 loss=3.449, nll_loss=1.755, ppl=3.37, wps=16452.6, ups=0.32, wpb=50710.8, bsz=2967.9, num_updates=247900, lr=0.000114323, gnorm=0.281, loss_scale=4, train_wall=305, wall=466729
2021-03-19 19:18:01 | INFO | train_inner | epoch 013:   5096 / 20258 loss=3.452, nll_loss=1.759, ppl=3.38, wps=16513.7, ups=0.32, wpb=50869.6, bsz=3060.6, num_updates=248000, lr=0.0001143, gnorm=0.28, loss_scale=8, train_wall=305, wall=467037
2021-03-19 19:23:10 | INFO | train_inner | epoch 013:   5196 / 20258 loss=3.447, nll_loss=1.753, ppl=3.37, wps=16423.7, ups=0.32, wpb=50687.1, bsz=2911.8, num_updates=248100, lr=0.000114277, gnorm=0.278, loss_scale=8, train_wall=305, wall=467345
2021-03-19 19:28:18 | INFO | train_inner | epoch 013:   5296 / 20258 loss=3.449, nll_loss=1.754, ppl=3.37, wps=16449.2, ups=0.32, wpb=50735.3, bsz=3099.5, num_updates=248200, lr=0.000114254, gnorm=0.279, loss_scale=8, train_wall=305, wall=467654
2021-03-19 19:33:29 | INFO | train_inner | epoch 013:   5396 / 20258 loss=3.441, nll_loss=1.746, ppl=3.35, wps=16450.4, ups=0.32, wpb=51110.8, bsz=3017.6, num_updates=248300, lr=0.000114231, gnorm=0.282, loss_scale=8, train_wall=308, wall=467965
2021-03-19 19:38:37 | INFO | train_inner | epoch 013:   5496 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=16452.7, ups=0.32, wpb=50678.2, bsz=2963.9, num_updates=248400, lr=0.000114208, gnorm=0.285, loss_scale=8, train_wall=305, wall=468273
2021-03-19 19:42:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-19 19:43:51 | INFO | train_inner | epoch 013:   5597 / 20258 loss=3.449, nll_loss=1.755, ppl=3.37, wps=16326.2, ups=0.32, wpb=51253.9, bsz=3088.2, num_updates=248500, lr=0.000114185, gnorm=0.279, loss_scale=4, train_wall=311, wall=468587
2021-03-19 19:49:00 | INFO | train_inner | epoch 013:   5697 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=16471.8, ups=0.32, wpb=50855.3, bsz=3054.2, num_updates=248600, lr=0.000114162, gnorm=0.279, loss_scale=4, train_wall=306, wall=468895
2021-03-19 19:54:09 | INFO | train_inner | epoch 013:   5797 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=16436.1, ups=0.32, wpb=50767.5, bsz=2987.3, num_updates=248700, lr=0.000114139, gnorm=0.276, loss_scale=4, train_wall=306, wall=469204
2021-03-19 19:59:17 | INFO | train_inner | epoch 013:   5897 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=16448, ups=0.32, wpb=50747.7, bsz=2961, num_updates=248800, lr=0.000114116, gnorm=0.281, loss_scale=4, train_wall=306, wall=469513
2021-03-19 20:04:26 | INFO | train_inner | epoch 013:   5997 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=16452.5, ups=0.32, wpb=50858.4, bsz=2947.7, num_updates=248900, lr=0.000114093, gnorm=0.285, loss_scale=4, train_wall=306, wall=469822
2021-03-19 20:09:34 | INFO | train_inner | epoch 013:   6097 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=16484.8, ups=0.32, wpb=50793.2, bsz=3178.6, num_updates=249000, lr=0.00011407, gnorm=0.289, loss_scale=4, train_wall=305, wall=470130
2021-03-19 20:14:44 | INFO | train_inner | epoch 013:   6197 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=16443.4, ups=0.32, wpb=50841.4, bsz=3115.3, num_updates=249100, lr=0.000114047, gnorm=0.283, loss_scale=4, train_wall=306, wall=470439
2021-03-19 20:19:54 | INFO | train_inner | epoch 013:   6297 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=16489.4, ups=0.32, wpb=51147.7, bsz=2977.7, num_updates=249200, lr=0.000114025, gnorm=0.281, loss_scale=4, train_wall=307, wall=470749
2021-03-19 20:25:03 | INFO | train_inner | epoch 013:   6397 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=16455.7, ups=0.32, wpb=50913, bsz=3033.7, num_updates=249300, lr=0.000114002, gnorm=0.28, loss_scale=4, train_wall=306, wall=471059
2021-03-19 20:30:13 | INFO | train_inner | epoch 013:   6497 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=16548.2, ups=0.32, wpb=51188.1, bsz=2950.9, num_updates=249400, lr=0.000113979, gnorm=0.285, loss_scale=4, train_wall=306, wall=471368
2021-03-19 20:35:22 | INFO | train_inner | epoch 013:   6597 / 20258 loss=3.439, nll_loss=1.743, ppl=3.35, wps=16518.6, ups=0.32, wpb=51114.4, bsz=2979, num_updates=249500, lr=0.000113956, gnorm=0.281, loss_scale=4, train_wall=306, wall=471677
2021-03-19 20:40:31 | INFO | train_inner | epoch 013:   6697 / 20258 loss=3.443, nll_loss=1.749, ppl=3.36, wps=16450.4, ups=0.32, wpb=50847.3, bsz=3043.3, num_updates=249600, lr=0.000113933, gnorm=0.283, loss_scale=8, train_wall=306, wall=471987
2021-03-19 20:45:41 | INFO | train_inner | epoch 013:   6797 / 20258 loss=3.428, nll_loss=1.731, ppl=3.32, wps=16459.3, ups=0.32, wpb=51093.5, bsz=3126.8, num_updates=249700, lr=0.00011391, gnorm=0.275, loss_scale=8, train_wall=307, wall=472297
2021-03-19 20:50:51 | INFO | train_inner | epoch 013:   6897 / 20258 loss=3.444, nll_loss=1.75, ppl=3.36, wps=16457.6, ups=0.32, wpb=50984.3, bsz=3072.7, num_updates=249800, lr=0.000113888, gnorm=0.279, loss_scale=8, train_wall=307, wall=472607
2021-03-19 20:56:01 | INFO | train_inner | epoch 013:   6997 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=16515.6, ups=0.32, wpb=51097.2, bsz=2964.2, num_updates=249900, lr=0.000113865, gnorm=0.281, loss_scale=8, train_wall=306, wall=472916
2021-03-19 21:01:10 | INFO | train_inner | epoch 013:   7097 / 20258 loss=3.452, nll_loss=1.759, ppl=3.38, wps=16477.7, ups=0.32, wpb=50971.5, bsz=3030.7, num_updates=250000, lr=0.000113842, gnorm=0.279, loss_scale=8, train_wall=306, wall=473226
2021-03-19 21:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-19 21:01:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:47 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.866 | nll_loss 2.155 | ppl 4.45 | bleu 29.95 | wps 2188 | wpb 2432 | bsz 90.4 | num_updates 250000 | best_loss 3.866
2021-03-19 21:01:47 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-19 21:01:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:01:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:01:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:01:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:02:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-19 21:02:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-19 21:02:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-19 21:03:37 | INFO | valid1 | epoch 013 | valid on 'valid1' subset | loss 3.872 | nll_loss 2.183 | ppl 4.54 | bleu 28.15 | wps 2021.9 | wpb 2359.4 | bsz 106.4 | num_updates 250000 | best_loss 3.869
2021-03-19 21:03:37 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-19 21:03:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_13_250000.pt (epoch 13 @ 250000 updates, score 3.866) (writing took 7.526045706123114 seconds)
2021-03-19 21:08:54 | INFO | train_inner | epoch 013:   7197 / 20258 loss=3.441, nll_loss=1.746, ppl=3.35, wps=11011.1, ups=0.22, wpb=51067.3, bsz=3074.6, num_updates=250100, lr=0.000113819, gnorm=0.285, loss_scale=8, train_wall=307, wall=473689
2021-03-19 21:14:01 | INFO | train_inner | epoch 013:   7297 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=16548.4, ups=0.33, wpb=50868.4, bsz=3018.2, num_updates=250200, lr=0.000113796, gnorm=0.285, loss_scale=8, train_wall=304, wall=473997
2021-03-19 21:19:08 | INFO | train_inner | epoch 013:   7397 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=16529.3, ups=0.33, wpb=50718.6, bsz=3042.1, num_updates=250300, lr=0.000113774, gnorm=0.288, loss_scale=8, train_wall=304, wall=474304
2021-03-19 21:24:16 | INFO | train_inner | epoch 013:   7497 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=16544.7, ups=0.32, wpb=50991, bsz=2974.2, num_updates=250400, lr=0.000113751, gnorm=0.281, loss_scale=8, train_wall=305, wall=474612
2021-03-19 21:29:25 | INFO | train_inner | epoch 013:   7597 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=16510.8, ups=0.32, wpb=51033.2, bsz=3024, num_updates=250500, lr=0.000113728, gnorm=0.285, loss_scale=8, train_wall=306, wall=474921
2021-03-19 21:34:35 | INFO | train_inner | epoch 013:   7697 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=16509.2, ups=0.32, wpb=51154.1, bsz=2930.6, num_updates=250600, lr=0.000113706, gnorm=0.28, loss_scale=16, train_wall=307, wall=475231
2021-03-19 21:36:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 21:39:45 | INFO | train_inner | epoch 013:   7798 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=16407.8, ups=0.32, wpb=50882.8, bsz=2945, num_updates=250700, lr=0.000113683, gnorm=0.288, loss_scale=8, train_wall=307, wall=475541
2021-03-19 21:44:53 | INFO | train_inner | epoch 013:   7898 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=16470.9, ups=0.32, wpb=50756.6, bsz=2982.3, num_updates=250800, lr=0.00011366, gnorm=0.278, loss_scale=8, train_wall=305, wall=475849
2021-03-19 21:50:01 | INFO | train_inner | epoch 013:   7998 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=16537.4, ups=0.32, wpb=50921.8, bsz=3052.6, num_updates=250900, lr=0.000113638, gnorm=0.286, loss_scale=8, train_wall=305, wall=476157
2021-03-19 21:55:09 | INFO | train_inner | epoch 013:   8098 / 20258 loss=3.458, nll_loss=1.766, ppl=3.4, wps=16493.8, ups=0.32, wpb=50754, bsz=3180.1, num_updates=251000, lr=0.000113615, gnorm=0.283, loss_scale=8, train_wall=305, wall=476465
2021-03-19 22:00:18 | INFO | train_inner | epoch 013:   8198 / 20258 loss=3.454, nll_loss=1.76, ppl=3.39, wps=16525, ups=0.32, wpb=51084.7, bsz=2959.4, num_updates=251100, lr=0.000113592, gnorm=0.279, loss_scale=8, train_wall=306, wall=476774
2021-03-19 22:05:27 | INFO | train_inner | epoch 013:   8298 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=16577.4, ups=0.32, wpb=51146.1, bsz=2974.7, num_updates=251200, lr=0.00011357, gnorm=0.286, loss_scale=8, train_wall=305, wall=477082
2021-03-19 22:10:37 | INFO | train_inner | epoch 013:   8398 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=16439.2, ups=0.32, wpb=50925.4, bsz=3037.8, num_updates=251300, lr=0.000113547, gnorm=0.278, loss_scale=8, train_wall=306, wall=477392
2021-03-19 22:15:45 | INFO | train_inner | epoch 013:   8498 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=16472.6, ups=0.32, wpb=50801.3, bsz=3009.2, num_updates=251400, lr=0.000113525, gnorm=0.278, loss_scale=8, train_wall=305, wall=477700
2021-03-19 22:20:53 | INFO | train_inner | epoch 013:   8598 / 20258 loss=3.469, nll_loss=1.777, ppl=3.43, wps=16488.4, ups=0.32, wpb=50830.1, bsz=3012.3, num_updates=251500, lr=0.000113502, gnorm=0.287, loss_scale=8, train_wall=305, wall=478009
2021-03-19 22:26:02 | INFO | train_inner | epoch 013:   8698 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=16488.4, ups=0.32, wpb=50969.8, bsz=3040.2, num_updates=251600, lr=0.000113479, gnorm=0.283, loss_scale=8, train_wall=306, wall=478318
2021-03-19 22:30:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 22:31:14 | INFO | train_inner | epoch 013:   8799 / 20258 loss=3.441, nll_loss=1.746, ppl=3.35, wps=16374.7, ups=0.32, wpb=51052.8, bsz=2954.3, num_updates=251700, lr=0.000113457, gnorm=0.284, loss_scale=8, train_wall=309, wall=478630
2021-03-19 22:34:23 | INFO | train_inner | epoch 013:   8899 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=27072.2, ups=0.53, wpb=51158.6, bsz=3035.5, num_updates=251800, lr=0.000113434, gnorm=0.282, loss_scale=8, train_wall=186, wall=478819
2021-03-19 22:37:25 | INFO | train_inner | epoch 013:   8999 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27913.8, ups=0.55, wpb=50759.3, bsz=2857, num_updates=251900, lr=0.000113412, gnorm=0.288, loss_scale=8, train_wall=179, wall=479000
2021-03-19 22:40:27 | INFO | train_inner | epoch 013:   9099 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27972, ups=0.55, wpb=50995.9, bsz=3020.4, num_updates=252000, lr=0.000113389, gnorm=0.28, loss_scale=8, train_wall=179, wall=479183
2021-03-19 22:43:29 | INFO | train_inner | epoch 013:   9199 / 20258 loss=3.468, nll_loss=1.776, ppl=3.43, wps=27933.9, ups=0.55, wpb=50859.1, bsz=3035.8, num_updates=252100, lr=0.000113367, gnorm=0.281, loss_scale=8, train_wall=179, wall=479365
2021-03-19 22:46:31 | INFO | train_inner | epoch 013:   9299 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27929.4, ups=0.55, wpb=50709.2, bsz=2954.5, num_updates=252200, lr=0.000113344, gnorm=0.279, loss_scale=8, train_wall=179, wall=479546
2021-03-19 22:49:33 | INFO | train_inner | epoch 013:   9399 / 20258 loss=3.449, nll_loss=1.754, ppl=3.37, wps=28022.4, ups=0.55, wpb=51066.5, bsz=2957, num_updates=252300, lr=0.000113322, gnorm=0.276, loss_scale=8, train_wall=179, wall=479729
2021-03-19 22:52:35 | INFO | train_inner | epoch 013:   9499 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27980.8, ups=0.55, wpb=50971.1, bsz=3116.7, num_updates=252400, lr=0.000113299, gnorm=0.28, loss_scale=8, train_wall=179, wall=479911
2021-03-19 22:55:37 | INFO | train_inner | epoch 013:   9599 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=27922.8, ups=0.55, wpb=50768.3, bsz=2946, num_updates=252500, lr=0.000113277, gnorm=0.286, loss_scale=8, train_wall=179, wall=480093
2021-03-19 22:58:39 | INFO | train_inner | epoch 013:   9699 / 20258 loss=3.463, nll_loss=1.77, ppl=3.41, wps=27973.3, ups=0.55, wpb=50843.5, bsz=3115.3, num_updates=252600, lr=0.000113255, gnorm=0.286, loss_scale=8, train_wall=179, wall=480274
2021-03-19 23:01:41 | INFO | train_inner | epoch 013:   9799 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=28007.5, ups=0.55, wpb=51082, bsz=2942.9, num_updates=252700, lr=0.000113232, gnorm=0.278, loss_scale=8, train_wall=179, wall=480457
2021-03-19 23:04:44 | INFO | train_inner | epoch 013:   9899 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27909.8, ups=0.55, wpb=50890, bsz=3092.8, num_updates=252800, lr=0.00011321, gnorm=0.285, loss_scale=16, train_wall=179, wall=480639
2021-03-19 23:07:45 | INFO | train_inner | epoch 013:   9999 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27945.3, ups=0.55, wpb=50744.5, bsz=2952.2, num_updates=252900, lr=0.000113187, gnorm=0.282, loss_scale=16, train_wall=179, wall=480821
2021-03-19 23:10:47 | INFO | train_inner | epoch 013:  10099 / 20258 loss=3.468, nll_loss=1.776, ppl=3.43, wps=27930.8, ups=0.55, wpb=50808.7, bsz=2986.5, num_updates=253000, lr=0.000113165, gnorm=0.285, loss_scale=16, train_wall=179, wall=481003
2021-03-19 23:10:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 23:10:49 | INFO | train_inner | epoch 013:  10100 / 20258 loss=None, nll_loss=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, loss_scale=8, train_wall=2, wall=481004
2021-03-19 23:13:52 | INFO | train_inner | epoch 013:  10200 / 20258 loss=3.437, nll_loss=1.741, ppl=3.34, wps=27986.3, ups=0.55, wpb=51132.2, bsz=2939, num_updates=253100, lr=0.000113143, gnorm=0.283, loss_scale=8, train_wall=180, wall=481187
2021-03-19 23:16:54 | INFO | train_inner | epoch 013:  10300 / 20258 loss=3.447, nll_loss=1.753, ppl=3.37, wps=27955.2, ups=0.55, wpb=50960, bsz=3057.4, num_updates=253200, lr=0.00011312, gnorm=0.28, loss_scale=8, train_wall=179, wall=481369
2021-03-19 23:19:56 | INFO | train_inner | epoch 013:  10400 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27866.9, ups=0.55, wpb=50772.9, bsz=2948.1, num_updates=253300, lr=0.000113098, gnorm=0.283, loss_scale=8, train_wall=179, wall=481552
2021-03-19 23:22:59 | INFO | train_inner | epoch 013:  10500 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=27991.6, ups=0.55, wpb=51137.2, bsz=2943.4, num_updates=253400, lr=0.000113076, gnorm=0.278, loss_scale=8, train_wall=179, wall=481734
2021-03-19 23:26:02 | INFO | train_inner | epoch 013:  10600 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27802.1, ups=0.55, wpb=50818.4, bsz=3013.3, num_updates=253500, lr=0.000113053, gnorm=0.284, loss_scale=8, train_wall=179, wall=481917
2021-03-19 23:29:04 | INFO | train_inner | epoch 013:  10700 / 20258 loss=3.445, nll_loss=1.75, ppl=3.36, wps=27750.6, ups=0.55, wpb=50606.8, bsz=3006, num_updates=253600, lr=0.000113031, gnorm=0.285, loss_scale=8, train_wall=179, wall=482099
2021-03-19 23:32:06 | INFO | train_inner | epoch 013:  10800 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=27928.3, ups=0.55, wpb=50965.7, bsz=3016.6, num_updates=253700, lr=0.000113009, gnorm=0.282, loss_scale=8, train_wall=179, wall=482282
2021-03-19 23:35:09 | INFO | train_inner | epoch 013:  10900 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27891.4, ups=0.55, wpb=51056.4, bsz=2928.1, num_updates=253800, lr=0.000112987, gnorm=0.281, loss_scale=8, train_wall=180, wall=482465
2021-03-19 23:38:12 | INFO | train_inner | epoch 013:  11000 / 20258 loss=3.434, nll_loss=1.738, ppl=3.34, wps=27795.2, ups=0.55, wpb=50655.1, bsz=3061.7, num_updates=253900, lr=0.000112964, gnorm=0.282, loss_scale=8, train_wall=179, wall=482647
2021-03-19 23:41:14 | INFO | train_inner | epoch 013:  11100 / 20258 loss=3.465, nll_loss=1.772, ppl=3.42, wps=28106, ups=0.55, wpb=51158.6, bsz=2952.5, num_updates=254000, lr=0.000112942, gnorm=0.276, loss_scale=8, train_wall=179, wall=482829
2021-03-19 23:42:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-19 23:44:18 | INFO | train_inner | epoch 013:  11201 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27600.1, ups=0.54, wpb=50799.6, bsz=2961, num_updates=254100, lr=0.00011292, gnorm=0.282, loss_scale=8, train_wall=181, wall=483013
2021-03-19 23:47:21 | INFO | train_inner | epoch 013:  11301 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=28033.6, ups=0.55, wpb=51236.4, bsz=3114.1, num_updates=254200, lr=0.000112898, gnorm=0.292, loss_scale=8, train_wall=180, wall=483196
2021-03-19 23:50:23 | INFO | train_inner | epoch 013:  11401 / 20258 loss=3.441, nll_loss=1.746, ppl=3.35, wps=27990, ups=0.55, wpb=51099.6, bsz=2947.3, num_updates=254300, lr=0.000112875, gnorm=0.283, loss_scale=8, train_wall=180, wall=483379
2021-03-19 23:53:25 | INFO | train_inner | epoch 013:  11501 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27920.7, ups=0.55, wpb=50846.1, bsz=2995.7, num_updates=254400, lr=0.000112853, gnorm=0.283, loss_scale=8, train_wall=179, wall=483561
2021-03-19 23:56:27 | INFO | train_inner | epoch 013:  11601 / 20258 loss=3.454, nll_loss=1.761, ppl=3.39, wps=27904.7, ups=0.55, wpb=50644.3, bsz=2939, num_updates=254500, lr=0.000112831, gnorm=0.284, loss_scale=8, train_wall=178, wall=483742
2021-03-19 23:59:29 | INFO | train_inner | epoch 013:  11701 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27877.2, ups=0.55, wpb=50854.9, bsz=3074.3, num_updates=254600, lr=0.000112809, gnorm=0.28, loss_scale=8, train_wall=179, wall=483925
2021-03-20 00:02:32 | INFO | train_inner | epoch 013:  11801 / 20258 loss=3.46, nll_loss=1.768, ppl=3.4, wps=27944.1, ups=0.55, wpb=50981.4, bsz=2937.8, num_updates=254700, lr=0.000112787, gnorm=0.287, loss_scale=8, train_wall=179, wall=484107
2021-03-20 00:05:33 | INFO | train_inner | epoch 013:  11901 / 20258 loss=3.443, nll_loss=1.748, ppl=3.36, wps=27900.9, ups=0.55, wpb=50710.8, bsz=2902.6, num_updates=254800, lr=0.000112765, gnorm=0.281, loss_scale=8, train_wall=179, wall=484289
2021-03-20 00:08:35 | INFO | train_inner | epoch 013:  12001 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=28005.5, ups=0.55, wpb=50978.1, bsz=2984.2, num_updates=254900, lr=0.000112742, gnorm=0.283, loss_scale=8, train_wall=179, wall=484471
2021-03-20 00:11:38 | INFO | train_inner | epoch 013:  12101 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=27944.1, ups=0.55, wpb=50901.7, bsz=3053.1, num_updates=255000, lr=0.00011272, gnorm=0.282, loss_scale=8, train_wall=179, wall=484653
2021-03-20 00:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-20 00:11:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:56 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.865 | nll_loss 2.15 | ppl 4.44 | bleu 30.02 | wps 4404.8 | wpb 2432 | bsz 90.4 | num_updates 255000 | best_loss 3.865
2021-03-20 00:11:56 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-20 00:11:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:11:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:11:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:11:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 00:12:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 00:12:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 00:12:48 | INFO | valid1 | epoch 013 | valid on 'valid1' subset | loss 3.872 | nll_loss 2.18 | ppl 4.53 | bleu 27.9 | wps 4238.8 | wpb 2359.4 | bsz 106.4 | num_updates 255000 | best_loss 3.866
2021-03-20 00:12:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-20 00:12:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_13_255000.pt (epoch 13 @ 255000 updates, score 3.865) (writing took 8.041047174949199 seconds)
2021-03-20 00:15:58 | INFO | train_inner | epoch 013:  12201 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=19448.5, ups=0.38, wpb=50650, bsz=2945.6, num_updates=255100, lr=0.000112698, gnorm=0.283, loss_scale=16, train_wall=178, wall=484914
2021-03-20 00:19:01 | INFO | train_inner | epoch 013:  12301 / 20258 loss=3.442, nll_loss=1.747, ppl=3.36, wps=28031.5, ups=0.55, wpb=51179.5, bsz=3055.4, num_updates=255200, lr=0.000112676, gnorm=0.279, loss_scale=16, train_wall=179, wall=485096
2021-03-20 00:19:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 00:22:05 | INFO | train_inner | epoch 013:  12402 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27609.4, ups=0.54, wpb=50821.6, bsz=3089.1, num_updates=255300, lr=0.000112654, gnorm=0.281, loss_scale=8, train_wall=181, wall=485280
2021-03-20 00:25:07 | INFO | train_inner | epoch 013:  12502 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27792, ups=0.55, wpb=50568.9, bsz=2984.4, num_updates=255400, lr=0.000112632, gnorm=0.281, loss_scale=8, train_wall=179, wall=485462
2021-03-20 00:28:09 | INFO | train_inner | epoch 013:  12602 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27748.5, ups=0.55, wpb=50631.7, bsz=3098.7, num_updates=255500, lr=0.00011261, gnorm=0.285, loss_scale=8, train_wall=179, wall=485645
2021-03-20 00:30:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-20 00:31:13 | INFO | train_inner | epoch 013:  12703 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27621.2, ups=0.54, wpb=50895.1, bsz=3053.8, num_updates=255600, lr=0.000112588, gnorm=0.285, loss_scale=4, train_wall=181, wall=485829
2021-03-20 00:32:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-20 00:34:18 | INFO | train_inner | epoch 013:  12804 / 20258 loss=3.466, nll_loss=1.774, ppl=3.42, wps=27727.8, ups=0.54, wpb=51083.4, bsz=2895, num_updates=255700, lr=0.000112566, gnorm=0.282, loss_scale=2, train_wall=181, wall=486013
2021-03-20 00:37:20 | INFO | train_inner | epoch 013:  12904 / 20258 loss=3.447, nll_loss=1.753, ppl=3.37, wps=27981.8, ups=0.55, wpb=51127.4, bsz=3080.6, num_updates=255800, lr=0.000112544, gnorm=0.29, loss_scale=2, train_wall=179, wall=486196
2021-03-20 00:40:22 | INFO | train_inner | epoch 013:  13004 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27910, ups=0.55, wpb=50736.4, bsz=2999.7, num_updates=255900, lr=0.000112522, gnorm=0.286, loss_scale=2, train_wall=178, wall=486378
2021-03-20 00:43:24 | INFO | train_inner | epoch 013:  13104 / 20258 loss=3.446, nll_loss=1.752, ppl=3.37, wps=27936, ups=0.55, wpb=50867.1, bsz=2938.1, num_updates=256000, lr=0.0001125, gnorm=0.278, loss_scale=2, train_wall=179, wall=486560
2021-03-20 00:46:26 | INFO | train_inner | epoch 013:  13204 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27921.5, ups=0.55, wpb=50808.4, bsz=3028.1, num_updates=256100, lr=0.000112478, gnorm=0.283, loss_scale=2, train_wall=179, wall=486742
2021-03-20 00:49:28 | INFO | train_inner | epoch 013:  13304 / 20258 loss=3.451, nll_loss=1.758, ppl=3.38, wps=27973.1, ups=0.55, wpb=50908.8, bsz=3013.7, num_updates=256200, lr=0.000112456, gnorm=0.281, loss_scale=2, train_wall=179, wall=486924
2021-03-20 00:52:30 | INFO | train_inner | epoch 013:  13404 / 20258 loss=3.444, nll_loss=1.75, ppl=3.36, wps=27971.7, ups=0.55, wpb=50906.4, bsz=2947.5, num_updates=256300, lr=0.000112434, gnorm=0.287, loss_scale=2, train_wall=179, wall=487106
2021-03-20 00:55:33 | INFO | train_inner | epoch 013:  13504 / 20258 loss=3.445, nll_loss=1.751, ppl=3.37, wps=27820.5, ups=0.55, wpb=50851.1, bsz=3049.4, num_updates=256400, lr=0.000112412, gnorm=0.283, loss_scale=2, train_wall=180, wall=487288
2021-03-20 00:58:35 | INFO | train_inner | epoch 013:  13604 / 20258 loss=3.45, nll_loss=1.757, ppl=3.38, wps=27906.4, ups=0.55, wpb=50805.6, bsz=3004.6, num_updates=256500, lr=0.00011239, gnorm=0.291, loss_scale=2, train_wall=179, wall=487470
2021-03-20 01:01:37 | INFO | train_inner | epoch 013:  13704 / 20258 loss=3.467, nll_loss=1.776, ppl=3.42, wps=28019.3, ups=0.55, wpb=51085, bsz=3029.1, num_updates=256600, lr=0.000112368, gnorm=0.343, loss_scale=2, train_wall=179, wall=487653
2021-03-20 01:04:40 | INFO | train_inner | epoch 013:  13804 / 20258 loss=3.44, nll_loss=1.745, ppl=3.35, wps=27997.5, ups=0.55, wpb=51081.8, bsz=2972.5, num_updates=256700, lr=0.000112347, gnorm=0.283, loss_scale=4, train_wall=179, wall=487835
2021-03-20 01:07:42 | INFO | train_inner | epoch 013:  13904 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27944.8, ups=0.55, wpb=50900.2, bsz=2931, num_updates=256800, lr=0.000112325, gnorm=0.286, loss_scale=4, train_wall=179, wall=488017
2021-03-20 01:10:45 | INFO | train_inner | epoch 013:  14004 / 20258 loss=3.444, nll_loss=1.75, ppl=3.36, wps=27906.3, ups=0.55, wpb=51023.9, bsz=3023.8, num_updates=256900, lr=0.000112303, gnorm=0.28, loss_scale=4, train_wall=179, wall=488200
2021-03-20 01:13:47 | INFO | train_inner | epoch 013:  14104 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=27921, ups=0.55, wpb=50864.8, bsz=2909.4, num_updates=257000, lr=0.000112281, gnorm=0.282, loss_scale=4, train_wall=179, wall=488382
2021-03-20 01:16:49 | INFO | train_inner | epoch 013:  14204 / 20258 loss=3.438, nll_loss=1.742, ppl=3.35, wps=27904.2, ups=0.55, wpb=50825.6, bsz=2961.3, num_updates=257100, lr=0.000112259, gnorm=0.283, loss_scale=4, train_wall=179, wall=488565
2021-03-20 01:19:51 | INFO | train_inner | epoch 013:  14304 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=28006.9, ups=0.55, wpb=50879.9, bsz=2914.6, num_updates=257200, lr=0.000112237, gnorm=0.286, loss_scale=4, train_wall=179, wall=488746
2021-03-20 01:22:53 | INFO | train_inner | epoch 013:  14404 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=28048.8, ups=0.55, wpb=50992.3, bsz=2896.5, num_updates=257300, lr=0.000112215, gnorm=0.278, loss_scale=4, train_wall=179, wall=488928
2021-03-20 01:25:54 | INFO | train_inner | epoch 013:  14504 / 20258 loss=3.446, nll_loss=1.751, ppl=3.37, wps=27950.5, ups=0.55, wpb=50795.7, bsz=2921.8, num_updates=257400, lr=0.000112194, gnorm=0.279, loss_scale=4, train_wall=179, wall=489110
2021-03-20 01:28:57 | INFO | train_inner | epoch 013:  14604 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27953.9, ups=0.55, wpb=50954.1, bsz=3183, num_updates=257500, lr=0.000112172, gnorm=0.281, loss_scale=4, train_wall=179, wall=489292
2021-03-20 01:31:58 | INFO | train_inner | epoch 013:  14704 / 20258 loss=3.461, nll_loss=1.768, ppl=3.41, wps=27956.2, ups=0.55, wpb=50851.7, bsz=2967.2, num_updates=257600, lr=0.00011215, gnorm=0.302, loss_scale=4, train_wall=179, wall=489474
2021-03-20 01:35:00 | INFO | train_inner | epoch 013:  14804 / 20258 loss=3.471, nll_loss=1.779, ppl=3.43, wps=27994.6, ups=0.55, wpb=50820.6, bsz=2891.6, num_updates=257700, lr=0.000112128, gnorm=0.285, loss_scale=8, train_wall=179, wall=489655
2021-03-20 01:38:02 | INFO | train_inner | epoch 013:  14904 / 20258 loss=3.457, nll_loss=1.765, ppl=3.4, wps=28014.5, ups=0.55, wpb=51068.8, bsz=3027.6, num_updates=257800, lr=0.000112107, gnorm=0.279, loss_scale=8, train_wall=179, wall=489838
2021-03-20 01:41:04 | INFO | train_inner | epoch 013:  15004 / 20258 loss=3.452, nll_loss=1.759, ppl=3.38, wps=28001.9, ups=0.55, wpb=50968.8, bsz=3018.6, num_updates=257900, lr=0.000112085, gnorm=0.281, loss_scale=8, train_wall=179, wall=490020
2021-03-20 01:44:07 | INFO | train_inner | epoch 013:  15104 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=28034, ups=0.55, wpb=51205.6, bsz=2968.6, num_updates=258000, lr=0.000112063, gnorm=0.282, loss_scale=8, train_wall=179, wall=490202
2021-03-20 01:47:09 | INFO | train_inner | epoch 013:  15204 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27969.9, ups=0.55, wpb=50997.4, bsz=3071.8, num_updates=258100, lr=0.000112041, gnorm=0.289, loss_scale=8, train_wall=179, wall=490385
2021-03-20 01:50:11 | INFO | train_inner | epoch 013:  15304 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=28056.9, ups=0.55, wpb=51082.8, bsz=2956.2, num_updates=258200, lr=0.00011202, gnorm=0.287, loss_scale=8, train_wall=179, wall=490567
2021-03-20 01:53:14 | INFO | train_inner | epoch 013:  15404 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=27793.9, ups=0.55, wpb=50698.8, bsz=3003.4, num_updates=258300, lr=0.000111998, gnorm=0.284, loss_scale=8, train_wall=179, wall=490749
2021-03-20 01:56:16 | INFO | train_inner | epoch 013:  15504 / 20258 loss=3.459, nll_loss=1.767, ppl=3.4, wps=27896.6, ups=0.55, wpb=50882.7, bsz=3043.7, num_updates=258400, lr=0.000111976, gnorm=0.282, loss_scale=8, train_wall=179, wall=490932
2021-03-20 01:59:19 | INFO | train_inner | epoch 013:  15604 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=28122.1, ups=0.55, wpb=51429.5, bsz=3007.3, num_updates=258500, lr=0.000111955, gnorm=0.282, loss_scale=8, train_wall=180, wall=491115
2021-03-20 02:02:21 | INFO | train_inner | epoch 013:  15704 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=27816.1, ups=0.55, wpb=50626.1, bsz=3082.6, num_updates=258600, lr=0.000111933, gnorm=0.288, loss_scale=8, train_wall=179, wall=491297
2021-03-20 02:05:23 | INFO | train_inner | epoch 013:  15804 / 20258 loss=3.456, nll_loss=1.762, ppl=3.39, wps=27841.8, ups=0.55, wpb=50764.1, bsz=2967.5, num_updates=258700, lr=0.000111911, gnorm=0.282, loss_scale=8, train_wall=179, wall=491479
2021-03-20 02:08:26 | INFO | train_inner | epoch 013:  15904 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27802, ups=0.55, wpb=50798.3, bsz=3019.4, num_updates=258800, lr=0.00011189, gnorm=0.287, loss_scale=16, train_wall=179, wall=491662
2021-03-20 02:11:28 | INFO | train_inner | epoch 013:  16004 / 20258 loss=3.446, nll_loss=1.752, ppl=3.37, wps=27907, ups=0.55, wpb=50859.5, bsz=3101, num_updates=258900, lr=0.000111868, gnorm=0.282, loss_scale=16, train_wall=179, wall=491844
2021-03-20 02:14:31 | INFO | train_inner | epoch 013:  16104 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27915, ups=0.55, wpb=50940.8, bsz=2955.7, num_updates=259000, lr=0.000111847, gnorm=0.285, loss_scale=16, train_wall=179, wall=492026
2021-03-20 02:17:33 | INFO | train_inner | epoch 013:  16204 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27929.7, ups=0.55, wpb=50842.6, bsz=3075.8, num_updates=259100, lr=0.000111825, gnorm=0.292, loss_scale=16, train_wall=179, wall=492208
2021-03-20 02:20:35 | INFO | train_inner | epoch 013:  16304 / 20258 loss=3.449, nll_loss=1.755, ppl=3.37, wps=27995.2, ups=0.55, wpb=51084.9, bsz=2966.7, num_updates=259200, lr=0.000111803, gnorm=0.29, loss_scale=16, train_wall=180, wall=492391
2021-03-20 02:23:38 | INFO | train_inner | epoch 013:  16404 / 20258 loss=3.457, nll_loss=1.765, ppl=3.4, wps=27814.3, ups=0.55, wpb=50778.7, bsz=3136.1, num_updates=259300, lr=0.000111782, gnorm=0.286, loss_scale=16, train_wall=179, wall=492573
2021-03-20 02:26:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 02:26:42 | INFO | train_inner | epoch 013:  16505 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27650.9, ups=0.54, wpb=50844.2, bsz=3000.2, num_updates=259400, lr=0.00011176, gnorm=0.281, loss_scale=8, train_wall=181, wall=492757
2021-03-20 02:29:44 | INFO | train_inner | epoch 013:  16605 / 20258 loss=3.442, nll_loss=1.747, ppl=3.36, wps=27819.4, ups=0.55, wpb=50695.1, bsz=3104, num_updates=259500, lr=0.000111739, gnorm=0.279, loss_scale=8, train_wall=179, wall=492940
2021-03-20 02:32:46 | INFO | train_inner | epoch 013:  16705 / 20258 loss=3.453, nll_loss=1.759, ppl=3.38, wps=27839.1, ups=0.55, wpb=50726.2, bsz=2892.5, num_updates=259600, lr=0.000111717, gnorm=0.286, loss_scale=8, train_wall=179, wall=493122
2021-03-20 02:35:48 | INFO | train_inner | epoch 013:  16805 / 20258 loss=3.464, nll_loss=1.772, ppl=3.41, wps=28005.2, ups=0.55, wpb=51026.7, bsz=2983.4, num_updates=259700, lr=0.000111696, gnorm=0.287, loss_scale=8, train_wall=179, wall=493304
2021-03-20 02:38:51 | INFO | train_inner | epoch 013:  16905 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27885.6, ups=0.55, wpb=50835.1, bsz=2967.1, num_updates=259800, lr=0.000111674, gnorm=0.28, loss_scale=8, train_wall=179, wall=493486
2021-03-20 02:41:53 | INFO | train_inner | epoch 013:  17005 / 20258 loss=3.479, nll_loss=1.789, ppl=3.46, wps=27967, ups=0.55, wpb=51068.7, bsz=3108.8, num_updates=259900, lr=0.000111653, gnorm=0.283, loss_scale=8, train_wall=179, wall=493669
2021-03-20 02:44:55 | INFO | train_inner | epoch 013:  17105 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27848.3, ups=0.55, wpb=50681.4, bsz=2977.9, num_updates=260000, lr=0.000111631, gnorm=0.286, loss_scale=8, train_wall=179, wall=493851
2021-03-20 02:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-20 02:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:44:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:44:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:44:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:44:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:44:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:44:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:44:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:44:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:44:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:44:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:44:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:44:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:44:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:44:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:44:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:14 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.869 | nll_loss 2.156 | ppl 4.46 | bleu 29.87 | wps 4349.7 | wpb 2432 | bsz 90.4 | num_updates 260000 | best_loss 3.865
2021-03-20 02:45:14 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-20 02:45:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:45:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 02:45:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 02:45:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 02:46:07 | INFO | valid1 | epoch 013 | valid on 'valid1' subset | loss 3.872 | nll_loss 2.18 | ppl 4.53 | bleu 27.94 | wps 4217.4 | wpb 2359.4 | bsz 106.4 | num_updates 260000 | best_loss 3.865
2021-03-20 02:46:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-20 02:46:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_13_260000.pt (epoch 13 @ 260000 updates, score 3.869) (writing took 4.484932332765311 seconds)
2021-03-20 02:49:14 | INFO | train_inner | epoch 013:  17205 / 20258 loss=3.464, nll_loss=1.772, ppl=3.41, wps=19733.7, ups=0.39, wpb=50975.7, bsz=3043.5, num_updates=260100, lr=0.00011161, gnorm=0.283, loss_scale=8, train_wall=179, wall=494109
2021-03-20 02:52:16 | INFO | train_inner | epoch 013:  17305 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27885.9, ups=0.55, wpb=50875, bsz=3003.1, num_updates=260200, lr=0.000111588, gnorm=0.28, loss_scale=8, train_wall=179, wall=494292
2021-03-20 02:55:19 | INFO | train_inner | epoch 013:  17405 / 20258 loss=3.46, nll_loss=1.768, ppl=3.41, wps=27843.2, ups=0.55, wpb=50929.6, bsz=3139.4, num_updates=260300, lr=0.000111567, gnorm=0.279, loss_scale=8, train_wall=179, wall=494475
2021-03-20 02:58:22 | INFO | train_inner | epoch 013:  17505 / 20258 loss=3.446, nll_loss=1.751, ppl=3.37, wps=27898, ups=0.55, wpb=50970.5, bsz=2997.6, num_updates=260400, lr=0.000111545, gnorm=0.283, loss_scale=8, train_wall=179, wall=494657
2021-03-20 03:00:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 03:01:26 | INFO | train_inner | epoch 013:  17606 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27549.1, ups=0.54, wpb=50881.4, bsz=3027, num_updates=260500, lr=0.000111524, gnorm=0.276, loss_scale=8, train_wall=181, wall=494842
2021-03-20 03:04:28 | INFO | train_inner | epoch 013:  17706 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27975.7, ups=0.55, wpb=50886, bsz=2902.9, num_updates=260600, lr=0.000111503, gnorm=0.282, loss_scale=8, train_wall=179, wall=495024
2021-03-20 03:07:30 | INFO | train_inner | epoch 013:  17806 / 20258 loss=3.446, nll_loss=1.751, ppl=3.37, wps=28046, ups=0.55, wpb=50985.9, bsz=2890.9, num_updates=260700, lr=0.000111481, gnorm=0.278, loss_scale=8, train_wall=179, wall=495206
2021-03-20 03:10:32 | INFO | train_inner | epoch 013:  17906 / 20258 loss=3.468, nll_loss=1.777, ppl=3.43, wps=27976.7, ups=0.55, wpb=50813.2, bsz=3013.2, num_updates=260800, lr=0.00011146, gnorm=0.282, loss_scale=8, train_wall=179, wall=495387
2021-03-20 03:13:34 | INFO | train_inner | epoch 013:  18006 / 20258 loss=3.43, nll_loss=1.733, ppl=3.32, wps=27928.5, ups=0.55, wpb=50870.4, bsz=2942.2, num_updates=260900, lr=0.000111439, gnorm=0.28, loss_scale=8, train_wall=179, wall=495569
2021-03-20 03:16:36 | INFO | train_inner | epoch 013:  18106 / 20258 loss=3.45, nll_loss=1.757, ppl=3.38, wps=27936.7, ups=0.55, wpb=50783.1, bsz=3053.8, num_updates=261000, lr=0.000111417, gnorm=0.287, loss_scale=8, train_wall=179, wall=495751
2021-03-20 03:19:38 | INFO | train_inner | epoch 013:  18206 / 20258 loss=3.445, nll_loss=1.751, ppl=3.37, wps=27938, ups=0.55, wpb=50836.4, bsz=3036.2, num_updates=261100, lr=0.000111396, gnorm=0.28, loss_scale=8, train_wall=179, wall=495933
2021-03-20 03:22:40 | INFO | train_inner | epoch 013:  18306 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=27821.5, ups=0.55, wpb=50703.8, bsz=3129.5, num_updates=261200, lr=0.000111375, gnorm=0.285, loss_scale=8, train_wall=179, wall=496115
2021-03-20 03:25:43 | INFO | train_inner | epoch 013:  18406 / 20258 loss=3.456, nll_loss=1.764, ppl=3.4, wps=27883.5, ups=0.55, wpb=50985.8, bsz=3046.4, num_updates=261300, lr=0.000111353, gnorm=0.287, loss_scale=8, train_wall=179, wall=496298
2021-03-20 03:28:45 | INFO | train_inner | epoch 013:  18506 / 20258 loss=3.46, nll_loss=1.768, ppl=3.41, wps=27860.5, ups=0.55, wpb=50833.5, bsz=3056.7, num_updates=261400, lr=0.000111332, gnorm=0.279, loss_scale=8, train_wall=179, wall=496481
2021-03-20 03:31:47 | INFO | train_inner | epoch 013:  18606 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27989.6, ups=0.55, wpb=50910.3, bsz=3057.4, num_updates=261500, lr=0.000111311, gnorm=0.283, loss_scale=8, train_wall=179, wall=496663
2021-03-20 03:33:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 03:34:51 | INFO | train_inner | epoch 013:  18707 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=27620.2, ups=0.54, wpb=50689.4, bsz=2928.4, num_updates=261600, lr=0.000111289, gnorm=0.285, loss_scale=8, train_wall=181, wall=496846
2021-03-20 03:37:53 | INFO | train_inner | epoch 013:  18807 / 20258 loss=3.457, nll_loss=1.765, ppl=3.4, wps=27889.5, ups=0.55, wpb=50833.2, bsz=3061.8, num_updates=261700, lr=0.000111268, gnorm=0.282, loss_scale=8, train_wall=179, wall=497028
2021-03-20 03:40:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-20 03:40:57 | INFO | train_inner | epoch 013:  18908 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27785.9, ups=0.54, wpb=51035, bsz=2889.4, num_updates=261800, lr=0.000111247, gnorm=0.281, loss_scale=4, train_wall=181, wall=497212
2021-03-20 03:43:58 | INFO | train_inner | epoch 013:  19008 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27993.6, ups=0.55, wpb=50853.6, bsz=2870.3, num_updates=261900, lr=0.000111226, gnorm=0.285, loss_scale=4, train_wall=179, wall=497394
2021-03-20 03:47:00 | INFO | train_inner | epoch 013:  19108 / 20258 loss=3.446, nll_loss=1.752, ppl=3.37, wps=27982.1, ups=0.55, wpb=50996, bsz=3161.1, num_updates=262000, lr=0.000111204, gnorm=0.282, loss_scale=4, train_wall=179, wall=497576
2021-03-20 03:50:03 | INFO | train_inner | epoch 013:  19208 / 20258 loss=3.469, nll_loss=1.778, ppl=3.43, wps=27968.9, ups=0.55, wpb=51095, bsz=2990, num_updates=262100, lr=0.000111183, gnorm=0.289, loss_scale=4, train_wall=179, wall=497759
2021-03-20 03:53:06 | INFO | train_inner | epoch 013:  19308 / 20258 loss=3.465, nll_loss=1.773, ppl=3.42, wps=27984.9, ups=0.55, wpb=51296, bsz=3077.8, num_updates=262200, lr=0.000111162, gnorm=0.286, loss_scale=4, train_wall=180, wall=497942
2021-03-20 03:56:08 | INFO | train_inner | epoch 013:  19408 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=27935.8, ups=0.55, wpb=50859.8, bsz=2918.8, num_updates=262300, lr=0.000111141, gnorm=0.282, loss_scale=4, train_wall=179, wall=498124
2021-03-20 03:59:10 | INFO | train_inner | epoch 013:  19508 / 20258 loss=3.452, nll_loss=1.759, ppl=3.38, wps=28044.3, ups=0.55, wpb=50951.9, bsz=3013.3, num_updates=262400, lr=0.00011112, gnorm=0.28, loss_scale=4, train_wall=179, wall=498306
2021-03-20 04:02:12 | INFO | train_inner | epoch 013:  19608 / 20258 loss=3.46, nll_loss=1.768, ppl=3.41, wps=27826.4, ups=0.55, wpb=50703.6, bsz=2973.5, num_updates=262500, lr=0.000111098, gnorm=0.282, loss_scale=4, train_wall=179, wall=498488
2021-03-20 04:05:15 | INFO | train_inner | epoch 013:  19708 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27799.7, ups=0.55, wpb=50659.4, bsz=3076.3, num_updates=262600, lr=0.000111077, gnorm=0.284, loss_scale=4, train_wall=179, wall=498670
2021-03-20 04:08:16 | INFO | train_inner | epoch 013:  19808 / 20258 loss=3.464, nll_loss=1.773, ppl=3.42, wps=28001.6, ups=0.55, wpb=50893.4, bsz=3057.5, num_updates=262700, lr=0.000111056, gnorm=0.282, loss_scale=4, train_wall=179, wall=498852
2021-03-20 04:11:19 | INFO | train_inner | epoch 013:  19908 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=27928.6, ups=0.55, wpb=50961, bsz=2950.8, num_updates=262800, lr=0.000111035, gnorm=0.285, loss_scale=4, train_wall=179, wall=499034
2021-03-20 04:14:21 | INFO | train_inner | epoch 013:  20008 / 20258 loss=3.458, nll_loss=1.766, ppl=3.4, wps=27775.1, ups=0.55, wpb=50693.7, bsz=3103.8, num_updates=262900, lr=0.000111014, gnorm=0.282, loss_scale=8, train_wall=179, wall=499217
2021-03-20 04:17:24 | INFO | train_inner | epoch 013:  20108 / 20258 loss=3.463, nll_loss=1.771, ppl=3.41, wps=27944.4, ups=0.55, wpb=51065.8, bsz=3047.3, num_updates=263000, lr=0.000110993, gnorm=0.282, loss_scale=8, train_wall=179, wall=499400
2021-03-20 04:17:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-20 04:20:28 | INFO | train_inner | epoch 013:  20209 / 20258 loss=3.467, nll_loss=1.776, ppl=3.42, wps=27667.8, ups=0.54, wpb=50834.1, bsz=3032.2, num_updates=263100, lr=0.000110972, gnorm=0.287, loss_scale=4, train_wall=181, wall=499583
2021-03-20 04:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-20 04:21:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:21:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:21:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:21:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:21:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:21:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:21:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:21:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:21:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:21:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:21:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:21:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:21:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:21:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:21:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:16 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.867 | nll_loss 2.152 | ppl 4.44 | bleu 29.88 | wps 4363.4 | wpb 2432 | bsz 90.4 | num_updates 263149 | best_loss 3.865
2021-03-20 04:22:16 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-20 04:22:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:22:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 04:22:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 04:22:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 04:23:08 | INFO | valid1 | epoch 013 | valid on 'valid1' subset | loss 3.87 | nll_loss 2.178 | ppl 4.52 | bleu 28.03 | wps 4251.1 | wpb 2359.4 | bsz 106.4 | num_updates 263149 | best_loss 3.865
2021-03-20 04:23:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-20 04:23:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint13.pt (epoch 13 @ 263149 updates, score 3.867) (writing took 4.534703759010881 seconds)
2021-03-20 04:23:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-03-20 04:23:12 | INFO | train | epoch 013 | loss 3.453 | nll_loss 1.76 | ppl 3.39 | wps 21203 | ups 0.42 | wpb 50905.1 | bsz 3010.2 | num_updates 263149 | lr 0.000110961 | gnorm 0.283 | loss_scale 4 | train_wall 47423 | wall 499748
2021-03-20 04:23:13 | INFO | fairseq.trainer | begin training epoch 14
2021-03-20 04:24:45 | INFO | train_inner | epoch 014:     51 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=19670.4, ups=0.39, wpb=50640.5, bsz=2993.1, num_updates=263200, lr=0.000110951, gnorm=0.283, loss_scale=4, train_wall=179, wall=499841
2021-03-20 04:27:48 | INFO | train_inner | epoch 014:    151 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=27867, ups=0.55, wpb=50980.6, bsz=2886.2, num_updates=263300, lr=0.00011093, gnorm=0.28, loss_scale=4, train_wall=179, wall=500024
2021-03-20 04:30:51 | INFO | train_inner | epoch 014:    251 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27991.2, ups=0.55, wpb=51043.8, bsz=3126.2, num_updates=263400, lr=0.000110908, gnorm=0.279, loss_scale=4, train_wall=179, wall=500206
2021-03-20 04:33:52 | INFO | train_inner | epoch 014:    351 / 20258 loss=3.446, nll_loss=1.751, ppl=3.37, wps=27978.6, ups=0.55, wpb=50781.3, bsz=2891.8, num_updates=263500, lr=0.000110887, gnorm=0.284, loss_scale=4, train_wall=178, wall=500388
2021-03-20 04:36:54 | INFO | train_inner | epoch 014:    451 / 20258 loss=3.427, nll_loss=1.73, ppl=3.32, wps=27992, ups=0.55, wpb=50792.8, bsz=2925.9, num_updates=263600, lr=0.000110866, gnorm=0.283, loss_scale=4, train_wall=179, wall=500569
2021-03-20 04:39:56 | INFO | train_inner | epoch 014:    551 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27934.3, ups=0.55, wpb=51010.2, bsz=2985.2, num_updates=263700, lr=0.000110845, gnorm=0.282, loss_scale=4, train_wall=179, wall=500752
2021-03-20 04:42:59 | INFO | train_inner | epoch 014:    651 / 20258 loss=3.443, nll_loss=1.748, ppl=3.36, wps=27913.7, ups=0.55, wpb=50956.7, bsz=2979.6, num_updates=263800, lr=0.000110824, gnorm=0.282, loss_scale=4, train_wall=179, wall=500934
2021-03-20 04:46:01 | INFO | train_inner | epoch 014:    751 / 20258 loss=3.439, nll_loss=1.743, ppl=3.35, wps=27923.8, ups=0.55, wpb=50906.5, bsz=3012.4, num_updates=263900, lr=0.000110803, gnorm=0.282, loss_scale=4, train_wall=179, wall=501117
2021-03-20 04:46:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-20 04:49:05 | INFO | train_inner | epoch 014:    852 / 20258 loss=3.439, nll_loss=1.744, ppl=3.35, wps=27771.9, ups=0.54, wpb=51150.7, bsz=3056.9, num_updates=264000, lr=0.000110782, gnorm=0.287, loss_scale=2, train_wall=181, wall=501301
2021-03-20 04:52:07 | INFO | train_inner | epoch 014:    952 / 20258 loss=3.435, nll_loss=1.739, ppl=3.34, wps=28034.1, ups=0.55, wpb=51093.6, bsz=3066.1, num_updates=264100, lr=0.000110761, gnorm=0.297, loss_scale=2, train_wall=179, wall=501483
2021-03-20 04:55:09 | INFO | train_inner | epoch 014:   1052 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=27890.7, ups=0.55, wpb=50674.8, bsz=2989.4, num_updates=264200, lr=0.00011074, gnorm=0.29, loss_scale=2, train_wall=179, wall=501665
2021-03-20 04:58:11 | INFO | train_inner | epoch 014:   1152 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=28030.3, ups=0.55, wpb=51083.6, bsz=2953.8, num_updates=264300, lr=0.000110719, gnorm=0.291, loss_scale=2, train_wall=179, wall=501847
2021-03-20 05:01:14 | INFO | train_inner | epoch 014:   1252 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27969.6, ups=0.55, wpb=51130.4, bsz=3186.7, num_updates=264400, lr=0.000110699, gnorm=0.299, loss_scale=2, train_wall=180, wall=502030
2021-03-20 05:04:17 | INFO | train_inner | epoch 014:   1352 / 20258 loss=3.435, nll_loss=1.739, ppl=3.34, wps=27853.1, ups=0.55, wpb=50879.6, bsz=3047.9, num_updates=264500, lr=0.000110678, gnorm=0.28, loss_scale=2, train_wall=179, wall=502212
2021-03-20 05:07:19 | INFO | train_inner | epoch 014:   1452 / 20258 loss=3.438, nll_loss=1.743, ppl=3.35, wps=27914, ups=0.55, wpb=50856.4, bsz=3093.6, num_updates=264600, lr=0.000110657, gnorm=0.279, loss_scale=2, train_wall=179, wall=502395
2021-03-20 05:10:22 | INFO | train_inner | epoch 014:   1552 / 20258 loss=3.439, nll_loss=1.743, ppl=3.35, wps=27877.7, ups=0.55, wpb=50895.1, bsz=2949, num_updates=264700, lr=0.000110636, gnorm=0.285, loss_scale=2, train_wall=179, wall=502577
2021-03-20 05:13:24 | INFO | train_inner | epoch 014:   1652 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27833.7, ups=0.55, wpb=50844.3, bsz=3016.1, num_updates=264800, lr=0.000110615, gnorm=0.291, loss_scale=2, train_wall=179, wall=502760
2021-03-20 05:16:27 | INFO | train_inner | epoch 014:   1752 / 20258 loss=3.432, nll_loss=1.735, ppl=3.33, wps=27891, ups=0.55, wpb=50878.6, bsz=3045, num_updates=264900, lr=0.000110594, gnorm=0.284, loss_scale=2, train_wall=179, wall=502942
2021-03-20 05:19:29 | INFO | train_inner | epoch 014:   1852 / 20258 loss=3.443, nll_loss=1.748, ppl=3.36, wps=27804.9, ups=0.55, wpb=50812.5, bsz=3066, num_updates=265000, lr=0.000110573, gnorm=0.281, loss_scale=4, train_wall=179, wall=503125
2021-03-20 05:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-20 05:19:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:48 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.868 | nll_loss 2.153 | ppl 4.45 | bleu 30.16 | wps 4456.9 | wpb 2432 | bsz 90.4 | num_updates 265000 | best_loss 3.865
2021-03-20 05:19:48 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-20 05:19:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:19:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:19:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:19:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:08 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:08 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:08 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 05:20:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 05:20:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 05:20:39 | INFO | valid1 | epoch 014 | valid on 'valid1' subset | loss 3.871 | nll_loss 2.178 | ppl 4.53 | bleu 28.26 | wps 4290 | wpb 2359.4 | bsz 106.4 | num_updates 265000 | best_loss 3.865
2021-03-20 05:20:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-20 05:20:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_14_265000.pt (epoch 14 @ 265000 updates, score 3.868) (writing took 4.527688428293914 seconds)
2021-03-20 05:23:46 | INFO | train_inner | epoch 014:   1952 / 20258 loss=3.44, nll_loss=1.744, ppl=3.35, wps=19920.5, ups=0.39, wpb=51042.1, bsz=2861, num_updates=265100, lr=0.000110552, gnorm=0.287, loss_scale=4, train_wall=179, wall=503381
2021-03-20 05:26:48 | INFO | train_inner | epoch 014:   2052 / 20258 loss=3.434, nll_loss=1.737, ppl=3.33, wps=27964.2, ups=0.55, wpb=51045.4, bsz=2948.2, num_updates=265200, lr=0.000110531, gnorm=0.282, loss_scale=4, train_wall=179, wall=503564
2021-03-20 05:29:51 | INFO | train_inner | epoch 014:   2152 / 20258 loss=3.436, nll_loss=1.74, ppl=3.34, wps=27935.5, ups=0.55, wpb=51033.8, bsz=3049.6, num_updates=265300, lr=0.000110511, gnorm=0.287, loss_scale=4, train_wall=180, wall=503746
2021-03-20 05:32:53 | INFO | train_inner | epoch 014:   2252 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27919.4, ups=0.55, wpb=50845.1, bsz=3017.4, num_updates=265400, lr=0.00011049, gnorm=0.286, loss_scale=4, train_wall=179, wall=503929
2021-03-20 05:35:56 | INFO | train_inner | epoch 014:   2352 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27924.7, ups=0.55, wpb=50952.3, bsz=3046.6, num_updates=265500, lr=0.000110469, gnorm=0.284, loss_scale=4, train_wall=179, wall=504111
2021-03-20 05:38:58 | INFO | train_inner | epoch 014:   2452 / 20258 loss=3.446, nll_loss=1.752, ppl=3.37, wps=28034.9, ups=0.55, wpb=51063.2, bsz=2993.7, num_updates=265600, lr=0.000110448, gnorm=0.286, loss_scale=4, train_wall=179, wall=504293
2021-03-20 05:42:00 | INFO | train_inner | epoch 014:   2552 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27877.7, ups=0.55, wpb=50707.1, bsz=2998.7, num_updates=265700, lr=0.000110427, gnorm=0.284, loss_scale=4, train_wall=179, wall=504475
2021-03-20 05:45:02 | INFO | train_inner | epoch 014:   2652 / 20258 loss=3.448, nll_loss=1.753, ppl=3.37, wps=27894.2, ups=0.55, wpb=50758.8, bsz=2898.3, num_updates=265800, lr=0.000110407, gnorm=0.285, loss_scale=4, train_wall=179, wall=504657
2021-03-20 05:48:04 | INFO | train_inner | epoch 014:   2752 / 20258 loss=3.441, nll_loss=1.746, ppl=3.36, wps=27879.9, ups=0.55, wpb=50766, bsz=3026.7, num_updates=265900, lr=0.000110386, gnorm=0.282, loss_scale=4, train_wall=179, wall=504839
2021-03-20 05:51:05 | INFO | train_inner | epoch 014:   2852 / 20258 loss=3.434, nll_loss=1.738, ppl=3.34, wps=27873.1, ups=0.55, wpb=50699.3, bsz=3042.9, num_updates=266000, lr=0.000110365, gnorm=0.284, loss_scale=8, train_wall=179, wall=505021
2021-03-20 05:53:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-20 05:54:10 | INFO | train_inner | epoch 014:   2953 / 20258 loss=3.436, nll_loss=1.741, ppl=3.34, wps=27540.4, ups=0.54, wpb=50717.3, bsz=3133.4, num_updates=266100, lr=0.000110344, gnorm=0.285, loss_scale=4, train_wall=181, wall=505205
2021-03-20 05:57:12 | INFO | train_inner | epoch 014:   3053 / 20258 loss=3.433, nll_loss=1.737, ppl=3.33, wps=27797.5, ups=0.55, wpb=50654.3, bsz=3030.1, num_updates=266200, lr=0.000110324, gnorm=0.283, loss_scale=4, train_wall=179, wall=505387
2021-03-20 06:00:14 | INFO | train_inner | epoch 014:   3153 / 20258 loss=3.446, nll_loss=1.751, ppl=3.37, wps=27969.4, ups=0.55, wpb=50886.5, bsz=2899.4, num_updates=266300, lr=0.000110303, gnorm=0.279, loss_scale=4, train_wall=179, wall=505569
2021-03-20 06:02:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2021-03-20 06:03:19 | INFO | train_inner | epoch 014:   3254 / 20258 loss=3.436, nll_loss=1.741, ppl=3.34, wps=27594.6, ups=0.54, wpb=50984.4, bsz=3051.5, num_updates=266400, lr=0.000110282, gnorm=0.286, loss_scale=2, train_wall=181, wall=505754
2021-03-20 06:06:20 | INFO | train_inner | epoch 014:   3354 / 20258 loss=3.447, nll_loss=1.753, ppl=3.37, wps=27832.2, ups=0.55, wpb=50527.5, bsz=2983.7, num_updates=266500, lr=0.000110262, gnorm=0.289, loss_scale=2, train_wall=178, wall=505936
2021-03-20 06:09:23 | INFO | train_inner | epoch 014:   3454 / 20258 loss=3.442, nll_loss=1.747, ppl=3.36, wps=27825.3, ups=0.55, wpb=50803.6, bsz=3069, num_updates=266600, lr=0.000110241, gnorm=0.279, loss_scale=2, train_wall=179, wall=506118
2021-03-20 06:12:25 | INFO | train_inner | epoch 014:   3554 / 20258 loss=3.434, nll_loss=1.738, ppl=3.34, wps=27906.6, ups=0.55, wpb=50976.3, bsz=3027.1, num_updates=266700, lr=0.00011022, gnorm=0.278, loss_scale=2, train_wall=179, wall=506301
2021-03-20 06:15:28 | INFO | train_inner | epoch 014:   3654 / 20258 loss=3.432, nll_loss=1.736, ppl=3.33, wps=27999.5, ups=0.55, wpb=51270.9, bsz=3040.7, num_updates=266800, lr=0.000110199, gnorm=0.275, loss_scale=2, train_wall=180, wall=506484
2021-03-20 06:18:30 | INFO | train_inner | epoch 014:   3754 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=28012.7, ups=0.55, wpb=50901.6, bsz=2950.6, num_updates=266900, lr=0.000110179, gnorm=0.292, loss_scale=2, train_wall=179, wall=506666
2021-03-20 06:21:33 | INFO | train_inner | epoch 014:   3854 / 20258 loss=3.44, nll_loss=1.744, ppl=3.35, wps=27848.7, ups=0.55, wpb=50896.3, bsz=3026.4, num_updates=267000, lr=0.000110158, gnorm=0.29, loss_scale=2, train_wall=179, wall=506848
2021-03-20 06:24:35 | INFO | train_inner | epoch 014:   3954 / 20258 loss=3.441, nll_loss=1.746, ppl=3.35, wps=27911.8, ups=0.55, wpb=50929.8, bsz=2966.7, num_updates=267100, lr=0.000110138, gnorm=0.281, loss_scale=2, train_wall=179, wall=507031
2021-03-20 06:27:37 | INFO | train_inner | epoch 014:   4054 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27983.7, ups=0.55, wpb=50781.7, bsz=3084.6, num_updates=267200, lr=0.000110117, gnorm=0.287, loss_scale=2, train_wall=178, wall=507212
2021-03-20 06:30:38 | INFO | train_inner | epoch 014:   4154 / 20258 loss=3.45, nll_loss=1.755, ppl=3.38, wps=27946.6, ups=0.55, wpb=50700.5, bsz=2965.2, num_updates=267300, lr=0.000110096, gnorm=0.287, loss_scale=2, train_wall=178, wall=507394
2021-03-20 06:33:40 | INFO | train_inner | epoch 014:   4254 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27991.1, ups=0.55, wpb=50901.3, bsz=3027.2, num_updates=267400, lr=0.000110076, gnorm=0.284, loss_scale=2, train_wall=179, wall=507576
2021-03-20 06:36:42 | INFO | train_inner | epoch 014:   4354 / 20258 loss=3.46, nll_loss=1.768, ppl=3.41, wps=28062.9, ups=0.55, wpb=51059.2, bsz=2977.7, num_updates=267500, lr=0.000110055, gnorm=0.282, loss_scale=4, train_wall=179, wall=507758
2021-03-20 06:39:44 | INFO | train_inner | epoch 014:   4454 / 20258 loss=3.441, nll_loss=1.747, ppl=3.36, wps=27829.5, ups=0.55, wpb=50650.7, bsz=3125.3, num_updates=267600, lr=0.000110035, gnorm=0.28, loss_scale=4, train_wall=179, wall=507940
2021-03-20 06:42:46 | INFO | train_inner | epoch 014:   4554 / 20258 loss=3.445, nll_loss=1.751, ppl=3.37, wps=28011.9, ups=0.55, wpb=50912.6, bsz=2965.8, num_updates=267700, lr=0.000110014, gnorm=0.286, loss_scale=4, train_wall=179, wall=508121
2021-03-20 06:45:48 | INFO | train_inner | epoch 014:   4654 / 20258 loss=3.435, nll_loss=1.739, ppl=3.34, wps=27867.5, ups=0.55, wpb=50677.4, bsz=3184.7, num_updates=267800, lr=0.000109994, gnorm=0.285, loss_scale=4, train_wall=179, wall=508303
2021-03-20 06:48:50 | INFO | train_inner | epoch 014:   4754 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=28041.4, ups=0.55, wpb=51090.4, bsz=3200.2, num_updates=267900, lr=0.000109973, gnorm=0.287, loss_scale=4, train_wall=179, wall=508485
2021-03-20 06:51:53 | INFO | train_inner | epoch 014:   4854 / 20258 loss=3.444, nll_loss=1.75, ppl=3.36, wps=28050, ups=0.55, wpb=51264.2, bsz=3020.1, num_updates=268000, lr=0.000109952, gnorm=0.275, loss_scale=4, train_wall=180, wall=508668
2021-03-20 06:54:55 | INFO | train_inner | epoch 014:   4954 / 20258 loss=3.433, nll_loss=1.737, ppl=3.33, wps=28104.7, ups=0.55, wpb=51225.3, bsz=3053.4, num_updates=268100, lr=0.000109932, gnorm=0.288, loss_scale=4, train_wall=179, wall=508850
2021-03-20 06:57:58 | INFO | train_inner | epoch 014:   5054 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=28041, ups=0.55, wpb=51281.8, bsz=3068.4, num_updates=268200, lr=0.000109911, gnorm=0.283, loss_scale=4, train_wall=180, wall=509033
2021-03-20 07:01:00 | INFO | train_inner | epoch 014:   5154 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27966.3, ups=0.55, wpb=50875.4, bsz=3011.4, num_updates=268300, lr=0.000109891, gnorm=0.285, loss_scale=4, train_wall=179, wall=509215
2021-03-20 07:04:02 | INFO | train_inner | epoch 014:   5254 / 20258 loss=3.447, nll_loss=1.752, ppl=3.37, wps=27976.2, ups=0.55, wpb=50929.8, bsz=2980.8, num_updates=268400, lr=0.000109871, gnorm=0.284, loss_scale=4, train_wall=179, wall=509397
2021-03-20 07:07:04 | INFO | train_inner | epoch 014:   5354 / 20258 loss=3.433, nll_loss=1.737, ppl=3.33, wps=27959.3, ups=0.55, wpb=50870.4, bsz=2867, num_updates=268500, lr=0.00010985, gnorm=0.285, loss_scale=8, train_wall=179, wall=509579
2021-03-20 07:10:06 | INFO | train_inner | epoch 014:   5454 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=27960.1, ups=0.55, wpb=50840.6, bsz=3111.9, num_updates=268600, lr=0.00010983, gnorm=0.284, loss_scale=8, train_wall=179, wall=509761
2021-03-20 07:13:08 | INFO | train_inner | epoch 014:   5554 / 20258 loss=3.44, nll_loss=1.744, ppl=3.35, wps=27979.1, ups=0.55, wpb=50929.2, bsz=2942, num_updates=268700, lr=0.000109809, gnorm=0.281, loss_scale=8, train_wall=179, wall=509943
2021-03-20 07:16:10 | INFO | train_inner | epoch 014:   5654 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27987, ups=0.55, wpb=50961.5, bsz=2989.8, num_updates=268800, lr=0.000109789, gnorm=0.287, loss_scale=8, train_wall=179, wall=510125
2021-03-20 07:19:12 | INFO | train_inner | epoch 014:   5754 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27967.8, ups=0.55, wpb=51029, bsz=3106.9, num_updates=268900, lr=0.000109768, gnorm=0.286, loss_scale=8, train_wall=179, wall=510308
2021-03-20 07:22:14 | INFO | train_inner | epoch 014:   5854 / 20258 loss=3.442, nll_loss=1.747, ppl=3.36, wps=27949.4, ups=0.55, wpb=50866.8, bsz=2960.5, num_updates=269000, lr=0.000109748, gnorm=0.283, loss_scale=8, train_wall=179, wall=510490
2021-03-20 07:25:16 | INFO | train_inner | epoch 014:   5954 / 20258 loss=3.447, nll_loss=1.753, ppl=3.37, wps=27890.2, ups=0.55, wpb=50812.6, bsz=3012.1, num_updates=269100, lr=0.000109728, gnorm=0.282, loss_scale=8, train_wall=179, wall=510672
2021-03-20 07:28:18 | INFO | train_inner | epoch 014:   6054 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=27936.9, ups=0.55, wpb=50766.6, bsz=3047.7, num_updates=269200, lr=0.000109707, gnorm=0.285, loss_scale=8, train_wall=179, wall=510854
2021-03-20 07:31:20 | INFO | train_inner | epoch 014:   6154 / 20258 loss=3.46, nll_loss=1.768, ppl=3.41, wps=28074.3, ups=0.55, wpb=51000.7, bsz=2964.9, num_updates=269300, lr=0.000109687, gnorm=0.283, loss_scale=8, train_wall=179, wall=511035
2021-03-20 07:34:21 | INFO | train_inner | epoch 014:   6254 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=28038.7, ups=0.55, wpb=50914.8, bsz=2910.9, num_updates=269400, lr=0.000109666, gnorm=0.283, loss_scale=8, train_wall=179, wall=511217
2021-03-20 07:37:24 | INFO | train_inner | epoch 014:   6354 / 20258 loss=3.44, nll_loss=1.745, ppl=3.35, wps=27932.1, ups=0.55, wpb=50898, bsz=3020.5, num_updates=269500, lr=0.000109646, gnorm=0.284, loss_scale=16, train_wall=179, wall=511399
2021-03-20 07:40:26 | INFO | train_inner | epoch 014:   6454 / 20258 loss=3.458, nll_loss=1.765, ppl=3.4, wps=27970.5, ups=0.55, wpb=50894.5, bsz=3026.2, num_updates=269600, lr=0.000109626, gnorm=0.287, loss_scale=16, train_wall=179, wall=511581
2021-03-20 07:43:28 | INFO | train_inner | epoch 014:   6554 / 20258 loss=3.438, nll_loss=1.742, ppl=3.35, wps=27867.7, ups=0.55, wpb=50882.6, bsz=3030.5, num_updates=269700, lr=0.000109605, gnorm=0.28, loss_scale=16, train_wall=179, wall=511764
2021-03-20 07:46:30 | INFO | train_inner | epoch 014:   6654 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27955.2, ups=0.55, wpb=50797.6, bsz=3019.5, num_updates=269800, lr=0.000109585, gnorm=0.286, loss_scale=16, train_wall=179, wall=511945
2021-03-20 07:49:32 | INFO | train_inner | epoch 014:   6754 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27949.7, ups=0.55, wpb=50832.2, bsz=2942.1, num_updates=269900, lr=0.000109565, gnorm=0.286, loss_scale=16, train_wall=179, wall=512127
2021-03-20 07:49:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 07:52:35 | INFO | train_inner | epoch 014:   6855 / 20258 loss=3.444, nll_loss=1.749, ppl=3.36, wps=27537.7, ups=0.54, wpb=50549.4, bsz=2943.6, num_updates=270000, lr=0.000109545, gnorm=0.293, loss_scale=8, train_wall=180, wall=512311
2021-03-20 07:52:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-20 07:52:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:38 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:38 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:38 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:54 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.865 | nll_loss 2.153 | ppl 4.45 | bleu 29.95 | wps 4390.2 | wpb 2432 | bsz 90.4 | num_updates 270000 | best_loss 3.865
2021-03-20 07:52:54 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-20 07:52:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:54 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:54 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:54 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:55 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:55 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:55 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:56 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:56 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:56 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:57 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:57 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:57 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:52:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:52:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:52:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:02 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:02 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:02 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:03 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:03 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:03 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:04 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:04 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:04 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:05 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:05 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:05 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:06 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:06 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:06 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:09 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:09 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:09 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:10 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:10 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:10 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:11 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:11 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:11 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:12 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:12 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:12 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:13 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:13 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:13 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:14 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:14 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:14 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:15 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:15 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:15 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 07:53:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 07:53:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 07:53:46 | INFO | valid1 | epoch 014 | valid on 'valid1' subset | loss 3.872 | nll_loss 2.184 | ppl 4.54 | bleu 27.79 | wps 4256.8 | wpb 2359.4 | bsz 106.4 | num_updates 270000 | best_loss 3.865
2021-03-20 07:53:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-20 07:53:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_14_270000.pt (epoch 14 @ 270000 updates, score 3.865) (writing took 7.817692779935896 seconds)
2021-03-20 07:56:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-03-20 07:56:58 | INFO | train_inner | epoch 014:   6956 / 20258 loss=3.43, nll_loss=1.734, ppl=3.33, wps=19385.2, ups=0.38, wpb=51021.1, bsz=2998.6, num_updates=270100, lr=0.000109524, gnorm=0.278, loss_scale=4, train_wall=181, wall=512574
2021-03-20 08:00:00 | INFO | train_inner | epoch 014:   7056 / 20258 loss=3.436, nll_loss=1.741, ppl=3.34, wps=27901.3, ups=0.55, wpb=50791, bsz=3074.4, num_updates=270200, lr=0.000109504, gnorm=0.28, loss_scale=4, train_wall=179, wall=512756
2021-03-20 08:03:03 | INFO | train_inner | epoch 014:   7156 / 20258 loss=3.445, nll_loss=1.751, ppl=3.37, wps=27988.4, ups=0.55, wpb=51112.3, bsz=2938, num_updates=270300, lr=0.000109484, gnorm=0.283, loss_scale=4, train_wall=179, wall=512939
2021-03-20 08:06:05 | INFO | train_inner | epoch 014:   7256 / 20258 loss=3.453, nll_loss=1.76, ppl=3.39, wps=27998.4, ups=0.55, wpb=51048.9, bsz=2924.9, num_updates=270400, lr=0.000109463, gnorm=0.284, loss_scale=4, train_wall=179, wall=513121
2021-03-20 08:09:07 | INFO | train_inner | epoch 014:   7356 / 20258 loss=3.438, nll_loss=1.742, ppl=3.35, wps=27820.3, ups=0.55, wpb=50622.7, bsz=2934.5, num_updates=270500, lr=0.000109443, gnorm=0.283, loss_scale=4, train_wall=179, wall=513303
2021-03-20 08:12:10 | INFO | train_inner | epoch 014:   7456 / 20258 loss=3.441, nll_loss=1.746, ppl=3.35, wps=27884.8, ups=0.55, wpb=50789.9, bsz=2935.2, num_updates=270600, lr=0.000109423, gnorm=0.289, loss_scale=4, train_wall=179, wall=513485
2021-03-20 08:15:12 | INFO | train_inner | epoch 014:   7556 / 20258 loss=3.443, nll_loss=1.748, ppl=3.36, wps=27954.4, ups=0.55, wpb=50940, bsz=3098.9, num_updates=270700, lr=0.000109403, gnorm=0.282, loss_scale=4, train_wall=179, wall=513667
2021-03-20 08:18:14 | INFO | train_inner | epoch 014:   7656 / 20258 loss=3.459, nll_loss=1.766, ppl=3.4, wps=27965.4, ups=0.55, wpb=50835.9, bsz=3026.5, num_updates=270800, lr=0.000109383, gnorm=0.285, loss_scale=4, train_wall=179, wall=513849
2021-03-20 08:21:15 | INFO | train_inner | epoch 014:   7756 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=27891.2, ups=0.55, wpb=50719.2, bsz=2986.4, num_updates=270900, lr=0.000109362, gnorm=0.282, loss_scale=4, train_wall=179, wall=514031
2021-03-20 08:24:17 | INFO | train_inner | epoch 014:   7856 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=27937.7, ups=0.55, wpb=50807.4, bsz=2928.5, num_updates=271000, lr=0.000109342, gnorm=0.288, loss_scale=4, train_wall=179, wall=514213
2021-03-20 08:27:19 | INFO | train_inner | epoch 014:   7956 / 20258 loss=3.448, nll_loss=1.754, ppl=3.37, wps=27924.3, ups=0.55, wpb=50722.1, bsz=2946.7, num_updates=271100, lr=0.000109322, gnorm=0.284, loss_scale=4, train_wall=179, wall=514394
2021-03-20 08:30:22 | INFO | train_inner | epoch 014:   8056 / 20258 loss=3.444, nll_loss=1.75, ppl=3.36, wps=27871.6, ups=0.55, wpb=50922.8, bsz=3195.2, num_updates=271200, lr=0.000109302, gnorm=0.283, loss_scale=8, train_wall=179, wall=514577
2021-03-20 08:33:23 | INFO | train_inner | epoch 014:   8156 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27958, ups=0.55, wpb=50810, bsz=3005.1, num_updates=271300, lr=0.000109282, gnorm=0.287, loss_scale=8, train_wall=179, wall=514759
2021-03-20 08:36:25 | INFO | train_inner | epoch 014:   8256 / 20258 loss=3.457, nll_loss=1.764, ppl=3.4, wps=27907.8, ups=0.55, wpb=50794.8, bsz=2942, num_updates=271400, lr=0.000109262, gnorm=0.286, loss_scale=8, train_wall=179, wall=514941
2021-03-20 08:39:27 | INFO | train_inner | epoch 014:   8356 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=28016.9, ups=0.55, wpb=50963, bsz=2969, num_updates=271500, lr=0.000109241, gnorm=0.286, loss_scale=8, train_wall=179, wall=515123
2021-03-20 08:42:30 | INFO | train_inner | epoch 014:   8456 / 20258 loss=3.446, nll_loss=1.752, ppl=3.37, wps=27908.6, ups=0.55, wpb=50905.6, bsz=2970.6, num_updates=271600, lr=0.000109221, gnorm=0.287, loss_scale=8, train_wall=179, wall=515305
2021-03-20 08:45:32 | INFO | train_inner | epoch 014:   8556 / 20258 loss=3.447, nll_loss=1.753, ppl=3.37, wps=27930.6, ups=0.55, wpb=50867.3, bsz=3095.6, num_updates=271700, lr=0.000109201, gnorm=0.285, loss_scale=8, train_wall=179, wall=515487
2021-03-20 08:48:34 | INFO | train_inner | epoch 014:   8656 / 20258 loss=3.446, nll_loss=1.752, ppl=3.37, wps=27898.8, ups=0.55, wpb=50777.6, bsz=2936.6, num_updates=271800, lr=0.000109181, gnorm=0.283, loss_scale=8, train_wall=179, wall=515669
2021-03-20 08:51:36 | INFO | train_inner | epoch 014:   8756 / 20258 loss=3.452, nll_loss=1.759, ppl=3.38, wps=27820.8, ups=0.55, wpb=50748.6, bsz=3054.5, num_updates=271900, lr=0.000109161, gnorm=0.288, loss_scale=8, train_wall=179, wall=515852
2021-03-20 08:54:38 | INFO | train_inner | epoch 014:   8856 / 20258 loss=3.441, nll_loss=1.746, ppl=3.35, wps=27995, ups=0.55, wpb=50954.5, bsz=3034.2, num_updates=272000, lr=0.000109141, gnorm=0.285, loss_scale=8, train_wall=179, wall=516034
2021-03-20 08:57:41 | INFO | train_inner | epoch 014:   8956 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=28098, ups=0.55, wpb=51272.5, bsz=2974.4, num_updates=272100, lr=0.000109121, gnorm=0.283, loss_scale=8, train_wall=179, wall=516216
2021-03-20 08:59:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 09:00:45 | INFO | train_inner | epoch 014:   9057 / 20258 loss=3.443, nll_loss=1.749, ppl=3.36, wps=27519.5, ups=0.54, wpb=50630.8, bsz=2974.3, num_updates=272200, lr=0.000109101, gnorm=0.285, loss_scale=8, train_wall=181, wall=516400
2021-03-20 09:03:47 | INFO | train_inner | epoch 014:   9157 / 20258 loss=3.46, nll_loss=1.767, ppl=3.4, wps=27974.7, ups=0.55, wpb=50999.4, bsz=2959.4, num_updates=272300, lr=0.000109081, gnorm=0.289, loss_scale=8, train_wall=179, wall=516583
2021-03-20 09:06:50 | INFO | train_inner | epoch 014:   9257 / 20258 loss=3.443, nll_loss=1.748, ppl=3.36, wps=28044.8, ups=0.55, wpb=51216.1, bsz=3045.3, num_updates=272400, lr=0.000109061, gnorm=0.283, loss_scale=8, train_wall=179, wall=516765
2021-03-20 09:09:52 | INFO | train_inner | epoch 014:   9357 / 20258 loss=3.447, nll_loss=1.753, ppl=3.37, wps=27821.5, ups=0.55, wpb=50828.3, bsz=2914.6, num_updates=272500, lr=0.000109041, gnorm=0.285, loss_scale=8, train_wall=179, wall=516948
2021-03-20 09:12:55 | INFO | train_inner | epoch 014:   9457 / 20258 loss=3.455, nll_loss=1.762, ppl=3.39, wps=27951.3, ups=0.55, wpb=51021.9, bsz=3017.5, num_updates=272600, lr=0.000109021, gnorm=0.279, loss_scale=8, train_wall=179, wall=517130
2021-03-20 09:15:58 | INFO | train_inner | epoch 014:   9557 / 20258 loss=3.44, nll_loss=1.746, ppl=3.35, wps=27912.2, ups=0.55, wpb=51115.4, bsz=3101.8, num_updates=272700, lr=0.000109001, gnorm=0.279, loss_scale=8, train_wall=180, wall=517314
2021-03-20 09:19:01 | INFO | train_inner | epoch 014:   9657 / 20258 loss=3.45, nll_loss=1.756, ppl=3.38, wps=28020.6, ups=0.55, wpb=51189.2, bsz=3078.7, num_updates=272800, lr=0.000108981, gnorm=0.285, loss_scale=8, train_wall=179, wall=517496
2021-03-20 09:22:03 | INFO | train_inner | epoch 014:   9757 / 20258 loss=3.462, nll_loss=1.769, ppl=3.41, wps=27942.7, ups=0.55, wpb=50893.1, bsz=2955.2, num_updates=272900, lr=0.000108961, gnorm=0.289, loss_scale=8, train_wall=179, wall=517678
2021-03-20 09:25:05 | INFO | train_inner | epoch 014:   9857 / 20258 loss=3.452, nll_loss=1.759, ppl=3.38, wps=27919.9, ups=0.55, wpb=50931.2, bsz=3138.6, num_updates=273000, lr=0.000108941, gnorm=0.284, loss_scale=8, train_wall=179, wall=517861
2021-03-20 09:28:08 | INFO | train_inner | epoch 014:   9957 / 20258 loss=3.445, nll_loss=1.751, ppl=3.37, wps=27957.9, ups=0.55, wpb=51043.2, bsz=3035, num_updates=273100, lr=0.000108921, gnorm=0.285, loss_scale=8, train_wall=179, wall=518043
2021-03-20 09:31:10 | INFO | train_inner | epoch 014:  10057 / 20258 loss=3.446, nll_loss=1.752, ppl=3.37, wps=27977.5, ups=0.55, wpb=50918.9, bsz=2998.6, num_updates=273200, lr=0.000108901, gnorm=0.29, loss_scale=16, train_wall=179, wall=518225
2021-03-20 09:32:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 09:34:14 | INFO | train_inner | epoch 014:  10158 / 20258 loss=3.439, nll_loss=1.743, ppl=3.35, wps=27572.5, ups=0.54, wpb=50736.1, bsz=2914.4, num_updates=273300, lr=0.000108881, gnorm=0.287, loss_scale=8, train_wall=181, wall=518409
2021-03-20 09:37:16 | INFO | train_inner | epoch 014:  10258 / 20258 loss=3.454, nll_loss=1.761, ppl=3.39, wps=27929.7, ups=0.55, wpb=50957.1, bsz=3025.2, num_updates=273400, lr=0.000108861, gnorm=0.282, loss_scale=8, train_wall=179, wall=518592
2021-03-20 09:40:18 | INFO | train_inner | epoch 014:  10358 / 20258 loss=3.455, nll_loss=1.761, ppl=3.39, wps=27857.1, ups=0.55, wpb=50700.9, bsz=2971.8, num_updates=273500, lr=0.000108841, gnorm=0.284, loss_scale=8, train_wall=179, wall=518774
2021-03-20 09:43:21 | INFO | train_inner | epoch 014:  10458 / 20258 loss=3.441, nll_loss=1.746, ppl=3.36, wps=27804.5, ups=0.55, wpb=50769.1, bsz=3006.9, num_updates=273600, lr=0.000108821, gnorm=0.284, loss_scale=8, train_wall=179, wall=518956
2021-03-20 09:46:24 | INFO | train_inner | epoch 014:  10558 / 20258 loss=3.451, nll_loss=1.758, ppl=3.38, wps=27937.9, ups=0.55, wpb=51120.2, bsz=3057.3, num_updates=273700, lr=0.000108802, gnorm=0.279, loss_scale=8, train_wall=180, wall=519139
2021-03-20 09:49:26 | INFO | train_inner | epoch 014:  10658 / 20258 loss=3.43, nll_loss=1.734, ppl=3.33, wps=27831.5, ups=0.55, wpb=50704.2, bsz=3016.5, num_updates=273800, lr=0.000108782, gnorm=0.284, loss_scale=8, train_wall=179, wall=519322
2021-03-20 09:52:28 | INFO | train_inner | epoch 014:  10758 / 20258 loss=3.452, nll_loss=1.758, ppl=3.38, wps=27969.6, ups=0.55, wpb=50927.8, bsz=2969, num_updates=273900, lr=0.000108762, gnorm=0.283, loss_scale=8, train_wall=179, wall=519504
2021-03-20 09:55:31 | INFO | train_inner | epoch 014:  10858 / 20258 loss=3.441, nll_loss=1.747, ppl=3.36, wps=27882.9, ups=0.55, wpb=50925.9, bsz=2992.6, num_updates=274000, lr=0.000108742, gnorm=0.289, loss_scale=8, train_wall=179, wall=519686
2021-03-20 09:58:33 | INFO | train_inner | epoch 014:  10958 / 20258 loss=3.451, nll_loss=1.757, ppl=3.38, wps=27911, ups=0.55, wpb=50877.4, bsz=3055.2, num_updates=274100, lr=0.000108722, gnorm=0.286, loss_scale=8, train_wall=179, wall=519869
2021-03-20 10:01:35 | INFO | train_inner | epoch 014:  11058 / 20258 loss=3.443, nll_loss=1.748, ppl=3.36, wps=27971.2, ups=0.55, wpb=50810.2, bsz=2912.2, num_updates=274200, lr=0.000108702, gnorm=0.287, loss_scale=8, train_wall=179, wall=520050
2021-03-20 10:04:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-03-20 10:04:39 | INFO | train_inner | epoch 014:  11159 / 20258 loss=3.448, nll_loss=1.755, ppl=3.37, wps=27650, ups=0.54, wpb=51070.6, bsz=3087.4, num_updates=274300, lr=0.000108682, gnorm=0.287, loss_scale=8, train_wall=181, wall=520235
2021-03-20 10:07:42 | INFO | train_inner | epoch 014:  11259 / 20258 loss=3.449, nll_loss=1.755, ppl=3.38, wps=28015.8, ups=0.55, wpb=51123.1, bsz=3106.6, num_updates=274400, lr=0.000108663, gnorm=0.287, loss_scale=8, train_wall=179, wall=520417
2021-03-20 10:10:45 | INFO | train_inner | epoch 014:  11359 / 20258 loss=3.439, nll_loss=1.744, ppl=3.35, wps=27983, ups=0.55, wpb=51154.7, bsz=3015.6, num_updates=274500, lr=0.000108643, gnorm=0.28, loss_scale=8, train_wall=180, wall=520600
2021-03-20 10:13:46 | INFO | train_inner | epoch 014:  11459 / 20258 loss=3.456, nll_loss=1.763, ppl=3.39, wps=27933.1, ups=0.55, wpb=50736, bsz=2945.4, num_updates=274600, lr=0.000108623, gnorm=0.283, loss_scale=8, train_wall=179, wall=520782
2021-03-20 10:16:49 | INFO | train_inner | epoch 014:  11559 / 20258 loss=3.438, nll_loss=1.743, ppl=3.35, wps=27861.1, ups=0.55, wpb=51004.6, bsz=2972.6, num_updates=274700, lr=0.000108603, gnorm=0.28, loss_scale=8, train_wall=180, wall=520965
2021-03-20 10:19:52 | INFO | train_inner | epoch 014:  11659 / 20258 loss=3.434, nll_loss=1.739, ppl=3.34, wps=27862.5, ups=0.55, wpb=50953.7, bsz=3037.3, num_updates=274800, lr=0.000108584, gnorm=0.286, loss_scale=8, train_wall=179, wall=521148
2021-03-20 10:22:55 | INFO | train_inner | epoch 014:  11759 / 20258 loss=3.437, nll_loss=1.742, ppl=3.34, wps=27883.7, ups=0.55, wpb=50855.4, bsz=2925.7, num_updates=274900, lr=0.000108564, gnorm=0.287, loss_scale=8, train_wall=179, wall=521330
2021-03-20 10:25:57 | INFO | train_inner | epoch 014:  11859 / 20258 loss=3.464, nll_loss=1.772, ppl=3.42, wps=28000.5, ups=0.55, wpb=51142.8, bsz=3056.9, num_updates=275000, lr=0.000108544, gnorm=0.285, loss_scale=8, train_wall=179, wall=521513
2021-03-20 10:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-20 10:25:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:25:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:25:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:25:58 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:25:58 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:25:58 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:25:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:25:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:25:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:25:59 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:25:59 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:25:59 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:00 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:00 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:00 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:01 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:01 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:01 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:16 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.867 | nll_loss 2.152 | ppl 4.44 | bleu 29.89 | wps 4404.5 | wpb 2432 | bsz 90.4 | num_updates 275000 | best_loss 3.865
2021-03-20 10:26:16 | INFO | fairseq_cli.train | begin validation on "valid1" subset
2021-03-20 10:26:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:16 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:16 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:16 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:17 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:17 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:17 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:18 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:18 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:18 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:19 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:19 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:19 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:21 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:21 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:21 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:22 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:22 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:22 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:23 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:23 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:23 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:24 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:24 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:24 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:26 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:26 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:26 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:30 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:30 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:30 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:31 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:31 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:31 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:33 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:33 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:33 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:34 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:34 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:34 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:36 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:36 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:36 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:37 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:37 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:37 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:26:40 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')
2021-03-20 10:26:40 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.
2021-03-20 10:26:40 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
2021-03-20 10:27:08 | INFO | valid1 | epoch 014 | valid on 'valid1' subset | loss 3.871 | nll_loss 2.179 | ppl 4.53 | bleu 27.9 | wps 4258.1 | wpb 2359.4 | bsz 106.4 | num_updates 275000 | best_loss 3.865
2021-03-20 10:27:08 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 5 runs
2021-03-20 10:27:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-03-20 10:27:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints_czeng2_en_cs/checkpoint_14_275000.pt (epoch 14 @ 275000 updates, score 3.867) (writing took 4.524605685845017 seconds)
2021-03-20 10:27:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-03-20 10:27:12 | INFO | train | epoch 014 | loss 3.446 | nll_loss 1.751 | ppl 3.37 | wps 27623.8 | ups 0.54 | wpb 50907.5 | bsz 3009.6 | num_updates 275000 | lr 0.000108544 | gnorm 0.285 | loss_scale 8 | train_wall 21234 | wall 521588
2021-03-20 10:27:12 | INFO | fairseq_cli.train | done training in 521548.5 seconds
